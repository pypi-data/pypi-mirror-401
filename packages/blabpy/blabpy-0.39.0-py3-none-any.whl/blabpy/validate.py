import click
import re
from blabpy.paths import get_blab_share_path
from blabpy.pipeline import find_eaf_paths, extract_aclew_data
from blabpy.eaf.eaf_plus import EafPlus
import os
from pathlib import Path
import pandas as pd
from blabpy.utils import convert_ms_to_hms
from datetime import date
from tqdm import tqdm
import string

# Paths
BLAB_SHARE_PATH = get_blab_share_path()
OVS_PATH = BLAB_SHARE_PATH / 'OvSpeech' / 'SubjectFiles' / "Seedlings" / 'overheard_speech'
VIHI_PATH = BLAB_SHARE_PATH / 'VIHI' / 'SubjectFiles' / 'LENA' 

cv_dict = {
    'vcm': ['L', 'Y', 'N', 'C', 'U'],
    'lex': ['W', '0'],
    'mwu': ['M', '1'],
    'xds': ['A', 'C', 'B', 'P', 'O', 'U'],
    'cds': ['T', 'K', 'M', 'X']
}

parent_dict = {
    'vcm': None,
    'lex': 'vcm',
    'mwu': 'lex',
    'xds': None,
    'cds': 'xds'
}

value_dict = {
    'lex': ('vcm', 'C'),
    'mwu': ('lex', 'W'),
    'cds': ('xds', 'C')
}

pd.options.mode.chained_assignment = None

def validate_one_file(eaf_path, output_folder):
    """
    Generate a Markdown validation report for a single ELAN (.eaf) file.
    This function reads and validates an ELAN file at `eaf_path` and writes a
    human-readable Markdown report summarizing a set of ACLEW-specific validation
    checks to a file inside `output_folder`. The output filename is derived from
    the input filename by replacing the ".eaf" suffix with "_report.md".
    Validation and report content include:
    - Listing all unique speakers and reporting any speakers that do not conform
        to the ACLEW naming scheme.
    - Validating standard tier hierarchy (e.g cds should be a child of xds), 
        reporting any unconventional tiers and their dependency.
    - Reporting the number of annotations per interval and whether intervals containing blank annotations, 
        as well as any annotations not coded for interval. 
    - Reporting any annotations that has blank code, with the tier and participant where it was found.
    - Validating that the code in each tier is in their controlled vocabulary (per `cv_dict`).
    - Validating parent-tier dependency values (e.g. if there is a mwu tier, its parent lex tier must be coded as W)
    - Validating transcription text according to ACLEW conventions.

    Parameters
    ----------
    eaf_path : str or pathlib.Path
            Path to the input ELAN (.eaf) file to be validated.
    output_folder : pathlib.Path
            Directory where the generated Markdown report will be written. 
    """

    eaf = EafPlus(Path(eaf_path))
    annotations, intervals = extract_aclew_data(Path(eaf_path))

    name = str(eaf_path).split('/')[-1].replace('.eaf', '_report.md')
    output_path = output_folder / name

    speakers, speaker_errs = validate_speaker(eaf)
    all_dependent_tiers, all_dependent_errs, other_errs = validate_standard_tiers_hierarchy(eaf)

    blanks, blank_cols = validate_blanks(annotations)
    cv_results = dict()
    for tier in cv_dict.keys():
        cv_results[tier] = validate_controlled_vocabulary_by_tier(annotations, tier)

    value_results = dict()
    for tier in value_dict.keys():
        value_results[tier] = validate_parent_tier_values(annotations, tier, value_dict[tier][0], value_dict[tier][1])

    with open(output_path, 'w') as f:
        f.write(f"# Validation report for {name.rstrip('_report.md')}\n\n")
        f.write(f"## Speakers\n\n")
        f.write(f"All unique speakers: {', '.join(speakers)}\n\n")
        if len(speaker_errs) > 0:
            f.write(f"❌ Speakers not conforming to ACLEW scheme: {', '.join(speaker_errs)}\n\n")
        else:
            f.write("✅ All speakers conform to ACLEW scheme.\n\n")

        f.write("## Standard Tiers Hierarchy Validation\n\n")
        for s in all_dependent_tiers.keys():
            if all_dependent_tiers[s] == []:
                f.write(f'### Speaker {s} does not have any valid dependent tiers\n\n')
            else:
                f.write(f'### Speaker {s} has dependent tiers: {", ".join(all_dependent_tiers[s])}\n\n')
            if all_dependent_errs[s] == []:
                f.write(f'✅ All tier dependency validated\n\n')
            else:
                for e in all_dependent_errs[s]:
                    f.write(f"{e}\n\n")
        f.write(f'### Other tiers:\n\n')
        if other_errs != []:
            for e in other_errs:
                f.write(f"{e}\n\n")

        f.write("## Number of Transcriptions in Each Interval\n\n")
        for code_num in intervals['code_num'].astype(int).sort_values():
            annotations_count = validate_each_interval(annotations, str(code_num))
            if not annotations_count:
                f.write(f"#### Interval {code_num}: 0 transcriptions\n\n")
            else:
                total_count, blank_annotations = annotations_count
                f.write(f"#### Interval {code_num}: {total_count} transcriptions\n\n")
                if len(blank_annotations) > 0:
                    f.write(f"❌  {int(len(blank_annotations))} blank transcriptions\n\n")
                    for _, row in blank_annotations.iterrows():
                        f.write(f"- From {convert_ms_to_hms(row['onset'])} to {convert_ms_to_hms(row['offset'])}\n\n")
        uncoded_interval = annotations[annotations['code_num'] == '-1']
        if not uncoded_interval.empty:
            total_count = len(uncoded_interval)
            f.write(f"#### ❌ Not coded for interval: {total_count} transcriptions\n\n")
            for _, row in uncoded_interval.iterrows():
                f.write(f"- From {convert_ms_to_hms(row['onset'])} to {convert_ms_to_hms(row['offset'])}\n\n")

        f.write("## Transcriptions Validation\n\n")
        for _, row in annotations.iterrows():
            transcriptions_errs = validate_transcription(row['transcription'])
            if transcriptions_errs:
                f.write(f"#### ❌ '{row['transcription']}' by {row['participant']} from {convert_ms_to_hms(row['onset'])} to {convert_ms_to_hms(row['offset'])}:\n\n")
                for err in transcriptions_errs:
                    f.write(f"- {err}\n\n")

        f.write("## Blank Code\n\n")
        if blanks.empty:
            f.write("✅ No blank code found.\n\n")
        else:
            for _, row in blanks.iterrows():
                for col in blank_cols:
                    if row[col]:
                        f.write(f"❌ Blank code found at tier {col}@{row['participant']} from {convert_ms_to_hms(row['onset'])} to {convert_ms_to_hms(row['offset'])}\n\n")

        f.write("## Controlled Vocabulary and Parent Tier Dependency Validation\n\n")
        for tier in cv_results.keys():
            f.write(f"### Tier {tier}\n\n")
            f.write(f'#### Controlled Vocabulary\n\n')
            tier_wrong_value, err_msg = cv_results[tier]
            if err_msg is not None:
                f.write(f"⚠️ {err_msg}\n\n")
            elif tier_wrong_value.empty:
                f.write(f"✅ All annotations in tier {tier} conform to the controlled vocabulary.\n\n")
            else:
                for _, row in tier_wrong_value.iterrows():  
                    f.write(f"❌ Wrong value *{row[tier]}* by {row['participant']} from {convert_ms_to_hms(row['onset'])} to {convert_ms_to_hms(row['offset'])}, should be one of {cv_dict[tier]}\n\n")
            
            if tier in value_results.keys():
                f.write(f'#### Parent Tier Value\n\n')
                if value_results[tier] is not None and not value_results[tier].empty:
                    for _, row in value_results[tier].iterrows():
                        f.write(f"❌ Incorrect parent tier value *{row[value_dict[tier][0]] if row[value_dict[tier][0]] != '' else '<blank>'}* by {row['participant']} from {convert_ms_to_hms(row['onset'])} to {convert_ms_to_hms(row['offset'])}, should be {value_dict[tier][1]}\n\n")
                elif value_results[tier] is not None:
                    f.write(f"✅ All {tier} annotations have correct parent value.\n\n")

def validate_each_interval(annotations, code_num):
    interval_annotations = annotations[annotations['code_num'] == code_num]
    total_annotations = len(interval_annotations)
    if total_annotations == 0:
        return None
    
    blank_annotations = interval_annotations[interval_annotations['transcription'] == '']

    return total_annotations, blank_annotations

def validate_speaker(eaf):
    """
    Validates that all speaker tiers conform to the ACLEW speaker coding scheme.
    Args:
        eaf (EafPlus): An instance of the EafPlus class representing the ELAN file of the annotation.
    Returns:
        all_speakers (list): List of all unique speaker tiers found in the ELAN file.
        errs (list): List of speaker tiers that do not conform to the ACLEW scheme.
    """
    SPEAKER_PATTERN = re.compile(r'CHI|[MFU][ACI][\dE]|EE1')
    all_speakers = eaf.get_participant_tier_ids()
    errs = []
    for speaker in all_speakers:
        if not SPEAKER_PATTERN.fullmatch(speaker):
            errs.append(speaker)
    return all_speakers, errs

def validate_blanks(annotations):
    """
    Validates that there are no tiers with blank annotations (i.e., represented by empty strings and not <NA>).
    Args:
        annotations (pd.DataFrame): DataFrame containing annotation data with multiple tiers.
    Returns:
        annotations (pd.DataFrame): DataFrame containing only the intervals with blank annotations, along with
                                   identifying information (eaf_filename, participant, onset, offset, code_num, transcription_id).
        blank_cols (list): List of tier names where blank annotations were found.
    """
    ids = annotations[["eaf_filename", "participant", "onset", "offset", 'code_num', 'transcription', 'transcription_id']]
    blanks = annotations.drop(
        ["eaf_filename", "participant", "onset", "offset", 'code_num', 'transcription', "transcription_id"], axis=1
    ).map(
        lambda x: not pd.isna(x) and x == ''
    )
    blanks = blanks[blanks.any(axis=1)]
    annotations = pd.merge(ids, blanks, left_index=True, right_index=True, how='right')

    return annotations, blanks.columns

def validate_controlled_vocabulary_by_tier(annotations, tier_name):
    """
    Validates that all non-null annotations in a specified tier conform to a controlled vocabulary.
    Args:
        annotations (pd.DataFrame): DataFrame containing annotation data with multiple tiers.
        tier_name (str): The name of the tier to validate.
    Returns:
        tier_wrong_value (pd.DataFrame or None): DataFrame containing intervals with invalid annotations in the specified tier,
                                                along with identifying information (eaf_filename, participant, onset, offset, code_num).
                                                Returns None if the tier is not found or no controlled vocabulary is defined.
        err_msg (str or None): Error message if the tier is not found or no controlled vocabulary is defined. None if validation is successful.
    """
    if tier_name not in cv_dict:
        return None, f"No controlled vocabulary defined for tier {tier_name}"
    if tier_name not in annotations.columns:
        return None, f"Tier {tier_name} not found in annotations dataframe"

    tier_annotations = annotations[["eaf_filename", "participant", "onset", "offset", "code_num", tier_name]].dropna()
    tier_wrong_value = tier_annotations.query(f"{tier_name} not in {cv_dict[tier_name]} and {tier_name} != ''")

    return tier_wrong_value, None

def validate_parent_tier_values(annotations, tier_name, parent_tier, parent_value):
    """
    Validates that all annotations in a specified tier have the expected value in a parent tier.
    Args:
        annotations (pd.DataFrame): DataFrame containing annotation data with multiple tiers.
        tier_name (str): The name of the tier to validate.
        parent_tier (str): The name of the parent tier whose value should be checked.
        parent_value (str): The expected value in the parent tier.
    Returns:
        tier_incorrect_parent (pd.DataFrame or None): DataFrame containing intervals where the parent tier does not have the expected value,
                                                       along with identifying information (eaf_filename, participant, onset, offset, code_num).
                                                       Returns None if the tier is not found.
    Raises:
        None
    Notes:
        - If the specified tier is not found in the annotations DataFrame, None is returned.
    """

    # TODO: So right now it is not handling missing parent tier well. Technically, this would be reported in 
    # the hiearchy validation step, but should be investigated further.
    if tier_name not in annotations.columns or parent_tier not in annotations.columns:
        return None
    
    # Select all annotations in the specified tier. Not NA is ensuring that only annotations with said tier is selected,
    # since every annotation will have a column for every tier, even if they are blank
    all_annotations_of_tier = annotations.loc[
        pd.notna(annotations[tier_name]), [
            "eaf_filename", "participant", "onset", "offset", 'code_num', tier_name, parent_tier
        ]
    ]
    # Check that the parent tier has the correct value
    tier_incorrect_parent = all_annotations_of_tier.query(f"{parent_tier} != '{parent_value}'")
    return tier_incorrect_parent


def validate_standard_tiers_hierarchy(eaf):
    """
    Validates the hierarchy and usage of tiers in an EAF (ELAN Annotation Format) file according to standard conventions.
    This function checks:
    - That all dependent tiers (of the form xxx@yyy) have the correct parent tier and speaker association.
    - That only standard tier types are used for each speaker.
    - That dependent tiers have the correct parent tier type and speaker tier.
    - That non-dependent tiers are either speaker tiers, standard non-speaker coding tiers, or are reported as non-standard.
    Parameters:
        eaf (EafPlus): An instance of the EafPlus class representing the ELAN file of the annotation.

    Returns:
        tuple:
            - all_dependent_tiers (dict): Mapping of speaker IDs to lists of their dependent tier types.
            - all_dependent_errs (dict): Mapping of speaker IDs to lists of error messages related to their dependent tiers.
            - other_errs (list): List of error messages for other issues found in the tier hierarchy.
    """
    TIER_PATTERN = re.compile(r'^\w+@\w\w\w$')
    chi_tiers = ['vcm', 'lex', 'mwu']
    other_speaker_tiers = ['xds', 'cds']
    other_tiers = ['on_off', 'code', 'code_num', 'context']

    all_tiers = eaf.get_tier_names()
    all_speakers = eaf.get_participant_tier_ids()

    all_dependent_tiers = dict()
    all_dependent_errs = dict()
    other_errs = []

    for speaker in all_speakers:
        all_dependent_tiers[speaker] = []
        all_dependent_errs[speaker] = []

    unused_common_tiers = [tier for tier in other_tiers if tier not in all_tiers]
    for t in unused_common_tiers:
        other_errs.append(f"⚠️ Common tier {t} not used")

    for tier in all_tiers:

        # For dependent tiers (of the form xxx@yyy), check that they have the correct parent tier 
        # and correct speaker tier all throughout
        # e.g. lex@CHI should have parent vcm@CHI
        if TIER_PATTERN.fullmatch(tier):
            params = eaf.get_parameters_for_tier(tier)
            current_tier_type, current_speaker = tier.split('@')

            if current_speaker not in all_dependent_tiers:
                other_errs.append(f"⚠️ Should not have dependent tier {current_tier_type}")
            else:
                # For speaker CHI
                if current_speaker == "CHI":
                    if current_tier_type in chi_tiers:
                        all_dependent_tiers["CHI"].append(current_tier_type)
                    else:
                        all_dependent_errs["CHI"].append(
                            f"❌ Non-standard tier type {current_tier_type}. CHI typically only has {chi_tiers} tiers"
                        )
                    if current_tier_type in ['lex', 'mwu']:
                        all_dependent_errs["CHI"].append(
                            f"⚠️ Tier {current_tier_type} is coded. Check that target child is 8 months or older."
                        )

                # For other speakers
                else:
                    if current_tier_type in other_speaker_tiers:
                        all_dependent_tiers[current_speaker].append(current_tier_type)
                    else:
                        all_dependent_errs[current_speaker].append(
                            f"❌ Non-standard tier type {current_tier_type}. Non-CHI speakers typically only have {other_speaker_tiers} tiers"
                        )
                
                # Check that each tier type has the correct parent tier type and speaker tier
                if current_tier_type not in parent_dict:
                    all_dependent_errs[current_speaker].append(f"⚠️ Non-standard dependent tier type {current_tier_type} with parent {params['PARENT_REF']}")

                # Case where the tier is a direct child tier of a transcription (speaker tier)
                elif not TIER_PATTERN.fullmatch(params['PARENT_REF']):
                    if parent_dict[current_tier_type] is not None:
                        all_dependent_errs[current_speaker].append(
                            f"❌ Tier {current_tier_type} should not be a direct child of a transcription tier"
                        )

                # Otherwise, the parent tier should also have the form xxx@yyy
                else:
                    parent_tier_type, parent_speaker = params['PARENT_REF'].split('@')
                    if parent_dict[current_tier_type] is None:
                        all_dependent_errs[current_speaker].append(
                            f"❌ Tier {current_tier_type} has incorrect parent tier {params['PARENT_REF']}, should be a direct child of a transcription tier"
                        )
                    elif parent_dict[current_tier_type] != parent_tier_type:
                        all_dependent_errs[current_speaker].append(
                            all_dependent_errs[current_speaker].append(
                                f"❌ Tier {current_tier_type} has incorrect parent tier {params['PARENT_REF']}"
                            )   
                        )

                    if current_speaker != parent_speaker:
                        all_dependent_errs[current_speaker].append(
                            f"❌ Tier {current_tier_type} has mismatched speaker {current_speaker} and parent speaker {parent_speaker}"
                        ) 

        # Tiers that are not of the form xxx@yyy are either speaker tiers,
        # standard non-speaker coding tiers 
        # (e.g. is_silent, code_num, on_off)
        # or non-standard tiers (these will be reported)
        else:
            params = eaf.get_parameters_for_tier(tier)
            if tier not in other_tiers and tier not in all_speakers:
                other_errs.append(f"⚠️ Non-standard tier found: {tier}")

    return all_dependent_tiers, all_dependent_errs, other_errs

def validate_transcription(transcription):
    """
    Validates the transcription text according to ACLEW transcription conventions,
    in particular checking that transcriptions end with exactly one terminal punctuation,
    that square bracketed annotations are correctly formatted as <blabla> [: blabla], <blabla> [=! blabla] or [- abc],
    and that at-sign annotations are correctly formatted as bla@c, bla@l, or bla@s:eng.
    Args:
        annotation (str): The transcription text to validate.
    Returns:
        errs (list): List of error messages for any violations found in the transcription.
    """
    errs = []

    transcription = transcription.strip()
    if transcription:

        # terminal
        if not transcription.endswith(('.', '!', '?')):
            errs.append(f"Utterance should end with a terminal")
        elif re.fullmatch(r'.*([.!?]){2,}$', transcription):
            errs.append(f"Utterance has multiple terminal marks, should only have one")

        # square brackets
        squareBracketMatches = re.findall(r'\[.*?\]', transcription)
        for match in squareBracketMatches:
            angle_brackets = r'<[^>]*> ' + re.escape(match)
            angle_match = re.search(angle_brackets, transcription)
            content = match.lstrip("[").rstrip("]").strip()
            if content.startswith("-"):
                if not re.fullmatch(r'-\s*[A-Za-z]{3}', content):
                    errs.append(f"Bracketed transcription '{match}' does not contain a valid 3-letter code after '-'")
                if angle_match:
                    errs.append(f"Bracketed transcription '{match}' should not be preceded by angle brackets")
            elif content.startswith((':', '=!')):
                if not angle_match:
                    errs.append(f"Bracketed transcription '{match}' is not preceded by angle brackets")
            else:
                errs.append(f"Bracketed transcription '{match}' does not start with :, =! or -.")

        # at sign
        atSignMatches = re.findall(r'\S*@\S*', transcription)
        for match in atSignMatches:
            if match.startswith('@'):
                errs.append(f"At-sign transcription '{match}' is missing preceding text before '@'")
            content = re.search(r'@.*', match).group(0).strip(string.punctuation)
            if content != "l" and content != "c" and not re.fullmatch(r's:[a-z]{3}', content):
                errs.append(f"At-sign transcription '{match}' does not conform to expected format '@c, @l, @s:eng'")

    return errs
