# PUSCH Autoencoder Demo

This demo implements an end-to-end autoencoder for the 5G NR Physical Uplink Shared Channel (PUSCH). The autoencoder jointly learns the transmitter constellation and neural receiver, optimizing the entire communication link for improved performance.

## Overview

The PUSCH autoencoder learns:
- **Trainable constellation**: Optimized symbol mapping (replaces standard 16-QAM)
- **Neural detector**: Learned receiver that performs joint channel estimation and detection
- **Correction scales**: Trainable scaling factors for channel estimates, error variance, and LLRs

**Key features:**
- Ray-tracing based channel model (loaded from TFRecords)
- Multi-user MIMO support (4 UEs Ã— 4 antennas each)
- Configurable BS antenna count (16 or 32)
- Imperfect CSI handling

## Training

Train the PUSCH autoencoder:

```bash
# Train with 16 BS antennas (default)
python demos/pusch_autoencoder/training.py

# Train with 32 BS antennas
python demos/pusch_autoencoder/training.py --num_bs_ant 32
```

**Training details:**
- Number of iterations: 5000
- Eb/N0 range: -2 dB to 10 dB
- Gradient accumulation: 16 steps
- Learning rates:
  - TX constellation: 1e-2
  - RX correction scales: 1e-2
  - RX neural network: 1e-4
- Optimizer: Adam with cosine decay schedule

**Outputs:**
- `results/PUSCH_autoencoder_weights_ant{N}` - Final trained weights
- `results/PUSCH_autoencoder_weights_iter_{I}_ant{N}` - Intermediate checkpoints (every 1000 iterations)
- `results/training_loss_ant{N}.npy` - Training loss history
- `results/training_loss_ant{N}.png` - Training loss plot
- `results/constellations_overlaid_ant{N}.png` - Initial vs trained constellation

## Baseline Evaluation

Evaluate the traditional LMMSE baseline receiver:

```bash
python demos/pusch_autoencoder/baseline.py
```

This runs BER/BLER simulations with:
- Standard 16-QAM constellation
- LMMSE detection
- Perfect and imperfect CSI modes

**Outputs:**
- `results/baseline_results_ant{N}.npz` - Baseline BER/BLER results

## Inference

Run inference with the trained autoencoder:

```bash
python demos/pusch_autoencoder/inference.py
```

**Prerequisites:**
- Trained weights at `results/PUSCH_autoencoder_weights_ant{N}`
- Channel model TFRecords (generated by CIRManager)

**Configuration:**
- Eb/N0 range: -2 dB to 10 dB
- Max Monte Carlo iterations: 50
- Target block errors: 200

**Outputs:**
- `results/inference_results_ant{N}.npz` - Autoencoder BER/BLER results

## Generating Plots

Generate comparison plots after running baseline and inference:

```bash
python demos/pusch_autoencoder/plots.py
```

**Prerequisites:**
- `results/baseline_results_ant{N}.npz` (baseline results)
- `results/inference_results_ant{N}.npz` (autoencoder results)
- `results/PUSCH_autoencoder_weights_ant{N}` (trained weights)

**Generated plots:**
- `results/ber_plot_1bs_{N}bs_ant_x_4ue_4ue_ant.png` - BER comparison
- `results/bler_plot_1bs_{N}bs_ant_x_4ue_4ue_ant.png` - BLER comparison
- `results/constellation_normalized_ant{N}.png` - Standard 16-QAM vs trained constellation

## Complete Workflow Example

```bash
# 1. Run baseline evaluation
python demos/pusch_autoencoder/baseline.py

# 2. Train autoencoder
python demos/pusch_autoencoder/training.py

# 3. Run inference with trained model
python demos/pusch_autoencoder/inference.py

# 4. Generate comparison plots
python demos/pusch_autoencoder/plots.py
```

## Channel Model Setup

The demo requires ray-tracing channel impulse responses stored as TFRecords. The `CIRManager` class handles loading and preprocessing:

```python
from demos.pusch_autoencoder.src.cir_manager import CIRManager
from demos.pusch_autoencoder.src.config import Config

cfg = Config(num_bs_ant=16)
cir_manager = CIRManager(config=cfg)
channel_model = cir_manager.load_from_tfrecord(group_for_mumimo=True)
```

## Running Tests

```bash
pytest demos/pusch_autoencoder/tests/ -v
```

## Configuration

Key parameters in `src/config.py`:
- `num_bs_ant`: Number of base station antennas (16 or 32)
- `batch_size`: Training/inference batch size (default: 32)
- `num_ue`: Number of user equipments (4)
- `num_ue_ant`: Number of UE antennas (4)
- `num_time_steps`: OFDM symbols per slot (14)
- `num_prb`: Physical resource blocks (16)
- `mcs_index`: Modulation and coding scheme (14 = 16-QAM)