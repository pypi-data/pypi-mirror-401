###############################################################################
#     Title :pg_meta.py
#    Author : Zaihua Ji,  zji@ucar.edu
#      Date : 09/18/2020
#             2025-01-22 transferred to package rda_python_dsarch from
#             https://github.com/NCAR/rda-shared-libraries.git
#             2025-12-09 convert to class PgMeta
#   Purpose : python library module to handle file counts and metadata gathering
#    Github : https://github.com/NCAR/rda-python-dsarch.git
###############################################################################
import os
import re
from os import path as op
from rda_python_common.pg_split import PgSplit
from rda_python_common.pg_cmd import PgCMD

class PgMeta(PgCMD, PgSplit):

   def __init__(self):
      super().__init__()  # initialize parent class
      self.GCOUNTS = {}
      self.META = {}     # keys: GM, GW, DM, DW, RM, RW, SM, and SW
      self.TGIDXS = {}   # cache value for function get_top_gindex()
      self.TIDXS = {}    # cache all unique top group index
      self.CMD = {
         'GX' : "gatherxml",
         'DX' : "dcm",
         'RX' : "rcm",
         'SX' : "scm",
         'SL' : "sml"
      }
      self.logfile = self.PGLOG['LOGFILE']
      self.errfile = self.PGLOG['ERRFILE']

   # switch to log file name provided
   def switch_logfile(self, logname = None):
      if logname:
         self.logfile = self.PGLOG['LOGFILE']
         self.errfile = self.PGLOG['ERRFILE']
         self.PGLOG['LOGFILE'] = logname + '.log'
         self.PGLOG['ERRFILE'] = logname + '.err'
      else:
         self.PGLOG['LOGFILE'] = self.logfile
         self.PGLOG['ERRFILE'] = self.errfile
   
   # get sub group level
   def get_group_levels(self, dsid, gindex, level):
      pgrec = self.pgget("dsgroup", "pindex", "dsid = '{}' AND gindex = {}".format(dsid, gindex), self.LGEREX)
      if pgrec and pgrec['pindex']:
         level = self.get_group_levels(dsid, pgrec['pindex'], level + 1)
      return level
   
   # reset datset/group file counts. Set all the way through if index is 0
   # act == 4/8 change web/saved file counts, respectively
   # go up if limit < 0 
   def reset_filenumber(self, dsid, gindex, act, level = 0, gtype = None, limit = 0):
      wcnd = "gindex = {}".format(gindex)
      dcnd = "dsid = '{}'".format(dsid)
      gcnd = "{} AND {}".format(dcnd, wcnd)
              # 0-pms,1-cpm,2-pm,3-mc,4-cdc,5-dc,6-wc,7-ds,8-nc,9-ns,10-sc,11-ss,12-tu
      counts = [0,    0,    0,   0,   0,    0,   0,   0,   0,   0,   0,    0,    0]
      pidx = None
      retcnt = 0
      if not gtype:
         retcnt = 1
         if gindex:
            pgrec = self.pgget("dsgroup", "pindex, grptype", gcnd, self.LGEREX)
            if not pgrec or abs(pgrec['pindex']) >= abs(gindex): return 0
            gtype = pgrec['grptype']
            pidx = pgrec['pindex']
         else:
            gtype = 'P'
         if not level:
            if act == 1: act = 14
            if gindex:
               level += 1
               if pidx: level = self.get_group_levels(dsid, pidx, level+1)
               if limit > 0: limit += level
      if not level: self.pgget("dataset", "dsid", dcnd, self.LGEREX|self.DOLOCK)
      # get file counts at the current group
      if act&4:
         if gtype == 'P':
            pgrec = self.pgget_wfile(dsid, "SUM(data_size) dsize, COUNT(wid) dcount", 
                                     wcnd + " AND type = 'D' AND status = 'P'", self.LGEREX)
            if pgrec:
               counts[5] = counts[4] = pgrec['dcount']
               if pgrec['dsize']: counts[7] = pgrec['dsize']
            pgrec = self.pgget_wfile(dsid, "SUM(data_size) nsize, COUNT(wid) ncount",
                                     wcnd + " AND type = 'N' AND status = 'P'", self.LGEREX)
            if pgrec:
               counts[8] = pgrec['ncount']
               if pgrec['nsize']: counts[9] = pgrec['nsize']
         counts[6] = self.pgget_wfile(dsid, "", wcnd, self.LGEREX)
      if act&8:
         pgrec = self.pgget("sfile", "SUM(data_size) ssize, COUNT(sid) scount",
                            gcnd + " AND status <> 'D'", self.LGEREX)
         if pgrec:
            counts[10] = pgrec['scount']
            if pgrec['ssize']: counts[11] = pgrec['ssize']
      pcnd = "{} AND pindex = {}".format(dcnd, gindex)
      if limit < 0:
         flds = "gindex"
         if act&4: flds += ", dwebcnt, webcnt, nwebcnt, dweb_size, nweb_size"
         if act&8: flds += ", savedcnt, saved_size"
         grecs = self.pgmget("dsgroup", flds, pcnd, self.LGEREX)
         gcnt =  len(grecs['gindex']) if grecs else 0
         if gcnt:
            for i in range(gcnt):
               if act&4:
                  if gtype == 'P':
                     counts[5] += grecs['dwebcnt'][i]
                     counts[7] += grecs['dweb_size'][i]
                     counts[8] += grecs['nwebcnt'][i]
                     counts[9] += grecs['nweb_size'][i]
                  counts[6] += grecs['webcnt'][i]
               if act&8:
                  counts[10] += grecs['savedcnt'][i]
                  counts[11] += grecs['saved_size'][i]
         cnt = self.update_filenumber(dsid, gindex, act, counts, level)
         if cnt:
            if pidx != None: cnt += self.reset_filenumber(dsid, pidx, act, (level-1), None, -1)
            counts[11] += cnt
      elif limit == 0 or level < limit:
         grecs = self.pgmget("dsgroup", "gindex, grptype", pcnd, self.LGEREX)
         gcnt = len(grecs['gindex']) if grecs else 0
         for i in range(gcnt):
            gidx = grecs['gindex'][i]
            if abs(gidx) <= abs(gindex): continue
            subcnts = self.reset_filenumber(dsid, gidx, act, level+1, grecs['grptype'][i], limit)
            if gtype == 'P':
               counts[0] += subcnts[0]
               counts[2] += subcnts[2]
               counts[5] += subcnts[5]
               counts[7] += subcnts[7]
               counts[8] += subcnts[8]
               counts[9] += subcnts[9]
            counts[3] += subcnts[3]
            counts[6] += subcnts[6]
            counts[10] += subcnts[10]
            counts[11] += subcnts[11]
            counts[12] += subcnts[12]
         cnt = self.update_filenumber(dsid, gindex, act, counts, level)
         if cnt:
            if pidx != None: cnt += self.reset_filenumber(dsid, pidx, act, level-1, None, -1)
            counts[12] += cnt
      if level == 0: self.endtran()
      return (counts[12] if retcnt else counts)
   
   # update group/dataset file counts
   def update_filenumber(self, dsid, gindex, act, counts, level = 0):
      flds = "mfstat, wfstat, dfstat"
      if gindex:
         table = "dsgroup"
         cnd = "dsid = '{}' AND gindex = {}".format(dsid, gindex)
         msg = "{}-G{}".format(dsid, gindex)
         if level: flds += ", level"
      else:
         table = "dataset"
         cnd = "dsid = '{}'".format(dsid)
         msg = dsid +":"
      if act&4: flds += ", dwebcnt, webcnt, cdwcnt, nwebcnt, dweb_size, nweb_size"
      if act&8: flds += ", saved_size, savedcnt"
      pgrec = self.pgget(table, flds, cnd, self.LGEREX)
      if not pgrec: return self.pglog("Group Index {} not exists for '{}'".format(gindex, dsid), self.LOGWRN)
      record = {}
      if act&4:
         if pgrec['dweb_size'] != counts[7]:
            record['dweb_size'] = counts[7]
            msg += " DS-{}".format(record['dweb_size'])
         if pgrec['nweb_size'] != counts[9]:
            record['nweb_size'] = counts[9]
            msg += " NS-{}".format(record['nweb_size'])
         if pgrec['cdwcnt'] != counts[4]:
            record['cdwcnt'] = counts[4]
            msg += " CDC-{}".format(record['cdwcnt'])
         if pgrec['dwebcnt'] != counts[5]:
            record['dwebcnt'] = counts[5]
            msg += " DC-{}".format(record['dwebcnt'])
         if pgrec['nwebcnt'] != counts[8]:
            record['nwebcnt'] = counts[8]
            msg += " NC-{}".format(record['nwebcnt'])
         if pgrec['webcnt'] != counts[6]:
            record['webcnt'] = counts[6]
            msg += " WC-{}".format(record['webcnt'])
         stat = 'D' if counts[5] else ('N' if counts[8] else ('W' if counts[6] else 'E'))
         if stat != pgrec['wfstat']:
            pgrec['wfstat'] = record['wfstat'] = stat
            msg += " WF-" + stat
      if act&8:
         if pgrec['savedcnt'] != counts[10]:
            record['savedcnt'] = counts[10]
            msg += " SC-{}".format(record['savedcnt'])
         if pgrec['saved_size'] != counts[11]:
            record['saved_size'] = counts[11]
            msg += " SS-{}".format(record['saved_size'])
      if level:
         if level != pgrec['level']:
            record['level'] = level
         else:
            level = None
      if record:
         stat = ('P' if (pgrec['wfstat'] == 'D' or pgrec['mfstat'] == 'P') else
                 ('N' if (pgrec['wfstat'] == 'W' or pgrec['wfstat'] == 'N' or pgrec['mfstat'] == 'M') else 'E'))
         if stat != pgrec['dfstat']:
            record['dfstat'] = stat
            msg += " DF-" + stat
         if level:
            msg += " LVL-{}".format(level)
         if self.pgupdt(table, record, cnd, self.LGEREX):
            self.pglog(msg, self.LOGWRN)
            return 1
      return 0
   
   # cache changes of the saved files
   def record_savedfile_changes(self, dsid, gindex, record, pgrec = None):
      ret = 0
      ostat = pgrec['status'] if pgrec else ""
      otype = pgrec['type'] if pgrec else ""
      stat = record['status'] if 'status' in record and record['status'] else ostat
      type = record['type'] if 'type' in record and record['type'] else otype
      size = record['data_size'] if 'data_size' in record and record['data_size'] else (pgrec['data_size'] if pgrec else 0)
      if otype == 'P' and ostat != 'P': otype = ''
      if type == 'P' and stat != 'P': type = ''
      if not pgrec or pgrec['status'] == 'D' or pgrec['dsid'] == self.PGLOG['DEFDSID']:   # new file record
         ret += self.record_filenumber(dsid, gindex, 8, type, 1, size)
      elif dsid != pgrec['dsid'] or gindex != pgrec['gindex']:   # file moved from one dataset/group to another
         ret += self.record_filenumber(dsid, gindex, 8, type, 1, size)
         ret += self.record_filenumber(pgrec['dsid'], pgrec['gindex'], 8, otype, -1, -pgrec['data_size'])
      elif type == otype:   # same type data
         if size != pgrec['data_size'] and type == "P":   # P type data size changed
            ret += self.record_filenumber(dsid, gindex, 8, "P", 0, (size - pgrec['data_size']))
      elif type == 'P' or otype == 'P':   # different types
         ret += self.record_filenumber(dsid, gindex, 8, type, 1, size)
         ret += self.record_filenumber(dsid, gindex, 8, otype, -1, -pgrec['data_size'])
      return ret
   
   # cache changes of web files
   def record_webfile_changes(self, dsid, gindex, record, pgrec = None):
      ret = 0
      ostat = pgrec['status'] if pgrec else ""
      otype = pgrec['type'] if pgrec else ""
      stat = record['status'] if 'status' in record and record['status'] else ostat
      type = record['type'] if 'type' in record and record['type'] else otype
      size = record['data_size'] if 'data_size' in record and record['data_size'] else (pgrec['data_size'] if pgrec else 0)
      if ostat != 'P': otype = ''
      if stat != 'P': type = ''
      if not pgrec or pgrec['status'] == 'D':   # new file record
         ret += self.record_filenumber(dsid, gindex, 4, type, 1, size)
      elif dsid != pgrec['dsid'] or gindex != pgrec['gindex']:   # file moved from one dataset/group to another
         ret += self.record_filenumber(dsid, gindex, 4, type, 1, size)
         ret += self.record_filenumber(pgrec['dsid'], pgrec['gindex'], 2, otype, -1, -pgrec['data_size'])
      elif type == otype:   # same type data
         if size != pgrec['data_size'] and (type == "D" or type == "N"):   # D or N type data size changed
            ret += self.record_filenumber(dsid, gindex, 4, type, 0, (size - pgrec['data_size']))
      elif type == 'D' or type == 'N' or otype == 'D' or otype == 'N':   # different types
         ret += self.record_filenumber(dsid, gindex, 4, type, 1, size)
         ret += self.record_filenumber(dsid, gindex, 4, otype, -1, -pgrec['data_size'])
      return ret
   
   # record group file counts act&4 for webfile and act&8 for savedfile
   def record_filenumber(self, dsid, gindex, act, type, cnt, size):
      if dsid not in self.GCOUNTS: self.GCOUNTS[dsid] = {}
      if gindex not in self.GCOUNTS[dsid]:
         # 0-pms,1-cpm,2-pm,3-mc,4-cdc,5-dc,6-wc,7-ds,8-nc,9-ns,10-sc,11-ss # 12-flag(1-group type is P)
         counts = self.GCOUNTS[dsid][gindex] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
         gcnd = "dsid = '{}' AND gindex = {} AND grptype = 'P'".format(dsid, gindex)
         if gindex and not self.pgget("dsgroup", "", gcnd, self.LGEREX): counts[12] = 0
      else:
         counts = self.GCOUNTS[dsid][gindex]
      if type and not counts[12]: type = ''
      if act == 1: act = 12  # for all
      if act&4:
         if type == 'D':
            counts[4] += cnt
            counts[5] += cnt
            if size: counts[7] += size
         if type == 'N':
            counts[8] += cnt
            if size: counts[9] += size
         counts[6] += cnt
      if act&8:
         counts[10] += cnt
         if size: counts[11] += size
      return 1
   
   # save the recorded COUNTS of group files into RDADB for given dsid
   def save_filenumber(self, dsid, act, reset, dosave = 0):
      dsids = [dsid] if dsid else list(self.GCOUNTS)
      ret = 0
      for dsid in dsids:
         if dsid not in self.GCOUNTS: continue
         if not dosave:
            del self.GCOUNTS[dsid]
            continue
         gindexs = sorted(self.GCOUNTS[dsid])
         if not gindexs: continue
         for gindex in gindexs:
            if not gindex: continue
            gcnts = self.GCOUNTS[dsid][gindex]
            while gindex:
               # loop to pass the group file counts upto the dataset
               gindex = self.group_filenumber(dsid, gindex, act, gcnts)
         # now update the file numbers
         gindexs = sorted(self.GCOUNTS[dsid])
         gcnt = len(gindexs)
         s = 's' if gcnt > 1 else ''
         self.pglog("Reset file counts for {} Groups of {} ...".format(gcnt, dsid), self.WARNLG)
         gcnt = 0
         for gindex in gindexs:
            gcnt += self.add_filenumber(dsid, gindex, act, self.GCOUNTS[dsid][gindex])
         del self.GCOUNTS[dsid]
         s = 's' if gcnt > 1 else ''
         self.pglog("{} Dataset/Group Record{} set for file counts of {}".format(gcnt, s, dsid), self.WARNLG)
         if reset and gcnt: self.reset_rdadb_version(dsid)
         ret += gcnt
      return ret
   
   #  add group file counts to parent group
   def group_filenumber(self, dsid, gindex, act, gcnts):
      pgrec = self.pgget("dsgroup", "pindex, grptype", "dsid = '{}' AND gindex = {}".format(dsid, gindex), self.LGEREX)
      if not pgrec: return 0    # should not happen
      pidx = pgrec['pindex']
      pflag = (1 if pgrec['grptype'] == 'P' else 0)
      if pidx not in self.GCOUNTS[dsid]: self.GCOUNTS[dsid][pidx] = [0]*13
      pcnts = self.GCOUNTS[dsid][pidx]
      pcnts[12] = pflag
      if act&4:
         if pflag:
            pcnts[5] += gcnts[5]
            pcnts[7] += gcnts[7]
            pcnts[8] += gcnts[8]
            pcnts[9] += gcnts[9]
         pcnts[6] += gcnts[6]
      if act&8:
         pcnts[10] += gcnts[10]
         pcnts[11] += gcnts[11]
      return pidx
   
   # add group/dataset file counts to RDADB
   def add_filenumber(self, dsid, gindex, act, counts):
      fields = ['primary_size', 'cpmcnt', 'pmsscnt', 'msscnt', 'cdwcnt', 'dwebcnt',
                'webcnt', 'dweb_size', 'nwebcnt', 'nweb_size', 'savedcnt', 'saved_size']
      shorts = ['PS', 'CPC', 'PC', 'MC', 'CDC', 'DC', 'WC', 'DS', 'NC', 'NS', 'SC', 'SS']
      i = 0 if act&2 else (4 if act&4 else 10)
      j = 12 if act&8 else (10 if act&4 else 4)
      if i >= j: return 0    # should not happen
      if gindex:
         table = "dsgroup"
         cnd = "dsid = '{}' AND gindex = {}".format(dsid, gindex)
         msg = "{}-G{}".format(dsid, gindex)
         flds = "gidx, "
      else:
         table = "dataset"
         cnd = "dsid = '{}'".format(dsid) 
         msg = dsid + ":"
         flds = ''
      flds += ', '.join(fields[i:j]) + ", mfstat, wfstat, dfstat"
      pgrec = self.pgget(table, flds, cnd, self.LGEREX)
      if not pgrec: return self.pglog("Group Index {} not exists for '{}'".format(gindex, dsid), self.LOGWRN)
      sqlary = []
      while i < j:
         if counts[i]:
            sqlary.append("{} = {} + {}".format(fields[i], fields[i], counts[i]))
            counts[i] += pgrec[fields[i]]
            msg += " {}-{}".format(shorts[i], counts[i])
         else:
            counts[i] = pgrec[fields[i]]
         i += 1
      if act&4:
         stat = 'D' if counts[5] else ('W' if counts[6] else 'E')
         if stat != pgrec['wfstat']:
            sqlary.append("wfstat = '{}'".format(stat))
            pgrec['wfstat'] = stat
            msg += " WF-" + stat
      if not sqlary: return 0   # nothing needs change
      stat = ('P' if (pgrec['wfstat'] == 'D' or pgrec['mfstat'] == 'P') else
              ('N' if (pgrec['wfstat'] == 'W' or pgrec['wfstat'] == 'N' or pgrec['mfstat'] == 'M') else 'E'))
      if stat != pgrec['dfstat']:
         sqlary.append("dfstat = '{}'".format(stat))
         pgrec['dfstat'] = stat
         msg += " DF-" + stat
      if gindex: cnd = "gidx = {}".format(pgrec['gidx'])
      if self.pgexec("UPDATE {} SET {} WHERE {}".format(table,  ', '.join(sqlary), cnd), self.LGEREX):
         self.pglog(msg, self.LOGWRN)
         return 1
      return 0
   
   # record actions of gathering xml metadata for mssfile/webfile
   # cate: M or W
   def record_meta_gather(self, cate, dsid, file, fmt, lfile = None, mfile = None):
      if cate == 'M': return 0
      if not fmt: return self.pglog("{}-{}: Miss Data Format for 'gatherxml'".format(dsid, file), self.LOGERR)
      c = "G" + cate
      if c not in self.META: self.META[c] = {}
      d = self.metadata_dataset_id(dsid)
      if d not in self.META[c]: self.META[c][d] = []
      f = fmt.lower()
      if f == "netcdf": f = "cf" + f
      if not lfile: lfile = op.basename(file)
      self.META[c][d].append([file, f, lfile, mfile])
      return 1
   
   # record actions of deleting xml metadata for mssfile/webfile
   # cate: M or W
   def record_meta_delete(self, cate, dsid, file):
      if cate == 'M': return 0
      c = "D" + cate
      if c not in self.META: self.META[c] = {}
      d = self.metadata_dataset_id(dsid)
      if d not in self.META[c]: self.META[c][d] = {}
      if file not in self.META[c][d]:
         self.META[c][d][file] = ''
         return 1
      return 0
   
   # record actions of moving xml metadata for mssfile/webfile
   # cate: M or W
   def record_meta_move(self, cate, dsid, ndsid, file, nfile):
      if cate == 'M': return 0
      c = "R" + cate
      if c not in self.META: self.META[c] = {}
      d = self.metadata_dataset_id(dsid)
      if d not in self.META[c]: self.META[c][d] = {}
      if file not in self.META[c][d]:
         n = None if ndsid == dsid else self.metadata_dataset_id(ndsid)
         self.META[c][d][file] = [n, nfile]
         return 1
      return 0
   
   # record actions of getting group summary xml metadata for mssfile/webfile
   # cate: M or W
   def record_meta_summary(self, cate, dsid, gindex, gindex1 = None):
      if cate == 'M': return 0
      ret = 0
      c = "S" + cate
      if c not in self.META: self.META[c] = {}
      d = self.metadata_dataset_id(dsid)
      if d not in self.META[c]: self.META[c][d] = {}
      if gindex not in self.META[c][d]:
         self.META[c][d][gindex] = 1
         ret += 1
      if  not (gindex1 is None or gindex1 in self.META[c][d]):
         self.META[c][d][gindex1] = 1
         ret += 1
      return ret
   
   # process all cached metadata actions cat == M or W
   def process_metadata(self, cate, metacnt, logact = None):
      if logact is None: logact = self.LOGWRN
      if cate == 'M': return 0
      cnt = 0
      cnt += self.process_meta_delete(cate, logact)
      cnt += self.process_meta_move(cate, logact)
      cnt += self.process_meta_summary(cate, logact)
      cnt += self.process_meta_gather(cate, logact)
      return cnt
   
   # process cached metadata gathering actions cate: M or W
   def process_meta_gather(self, cate, logact = None):
      if logact is None: logact = self.LOGWRN
      if cate == 'M': return 0
      c = 'G' + cate
      if c not in self.META: return 0
      opt = 5
      act = logact
      if act&self.EXITLG:
         act &= ~self.EXITLG
         if self.PGLOG['DSCHECK']: opt |= 256
      self.PGLOG['ERR2STD'] = ["Warning: ", "already up-to-date", "process currently running",
                                "rsync", "No route to host", "''*'"]
      self.switch_logfile("gatherxml")
      dary = list(self.META[c])
      dcnt = len(dary)
      cnt = 0
      sx = ''
      rs = self.PGLOG['RSOptions']
      if not rs and dcnt == 1:
         if len(self.META[c][dary[0]]) > 2:
            sx = "{} -d {} -r{} ".format(self.CMD['SX'], dary[0], ('m' if cate == 'M' else 'w'))
            rs = " -S -R"
      for d in dary:
         for ary in self.META[c][d]:
            cmd = "{} -d {} -f {}{} ".format(self.CMD['GX'], d, ary[1], rs)
            if cate == 'M':
               if ary[2] and op.exists(ary[2]): cmd += "-l {} ".format(ary[2])
               if ary[3]: cmd += "-m {} ".format(ary[3])
            cmd += ary[0]
            if self.start_background(cmd, act, opt, 1):
               cnt += 1
               if self.PGLOG['DSCHECK'] and cnt > 0 and (cnt%10) == 0:
                  self.add_dscheck_dcount(10, 0, logact)
            elif self.PGLOG['SYSERR']:
               self.record_dscheck_error(self.PGLOG['SYSERR'], act)
      self.PGLOG['ERR2STD'] = []
      if cnt > 0:
         if self.PGSIG['BPROC'] > 1: self.check_background(None, 0, logact, 1)
         if cnt > 1: self.pglog("Metadata gathered for {} files".format(cnt), self.WARNLG)
         if sx:
            if 'all' in self.TIDXS:
               self.pgsystem(sx + 'all', act, opt)
            else:
               for tidx in self.TIDXS:
                  self.pgsystem("{}{}".format(sx, tidx), act, opt)
      del self.META[c]
      self.TIDXS = {}
      self.switch_logfile()
      return cnt
   
   # process cached metadata deleting actions cate: M or W
   def process_meta_delete(self, cate, logact = None):
      if logact is None: logact = self.LOGWRN
      if cate == 'M': return 0
      c = 'D' + cate
      if c not in self.META: return 0
      cnt = 0
      opt = 5
      act = logact
      if act&self.EXITLG:
         act &= ~self.EXITLG
         if self.PGLOG['DSCHECK']: opt |= 256
      self.PGLOG['ERR2STD'] = ["Warning: "]
      self.switch_logfile("gatherxml")
      for d in self.META[c]:
         cmd = "{} -d {}".format(self.CMD['DX'], d)
         dcnt = 0
         for file in self.META[c][d]:
            cmd += " " + file
            dcnt += 1
         if dcnt > 0:
            if self.start_background(cmd, act, opt, 1):
               cnt += dcnt
            elif self.PGLOG['SYSERR']:
               self.record_dscheck_error(self.PGLOG['SYSERR'], act)
      self.PGLOG['ERR2STD'] = []
      if cnt > 0:
         if self.PGSIG['BPROC'] > 1: self.check_background(None, 0, logact, 1)
         if cnt > 1: self.pglog("Metadata deleted for {} files".format(cnt), self.WARNLG)
      del self.META[c]
      self.switch_logfile()
      return cnt
   
   # delete metadata for given file
   def delete_file_metadata(self, dsid, file, logact = None):
      if logact is None: logact = self.LOGWRN
      d = self.metadata_dataset_id(dsid)
      opt = 5
      if logact&self.EXITLG:
         logact &= ~self.EXITLG
         if self.PGLOG['DSCHECK']: opt |= 256
      self.PGLOG['ERR2STD'] = ["Warning: "]
      self.switch_logfile("gatherxml")
      if not self.pgsystem("{} -d {} {}".format(self.CMD['DX'], d, file), logact, opt) and self.PGLOG['SYSERR']:
         self.record_dscheck_error(self.PGLOG['SYSERR'], logact)
      self.PGLOG['ERR2STD'] = []
      self.switch_logfile()
   
   # process cached metadata moving actions cate: M or W
   def process_meta_move(self, cate, logact = None):
      if logact is None: logact = self.LOGWRN
      if cate == 'M': return 0
      c = 'R' + cate
      if c not in self.META: return 0
      cnt = 0
      opt = 5
      act = logact
      if act&self.EXITLG:
         act &= ~self.EXITLG
         if self.PGLOG['DSCHECK']: opt |= 256
      self.PGLOG['ERR2STD'] = ["Warning: "]
      self.switch_logfile("gatherxml")
      for d in self.META[c]:
         dmeta = self.META[c][d]
         files = list(dmeta)
         fcnt = len(files)
         for i in range(fcnt):
            file = files[i]
            cmd = "{} -d {} ".format(self.CMD['RX'], d)
            n = dmeta[file][0]
            if n:
               cmd += "-nd {} ".format(n)
            elif i < fcnt - 1:
               cmd += "-C "
            cmd += "{} {}".format(file, dmeta[file][1])
            if self.start_background(cmd, act, opt, 1):
               cnt += 1
            elif self.PGLOG['SYSERR']:
               self.record_dscheck_error(self.PGLOG['SYSERR'], act)
      self.PGLOG['ERR2STD'] = []
      if cnt > 0:
         if self.PGSIG['BPROC'] > 1: self.check_background(None, 0, logact, 1)
         if cnt > 1: self.pglog("Metadata moved for {} files".format(cnt), self.WARNLG)
      del self.META[c]
      self.switch_logfile()
      return cnt
   
   # process cached metadata of getting group summary actions cate: M or W
   def process_meta_summary(self, cate, logact = None):
      if logact is None: logact = self.LOGWRN
      if cate == 'M': return 0
      c = 'S' + cate
      if c not in self.META: return 0
      cnt = 0
      opt = 5
      ctype = cate.lower()
      act = logact
      if act&self.EXITLG:
         act &= ~self.EXITLG
         if self.PGLOG['DSCHECK']: opt |= 256
      self.PGLOG['ERR2STD'] = ["Warning: "]
      self.switch_logfile("gatherxml")
      for d in self.META[c]:
         for gindex in self.META[c][d]:
            cmd = "{} -d {} -{} {}".format(self.CMD['SX'], d, ctype, gindex)
            if self.start_background(cmd, act, opt, 1):
               cnt += 1
            elif self.PGLOG['SYSERR']:
               self.record_dscheck_error(self.PGLOG['SYSERR'], act)
      self.PGLOG['ERR2STD'] = []
      if cnt > 0:
         if self.PGSIG['BPROC'] > 1: self.check_background(None, 0, logact, 1)
         if cnt > 1: self.pglog("Group Metadata summarized for {} groups".format(cnt), self.WARNLG)
      del self.META[c]
      self.switch_logfile()
      return cnt
   
   # find a top group index if given group index is not otherwise return itself
   # cache the results for later use
   def get_top_gindex(self, dsid, gindex, logact = None):
      if logact is None: logact = self.LGEREX
      if gindex in self.TGIDXS: return self.TGIDXS[gindex]
      gcnd = "dsid = '{}' AND gindex = {}".format(dsid, gindex)
      pgrec = self.pgget("dsgroup", "pindex", gcnd, logact)
      if pgrec and pgrec['pindex']:
         tindex = self.get_top_gindex(dsid, pgrec['pindex'])
      else:
         tindex = gindex
      self.TGIDXS[gindex] = tindex
      return tindex
   
   # cache file top group index for meta gathering 
   def cache_meta_tindex(self, dsid, id, type, logact = None):
      if logact is None: logact = self.LGEREX
      pgrec = self.pgget_wfile(dsid, "tindex, gindex", "wid = {}".format(id), logact)
      if pgrec:
         if pgrec['tindex']:
            tidx = pgrec['tindex']
         else:
            tidx = self.get_top_gindex(dsid, pgrec['gindex'], logact)
      else:
         tidx = 0
      if tidx:
         self.TIDXS[tidx] = 1
      else:
         self.TIDXS['all'] = 1
   
   # reset the top group index values for the current and sub groups of
   # given dsid and/or group index 
   # act == 2/4 reset for mss/web files, respectively 1 for both
   def reset_top_gindex(self, dsid, gindex, act):
      tcnt = 0
      if act == 1: act = 12
      tindex = self.get_top_gindex(dsid, gindex)
      record = {'tindex' : tindex}
      tcnd = "gindex = {} AND tindex <> {}".format(gindex, tindex) 
      dcnd = "dsid = '{}'".format(dsid)
      if act&4:
         cnt = self.pgupdt_wfile(dsid, record, tcnd, self.LGEREX)
         if cnt > 0:
            s = ('s' if cnt > 1 else '')
            self.pglog("set tindex {} for {} web files in gindex {} of {}".format(tindex, cnt, gindex, dsid), self.WARNLG)
            tcnt += cnt
      if act&8:
         cnt = self.pgupdt("sfile", record, dcnd + ' AND ' + tcnd, self.LGEREX)
         if cnt > 0:
            s = ('s' if cnt > 1 else '')
            self.pglog("set tindex {} for {} saved files in gindex {} of {}".format(tindex, cnt, gindex, dsid), self.WARNLG)
            tcnt += cnt
      pcnd = "{} AND pindex = {}".format(dcnd, gindex)
      pgrecs = self.pgmget("dsgroup", "gindex", pcnd, self.LGEREX)
      cnt = len(pgrecs['gindex']) if pgrecs else 0
      for i in range(cnt):
         tcnt += self.reset_top_gindex(dsid, pgrecs['gindex'][i], act)
      return tcnt
   
   # reset metalink in table wfile
   def set_meta_link(self, dsid, fname):
      return self.pgsystem("{} -d {} {}".format(self.CMD['SL'], dsid, fname))
