{
  "defaults":
  {
    "hw_version": "V69",
    "ops":
    {
      "is_output_quantized": "True"
    },
    "params":
    {
      "is_quantized": "True",
      "is_symmetric": "True"
    },
    "per_channel_quantization": "True",
    "strict_symmetric": "False",
    "unsigned_symmetric": "False"
  },

  "params":
  {
    "bias":
    {
      "is_quantized": "False"
    }
  },

  "op_type":
  {
    "Cast":
    {
      "is_output_quantized": "False"
    },
    "BatchPermutation":
    {
      "is_output_quantized": "False"
    },
    "ChannelShuffle":
    {
      "is_output_quantized": "False"
    },
    "CropAndResize":
    {
      "is_output_quantized": "False"
    },
    "DepthToSpace":
    {
      "is_output_quantized": "False"
    },
    "Dropout":
    {
      "is_output_quantized": "False"
    },
    "Expand":
    {
      "is_output_quantized": "False"
    },
    "GatherND":
    {
      "is_output_quantized": "False"
    },
    "ReduceMax":
    {
      "is_output_quantized": "False"
    },
    "Relu":
    {
      "encoding_constraints":
      {
        "min": 0.0
      }
    },
    "Reshape":
    {
      "is_output_quantized": "False"
    },
    "MaxPool":
    {
      "is_output_quantized": "False"
    },
    "Upsample":
    {
      "is_output_quantized": "False"
    },
    "SpaceToDepth":
    {
      "is_output_quantized": "False"
    },
    "Split":
    {
      "is_output_quantized": "False"
    },
    "Slice":
    {
      "is_output_quantized": "False"
    },
    "TopK":
    {
      "is_output_quantized": "False"
    },
    "Transpose":
    {
      "is_output_quantized": "False"
    },
    "BatchToSpace":
    {
      "is_output_quantized": "False"
    },
    "SpaceToBatch":
    {
      "is_output_quantized": "False"
    },
    "NonMaxSuppression":
    {
      "is_output_quantized": "False"
    },
    "NonZero":
    {
      "is_output_quantized": "False"
    },
    "Tanh":
    {
      "encoding_constraints":
      {
        "min": -1.0,
        "max": 1.0
      }
    },
    "Tile":
    {
      "is_output_quantized": "False"
    },
    "Squeeze":
    {
      "is_output_quantized": "False"
    },
    "Pad":
    {
      "is_output_quantized": "False"
    },
    "Mean":
    {
      "is_output_quantized": "False"
    },
    "ReduceMin":
    {
      "is_output_quantized": "False"
    },
    "RMSNormalization":
    {
      "per_channel_quantization": "False",
      "params": {
        "weight": {
          "is_symmetric": "False"
        }
      }
    },
    "LayerNormalization":
    {
      "per_channel_quantization": "False",
      "params": {
        "weight": {
          "is_symmetric": "False"
        }
      }
    },
    "BatchNormalization":
    {
      "per_channel_quantization": "False",
      "params": {
        "running_mean": {
          "is_quantized": "False"
        },
        "running_var": {
          "is_quantized": "False"
        }
      }
    },
    "InstanceNormalization":
    {
      "per_channel_quantization": "False",
      "params": {
        "weight": {
          "is_symmetric": "False"
        }
      }
    },
    "Gather":
    {
      "is_output_quantized": "False",
      "per_channel_quantization": "False"
    },
    "Flatten":
    {
      "is_output_quantized" : "False"
    },
    "Unsqueeze":
    {
      "is_output_quantized" : "False"
    },
    "Compress":
    {
      "is_output_quantized" : "False"
    },
    "Identity":
    {
      "is_output_quantized" : "False"
    },
    "Shape":
    {
      "is_output_quantized" : "False"
    },
    "If":
    {
      "is_output_quantized" : "False"
    },
    "RNN":
    {
      "per_channel_quantization": "False"
    },
    "GRU":
    {
      "per_channel_quantization": "False"
    },
    "LSTM":
    {
      "per_channel_quantization": "False"
    }
  },

  "supergroup_pass_list":
  [
    "LayerNormalization",
    "RMSNormalization",
    "MatmulAdd"
  ],
  "supergroups":
  [
    {
      "op_list": ["ConvTranspose", "Relu"]
    },
    {
      "op_list": ["Add", "Relu"]
    },
    {
      "op_list": ["Gemm", "Relu"]
    }
  ],

  "model_input":
  {
    "is_input_quantized": "True"
  },

  "model_output":
  {}
}
