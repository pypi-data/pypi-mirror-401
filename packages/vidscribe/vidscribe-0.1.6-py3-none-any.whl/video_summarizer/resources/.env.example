# MoviePy Configuration (FFmpeg/FFplay/FFprobe)
# Options:
#   - auto-detect: Automatically find ffmpeg/ffplay/ffprobe in PATH (default)
#   - ffmpeg-imageio: Use imageio's bundled ffmpeg binary
#   - /path/to/binary: Absolute path to custom binary (do not use quotes)
#   - ffmpeg: Use 'ffmpeg' command from PATH
FFMPEG_BINARY=auto-detect
FFPLAY_BINARY=auto-detect
FFPROBE_BINARY=auto-detect

# Docker Container Configuration
SPEACHES_CONTAINER_NAME=speaches
SPEACHES_CONTAINER_PORT=8000
SPEACHES_CONTAINER_IMAGE=ghcr.io/speaches-ai/speaches:latest-cpu

# GPU Configuration
SPEACHES_USE_GPU=false
SPEACHES_GPU_CONTAINER_IMAGE=ghcr.io/speaches-ai/speaches:latest-cuda

# Transcription Configuration
SPEACHES_MODEL=Systran/faster-distil-whisper-small.en
AUTO_START_CONTAINER=true
SPEACHES_RESPONSE_FORMAT=verbose_json  # verbose_json, json, text, srt, vtt
SPEACHES_VAD_FILTER=false  # Enable voice activity detection
SPEACHES_CHUNK_DURATION_SEC=90  # Split audio into chunks (in seconds)
SPEACHES_CHUNK_DURATION_THRESHOLD=180  # Use chunked transcription for audio longer than this (seconds)
SPEACHES_CHUNK_OVERLAP_SEC=0  # Overlap between chunks (0 = no overlap, currently disabled)
# SPEACHES_LANGUAGE=en  # Optional: force language (e.g., en, zh, es)

# OpenAI API Configuration
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4o
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7
OPENAI_SUMMARY_STYLE=concise
OPENAI_MAX_TRANSCRIPT_LENGTH=128000

# Scraper Configuration
OUTPUT_FORMAT=wav
AUDIO_QUALITY=medium
TEMP_DIR=/tmp/vidscribe

# Output Configuration
OUTPUT_DIR=./summaries
SAVE_TRANSCRIPT=false
SAVE_SUMMARY=true

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=
