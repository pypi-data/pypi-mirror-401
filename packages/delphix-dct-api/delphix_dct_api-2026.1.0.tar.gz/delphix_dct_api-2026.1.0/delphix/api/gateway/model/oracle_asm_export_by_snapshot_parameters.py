"""
    Delphix DCT API

    Delphix DCT API  # noqa: E501

    The version of the OpenAPI document: 3.26.0
    Contact: support@delphix.com
    Generated by: https://openapi-generator.tech
"""


import re  # noqa: F401
import sys  # noqa: F401

from delphix.api.gateway.model_utils import (  # noqa: F401
    ApiTypeError,
    ModelComposed,
    ModelNormal,
    ModelSimple,
    cached_property,
    change_keys_js_to_python,
    convert_js_args_to_python_args,
    date,
    datetime,
    file_type,
    none_type,
    validate_get_composed_info,
)
from ..model_utils import OpenApiModel
from delphix.api.gateway.exceptions import ApiAttributeError


def lazy_import():
    from delphix.api.gateway.model.base_export_transfer_strategy_parameters import BaseExportTransferStrategyParameters
    from delphix.api.gateway.model.export_by_snapshot_parameters_all_of import ExportBySnapshotParametersAllOf
    from delphix.api.gateway.model.export_db_timeflow_point_parameters import ExportDBTimeflowPointParameters
    from delphix.api.gateway.model.oracle_asm_layout_parameters import OracleAsmLayoutParameters
    from delphix.api.gateway.model.oracle_rac_database_instance import OracleRACDatabaseInstance
    from delphix.api.gateway.model.oracle_tde_keystore_config_type_enum import OracleTdeKeystoreConfigTypeEnum
    globals()['BaseExportTransferStrategyParameters'] = BaseExportTransferStrategyParameters
    globals()['ExportBySnapshotParametersAllOf'] = ExportBySnapshotParametersAllOf
    globals()['ExportDBTimeflowPointParameters'] = ExportDBTimeflowPointParameters
    globals()['OracleAsmLayoutParameters'] = OracleAsmLayoutParameters
    globals()['OracleRACDatabaseInstance'] = OracleRACDatabaseInstance
    globals()['OracleTdeKeystoreConfigTypeEnum'] = OracleTdeKeystoreConfigTypeEnum


class OracleAsmExportBySnapshotParameters(ModelComposed):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.

    Attributes:
      allowed_values (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          with a capitalized key describing the allowed value and an allowed
          value. These dicts store the allowed enum values.
      attribute_map (dict): The key is attribute name
          and the value is json key in definition.
      discriminator_value_class_map (dict): A dict to go from the discriminator
          variable value to the discriminator class name.
      validations (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          that stores validations for max_length, min_length, max_items,
          min_items, exclusive_maximum, inclusive_maximum, exclusive_minimum,
          inclusive_minimum, and regex.
      additional_properties_type (tuple): A tuple of classes accepted
          as additional properties values.
    """

    allowed_values = {
        ('recovery_model',): {
            'FULL': "FULL",
            'SIMPLE': "SIMPLE",
            'BULK_LOGGED': "BULK_LOGGED",
        },
        ('mirroring_state',): {
            'SUSPENDED': "SUSPENDED",
            'DISCONNECTED': "DISCONNECTED",
            'SYNCHRONIZING': "SYNCHRONIZING",
            'PENDING_FAILOVER': "PENDING_FAILOVER",
            'SYNCHRONIZED': "SYNCHRONIZED",
            'NOT_SYNCHRONIZED': "NOT_SYNCHRONIZED",
            'FAILOVER_POSSIBLE': "FAILOVER_POSSIBLE",
            'NONE': "NONE",
        },
    }

    validations = {
        ('oracle_instance_name',): {
            'max_length': 15,
            'min_length': 1,
            'regex': {
                'pattern': r'^[a-zA-Z0-9_]+$',  # noqa: E501
            },
        },
        ('parent_pdb_tde_keystore_path',): {
            'max_length': 512,
            'min_length': 1,
        },
        ('parent_pdb_tde_keystore_password',): {
            'max_length': 128,
            'min_length': 1,
        },
        ('target_pdb_tde_keystore_password',): {
            'max_length': 128,
            'min_length': 1,
        },
        ('backup_frequency_minutes',): {
            'inclusive_minimum': 10,
        },
        ('rman_channels_for_incremental_backup',): {
            'inclusive_maximum': 255,
            'inclusive_minimum': 1,
        },
        ('rman_files_per_set_for_incremental_backup',): {
            'inclusive_maximum': 64,
            'inclusive_minimum': 1,
        },
        ('rman_file_section_size_in_gb_for_incremental_backup',): {
            'inclusive_minimum': 0,
        },
        ('rman_channels',): {
            'inclusive_maximum': 32,
            'inclusive_minimum': 1,
        },
    }

    @cached_property
    def additional_properties_type():
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded
        """
        lazy_import()
        return (bool, date, datetime, dict, float, int, list, str, none_type,)  # noqa: E501

    _nullable = False

    @cached_property
    def openapi_types():
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded

        Returns
            openapi_types (dict): The key is attribute name
                and the value is attribute type.
        """
        lazy_import()
        return {
            'default_data_diskgroup': (str,),  # noqa: E501
            'unique_name': (str,),  # noqa: E501
            'database_name': (str,),  # noqa: E501
            'repository_id': (str,),  # noqa: E501
            'environment_user_ref': (str,),  # noqa: E501
            'tde_keystore_password': (str,),  # noqa: E501
            'tde_keystore_config_type': (OracleTdeKeystoreConfigTypeEnum,),  # noqa: E501
            'oracle_instance_name': (str,),  # noqa: E501
            'instance_number': (int,),  # noqa: E501
            'instances': ([OracleRACDatabaseInstance],),  # noqa: E501
            'mount_base': (str,),  # noqa: E501
            'config_params': ({str: (bool, date, datetime, dict, float, int, list, str, none_type)}, none_type,),  # noqa: E501
            'cdb_id': (str,),  # noqa: E501
            'parent_tde_keystore_path': (str,),  # noqa: E501
            'parent_tde_keystore_password': (str,),  # noqa: E501
            'tde_exported_keyfile_secret': (str,),  # noqa: E501
            'tde_key_identifier': (str,),  # noqa: E501
            'parent_pdb_tde_keystore_path': (str,),  # noqa: E501
            'parent_pdb_tde_keystore_password': (str,),  # noqa: E501
            'target_pdb_tde_keystore_password': (str,),  # noqa: E501
            'crs_database_name': (str,),  # noqa: E501
            'recover_database': (bool,),  # noqa: E501
            'file_mapping_rules': (str,),  # noqa: E501
            'enable_cdc': (bool,),  # noqa: E501
            'recovery_model': (str,),  # noqa: E501
            'mirroring_state': (str,),  # noqa: E501
            'is_incremental_v2p': (bool,),  # noqa: E501
            'backup_frequency_minutes': (int,),  # noqa: E501
            'rman_channels_for_incremental_backup': (int,),  # noqa: E501
            'rman_files_per_set_for_incremental_backup': (int,),  # noqa: E501
            'rman_file_section_size_in_gb_for_incremental_backup': (int,),  # noqa: E501
            'redo_diskgroup': (str,),  # noqa: E501
            'rman_channels': (int,),  # noqa: E501
            'rman_file_section_size_in_gb': (int,),  # noqa: E501
            'snapshot_id': (str,),  # noqa: E501
        }

    @cached_property
    def discriminator():
        return None


    attribute_map = {
        'default_data_diskgroup': 'default_data_diskgroup',  # noqa: E501
        'unique_name': 'unique_name',  # noqa: E501
        'database_name': 'database_name',  # noqa: E501
        'repository_id': 'repository_id',  # noqa: E501
        'environment_user_ref': 'environment_user_ref',  # noqa: E501
        'tde_keystore_password': 'tde_keystore_password',  # noqa: E501
        'tde_keystore_config_type': 'tde_keystore_config_type',  # noqa: E501
        'oracle_instance_name': 'oracle_instance_name',  # noqa: E501
        'instance_number': 'instance_number',  # noqa: E501
        'instances': 'instances',  # noqa: E501
        'mount_base': 'mount_base',  # noqa: E501
        'config_params': 'config_params',  # noqa: E501
        'cdb_id': 'cdb_id',  # noqa: E501
        'parent_tde_keystore_path': 'parent_tde_keystore_path',  # noqa: E501
        'parent_tde_keystore_password': 'parent_tde_keystore_password',  # noqa: E501
        'tde_exported_keyfile_secret': 'tde_exported_keyfile_secret',  # noqa: E501
        'tde_key_identifier': 'tde_key_identifier',  # noqa: E501
        'parent_pdb_tde_keystore_path': 'parent_pdb_tde_keystore_path',  # noqa: E501
        'parent_pdb_tde_keystore_password': 'parent_pdb_tde_keystore_password',  # noqa: E501
        'target_pdb_tde_keystore_password': 'target_pdb_tde_keystore_password',  # noqa: E501
        'crs_database_name': 'crs_database_name',  # noqa: E501
        'recover_database': 'recover_database',  # noqa: E501
        'file_mapping_rules': 'file_mapping_rules',  # noqa: E501
        'enable_cdc': 'enable_cdc',  # noqa: E501
        'recovery_model': 'recovery_model',  # noqa: E501
        'mirroring_state': 'mirroring_state',  # noqa: E501
        'is_incremental_v2p': 'is_incremental_v2p',  # noqa: E501
        'backup_frequency_minutes': 'backup_frequency_minutes',  # noqa: E501
        'rman_channels_for_incremental_backup': 'rman_channels_for_incremental_backup',  # noqa: E501
        'rman_files_per_set_for_incremental_backup': 'rman_files_per_set_for_incremental_backup',  # noqa: E501
        'rman_file_section_size_in_gb_for_incremental_backup': 'rman_file_section_size_in_gb_for_incremental_backup',  # noqa: E501
        'redo_diskgroup': 'redo_diskgroup',  # noqa: E501
        'rman_channels': 'rman_channels',  # noqa: E501
        'rman_file_section_size_in_gb': 'rman_file_section_size_in_gb',  # noqa: E501
        'snapshot_id': 'snapshot_id',  # noqa: E501
    }

    read_only_vars = {
    }

    @classmethod
    @convert_js_args_to_python_args
    def _from_openapi_data(cls, *args, **kwargs):  # noqa: E501
        """OracleAsmExportBySnapshotParameters - a model defined in OpenAPI

        Keyword Args:
            default_data_diskgroup (str): Default diskgroup for datafiles.
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            unique_name (str): The unique name of the database.. [optional]  # noqa: E501
            database_name (str): The name of the database.. [optional]  # noqa: E501
            repository_id (str): The repository_id to use for this operation.. [optional]  # noqa: E501
            environment_user_ref (str): The environment user reference.. [optional]  # noqa: E501
            tde_keystore_password (str): The password for the Transparent Data Encryption keystore associated with this database.. [optional]  # noqa: E501
            tde_keystore_config_type (OracleTdeKeystoreConfigTypeEnum): [optional]  # noqa: E501
            oracle_instance_name (str): SID of the exported database. [optional]  # noqa: E501
            instance_number (int): The number of the instance.. [optional]  # noqa: E501
            instances ([OracleRACDatabaseInstance]): [optional]  # noqa: E501
            mount_base (str): The base mount point to use for the NFS mounts for the temporary VDB.. [optional]  # noqa: E501
            config_params ({str: (bool, date, datetime, dict, float, int, list, str, none_type)}, none_type): Database configuration parameter overrides.. [optional]  # noqa: E501
            cdb_id (str): ID of an Oracle multitenant database this pluggable database belongs to.. [optional]  # noqa: E501
            parent_tde_keystore_path (str): Path to a copy of the parent's Oracle transparent data encryption keystore on the target host.. [optional]  # noqa: E501
            parent_tde_keystore_password (str): The password of the keystore specified in parentTdeKeystorePath.. [optional]  # noqa: E501
            tde_exported_keyfile_secret (str): Secret to be used while exporting and importing vPDB encryption keys.. [optional]  # noqa: E501
            tde_key_identifier (str): PDB database master encryption key id, as recorded in v$encryption_keys.key_id.. [optional]  # noqa: E501
            parent_pdb_tde_keystore_path (str): Path to a copy of the parent PDB's Oracle transparent data encryption keystore on the target host. Required to export of PDB containing encrypted database files with isolated mode keystore.(Oracle Multitenant Only) . [optional]  # noqa: E501
            parent_pdb_tde_keystore_password (str): The password of the parent PDB keystore. (Oracle Multitenant Only). [optional]  # noqa: E501
            target_pdb_tde_keystore_password (str): The password for the isolated mode TDE keystore of the target PDB. (Oracle Multitenant Only). [optional]  # noqa: E501
            crs_database_name (str): The Oracle Clusterware database name.. [optional]  # noqa: E501
            recover_database (bool): If specified, then take the exported database through recovery procedures, if necessary, to reach a consistent point.. [optional] if omitted the server will use the default value of True  # noqa: E501
            file_mapping_rules (str): Database file mapping rules.. [optional]  # noqa: E501
            enable_cdc (bool): Indicates whether to enable Change Data Capture (CDC) or not on exported database(MSSql Only).. [optional] if omitted the server will use the default value of False  # noqa: E501
            recovery_model (str): Recovery model of the database (MSSql Only).. [optional] if omitted the server will use the default value of "FULL"  # noqa: E501
            mirroring_state (str): Recovery model of the database (MSSql Only).. [optional] if omitted the server will use the default value of "NONE"  # noqa: E501
            is_incremental_v2p (bool): Whether to enable incremental V2P (Virtual to Physical) export. When enabled, the export will be configured for incremental backups.. [optional]  # noqa: E501
            backup_frequency_minutes (int): The frequency with which the incremental backup will be taken in minutes.. [optional] if omitted the server will use the default value of 30  # noqa: E501
            rman_channels_for_incremental_backup (int): Number of data streams to connect to the database for incremental backup.. [optional] if omitted the server will use the default value of 8  # noqa: E501
            rman_files_per_set_for_incremental_backup (int): Number of data files to include in each RMAN backup set for incremental backup.. [optional] if omitted the server will use the default value of 5  # noqa: E501
            rman_file_section_size_in_gb_for_incremental_backup (int): Number of GigaBytes in which RMAN will break large files to back them up in parallel for incremental backup.. [optional] if omitted the server will use the default value of 0  # noqa: E501
            redo_diskgroup (str): Diskgroup for archive logs. Optional as it is not required for PDB databases.. [optional]  # noqa: E501
            rman_channels (int): Number of data streams to connect to the database.. [optional] if omitted the server will use the default value of 8  # noqa: E501
            rman_file_section_size_in_gb (int): Number of GigaBytes in which RMAN will break large files to back them in parallel.. [optional] if omitted the server will use the default value of 0  # noqa: E501
            snapshot_id (str): The ID of the snapshot from which to execute the operation. If snapshot_id is not provided, the latest snapshot will be selected.. [optional]  # noqa: E501
        """

        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        self = super(OpenApiModel, cls).__new__(cls)

        if args:
            raise ApiTypeError(
                "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments." % (
                    args,
                    self.__class__.__name__,
                ),
                path_to_item=_path_to_item,
                valid_classes=(self.__class__,),
            )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        constant_args = {
            '_check_type': _check_type,
            '_path_to_item': _path_to_item,
            '_spec_property_naming': _spec_property_naming,
            '_configuration': _configuration,
            '_visited_composed_classes': self._visited_composed_classes,
        }
        composed_info = validate_get_composed_info(
            constant_args, kwargs, self)
        self._composed_instances = composed_info[0]
        self._var_name_to_model_instances = composed_info[1]
        self._additional_properties_model_instances = composed_info[2]
        discarded_args = composed_info[3]

        for var_name, var_value in kwargs.items():
            if var_name in discarded_args and \
                        self._configuration is not None and \
                        self._configuration.discard_unknown_keys and \
                        self._additional_properties_model_instances:
                # discard variable.
                continue
            setattr(self, var_name, var_value)

        return self

    required_properties = set([
        '_data_store',
        '_check_type',
        '_spec_property_naming',
        '_path_to_item',
        '_configuration',
        '_visited_composed_classes',
        '_composed_instances',
        '_var_name_to_model_instances',
        '_additional_properties_model_instances',
    ])

    @convert_js_args_to_python_args
    def __init__(self, *args, **kwargs):  # noqa: E501
        """OracleAsmExportBySnapshotParameters - a model defined in OpenAPI

        Keyword Args:
            default_data_diskgroup (str): Default diskgroup for datafiles.
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            unique_name (str): The unique name of the database.. [optional]  # noqa: E501
            database_name (str): The name of the database.. [optional]  # noqa: E501
            repository_id (str): The repository_id to use for this operation.. [optional]  # noqa: E501
            environment_user_ref (str): The environment user reference.. [optional]  # noqa: E501
            tde_keystore_password (str): The password for the Transparent Data Encryption keystore associated with this database.. [optional]  # noqa: E501
            tde_keystore_config_type (OracleTdeKeystoreConfigTypeEnum): [optional]  # noqa: E501
            oracle_instance_name (str): SID of the exported database. [optional]  # noqa: E501
            instance_number (int): The number of the instance.. [optional]  # noqa: E501
            instances ([OracleRACDatabaseInstance]): [optional]  # noqa: E501
            mount_base (str): The base mount point to use for the NFS mounts for the temporary VDB.. [optional]  # noqa: E501
            config_params ({str: (bool, date, datetime, dict, float, int, list, str, none_type)}, none_type): Database configuration parameter overrides.. [optional]  # noqa: E501
            cdb_id (str): ID of an Oracle multitenant database this pluggable database belongs to.. [optional]  # noqa: E501
            parent_tde_keystore_path (str): Path to a copy of the parent's Oracle transparent data encryption keystore on the target host.. [optional]  # noqa: E501
            parent_tde_keystore_password (str): The password of the keystore specified in parentTdeKeystorePath.. [optional]  # noqa: E501
            tde_exported_keyfile_secret (str): Secret to be used while exporting and importing vPDB encryption keys.. [optional]  # noqa: E501
            tde_key_identifier (str): PDB database master encryption key id, as recorded in v$encryption_keys.key_id.. [optional]  # noqa: E501
            parent_pdb_tde_keystore_path (str): Path to a copy of the parent PDB's Oracle transparent data encryption keystore on the target host. Required to export of PDB containing encrypted database files with isolated mode keystore.(Oracle Multitenant Only) . [optional]  # noqa: E501
            parent_pdb_tde_keystore_password (str): The password of the parent PDB keystore. (Oracle Multitenant Only). [optional]  # noqa: E501
            target_pdb_tde_keystore_password (str): The password for the isolated mode TDE keystore of the target PDB. (Oracle Multitenant Only). [optional]  # noqa: E501
            crs_database_name (str): The Oracle Clusterware database name.. [optional]  # noqa: E501
            recover_database (bool): If specified, then take the exported database through recovery procedures, if necessary, to reach a consistent point.. [optional] if omitted the server will use the default value of True  # noqa: E501
            file_mapping_rules (str): Database file mapping rules.. [optional]  # noqa: E501
            enable_cdc (bool): Indicates whether to enable Change Data Capture (CDC) or not on exported database(MSSql Only).. [optional] if omitted the server will use the default value of False  # noqa: E501
            recovery_model (str): Recovery model of the database (MSSql Only).. [optional] if omitted the server will use the default value of "FULL"  # noqa: E501
            mirroring_state (str): Recovery model of the database (MSSql Only).. [optional] if omitted the server will use the default value of "NONE"  # noqa: E501
            is_incremental_v2p (bool): Whether to enable incremental V2P (Virtual to Physical) export. When enabled, the export will be configured for incremental backups.. [optional]  # noqa: E501
            backup_frequency_minutes (int): The frequency with which the incremental backup will be taken in minutes.. [optional] if omitted the server will use the default value of 30  # noqa: E501
            rman_channels_for_incremental_backup (int): Number of data streams to connect to the database for incremental backup.. [optional] if omitted the server will use the default value of 8  # noqa: E501
            rman_files_per_set_for_incremental_backup (int): Number of data files to include in each RMAN backup set for incremental backup.. [optional] if omitted the server will use the default value of 5  # noqa: E501
            rman_file_section_size_in_gb_for_incremental_backup (int): Number of GigaBytes in which RMAN will break large files to back them up in parallel for incremental backup.. [optional] if omitted the server will use the default value of 0  # noqa: E501
            redo_diskgroup (str): Diskgroup for archive logs. Optional as it is not required for PDB databases.. [optional]  # noqa: E501
            rman_channels (int): Number of data streams to connect to the database.. [optional] if omitted the server will use the default value of 8  # noqa: E501
            rman_file_section_size_in_gb (int): Number of GigaBytes in which RMAN will break large files to back them in parallel.. [optional] if omitted the server will use the default value of 0  # noqa: E501
            snapshot_id (str): The ID of the snapshot from which to execute the operation. If snapshot_id is not provided, the latest snapshot will be selected.. [optional]  # noqa: E501
        """

        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        if args:
            raise ApiTypeError(
                "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments." % (
                    args,
                    self.__class__.__name__,
                ),
                path_to_item=_path_to_item,
                valid_classes=(self.__class__,),
            )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        constant_args = {
            '_check_type': _check_type,
            '_path_to_item': _path_to_item,
            '_spec_property_naming': _spec_property_naming,
            '_configuration': _configuration,
            '_visited_composed_classes': self._visited_composed_classes,
        }
        composed_info = validate_get_composed_info(
            constant_args, kwargs, self)
        self._composed_instances = composed_info[0]
        self._var_name_to_model_instances = composed_info[1]
        self._additional_properties_model_instances = composed_info[2]
        discarded_args = composed_info[3]

        for var_name, var_value in kwargs.items():
            if var_name in discarded_args and \
                        self._configuration is not None and \
                        self._configuration.discard_unknown_keys and \
                        self._additional_properties_model_instances:
                # discard variable.
                continue
            setattr(self, var_name, var_value)
            if var_name in self.read_only_vars:
                raise ApiAttributeError(f"`{var_name}` is a read-only attribute. Use `from_openapi_data` to instantiate "
                                     f"class with read only attributes.")

    @cached_property
    def _composed_schemas():
        # we need this here to make our import statements work
        # we must store _composed_schemas in here so the code is only run
        # when we invoke this method. If we kept this at the class
        # level we would get an error beause the class level
        # code would be run when this module is imported, and these composed
        # classes don't exist yet because their module has not finished
        # loading
        lazy_import()
        return {
          'anyOf': [
          ],
          'allOf': [
              BaseExportTransferStrategyParameters,
              ExportBySnapshotParametersAllOf,
              ExportDBTimeflowPointParameters,
              OracleAsmLayoutParameters,
          ],
          'oneOf': [
          ],
        }
