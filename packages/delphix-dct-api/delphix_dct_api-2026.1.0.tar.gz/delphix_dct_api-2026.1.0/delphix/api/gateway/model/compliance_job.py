"""
    Delphix DCT API

    Delphix DCT API  # noqa: E501

    The version of the OpenAPI document: 3.26.0
    Contact: support@delphix.com
    Generated by: https://openapi-generator.tech
"""


import re  # noqa: F401
import sys  # noqa: F401

from delphix.api.gateway.model_utils import (  # noqa: F401
    ApiTypeError,
    ModelComposed,
    ModelNormal,
    ModelSimple,
    cached_property,
    change_keys_js_to_python,
    convert_js_args_to_python_args,
    date,
    datetime,
    file_type,
    none_type,
    validate_get_composed_info,
)
from ..model_utils import OpenApiModel
from delphix.api.gateway.exceptions import ApiAttributeError


def lazy_import():
    from delphix.api.gateway.model.compliance_job_script import ComplianceJobScript
    from delphix.api.gateway.model.execution_status import ExecutionStatus
    from delphix.api.gateway.model.tag import Tag
    globals()['ComplianceJobScript'] = ComplianceJobScript
    globals()['ExecutionStatus'] = ExecutionStatus
    globals()['Tag'] = Tag


class ComplianceJob(ModelNormal):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.

    Attributes:
      allowed_values (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          with a capitalized key describing the allowed value and an allowed
          value. These dicts store the allowed enum values.
      attribute_map (dict): The key is attribute name
          and the value is json key in definition.
      discriminator_value_class_map (dict): A dict to go from the discriminator
          variable value to the discriminator class name.
      validations (dict): The key is the tuple path to the attribute
          and the for var_name this is (var_name,). The value is a dict
          that stores validations for max_length, min_length, max_items,
          min_items, exclusive_maximum, inclusive_maximum, exclusive_minimum,
          inclusive_minimum, and regex.
      additional_properties_type (tuple): A tuple of classes accepted
          as additional properties values.
    """

    allowed_values = {
        ('type',): {
            'MASKING': "MASKING",
            'DISCOVERY': "DISCOVERY",
            'TOKENIZATION': "TOKENIZATION",
            'REIDENTIFICATION': "REIDENTIFICATION",
        },
        ('execution_type',): {
            'STANDARD': "STANDARD",
            'HYPERSCALE': "HYPERSCALE",
        },
        ('retain_execution_data',): {
            'NO': "NO",
            'ON_ERROR': "ON_ERROR",
            'ALWAYS': "ALWAYS",
        },
    }

    validations = {
        ('max_memory',): {
            'inclusive_minimum': 0,
        },
        ('min_memory',): {
            'inclusive_minimum': 0,
        },
        ('feedback_size',): {
            'inclusive_minimum': 1,
        },
        ('stream_row_limit',): {
            'inclusive_minimum': -1,
        },
        ('num_input_streams',): {
            'inclusive_minimum': 1,
        },
        ('commit_size',): {
            'inclusive_minimum': 1,
        },
        ('num_output_threads_per_stream',): {
            'inclusive_minimum': 1,
        },
    }

    @cached_property
    def additional_properties_type():
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded
        """
        lazy_import()
        return (bool, date, datetime, dict, float, int, list, str, none_type,)  # noqa: E501

    _nullable = False

    @cached_property
    def openapi_types():
        """
        This must be a method because a model may have properties that are
        of type self, this must run after the class is loaded

        Returns
            openapi_types (dict): The key is attribute name
                and the value is attribute type.
        """
        lazy_import()
        return {
            'id': (str,),  # noqa: E501
            'name': (str,),  # noqa: E501
            'rule_set_id': (str,),  # noqa: E501
            'rule_set_name': (str,),  # noqa: E501
            'connector_type': (str,),  # noqa: E501
            'is_on_the_fly_masking': (bool,),  # noqa: E501
            'is_multi_tenant': (bool,),  # noqa: E501
            'pre_script': (ComplianceJobScript,),  # noqa: E501
            'post_script': (ComplianceJobScript,),  # noqa: E501
            'creation_date': (datetime,),  # noqa: E501
            'last_completed_execution_date': (datetime,),  # noqa: E501
            'last_execution_status': (ExecutionStatus,),  # noqa: E501
            'last_execution_id': (str,),  # noqa: E501
            'last_execution_start_time': (datetime,),  # noqa: E501
            'last_execution_run_time': (int,),  # noqa: E501
            'on_the_fly_source_connector_id': (str, none_type,),  # noqa: E501
            'on_the_fly_source_connector_name': (str, none_type,),  # noqa: E501
            'on_the_fly_source_connector_type': (str, none_type,),  # noqa: E501
            'type': (str,),  # noqa: E501
            'execution_type': (str,),  # noqa: E501
            'hyperscale_instance_id': (str,),  # noqa: E501
            'description': (str,),  # noqa: E501
            'dataset_id': (str,),  # noqa: E501
            'retain_execution_data': (str,),  # noqa: E501
            'max_memory': (int,),  # noqa: E501
            'min_memory': (int,),  # noqa: E501
            'feedback_size': (int,),  # noqa: E501
            'stream_row_limit': (int,),  # noqa: E501
            'num_input_streams': (int,),  # noqa: E501
            'max_concurrent_source_connections': (int,),  # noqa: E501
            'max_concurrent_target_connections': (int,),  # noqa: E501
            'parallelism_degree': (int,),  # noqa: E501
            'source_masking_job_id': (str,),  # noqa: E501
            'engine_id': (str,),  # noqa: E501
            'engine_name': (str,),  # noqa: E501
            'engine_ids': ([str],),  # noqa: E501
            'discovery_policy_id': (str, none_type,),  # noqa: E501
            'discovery_policy_name': (str, none_type,),  # noqa: E501
            'environment_name': (str,),  # noqa: E501
            'application_name': (str,),  # noqa: E501
            'account_id': (int,),  # noqa: E501
            'account_name': (str,),  # noqa: E501
            'dct_managed': (bool,),  # noqa: E501
            'fail_immediately': (bool,),  # noqa: E501
            'batch_update': (bool,),  # noqa: E501
            'commit_size': (int,),  # noqa: E501
            'num_output_threads_per_stream': (int,),  # noqa: E501
            'tags': ([Tag],),  # noqa: E501
            'job_orchestrator_id': (str,),  # noqa: E501
            'job_orchestrator_name': (str,),  # noqa: E501
            'reset_profiling_assignments': (bool,),  # noqa: E501
            'multiple_profiler_check': (bool,),  # noqa: E501
        }

    @cached_property
    def discriminator():
        return None


    attribute_map = {
        'id': 'id',  # noqa: E501
        'name': 'name',  # noqa: E501
        'rule_set_id': 'rule_set_id',  # noqa: E501
        'rule_set_name': 'rule_set_name',  # noqa: E501
        'connector_type': 'connector_type',  # noqa: E501
        'is_on_the_fly_masking': 'is_on_the_fly_masking',  # noqa: E501
        'is_multi_tenant': 'is_multi_tenant',  # noqa: E501
        'pre_script': 'pre_script',  # noqa: E501
        'post_script': 'post_script',  # noqa: E501
        'creation_date': 'creation_date',  # noqa: E501
        'last_completed_execution_date': 'last_completed_execution_date',  # noqa: E501
        'last_execution_status': 'last_execution_status',  # noqa: E501
        'last_execution_id': 'last_execution_id',  # noqa: E501
        'last_execution_start_time': 'last_execution_start_time',  # noqa: E501
        'last_execution_run_time': 'last_execution_run_time',  # noqa: E501
        'on_the_fly_source_connector_id': 'on_the_fly_source_connector_id',  # noqa: E501
        'on_the_fly_source_connector_name': 'on_the_fly_source_connector_name',  # noqa: E501
        'on_the_fly_source_connector_type': 'on_the_fly_source_connector_type',  # noqa: E501
        'type': 'type',  # noqa: E501
        'execution_type': 'execution_type',  # noqa: E501
        'hyperscale_instance_id': 'hyperscale_instance_id',  # noqa: E501
        'description': 'description',  # noqa: E501
        'dataset_id': 'dataset_id',  # noqa: E501
        'retain_execution_data': 'retain_execution_data',  # noqa: E501
        'max_memory': 'max_memory',  # noqa: E501
        'min_memory': 'min_memory',  # noqa: E501
        'feedback_size': 'feedback_size',  # noqa: E501
        'stream_row_limit': 'stream_row_limit',  # noqa: E501
        'num_input_streams': 'num_input_streams',  # noqa: E501
        'max_concurrent_source_connections': 'max_concurrent_source_connections',  # noqa: E501
        'max_concurrent_target_connections': 'max_concurrent_target_connections',  # noqa: E501
        'parallelism_degree': 'parallelism_degree',  # noqa: E501
        'source_masking_job_id': 'source_masking_job_id',  # noqa: E501
        'engine_id': 'engine_id',  # noqa: E501
        'engine_name': 'engine_name',  # noqa: E501
        'engine_ids': 'engine_ids',  # noqa: E501
        'discovery_policy_id': 'discovery_policy_id',  # noqa: E501
        'discovery_policy_name': 'discovery_policy_name',  # noqa: E501
        'environment_name': 'environment_name',  # noqa: E501
        'application_name': 'application_name',  # noqa: E501
        'account_id': 'account_id',  # noqa: E501
        'account_name': 'account_name',  # noqa: E501
        'dct_managed': 'dct_managed',  # noqa: E501
        'fail_immediately': 'fail_immediately',  # noqa: E501
        'batch_update': 'batch_update',  # noqa: E501
        'commit_size': 'commit_size',  # noqa: E501
        'num_output_threads_per_stream': 'num_output_threads_per_stream',  # noqa: E501
        'tags': 'tags',  # noqa: E501
        'job_orchestrator_id': 'job_orchestrator_id',  # noqa: E501
        'job_orchestrator_name': 'job_orchestrator_name',  # noqa: E501
        'reset_profiling_assignments': 'reset_profiling_assignments',  # noqa: E501
        'multiple_profiler_check': 'multiple_profiler_check',  # noqa: E501
    }

    read_only_vars = {
        'id',  # noqa: E501
        'job_orchestrator_id',  # noqa: E501
        'job_orchestrator_name',  # noqa: E501
    }

    _composed_schemas = {}

    @classmethod
    @convert_js_args_to_python_args
    def _from_openapi_data(cls, *args, **kwargs):  # noqa: E501
        """ComplianceJob - a model defined in OpenAPI

        Keyword Args:
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            id (str): The Compliance Job entity ID.. [optional]  # noqa: E501
            name (str): The name of this Compliance Job.. [optional]  # noqa: E501
            rule_set_id (str): The ID of the Rule Set used by this Compliance Job (Standard Job only). For hyperscale jobs, see dataset_id.. [optional]  # noqa: E501
            rule_set_name (str): The name of the Rule Set used by this Compliance Job (Standard Job only). For hyperscale jobs, see dataset_id.. [optional]  # noqa: E501
            connector_type (str): The type of data being masked by this Job. If the Compliance Job is masking a database this is the type of the database (Standard Job only).. [optional]  # noqa: E501
            is_on_the_fly_masking (bool): Whether this is an on-the-fly masking job (Standard Job only).. [optional]  # noqa: E501
            is_multi_tenant (bool): If true, this job must be executed using a connector that is different from the underlying connector associated with its ruleset.. [optional]  # noqa: E501
            pre_script (ComplianceJobScript): [optional]  # noqa: E501
            post_script (ComplianceJobScript): [optional]  # noqa: E501
            creation_date (datetime): The date this ComplianceJob was created (Standard Job only).. [optional]  # noqa: E501
            last_completed_execution_date (datetime): The date this ComplianceJob was last executed to completion.. [optional]  # noqa: E501
            last_execution_status (ExecutionStatus): [optional]  # noqa: E501
            last_execution_id (str): The ID of this ComplianceJob's last execution.. [optional]  # noqa: E501
            last_execution_start_time (datetime): The start time of the most recent execution of this compliance job.. [optional]  # noqa: E501
            last_execution_run_time (int): The run time of the most recent execution of this compliance job in ms.. [optional]  # noqa: E501
            on_the_fly_source_connector_id (str, none_type): The ID of the OTF source connector for this job. [optional]  # noqa: E501
            on_the_fly_source_connector_name (str, none_type): The name of the OTF source connector for this job. [optional]  # noqa: E501
            on_the_fly_source_connector_type (str, none_type): The type of the OTF source connector for this job. [optional]  # noqa: E501
            type (str): The type of compliance job.. [optional]  # noqa: E501
            execution_type (str): The execution type of this Job.. [optional]  # noqa: E501
            hyperscale_instance_id (str): The ID of the Hyperscale instance of this job (Hyperscale Job only).. [optional]  # noqa: E501
            description (str): Description of the job (Hyperscale Job only).. [optional]  # noqa: E501
            dataset_id (str): Dataset of the Hyperscale Job (Hyperscale Job only).. [optional]  # noqa: E501
            retain_execution_data (str): Defines whether execution data will be stored after execution is complete (Hyperscale Job only).. [optional]  # noqa: E501
            max_memory (int): The maximum amount of memory, in MB, that the compliance job can consume during execution. A value of 0 uses the default max memory set in application settings.. [optional] if omitted the server will use the default value of 0  # noqa: E501
            min_memory (int): The minimum amount of memory, in MB, that the compliance job can consume during execution.. [optional]  # noqa: E501
            feedback_size (int): The granularity with which the system provides updates on the progress of the compliance job. For instance, a feedback size of 50000 results in log updates whenever 50000 rows are processed during the masking phase.. [optional]  # noqa: E501
            stream_row_limit (int): This value constrains the total number of rows that may enter the job for each masking stream. A value of 0 means unlimited. A value of -1 selects the default value. The default value for this setting varies by job type. The minimum explicit value allowed is 20.. [optional]  # noqa: E501
            num_input_streams (int): This field controls the amount of parallelism that the masking job uses to extract out the data to be masked.. [optional] if omitted the server will use the default value of 1  # noqa: E501
            max_concurrent_source_connections (int): Maximum number of parallel connection that the Hyperscale instance can have with the source datasource (Hyperscale Job only).. [optional]  # noqa: E501
            max_concurrent_target_connections (int): Maximum number of parallel connection that the Hyperscale instance can have with the target datasource (Hyperscale Job only).. [optional]  # noqa: E501
            parallelism_degree (int): The degree of parallelism (DOP) per Oracle job to recreate the index in the post-load process (Hyperscale Job only).. [optional]  # noqa: E501
            source_masking_job_id (str): The ID of the MaskingJob that was used as the source to create this job (Hyperscale Job only).. [optional]  # noqa: E501
            engine_id (str): The engine on which this job resides (Standard Job only).. [optional]  # noqa: E501
            engine_name (str): The name of the engine on which this job resides (Standard Job only).. [optional]  # noqa: E501
            engine_ids ([str]): List of engines that this job can run on (Hyperscale Job only).. [optional]  # noqa: E501
            discovery_policy_id (str, none_type): The id of the discovery policy in use - applicable for discovery jobs only.. [optional]  # noqa: E501
            discovery_policy_name (str, none_type): The name of the discovery policy in use - applicable for discovery jobs only.. [optional]  # noqa: E501
            environment_name (str): The name of the environment in which this job resides on the compliance engine.. [optional]  # noqa: E501
            application_name (str): The name of the application associated with the environment in which this job resides on the compliance engine.. [optional]  # noqa: E501
            account_id (int): The ID of the Account that created this ComplianceJob (Standard Job only).. [optional]  # noqa: E501
            account_name (str): The username of the Account that created this ComplianceJob (Standard Job only).. [optional]  # noqa: E501
            dct_managed (bool): Whether or not this ComplianceJob is managed by DCT (Standard Job only).. [optional]  # noqa: E501
            fail_immediately (bool): Whether to fail immediately or delay failure until job completion when a masking algorithm fails to mask its data (Standard Job only).. [optional] if omitted the server will use the default value of False  # noqa: E501
            batch_update (bool): Whether the database load phase to output the masked data will be performed in batches. The size of the batches is determined by the field 'commit_size'. (Standard Job only).. [optional] if omitted the server will use the default value of True  # noqa: E501
            commit_size (int): The size of the database commits when performing batch updates (Standard Job only).. [optional]  # noqa: E501
            num_output_threads_per_stream (int): The amount of parallelism, per input stream, that the job uses to load back the masked data. For example, specifying 4 output threads per stream with 5 input streams results in a total of 20 output threads for the whole job. (Standard Job only).. [optional] if omitted the server will use the default value of 1  # noqa: E501
            tags ([Tag]): [optional]  # noqa: E501
            job_orchestrator_id (str): [optional]  # noqa: E501
            job_orchestrator_name (str): [optional]  # noqa: E501
            reset_profiling_assignments (bool): Determines whether the ruleset assignments for the previous profiling execution need to be cleared before this job gets executed.. [optional]  # noqa: E501
            multiple_profiler_check (bool): When enabled, assigns a default algorithm if multiple classifiers match across different data classes above the threshold.. [optional]  # noqa: E501
        """

        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        self = super(OpenApiModel, cls).__new__(cls)

        if args:
            raise ApiTypeError(
                "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments." % (
                    args,
                    self.__class__.__name__,
                ),
                path_to_item=_path_to_item,
                valid_classes=(self.__class__,),
            )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        for var_name, var_value in kwargs.items():
            if var_name not in self.attribute_map and \
                        self._configuration is not None and \
                        self._configuration.discard_unknown_keys and \
                        self.additional_properties_type is None:
                # discard variable.
                continue
            setattr(self, var_name, var_value)
        return self

    required_properties = set([
        '_data_store',
        '_check_type',
        '_spec_property_naming',
        '_path_to_item',
        '_configuration',
        '_visited_composed_classes',
    ])

    @convert_js_args_to_python_args
    def __init__(self, *args, **kwargs):  # noqa: E501
        """ComplianceJob - a model defined in OpenAPI

        Keyword Args:
            _check_type (bool): if True, values for parameters in openapi_types
                                will be type checked and a TypeError will be
                                raised if the wrong type is input.
                                Defaults to True
            _path_to_item (tuple/list): This is a list of keys or values to
                                drill down to the model in received_data
                                when deserializing a response
            _spec_property_naming (bool): True if the variable names in the input data
                                are serialized names, as specified in the OpenAPI document.
                                False if the variable names in the input data
                                are pythonic names, e.g. snake case (default)
            _configuration (Configuration): the instance to use when
                                deserializing a file_type parameter.
                                If passed, type conversion is attempted
                                If omitted no type conversion is done.
            _visited_composed_classes (tuple): This stores a tuple of
                                classes that we have traveled through so that
                                if we see that class again we will not use its
                                discriminator again.
                                When traveling through a discriminator, the
                                composed schema that is
                                is traveled through is added to this set.
                                For example if Animal has a discriminator
                                petType and we pass in "Dog", and the class Dog
                                allOf includes Animal, we move through Animal
                                once using the discriminator, and pick Dog.
                                Then in Dog, we will make an instance of the
                                Animal class but this time we won't travel
                                through its discriminator because we passed in
                                _visited_composed_classes = (Animal,)
            id (str): The Compliance Job entity ID.. [optional]  # noqa: E501
            name (str): The name of this Compliance Job.. [optional]  # noqa: E501
            rule_set_id (str): The ID of the Rule Set used by this Compliance Job (Standard Job only). For hyperscale jobs, see dataset_id.. [optional]  # noqa: E501
            rule_set_name (str): The name of the Rule Set used by this Compliance Job (Standard Job only). For hyperscale jobs, see dataset_id.. [optional]  # noqa: E501
            connector_type (str): The type of data being masked by this Job. If the Compliance Job is masking a database this is the type of the database (Standard Job only).. [optional]  # noqa: E501
            is_on_the_fly_masking (bool): Whether this is an on-the-fly masking job (Standard Job only).. [optional]  # noqa: E501
            is_multi_tenant (bool): If true, this job must be executed using a connector that is different from the underlying connector associated with its ruleset.. [optional]  # noqa: E501
            pre_script (ComplianceJobScript): [optional]  # noqa: E501
            post_script (ComplianceJobScript): [optional]  # noqa: E501
            creation_date (datetime): The date this ComplianceJob was created (Standard Job only).. [optional]  # noqa: E501
            last_completed_execution_date (datetime): The date this ComplianceJob was last executed to completion.. [optional]  # noqa: E501
            last_execution_status (ExecutionStatus): [optional]  # noqa: E501
            last_execution_id (str): The ID of this ComplianceJob's last execution.. [optional]  # noqa: E501
            last_execution_start_time (datetime): The start time of the most recent execution of this compliance job.. [optional]  # noqa: E501
            last_execution_run_time (int): The run time of the most recent execution of this compliance job in ms.. [optional]  # noqa: E501
            on_the_fly_source_connector_id (str, none_type): The ID of the OTF source connector for this job. [optional]  # noqa: E501
            on_the_fly_source_connector_name (str, none_type): The name of the OTF source connector for this job. [optional]  # noqa: E501
            on_the_fly_source_connector_type (str, none_type): The type of the OTF source connector for this job. [optional]  # noqa: E501
            type (str): The type of compliance job.. [optional]  # noqa: E501
            execution_type (str): The execution type of this Job.. [optional]  # noqa: E501
            hyperscale_instance_id (str): The ID of the Hyperscale instance of this job (Hyperscale Job only).. [optional]  # noqa: E501
            description (str): Description of the job (Hyperscale Job only).. [optional]  # noqa: E501
            dataset_id (str): Dataset of the Hyperscale Job (Hyperscale Job only).. [optional]  # noqa: E501
            retain_execution_data (str): Defines whether execution data will be stored after execution is complete (Hyperscale Job only).. [optional]  # noqa: E501
            max_memory (int): The maximum amount of memory, in MB, that the compliance job can consume during execution. A value of 0 uses the default max memory set in application settings.. [optional] if omitted the server will use the default value of 0  # noqa: E501
            min_memory (int): The minimum amount of memory, in MB, that the compliance job can consume during execution.. [optional]  # noqa: E501
            feedback_size (int): The granularity with which the system provides updates on the progress of the compliance job. For instance, a feedback size of 50000 results in log updates whenever 50000 rows are processed during the masking phase.. [optional]  # noqa: E501
            stream_row_limit (int): This value constrains the total number of rows that may enter the job for each masking stream. A value of 0 means unlimited. A value of -1 selects the default value. The default value for this setting varies by job type. The minimum explicit value allowed is 20.. [optional]  # noqa: E501
            num_input_streams (int): This field controls the amount of parallelism that the masking job uses to extract out the data to be masked.. [optional] if omitted the server will use the default value of 1  # noqa: E501
            max_concurrent_source_connections (int): Maximum number of parallel connection that the Hyperscale instance can have with the source datasource (Hyperscale Job only).. [optional]  # noqa: E501
            max_concurrent_target_connections (int): Maximum number of parallel connection that the Hyperscale instance can have with the target datasource (Hyperscale Job only).. [optional]  # noqa: E501
            parallelism_degree (int): The degree of parallelism (DOP) per Oracle job to recreate the index in the post-load process (Hyperscale Job only).. [optional]  # noqa: E501
            source_masking_job_id (str): The ID of the MaskingJob that was used as the source to create this job (Hyperscale Job only).. [optional]  # noqa: E501
            engine_id (str): The engine on which this job resides (Standard Job only).. [optional]  # noqa: E501
            engine_name (str): The name of the engine on which this job resides (Standard Job only).. [optional]  # noqa: E501
            engine_ids ([str]): List of engines that this job can run on (Hyperscale Job only).. [optional]  # noqa: E501
            discovery_policy_id (str, none_type): The id of the discovery policy in use - applicable for discovery jobs only.. [optional]  # noqa: E501
            discovery_policy_name (str, none_type): The name of the discovery policy in use - applicable for discovery jobs only.. [optional]  # noqa: E501
            environment_name (str): The name of the environment in which this job resides on the compliance engine.. [optional]  # noqa: E501
            application_name (str): The name of the application associated with the environment in which this job resides on the compliance engine.. [optional]  # noqa: E501
            account_id (int): The ID of the Account that created this ComplianceJob (Standard Job only).. [optional]  # noqa: E501
            account_name (str): The username of the Account that created this ComplianceJob (Standard Job only).. [optional]  # noqa: E501
            dct_managed (bool): Whether or not this ComplianceJob is managed by DCT (Standard Job only).. [optional]  # noqa: E501
            fail_immediately (bool): Whether to fail immediately or delay failure until job completion when a masking algorithm fails to mask its data (Standard Job only).. [optional] if omitted the server will use the default value of False  # noqa: E501
            batch_update (bool): Whether the database load phase to output the masked data will be performed in batches. The size of the batches is determined by the field 'commit_size'. (Standard Job only).. [optional] if omitted the server will use the default value of True  # noqa: E501
            commit_size (int): The size of the database commits when performing batch updates (Standard Job only).. [optional]  # noqa: E501
            num_output_threads_per_stream (int): The amount of parallelism, per input stream, that the job uses to load back the masked data. For example, specifying 4 output threads per stream with 5 input streams results in a total of 20 output threads for the whole job. (Standard Job only).. [optional] if omitted the server will use the default value of 1  # noqa: E501
            tags ([Tag]): [optional]  # noqa: E501
            job_orchestrator_id (str): [optional]  # noqa: E501
            job_orchestrator_name (str): [optional]  # noqa: E501
            reset_profiling_assignments (bool): Determines whether the ruleset assignments for the previous profiling execution need to be cleared before this job gets executed.. [optional]  # noqa: E501
            multiple_profiler_check (bool): When enabled, assigns a default algorithm if multiple classifiers match across different data classes above the threshold.. [optional]  # noqa: E501
        """

        _check_type = kwargs.pop('_check_type', True)
        _spec_property_naming = kwargs.pop('_spec_property_naming', False)
        _path_to_item = kwargs.pop('_path_to_item', ())
        _configuration = kwargs.pop('_configuration', None)
        _visited_composed_classes = kwargs.pop('_visited_composed_classes', ())

        if args:
            raise ApiTypeError(
                "Invalid positional arguments=%s passed to %s. Remove those invalid positional arguments." % (
                    args,
                    self.__class__.__name__,
                ),
                path_to_item=_path_to_item,
                valid_classes=(self.__class__,),
            )

        self._data_store = {}
        self._check_type = _check_type
        self._spec_property_naming = _spec_property_naming
        self._path_to_item = _path_to_item
        self._configuration = _configuration
        self._visited_composed_classes = _visited_composed_classes + (self.__class__,)

        for var_name, var_value in kwargs.items():
            if var_name not in self.attribute_map and \
                        self._configuration is not None and \
                        self._configuration.discard_unknown_keys and \
                        self.additional_properties_type is None:
                # discard variable.
                continue
            setattr(self, var_name, var_value)
            if var_name in self.read_only_vars:
                raise ApiAttributeError(f"`{var_name}` is a read-only attribute. Use `from_openapi_data` to instantiate "
                                     f"class with read only attributes.")
