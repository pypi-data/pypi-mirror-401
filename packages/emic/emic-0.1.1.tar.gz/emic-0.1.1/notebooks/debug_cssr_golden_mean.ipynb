{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c04e92f",
   "metadata": {},
   "source": [
    "# CSSR Algorithm Debugging: Golden Mean Process\n",
    "\n",
    "This notebook provides a step-by-step walkthrough of the CSSR (Causal State Splitting Reconstruction) algorithm applied to the Golden Mean process.\n",
    "\n",
    "## Expected Result\n",
    "\n",
    "The Golden Mean process forbids consecutive 1s. It has exactly **2 causal states**:\n",
    "- **State A**: Last symbol was 0 → can emit 0 or 1 with probability p and 1-p\n",
    "- **State B**: Last symbol was 1 → must emit 0 with probability 1.0\n",
    "\n",
    "The true entropy rate is: $h_\\mu = -p \\log_2(p) / (1 + p)$ where $p$ is the probability of emitting 1 after a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03377082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "from emic.sources import GoldenMeanSource\n",
    "from emic.inference import CSSR, CSSRConfig\n",
    "from emic.inference.cssr.algorithm import SuffixTree, StatePartition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fbe45",
   "metadata": {},
   "source": [
    "## Step 1: Generate Data\n",
    "\n",
    "Generate a sample from the Golden Mean process with p=0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Golden Mean data\n",
    "source = GoldenMeanSource(p=0.5, _seed=42)\n",
    "data = list(itertools.islice(source, 10000))\n",
    "\n",
    "# Quick statistics\n",
    "print(f\"Data length: {len(data)}\")\n",
    "print(f\"Symbol counts: 0={data.count(0)}, 1={data.count(1)}\")\n",
    "print(f\"First 50 symbols: {data[:50]}\")\n",
    "\n",
    "# Verify no consecutive 1s\n",
    "consecutive_ones = sum(1 for i in range(len(data) - 1) if data[i] == 1 and data[i + 1] == 1)\n",
    "print(f\"Consecutive 1s (should be 0): {consecutive_ones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b7d9d1",
   "metadata": {},
   "source": [
    "## Step 2: Build the Suffix Tree\n",
    "\n",
    "The suffix tree stores statistics for each history (suffix). For each history, we track:\n",
    "- How many times it occurred\n",
    "- The distribution of next symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build suffix tree with max_history=3\n",
    "max_history = 3\n",
    "alphabet = frozenset([0, 1])\n",
    "tree = SuffixTree(max_depth=max_history, alphabet=alphabet)\n",
    "tree.build_from_sequence(data)\n",
    "\n",
    "print(f\"Suffix tree built with max_history={max_history}\")\n",
    "print(f\"Alphabet: {alphabet}\")\n",
    "print(f\"Number of histories: {len(tree)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the suffix tree entries\n",
    "print(\"=== Suffix Tree Statistics ===\")\n",
    "\n",
    "print(\"\\nLength 0 (empty history):\")\n",
    "empty = tree.get_stats(())\n",
    "if empty:\n",
    "    total = sum(empty.next_symbol_counts.values())\n",
    "    print(f\"  (): count={empty.count}, next_symbols={dict(empty.next_symbol_counts)}\")\n",
    "    for sym, cnt in empty.next_symbol_counts.items():\n",
    "        print(f\"      P({sym}|()) = {cnt / total:.4f}\")\n",
    "\n",
    "print(\"\\nLength 1 histories:\")\n",
    "for suffix in [(0,), (1,)]:\n",
    "    stats = tree.get_stats(suffix)\n",
    "    if stats and stats.count > 0:\n",
    "        total = sum(stats.next_symbol_counts.values())\n",
    "        print(f\"  {suffix}: count={stats.count}, next_symbols={dict(stats.next_symbol_counts)}\")\n",
    "        for sym, cnt in stats.next_symbol_counts.items():\n",
    "            print(f\"      P({sym}|{suffix}) = {cnt / total:.4f}\")\n",
    "\n",
    "print(\"\\nLength 2 histories:\")\n",
    "for suffix in [(0, 0), (0, 1), (1, 0)]:\n",
    "    stats = tree.get_stats(suffix)\n",
    "    if stats and stats.count > 0:\n",
    "        total = sum(stats.next_symbol_counts.values())\n",
    "        print(f\"  {suffix}: count={stats.count}, next_symbols={dict(stats.next_symbol_counts)}\")\n",
    "        for sym, cnt in stats.next_symbol_counts.items():\n",
    "            print(f\"      P({sym}|{suffix}) = {cnt / total:.4f}\")\n",
    "\n",
    "print(\"\\nLength 3 histories:\")\n",
    "for suffix in [(0, 0, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0), (1, 0, 1)]:\n",
    "    stats = tree.get_stats(suffix)\n",
    "    if stats and stats.count > 0:\n",
    "        total = sum(stats.next_symbol_counts.values())\n",
    "        print(f\"  {suffix}: count={stats.count}, next_symbols={dict(stats.next_symbol_counts)}\")\n",
    "        for sym, cnt in stats.next_symbol_counts.items():\n",
    "            print(f\"      P({sym}|{suffix}) = {cnt / total:.4f}\")\n",
    "\n",
    "# Note: (1,1) should have 0 count - forbidden\n",
    "stats_11 = tree.get_stats((1, 1))\n",
    "print(f\"\\n  (1,1): count={stats_11.count if stats_11 else 0} (forbidden - should be 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f6bba",
   "metadata": {},
   "source": [
    "## Step 3: Analyze Expected State Assignments\n",
    "\n",
    "Based on the suffix tree, we should see:\n",
    "- Histories ending in 1: `(1,)`, `(0,1)`, `(0,0,1)`, etc. → All have P(0|h) = 1.0 → **Same causal state**\n",
    "- Histories ending in 0: `(0,)`, `(1,0)`, `(0,0)`, etc. → All have P(0|h) ≈ P(1|h) ≈ 0.5 → **Same causal state**\n",
    "\n",
    "The key insight: **Causal states are determined by the distribution of futures, not the specific history.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90882e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize histories by their predictive distribution\n",
    "def get_distribution(tree, suffix):\n",
    "    \"\"\"Get normalized distribution for a suffix.\"\"\"\n",
    "    stats = tree.get_stats(suffix)\n",
    "    if not stats or stats.count == 0:\n",
    "        return None\n",
    "    total = sum(stats.next_symbol_counts.values())\n",
    "    return {sym: cnt / total for sym, cnt in stats.next_symbol_counts.items()}\n",
    "\n",
    "\n",
    "# All possible histories up to length 3 that exist in Golden Mean\n",
    "histories_ending_in_0 = [(0,), (1, 0), (0, 0), (0, 1, 0), (1, 0, 0), (0, 0, 0)]\n",
    "histories_ending_in_1 = [(1,), (0, 1), (1, 0, 1), (0, 0, 1)]\n",
    "\n",
    "print(\"=== Histories Ending in 0 (should all have ~50/50 distribution) ===\")\n",
    "for h in histories_ending_in_0:\n",
    "    dist = get_distribution(tree, h)\n",
    "    if dist:\n",
    "        print(f\"  {h}: P(0)={dist.get(0, 0):.4f}, P(1)={dist.get(1, 0):.4f}\")\n",
    "\n",
    "print(\"\\n=== Histories Ending in 1 (should all have 100% → 0) ===\")\n",
    "for h in histories_ending_in_1:\n",
    "    dist = get_distribution(tree, h)\n",
    "    if dist:\n",
    "        print(f\"  {h}: P(0)={dist.get(0, 0):.4f}, P(1)={dist.get(1, 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cecf30",
   "metadata": {},
   "source": [
    "## Step 4: Run CSSR and Trace State Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CSSR with our configuration\n",
    "from emic.inference import CSSRConfig\n",
    "\n",
    "config = CSSRConfig(max_history=3, significance=0.05, min_count=10)\n",
    "cssr = CSSR(config)\n",
    "\n",
    "# Step through the algorithm manually\n",
    "print(\"=== CSSR Algorithm Trace ===\")\n",
    "\n",
    "# Build suffix tree (same as above)\n",
    "tree2 = SuffixTree(max_depth=config.max_history, alphabet=frozenset([0, 1]))\n",
    "tree2.build_from_sequence(data)\n",
    "\n",
    "\n",
    "# Helper to display partition\n",
    "def show_partition(partition, label):\n",
    "    print(f\"\\n{label}: {len(partition.state_ids())} states\")\n",
    "    for state_id in partition.state_ids():\n",
    "        histories = partition.get_histories(state_id)\n",
    "        print(f\"  {state_id}: {sorted(histories, key=lambda x: (len(x), x))}\")\n",
    "\n",
    "\n",
    "# Initialize partition\n",
    "partition = cssr._initialize_partition(tree2)\n",
    "show_partition(partition, \"After initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split states\n",
    "partition = cssr._split_states(partition, tree2)\n",
    "show_partition(partition, \"After splitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2beffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge states\n",
    "partition = cssr._merge_states(partition, tree2)\n",
    "show_partition(partition, \"After merging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine distributions in each state\n",
    "print(\"=== State Distributions ===\")\n",
    "for state_id in partition.state_ids():\n",
    "    histories = partition.get_histories(state_id)\n",
    "    print(f\"\\n{state_id}:\")\n",
    "    for h in sorted(histories, key=lambda x: (len(x), x)):\n",
    "        dist = get_distribution(tree2, h)\n",
    "        if dist:\n",
    "            print(f\"  {h}: P(0)={dist.get(0, 0):.4f}, P(1)={dist.get(1, 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96a6b3",
   "metadata": {},
   "source": [
    "## Step 5: Run Full Inference and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50941c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full inference\n",
    "result = CSSR(config).infer(data)\n",
    "\n",
    "print(f\"=== Inferred Machine ===\")\n",
    "print(f\"Number of states: {len(result.machine.states)}\")\n",
    "\n",
    "# Expected entropy rate for Golden Mean with p=0.5\n",
    "p = 0.5\n",
    "expected_h = -p * math.log2(p) / (1 + p) if p > 0 else 0\n",
    "print(f\"Expected entropy rate: {expected_h:.4f}\")\n",
    "\n",
    "print(\"\\nTransitions:\")\n",
    "for state in result.machine.states:\n",
    "    print(f\"  State {state.id}:\")\n",
    "    for t in state.transitions:\n",
    "        print(f\"    --{t.symbol} (p={t.probability:.3f})--> {t.target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace the full iteration loop\n",
    "print(\"=== Tracing Full CSSR Iteration ===\\n\")\n",
    "\n",
    "tree3 = SuffixTree(max_depth=config.max_history, alphabet=frozenset([0, 1]))\n",
    "tree3.build_from_sequence(data)\n",
    "\n",
    "partition3 = cssr._initialize_partition(tree3)\n",
    "print(f\"Initial: {len(partition3.state_ids())} states\")\n",
    "\n",
    "for i in range(5):  # Max 5 iterations\n",
    "    old_state_ids = set(partition3.state_ids())\n",
    "    old_assignments = {h: partition3.get_state(h) for h in tree3.all_histories()}\n",
    "\n",
    "    # Split\n",
    "    partition3 = cssr._split_states(partition3, tree3)\n",
    "    print(f\"  Iter {i + 1} after split: {len(partition3.state_ids())} states\")\n",
    "\n",
    "    # Merge\n",
    "    partition3 = cssr._merge_states(partition3, tree3)\n",
    "    print(f\"  Iter {i + 1} after merge: {len(partition3.state_ids())} states\")\n",
    "\n",
    "    new_assignments = {h: partition3.get_state(h) for h in tree3.all_histories()}\n",
    "\n",
    "    # Check if converged\n",
    "    if new_assignments == old_assignments:\n",
    "        print(f\"\\nConverged at iteration {i + 1}!\")\n",
    "        break\n",
    "\n",
    "    # Show changes\n",
    "    for h in sorted(tree3.all_histories(), key=lambda x: (len(x), x)):\n",
    "        old_s = old_assignments.get(h)\n",
    "        new_s = new_assignments.get(h)\n",
    "        if old_s != new_s:\n",
    "            print(f\"    {h}: {old_s} -> {new_s}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nFinal partition: {len(partition3.state_ids())} states\")\n",
    "show_partition(partition3, \"Final state assignments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose: Why is () being split from the other \"ending in 0\" histories?\n",
    "print(\"=== Distribution Comparison ===\\n\")\n",
    "\n",
    "print(\"Empty history vs length-1 histories:\")\n",
    "for h in [(), (0,), (1,)]:\n",
    "    dist = get_distribution(tree3, h)\n",
    "    if dist:\n",
    "        print(f\"  {h}: P(0)={dist.get(0, 0):.4f}, P(1)={dist.get(1, 0):.4f}\")\n",
    "\n",
    "print(\"\\n() reflects the STATIONARY distribution of the process\")\n",
    "print(\"(0,) reflects the CONDITIONAL distribution given last symbol was 0\")\n",
    "print(\"\\nFor Golden Mean with p=0.5:\")\n",
    "print(\"  Stationary: ~2/3 zeros, ~1/3 ones (because 1 must be followed by 0)\")\n",
    "print(\"  After 0: ~50/50 (can emit either)\")\n",
    "print(\"  After 1: 100% -> 0\")\n",
    "\n",
    "print(\"\\n\\n=== Chi-squared test: () vs (0,) ===\")\n",
    "from emic.inference.cssr.tests import distributions_differ\n",
    "\n",
    "stats_empty = tree3.get_stats(())\n",
    "stats_0 = tree3.get_stats((0,))\n",
    "\n",
    "print(f\"(): {dict(stats_empty.next_symbol_counts)}\")\n",
    "print(f\"(0,): {dict(stats_0.next_symbol_counts)}\")\n",
    "\n",
    "# Check if they differ\n",
    "differ = distributions_differ(\n",
    "    stats_empty.next_symbol_counts, stats_0.next_symbol_counts, config.significance\n",
    ")\n",
    "print(f\"\\nDo they differ (α=0.05)? {differ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35474e7",
   "metadata": {},
   "source": [
    "## Root Cause Analysis\n",
    "\n",
    "The issue is that the **empty history `()`** represents a mixture of causal states (weighted by the stationary distribution), not a single causal state.\n",
    "\n",
    "For the Golden Mean process:\n",
    "- `()` has distribution ~66% 0, ~33% 1 (the stationary distribution)\n",
    "- `(0,)` has distribution ~50% 0, ~50% 1 (conditional on being in \"state after 0\")\n",
    "- `(1,)` has distribution 100% 0 (conditional on being in \"state after 1\")\n",
    "\n",
    "Since `()` is statistically different from both `(0,)` and `(1,)`, the chi-squared test correctly identifies it as distinct, leading to 3 states instead of 2.\n",
    "\n",
    "### Solution Options\n",
    "\n",
    "1. **Exclude empty history**: Don't include `()` in the partition. Only use histories of length ≥ 1.\n",
    "\n",
    "2. **Assign `()` to the most likely state**: After inferring states from length ≥ 1 histories, assign `()` to the state with highest stationary probability.\n",
    "\n",
    "3. **Use `()` only for machine building**: Include `()` in the suffix tree for transition calculations but not in state equivalence testing.\n",
    "\n",
    "The standard CSSR approach is option 1: only partition histories of length 1 to L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fix: Exclude empty history from partition\n",
    "print(\"=== Testing Fix: Exclude Empty History ===\\n\")\n",
    "\n",
    "# Manually trace CSSR without empty history\n",
    "tree4 = SuffixTree(max_depth=config.max_history, alphabet=frozenset([0, 1]))\n",
    "tree4.build_from_sequence(data)\n",
    "\n",
    "# Modified initialization: only include histories of length >= 1\n",
    "partition4 = StatePartition()\n",
    "valid_histories = [\n",
    "    h for h in tree4.all_histories() if len(h) >= 1 and tree4.get_stats(h).count >= config.min_count\n",
    "]\n",
    "\n",
    "initial_state = partition4.new_state_id()\n",
    "for h in valid_histories:\n",
    "    partition4.assign(h, initial_state)\n",
    "\n",
    "print(f\"Initial (length >= 1 only): {len(partition4.state_ids())} states\")\n",
    "print(f\"  Histories: {sorted(valid_histories, key=lambda x: (len(x), x))}\")\n",
    "\n",
    "# Run split/merge iterations\n",
    "for i in range(5):\n",
    "    old_assignments = {h: partition4.get_state(h) for h in valid_histories}\n",
    "\n",
    "    partition4 = cssr._split_states(partition4, tree4)\n",
    "    partition4 = cssr._merge_states(partition4, tree4)\n",
    "\n",
    "    new_assignments = {h: partition4.get_state(h) for h in valid_histories}\n",
    "\n",
    "    print(f\"Iter {i + 1}: {len(partition4.state_ids())} states\")\n",
    "\n",
    "    if new_assignments == old_assignments:\n",
    "        print(\"Converged!\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nFinal: {len(partition4.state_ids())} states (expected: 2)\")\n",
    "show_partition(partition4, \"Final partition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea4542",
   "metadata": {},
   "source": [
    "## Step 7: Verify Entropy Rate Calculation\n",
    "\n",
    "Now that we have 2 states, let's verify the entropy rate is calculated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected entropy rate for Golden Mean\n",
    "# For Golden Mean with parameter p (prob of 1 after 0):\n",
    "# Entropy rate h = H(p) / (1 + p) where H is binary entropy\n",
    "\n",
    "\n",
    "def binary_entropy(p):\n",
    "    \"\"\"Binary entropy H(p) = -p*log2(p) - (1-p)*log2(1-p)\"\"\"\n",
    "    if p == 0 or p == 1:\n",
    "        return 0\n",
    "    return -p * math.log2(p) - (1 - p) * math.log2(1 - p)\n",
    "\n",
    "\n",
    "p = 0.5  # Our Golden Mean parameter\n",
    "expected_entropy_rate = binary_entropy(p) / (1 + p)\n",
    "print(f\"Expected entropy rate for Golden Mean (p={p}): {expected_entropy_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual entropy rate calculation from the inferred machine\n",
    "# Entropy rate = sum over states: pi_s * H(P(·|s))\n",
    "# where pi_s is the stationary probability of state s\n",
    "\n",
    "# Our inferred machine:\n",
    "# S2 (after 0): P(0) ≈ 0.495, P(1) ≈ 0.505 -> transitions to S2 and S1\n",
    "# S1 (after 1): P(0) = 1.0 -> transitions to S2\n",
    "\n",
    "# Get the actual probabilities from the inferred machine\n",
    "p_1_given_A = None  # P(1 | state A)\n",
    "for state in result.machine.states:\n",
    "    for t in state.transitions:\n",
    "        if t.symbol == 1:\n",
    "            p_1_given_A = t.probability\n",
    "            state_A = state.id\n",
    "            break\n",
    "    if p_1_given_A:\n",
    "        break\n",
    "\n",
    "print(f\"From inferred machine:\")\n",
    "print(f\"  State A ({state_A}): P(1) = {p_1_given_A:.4f}\")\n",
    "\n",
    "# Stationary distribution\n",
    "# Balance: pi_A * P(1|A) = pi_B (since B always goes to A)\n",
    "# pi_A + pi_B = 1\n",
    "# => pi_A = 1 / (1 + P(1|A))\n",
    "pi_A = 1 / (1 + p_1_given_A)\n",
    "pi_B = p_1_given_A / (1 + p_1_given_A)\n",
    "\n",
    "print(f\"\\nStationary distribution:\")\n",
    "print(f\"  pi_A = {pi_A:.4f}\")\n",
    "print(f\"  pi_B = {pi_B:.4f}\")\n",
    "\n",
    "# Entropy of each state\n",
    "H_A = binary_entropy(p_1_given_A)\n",
    "H_B = 0  # deterministic\n",
    "\n",
    "print(f\"\\nState entropies:\")\n",
    "print(f\"  H(A) = {H_A:.4f}\")\n",
    "print(f\"  H(B) = {H_B:.4f}\")\n",
    "\n",
    "# Entropy rate\n",
    "manual_entropy_rate = pi_A * H_A + pi_B * H_B\n",
    "print(f\"\\nManual entropy rate: {manual_entropy_rate:.4f}\")\n",
    "print(f\"Expected: {expected_entropy_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what analyze() returns\n",
    "from emic.analysis import analyze\n",
    "\n",
    "summary = analyze(result.machine)\n",
    "print(\"Analysis summary:\")\n",
    "print(f\"  Entropy rate (from analyze): {summary.entropy_rate:.4f}\")\n",
    "print(f\"  Manual calculation: {manual_entropy_rate:.4f}\")\n",
    "print(f\"  Expected: {expected_entropy_rate:.4f}\")\n",
    "print(f\"  Number of states: {summary.num_states}\")\n",
    "print(f\"  Statistical complexity: {summary.statistical_complexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb094c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Root Cause of 3-State Bug**: The empty history `()` was being included in the partition. Since `()` reflects the stationary distribution (mixture of causal states), not a specific causal state, it was incorrectly identified as a distinct state.\n",
    "\n",
    "2. **Fix Applied**: Modified `_initialize_partition()` to exclude the empty history `()` from partitioning. Only histories of length ≥ 1 are used for state equivalence testing.\n",
    "\n",
    "3. **Result**: After the fix, CSSR correctly infers 2 states for the Golden Mean process:\n",
    "   - **State A** (histories ending in 0): ~50/50 distribution\n",
    "   - **State B** (histories ending in 1): 100% → 0 (deterministic)\n",
    "\n",
    "4. **Entropy Rate**: The inferred machine's entropy rate matches the theoretical value of ~0.667 bits for Golden Mean with p=0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bcd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final verification: Run fresh CSSR inference with the fix\n",
    "# Reload modules to pick up the fix\n",
    "import importlib\n",
    "import emic.inference.cssr.algorithm\n",
    "\n",
    "importlib.reload(emic.inference.cssr.algorithm)\n",
    "\n",
    "from emic.sources import GoldenMeanSource\n",
    "from emic.sources.transforms import TakeN\n",
    "from emic.inference import CSSR, CSSRConfig\n",
    "from emic.analysis import analyze\n",
    "\n",
    "# Generate fresh data and run inference\n",
    "final_result = GoldenMeanSource(p=0.5, _seed=42) >> TakeN(10000) >> CSSR(CSSRConfig(max_history=3))\n",
    "\n",
    "print(\"=== Final Verification ===\")\n",
    "print(f\"\\nNumber of states: {len(final_result.machine.states)} (expected: 2)\")\n",
    "\n",
    "print(\"\\nMachine structure:\")\n",
    "for state in final_result.machine.states:\n",
    "    print(f\"  {state.id}:\")\n",
    "    for t in state.transitions:\n",
    "        print(f\"    --{t.symbol} (p={t.probability:.4f})--> {t.target}\")\n",
    "\n",
    "final_summary = analyze(final_result.machine)\n",
    "print(f\"\\nEntropy rate: {final_summary.entropy_rate:.4f}\")\n",
    "print(f\"Expected: {expected_entropy_rate:.4f}\")\n",
    "print(f\"Match: {abs(final_summary.entropy_rate - expected_entropy_rate) < 0.05}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5931ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-squared comparisons using our implementation\n",
    "from emic.inference.cssr.tests import distributions_differ\n",
    "\n",
    "\n",
    "def compare_histories(tree, h1, h2, significance=0.05):\n",
    "    \"\"\"Compare two histories' distributions using chi-squared test.\"\"\"\n",
    "    stats1 = tree.get_stats(h1)\n",
    "    stats2 = tree.get_stats(h2)\n",
    "\n",
    "    if not stats1 or not stats2:\n",
    "        return None\n",
    "\n",
    "    return distributions_differ(stats1.next_symbol_counts, stats2.next_symbol_counts, significance)\n",
    "\n",
    "\n",
    "print(\"=== Chi-Squared Comparisons (True = distributions DIFFER) ===\")\n",
    "print(\"\\nHistories ending in 0 (should all be similar -> False):\")\n",
    "pairs = [((0,), (1, 0)), ((0,), (0, 0)), ((1, 0), (0, 0))]\n",
    "for h1, h2 in pairs:\n",
    "    result_cmp = compare_histories(tree, h1, h2)\n",
    "    print(f\"  {h1} vs {h2}: differ={result_cmp}\")\n",
    "\n",
    "print(\"\\nHistories ending in 1 (should all be similar -> False):\")\n",
    "pairs = [((1,), (0, 1))]\n",
    "for h1, h2 in pairs:\n",
    "    result_cmp = compare_histories(tree, h1, h2)\n",
    "    print(f\"  {h1} vs {h2}: differ={result_cmp}\")\n",
    "\n",
    "print(\"\\nCross comparisons (should be True - different distributions):\")\n",
    "pairs = [((0,), (1,)), ((0, 0), (0, 1))]\n",
    "for h1, h2 in pairs:\n",
    "    result_cmp = compare_histories(tree, h1, h2)\n",
    "    print(f\"  {h1} vs {h2}: differ={result_cmp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9187119",
   "metadata": {},
   "source": [
    "## Detailed Chi-Squared Analysis\n",
    "\n",
    "Let's examine the chi-squared test with scipy for detailed statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed chi-squared analysis using scipy\n",
    "from scipy import stats as scipy_stats\n",
    "\n",
    "\n",
    "def detailed_chi_squared(tree, h1, h2):\n",
    "    \"\"\"Detailed chi-squared analysis.\"\"\"\n",
    "    stats1 = tree.get_stats(h1)\n",
    "    stats2 = tree.get_stats(h2)\n",
    "\n",
    "    if not stats1 or not stats2:\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{h1} vs {h2}:\")\n",
    "    print(\n",
    "        f\"  {h1}: {dict(stats1.next_symbol_counts)} (total: {sum(stats1.next_symbol_counts.values())})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  {h2}: {dict(stats2.next_symbol_counts)} (total: {sum(stats2.next_symbol_counts.values())})\"\n",
    "    )\n",
    "\n",
    "    # Build contingency table\n",
    "    alphabet = sorted(set(stats1.next_symbol_counts.keys()) | set(stats2.next_symbol_counts.keys()))\n",
    "    observed = []\n",
    "    for sym in alphabet:\n",
    "        observed.append(\n",
    "            [stats1.next_symbol_counts.get(sym, 0), stats2.next_symbol_counts.get(sym, 0)]\n",
    "        )\n",
    "\n",
    "    print(f\"  Contingency table: {observed}\")\n",
    "\n",
    "    # Chi-squared test\n",
    "    chi2, p_value, dof, expected = scipy_stats.chi2_contingency(observed)\n",
    "    print(f\"  Chi2={chi2:.4f}, p-value={p_value:.6f}, dof={dof}\")\n",
    "    print(f\"  Same distribution (α=0.05)? {p_value > 0.05}\")\n",
    "\n",
    "\n",
    "print(\"=== Detailed Chi-Squared Tests ===\")\n",
    "detailed_chi_squared(tree, (0,), (1, 0))\n",
    "detailed_chi_squared(tree, (0,), (0, 0))\n",
    "detailed_chi_squared(tree, (1, 0), (0, 0))\n",
    "detailed_chi_squared(tree, (1,), (0, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
