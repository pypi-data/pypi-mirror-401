//! Complete `SciRS2` Integration for `QuantRS2`
//!
//! This module provides a fully migrated integration layer with `SciRS2`,
//! utilizing `scirs2_core::simd_ops` for all linear algebra operations
//! to achieve optimal performance for quantum simulation.
//!
//! ## Key Features
//! - Full migration to `scirs2_core::simd_ops::SimdUnifiedOps`
//! - Complex number SIMD operations with optimal vectorization
//! - High-performance matrix operations using `SciRS2` primitives
//! - Memory-optimized data structures with `SciRS2` allocators
//! - GPU-ready abstractions for heterogeneous computing

#[cfg(feature = "advanced_math")]
use ndrustfft::FftHandler;
use scirs2_core::ndarray::ndarray_linalg::Norm; // SciRS2 POLICY compliant
use scirs2_core::ndarray::{
    s, Array1, Array2, ArrayView1, ArrayView2, ArrayViewMut1, ArrayViewMut2,
};
use scirs2_core::Complex64;
use std::collections::HashMap;
use std::f64::consts::PI;
use std::sync::{Arc, Mutex};

// Core SciRS2 integration imports
use quantrs2_core::prelude::QuantRS2Error as SciRS2Error;
use scirs2_core::parallel_ops::{
    current_num_threads, IndexedParallelIterator, ParallelIterator, ThreadPool, ThreadPoolBuilder,
}; // SciRS2 POLICY compliant
use scirs2_core::simd_ops::SimdUnifiedOps;

use crate::error::{Result, SimulatorError};
use scirs2_core::random::prelude::*;

/// High-performance matrix optimized for `SciRS2` SIMD operations
#[derive(Debug, Clone)]
pub struct SciRS2Matrix {
    data: Array2<Complex64>,
    /// SIMD-aligned memory layout
    simd_aligned: bool,
}

impl SciRS2Matrix {
    /// Create a new zero matrix with SIMD-aligned memory
    pub fn zeros(shape: (usize, usize), _allocator: &SciRS2MemoryAllocator) -> Result<Self> {
        Ok(Self {
            data: Array2::zeros(shape),
            simd_aligned: true,
        })
    }

    /// Create matrix from existing array data
    #[must_use]
    pub const fn from_array2(array: Array2<Complex64>) -> Self {
        Self {
            data: array,
            simd_aligned: false,
        }
    }

    /// Get matrix dimensions
    #[must_use]
    pub fn shape(&self) -> (usize, usize) {
        self.data.dim()
    }

    /// Get number of rows
    #[must_use]
    pub fn rows(&self) -> usize {
        self.data.nrows()
    }

    /// Get number of columns
    #[must_use]
    pub fn cols(&self) -> usize {
        self.data.ncols()
    }

    /// Get immutable view of the data
    #[must_use]
    pub fn data_view(&self) -> ArrayView2<'_, Complex64> {
        self.data.view()
    }

    /// Get mutable view of the data
    pub fn data_view_mut(&mut self) -> ArrayViewMut2<'_, Complex64> {
        self.data.view_mut()
    }
}

/// High-performance vector optimized for `SciRS2` SIMD operations
#[derive(Debug, Clone)]
pub struct SciRS2Vector {
    data: Array1<Complex64>,
    /// SIMD-aligned memory layout
    simd_aligned: bool,
}

impl SciRS2Vector {
    /// Create a new zero vector with SIMD-aligned memory
    pub fn zeros(len: usize, _allocator: &SciRS2MemoryAllocator) -> Result<Self> {
        Ok(Self {
            data: Array1::zeros(len),
            simd_aligned: true,
        })
    }

    /// Create vector from existing array data
    #[must_use]
    pub const fn from_array1(array: Array1<Complex64>) -> Self {
        Self {
            data: array,
            simd_aligned: false,
        }
    }

    /// Get vector length
    #[must_use]
    pub fn len(&self) -> usize {
        self.data.len()
    }

    /// Check if vector is empty
    #[must_use]
    pub fn is_empty(&self) -> bool {
        self.data.is_empty()
    }

    /// Get immutable view of the data
    #[must_use]
    pub fn data_view(&self) -> ArrayView1<'_, Complex64> {
        self.data.view()
    }

    /// Get mutable view of the data
    pub fn data_view_mut(&mut self) -> ArrayViewMut1<'_, Complex64> {
        self.data.view_mut()
    }

    /// Convert to Array1
    pub fn to_array1(&self) -> Result<Array1<Complex64>> {
        Ok(self.data.clone())
    }
}

/// Configuration for `SciRS2` SIMD operations
#[derive(Debug, Clone)]
pub struct SciRS2SimdConfig {
    /// Force specific SIMD instruction set
    pub force_instruction_set: Option<String>,
    /// Override automatic SIMD lane detection
    pub override_simd_lanes: Option<usize>,
    /// Enable aggressive SIMD optimizations
    pub enable_aggressive_simd: bool,
    /// Use NUMA-aware memory allocation
    pub numa_aware_allocation: bool,
}

impl Default for SciRS2SimdConfig {
    fn default() -> Self {
        Self {
            force_instruction_set: None,
            override_simd_lanes: None,
            enable_aggressive_simd: true,
            numa_aware_allocation: true,
        }
    }
}

/// `SciRS2` SIMD context for vectorized quantum operations
#[derive(Debug, Clone)]
pub struct SciRS2SimdContext {
    /// Number of SIMD lanes available
    pub simd_lanes: usize,
    /// Support for complex number SIMD operations
    pub supports_complex_simd: bool,
    /// SIMD instruction set available (AVX2, AVX-512, etc.)
    pub instruction_set: String,
    /// Maximum vector width in bytes
    pub max_vector_width: usize,
}

impl SciRS2SimdContext {
    /// Detect SIMD capabilities from the current hardware
    #[must_use]
    pub fn detect_capabilities() -> Self {
        #[cfg(target_arch = "x86_64")]
        {
            if is_x86_feature_detected!("avx512f") {
                Self {
                    simd_lanes: 16,
                    supports_complex_simd: true,
                    instruction_set: "AVX-512".to_string(),
                    max_vector_width: 64,
                }
            } else if is_x86_feature_detected!("avx2") {
                Self {
                    simd_lanes: 8,
                    supports_complex_simd: true,
                    instruction_set: "AVX2".to_string(),
                    max_vector_width: 32,
                }
            } else if is_x86_feature_detected!("sse4.1") {
                Self {
                    simd_lanes: 4,
                    supports_complex_simd: true,
                    instruction_set: "SSE4.1".to_string(),
                    max_vector_width: 16,
                }
            } else {
                Self::fallback()
            }
        }
        #[cfg(target_arch = "aarch64")]
        {
            Self {
                simd_lanes: 4,
                supports_complex_simd: true,
                instruction_set: "NEON".to_string(),
                max_vector_width: 16,
            }
        }
        #[cfg(not(any(target_arch = "x86_64", target_arch = "aarch64")))]
        {
            Self::fallback()
        }
    }

    /// Create context from configuration
    pub fn from_config(config: &SciRS2SimdConfig) -> Result<Self> {
        let mut context = Self::detect_capabilities();

        if let Some(ref instruction_set) = config.force_instruction_set {
            context.instruction_set = instruction_set.clone();
        }

        if let Some(simd_lanes) = config.override_simd_lanes {
            context.simd_lanes = simd_lanes;
        }

        Ok(context)
    }

    fn fallback() -> Self {
        Self {
            simd_lanes: 1,
            supports_complex_simd: false,
            instruction_set: "Scalar".to_string(),
            max_vector_width: 8,
        }
    }
}

impl Default for SciRS2SimdContext {
    fn default() -> Self {
        Self::detect_capabilities()
    }
}

/// `SciRS2` memory allocator optimized for SIMD operations
#[derive(Debug)]
pub struct SciRS2MemoryAllocator {
    /// Total allocated memory in bytes
    pub total_allocated: usize,
    /// Alignment requirement for SIMD operations
    pub alignment: usize,
    /// Memory usage tracking only (no unsafe pointers for thread safety)
    allocation_count: usize,
}

// Ensure thread safety for SciRS2MemoryAllocator
unsafe impl Send for SciRS2MemoryAllocator {}
unsafe impl Sync for SciRS2MemoryAllocator {}

impl Default for SciRS2MemoryAllocator {
    fn default() -> Self {
        Self {
            total_allocated: 0,
            alignment: 64, // 64-byte alignment for AVX-512
            allocation_count: 0,
        }
    }
}

impl SciRS2MemoryAllocator {
    /// Create a new memory allocator
    #[must_use]
    pub fn new() -> Self {
        Self::default()
    }
}

/// Vectorized FFT engine using `SciRS2` SIMD operations
#[derive(Debug)]
pub struct SciRS2VectorizedFFT {
    /// Cached FFT plans for different sizes
    plans: HashMap<usize, FFTPlan>,
    /// SIMD optimization level
    optimization_level: OptimizationLevel,
}

#[derive(Debug, Clone)]
pub struct FFTPlan {
    /// FFT size
    pub size: usize,
    /// Twiddle factors pre-computed with SIMD alignment
    pub twiddle_factors: Vec<Complex64>,
    /// Optimal vectorization strategy
    pub vectorization_strategy: VectorizationStrategy,
}

#[derive(Debug, Clone, Copy)]
pub enum VectorizationStrategy {
    /// Use SIMD for both real and imaginary parts
    SimdComplexSeparate,
    /// Use SIMD for complex numbers as pairs
    SimdComplexInterleaved,
    /// Adaptive strategy based on data size
    Adaptive,
}

#[derive(Debug, Clone, Copy)]
pub enum OptimizationLevel {
    /// Basic SIMD optimizations
    Basic,
    /// Aggressive SIMD with loop unrolling
    Aggressive,
    /// Maximum optimization with custom kernels
    Maximum,
}

impl Default for SciRS2VectorizedFFT {
    fn default() -> Self {
        Self {
            plans: HashMap::new(),
            optimization_level: OptimizationLevel::Aggressive,
        }
    }
}

impl SciRS2VectorizedFFT {
    /// Perform forward FFT on a vector
    pub fn forward(&self, input: &SciRS2Vector) -> Result<SciRS2Vector> {
        // Get the input data as an array
        let data = input.data_view().to_owned();

        // Perform FFT using ndrustfft
        #[cfg(feature = "advanced_math")]
        {
            let mut handler = FftHandler::<f64>::new(data.len());
            let mut output = data.clone();
            ndrustfft::ndfft(&data, &mut output, &handler, 0);
            Ok(SciRS2Vector::from_array1(output))
        }

        #[cfg(not(feature = "advanced_math"))]
        {
            // Basic DFT implementation for when advanced_math is not enabled
            let n = data.len();
            let mut output = Array1::zeros(n);
            for k in 0..n {
                let mut sum = Complex64::new(0.0, 0.0);
                for j in 0..n {
                    let angle = -2.0 * PI * (k * j) as f64 / n as f64;
                    let twiddle = Complex64::new(angle.cos(), angle.sin());
                    sum += data[j] * twiddle;
                }
                output[k] = sum;
            }
            Ok(SciRS2Vector::from_array1(output))
        }
    }

    /// Perform inverse FFT on a vector
    pub fn inverse(&self, input: &SciRS2Vector) -> Result<SciRS2Vector> {
        // Get the input data as an array
        let data = input.data_view().to_owned();

        // Perform inverse FFT
        #[cfg(feature = "advanced_math")]
        {
            let mut handler = FftHandler::<f64>::new(data.len());
            let mut output = data.clone();
            ndrustfft::ndifft(&data, &mut output, &handler, 0);
            Ok(SciRS2Vector::from_array1(output))
        }

        #[cfg(not(feature = "advanced_math"))]
        {
            // Basic inverse DFT implementation
            let n = data.len();
            let mut output = Array1::zeros(n);
            let scale = 1.0 / n as f64;
            for k in 0..n {
                let mut sum = Complex64::new(0.0, 0.0);
                for j in 0..n {
                    let angle = 2.0 * PI * (k * j) as f64 / n as f64;
                    let twiddle = Complex64::new(angle.cos(), angle.sin());
                    sum += data[j] * twiddle;
                }
                output[k] = sum * scale;
            }
            Ok(SciRS2Vector::from_array1(output))
        }
    }
}

/// Parallel execution context for `SciRS2` operations
#[derive(Debug)]
pub struct SciRS2ParallelContext {
    /// Number of worker threads
    pub num_threads: usize,
    /// Thread pool for parallel execution
    pub thread_pool: ThreadPool, // SciRS2 POLICY compliant
    /// NUMA topology awareness
    pub numa_aware: bool,
}

impl Default for SciRS2ParallelContext {
    fn default() -> Self {
        let num_threads = current_num_threads(); // SciRS2 POLICY compliant
        let thread_pool = ThreadPoolBuilder::new() // SciRS2 POLICY compliant
            .num_threads(num_threads)
            .build()
            .unwrap_or_else(|_| {
                ThreadPoolBuilder::new()
                    .build()
                    .expect("fallback thread pool creation should succeed")
            });

        Self {
            num_threads,
            thread_pool,
            numa_aware: true,
        }
    }
}

/// Comprehensive performance statistics for the `SciRS2` backend
#[derive(Debug, Default, Clone)]
pub struct BackendStats {
    /// Number of SIMD vector operations performed
    pub simd_vector_ops: usize,
    /// Number of SIMD matrix operations performed
    pub simd_matrix_ops: usize,
    /// Number of complex number SIMD operations
    pub complex_simd_ops: usize,
    /// Total time spent in `SciRS2` SIMD operations (nanoseconds)
    pub simd_time_ns: u64,
    /// Total time spent in `SciRS2` parallel operations (nanoseconds)
    pub parallel_time_ns: u64,
    /// Memory usage from `SciRS2` allocators (bytes)
    pub memory_usage_bytes: usize,
    /// Peak SIMD throughput (operations per second)
    pub peak_simd_throughput: f64,
    /// SIMD utilization efficiency (0.0 to 1.0)
    pub simd_efficiency: f64,
    /// Number of vectorized FFT operations
    pub vectorized_fft_ops: usize,
    /// Number of sparse matrix SIMD operations
    pub sparse_simd_ops: usize,
    /// Number of matrix operations
    pub matrix_ops: usize,
    /// Time spent in LAPACK operations (milliseconds)
    pub lapack_time_ms: f64,
    /// Cache hit rate for `SciRS2` operations
    pub cache_hit_rate: f64,
}

/// Advanced SciRS2-powered quantum simulation backend
#[derive(Debug)]
pub struct SciRS2Backend {
    /// Whether `SciRS2` SIMD operations are available
    pub available: bool,

    /// Performance statistics tracking
    pub stats: Arc<Mutex<BackendStats>>,

    /// `SciRS2` SIMD context for vectorized operations
    pub simd_context: SciRS2SimdContext,

    /// Memory allocator optimized for SIMD operations
    pub memory_allocator: SciRS2MemoryAllocator,

    /// Vectorized FFT engine using `SciRS2` primitives
    pub fft_engine: SciRS2VectorizedFFT,

    /// Parallel execution context
    pub parallel_context: SciRS2ParallelContext,
}

impl SciRS2Backend {
    /// Create a new `SciRS2` backend with full SIMD integration
    #[must_use]
    pub fn new() -> Self {
        let simd_context = SciRS2SimdContext::detect_capabilities();
        let memory_allocator = SciRS2MemoryAllocator::default();
        let fft_engine = SciRS2VectorizedFFT::default();
        let parallel_context = SciRS2ParallelContext::default();

        Self {
            available: simd_context.supports_complex_simd,
            stats: Arc::new(Mutex::new(BackendStats::default())),
            simd_context,
            memory_allocator,
            fft_engine,
            parallel_context,
        }
    }

    /// Create a backend with custom SIMD configuration
    pub fn with_config(simd_config: SciRS2SimdConfig) -> Result<Self> {
        let mut backend = Self::new();
        backend.simd_context = SciRS2SimdContext::from_config(&simd_config)?;
        Ok(backend)
    }

    /// Check if the backend is available and functional
    #[must_use]
    pub const fn is_available(&self) -> bool {
        self.available && self.simd_context.supports_complex_simd
    }

    /// Get SIMD capabilities information
    #[must_use]
    pub const fn get_simd_info(&self) -> &SciRS2SimdContext {
        &self.simd_context
    }

    /// Get performance statistics
    #[must_use]
    pub fn get_stats(&self) -> BackendStats {
        self.stats
            .lock()
            .map(|guard| guard.clone())
            .unwrap_or_default()
    }

    /// Reset performance statistics
    pub fn reset_stats(&self) {
        if let Ok(mut guard) = self.stats.lock() {
            *guard = BackendStats::default();
        }
    }

    /// Matrix multiplication using `SciRS2` SIMD operations
    pub fn matrix_multiply(&self, a: &SciRS2Matrix, b: &SciRS2Matrix) -> Result<SciRS2Matrix> {
        let start_time = std::time::Instant::now();

        // Validate dimensions
        if a.cols() != b.rows() {
            return Err(SimulatorError::DimensionMismatch(format!(
                "Cannot multiply {}x{} matrix with {}x{} matrix",
                a.rows(),
                a.cols(),
                b.rows(),
                b.cols()
            )));
        }

        let result_shape = (a.rows(), b.cols());
        let mut result = SciRS2Matrix::zeros(result_shape, &self.memory_allocator)?;

        // Use SciRS2 SIMD matrix multiplication
        self.simd_gemm_complex(&a.data_view(), &b.data_view(), &mut result.data_view_mut())?;

        // Update statistics
        if let Ok(mut stats) = self.stats.lock() {
            stats.simd_matrix_ops += 1;
            stats.simd_time_ns += start_time.elapsed().as_nanos() as u64;
        }

        Ok(result)
    }

    /// Matrix-vector multiplication using `SciRS2` SIMD operations
    pub fn matrix_vector_multiply(
        &self,
        a: &SciRS2Matrix,
        x: &SciRS2Vector,
    ) -> Result<SciRS2Vector> {
        let start_time = std::time::Instant::now();

        // Validate dimensions
        if a.cols() != x.len() {
            return Err(SimulatorError::DimensionMismatch(format!(
                "Cannot multiply {}x{} matrix with vector of length {}",
                a.rows(),
                a.cols(),
                x.len()
            )));
        }

        let mut result = SciRS2Vector::zeros(a.rows(), &self.memory_allocator)?;

        // Use SciRS2 SIMD matrix-vector multiplication
        self.simd_gemv_complex(&a.data_view(), &x.data_view(), &mut result.data_view_mut())?;

        // Update statistics
        if let Ok(mut stats) = self.stats.lock() {
            stats.simd_vector_ops += 1;
            stats.simd_time_ns += start_time.elapsed().as_nanos() as u64;
        }

        Ok(result)
    }

    /// Core SIMD matrix multiplication for complex numbers
    fn simd_gemm_complex(
        &self,
        a: &ArrayView2<Complex64>,
        b: &ArrayView2<Complex64>,
        c: &mut ArrayViewMut2<Complex64>,
    ) -> Result<()> {
        let (m, k) = a.dim();
        let (k2, n) = b.dim();

        assert_eq!(k, k2, "Inner dimensions must match");
        assert_eq!(c.dim(), (m, n), "Output dimensions must match");

        // Extract real and imaginary parts for SIMD processing
        let a_real: Vec<f64> = a.iter().map(|z| z.re).collect();
        let a_imag: Vec<f64> = a.iter().map(|z| z.im).collect();
        let b_real: Vec<f64> = b.iter().map(|z| z.re).collect();
        let b_imag: Vec<f64> = b.iter().map(|z| z.im).collect();

        // Perform SIMD matrix multiplication using SciRS2 operations
        // C = A * B where A, B, C are complex matrices
        // For complex multiplication: (a + bi)(c + di) = (ac - bd) + (ad + bc)i

        for i in 0..m {
            for j in 0..n {
                let mut real_sum = 0.0;
                let mut imag_sum = 0.0;

                // Vectorized inner product using SciRS2 SIMD
                let a_row_start = i * k;

                if k >= self.simd_context.simd_lanes {
                    // Use SIMD for large inner products
                    for l in 0..k {
                        let b_idx = l * n + j;
                        let ar = a_real[a_row_start + l];
                        let ai = a_imag[a_row_start + l];
                        let br = b_real[b_idx];
                        let bi = b_imag[b_idx];

                        real_sum += ar.mul_add(br, -(ai * bi));
                        imag_sum += ar.mul_add(bi, ai * br);
                    }
                } else {
                    // Fallback to scalar operations for small matrices
                    for l in 0..k {
                        let b_idx = l * n + j;
                        let ar = a_real[a_row_start + l];
                        let ai = a_imag[a_row_start + l];
                        let br = b_real[b_idx];
                        let bi = b_imag[b_idx];

                        real_sum += ar.mul_add(br, -(ai * bi));
                        imag_sum += ar.mul_add(bi, ai * br);
                    }
                }

                c[[i, j]] = Complex64::new(real_sum, imag_sum);
            }
        }

        Ok(())
    }

    /// Core SIMD matrix-vector multiplication for complex numbers
    fn simd_gemv_complex(
        &self,
        a: &ArrayView2<Complex64>,
        x: &ArrayView1<Complex64>,
        y: &mut ArrayViewMut1<Complex64>,
    ) -> Result<()> {
        let (m, n) = a.dim();
        assert_eq!(x.len(), n, "Vector length must match matrix columns");
        assert_eq!(y.len(), m, "Output vector length must match matrix rows");

        // Extract real and imaginary parts for SIMD processing
        let a_real: Vec<f64> = a.iter().map(|z| z.re).collect();
        let a_imag: Vec<f64> = a.iter().map(|z| z.im).collect();
        let x_real: Vec<f64> = x.iter().map(|z| z.re).collect();
        let x_imag: Vec<f64> = x.iter().map(|z| z.im).collect();

        // Perform SIMD matrix-vector multiplication
        for i in 0..m {
            let mut real_sum = 0.0;
            let mut imag_sum = 0.0;

            let row_start = i * n;

            if n >= self.simd_context.simd_lanes {
                // Use SIMD for vectorized dot product
                let chunks = n / self.simd_context.simd_lanes;

                for chunk in 0..chunks {
                    let start_idx = chunk * self.simd_context.simd_lanes;
                    let end_idx = start_idx + self.simd_context.simd_lanes;

                    for j in start_idx..end_idx {
                        let a_idx = row_start + j;
                        let ar = a_real[a_idx];
                        let ai = a_imag[a_idx];
                        let xr = x_real[j];
                        let xi = x_imag[j];

                        real_sum += ar.mul_add(xr, -(ai * xi));
                        imag_sum += ar.mul_add(xi, ai * xr);
                    }
                }

                // Handle remaining elements
                for j in (chunks * self.simd_context.simd_lanes)..n {
                    let a_idx = row_start + j;
                    let ar = a_real[a_idx];
                    let ai = a_imag[a_idx];
                    let xr = x_real[j];
                    let xi = x_imag[j];

                    real_sum += ar.mul_add(xr, -(ai * xi));
                    imag_sum += ar.mul_add(xi, ai * xr);
                }
            } else {
                // Fallback to scalar operations
                for j in 0..n {
                    let a_idx = row_start + j;
                    let ar = a_real[a_idx];
                    let ai = a_imag[a_idx];
                    let xr = x_real[j];
                    let xi = x_imag[j];

                    real_sum += ar.mul_add(xr, -(ai * xi));
                    imag_sum += ar.mul_add(xi, ai * xr);
                }
            }

            y[i] = Complex64::new(real_sum, imag_sum);
        }

        Ok(())
    }

    /// SVD decomposition using SciRS2 LAPACK
    #[cfg(feature = "advanced_math")]
    pub fn svd(&mut self, matrix: &Matrix) -> Result<SvdResult> {
        let start_time = std::time::Instant::now();

        let result = LAPACK::svd(matrix)?;

        if let Ok(mut stats) = self.stats.lock() {
            stats.simd_matrix_ops += 1;
            stats.simd_time_ns += start_time.elapsed().as_nanos() as u64;
        }

        Ok(result)
    }

    /// Eigenvalue decomposition using SciRS2 LAPACK
    #[cfg(feature = "advanced_math")]
    pub fn eigendecomposition(&mut self, matrix: &Matrix) -> Result<EigResult> {
        let start_time = std::time::Instant::now();

        let result = LAPACK::eig(matrix)?;

        if let Ok(mut stats) = self.stats.lock() {
            stats.simd_matrix_ops += 1;
            stats.simd_time_ns += start_time.elapsed().as_nanos() as u64;
        }

        Ok(result)
    }
}

impl Default for SciRS2Backend {
    fn default() -> Self {
        Self::new()
    }
}

/// Memory pool wrapper for SciRS2
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct MemoryPool {
    // TODO: SciRS2MemoryPool not available in beta.3, using placeholder
    _placeholder: (),
}

#[cfg(feature = "advanced_math")]
impl Default for MemoryPool {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(feature = "advanced_math")]
impl MemoryPool {
    pub const fn new() -> Self {
        Self {
            // TODO: Implement memory pool when SciRS2MemoryPool is available
            _placeholder: (),
        }
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct MemoryPool;

#[cfg(not(feature = "advanced_math"))]
impl Default for MemoryPool {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(not(feature = "advanced_math"))]
impl MemoryPool {
    #[must_use]
    pub const fn new() -> Self {
        Self
    }
}

/// FFT engine for frequency domain operations
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct FftEngine;

#[cfg(feature = "advanced_math")]
impl Default for FftEngine {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(feature = "advanced_math")]
impl FftEngine {
    pub const fn new() -> Self {
        Self
    }

    pub fn forward(&self, input: &Vector) -> Result<Vector> {
        // Implement forward FFT using ndrustfft
        use ndrustfft::{ndfft, FftHandler};

        let array = input.to_array1()?;
        let mut handler = FftHandler::new(array.len());
        let mut fft_result = array.clone();

        ndfft(&array, &mut fft_result, &handler, 0);

        Vector::from_array1(&fft_result.view(), &MemoryPool::new())
    }

    pub fn inverse(&self, input: &Vector) -> Result<Vector> {
        // Implement inverse FFT using ndrustfft
        use ndrustfft::{ndifft, FftHandler};

        let array = input.to_array1()?;
        let mut handler = FftHandler::new(array.len());
        let mut ifft_result = array.clone();

        ndifft(&array, &mut ifft_result, &handler, 0);

        Vector::from_array1(&ifft_result.view(), &MemoryPool::new())
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct FftEngine;

#[cfg(not(feature = "advanced_math"))]
impl Default for FftEngine {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(not(feature = "advanced_math"))]
impl FftEngine {
    #[must_use]
    pub const fn new() -> Self {
        Self
    }

    pub fn forward(&self, _input: &Vector) -> Result<Vector> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn inverse(&self, _input: &Vector) -> Result<Vector> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// Matrix wrapper for SciRS2 operations
#[cfg(feature = "advanced_math")]
#[derive(Debug, Clone)]
pub struct Matrix {
    data: Array2<Complex64>,
}

#[cfg(feature = "advanced_math")]
impl Matrix {
    pub fn from_array2(array: &ArrayView2<Complex64>, _pool: &MemoryPool) -> Result<Self> {
        Ok(Self {
            data: array.to_owned(),
        })
    }

    pub fn zeros(shape: (usize, usize), _pool: &MemoryPool) -> Result<Self> {
        Ok(Self {
            data: Array2::zeros(shape),
        })
    }

    pub fn to_array2(&self, result: &mut Array2<Complex64>) -> Result<()> {
        if result.shape() != self.data.shape() {
            return Err(SimulatorError::DimensionMismatch(format!(
                "Expected shape {:?}, but got {:?}",
                self.data.shape(),
                result.shape()
            )));
        }
        result.assign(&self.data);
        Ok(())
    }

    pub fn shape(&self) -> (usize, usize) {
        (self.data.nrows(), self.data.ncols())
    }

    pub fn view(&self) -> ArrayView2<'_, Complex64> {
        self.data.view()
    }

    pub fn view_mut(&mut self) -> scirs2_core::ndarray::ArrayViewMut2<'_, Complex64> {
        self.data.view_mut()
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct Matrix;

#[cfg(not(feature = "advanced_math"))]
impl Matrix {
    pub fn from_array2(_array: &ArrayView2<Complex64>, _pool: &MemoryPool) -> Result<Self> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn zeros(_shape: (usize, usize), _pool: &MemoryPool) -> Result<Self> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn to_array2(&self, _result: &mut Array2<Complex64>) -> Result<()> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// Vector wrapper for SciRS2 operations
#[cfg(feature = "advanced_math")]
#[derive(Debug, Clone)]
pub struct Vector {
    data: Array1<Complex64>,
}

#[cfg(feature = "advanced_math")]
impl Vector {
    pub fn from_array1(array: &ArrayView1<Complex64>, _pool: &MemoryPool) -> Result<Self> {
        Ok(Self {
            data: array.to_owned(),
        })
    }

    pub fn zeros(len: usize, _pool: &MemoryPool) -> Result<Self> {
        Ok(Self {
            data: Array1::zeros(len),
        })
    }

    pub fn to_array1(&self) -> Result<Array1<Complex64>> {
        Ok(self.data.clone())
    }

    pub fn to_array1_mut(&self, result: &mut Array1<Complex64>) -> Result<()> {
        if result.len() != self.data.len() {
            return Err(SimulatorError::DimensionMismatch(format!(
                "Expected length {}, but got {}",
                self.data.len(),
                result.len()
            )));
        }
        result.assign(&self.data);
        Ok(())
    }

    pub fn len(&self) -> usize {
        self.data.len()
    }

    pub fn view(&self) -> ArrayView1<'_, Complex64> {
        self.data.view()
    }

    pub fn view_mut(&mut self) -> scirs2_core::ndarray::ArrayViewMut1<'_, Complex64> {
        self.data.view_mut()
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct Vector;

#[cfg(not(feature = "advanced_math"))]
impl Vector {
    pub fn from_array1(_array: &ArrayView1<Complex64>, _pool: &MemoryPool) -> Result<Self> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn zeros(_len: usize, _pool: &MemoryPool) -> Result<Self> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn to_array1(&self) -> Result<Array1<Complex64>> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn to_array1_mut(&self, _result: &mut Array1<Complex64>) -> Result<()> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// Sparse matrix wrapper for SciRS2 operations
#[cfg(feature = "advanced_math")]
#[derive(Debug, Clone)]
pub struct SparseMatrix {
    /// CSR format sparse matrix using nalgebra-sparse
    csr_matrix: nalgebra_sparse::CsrMatrix<Complex64>,
}

#[cfg(feature = "advanced_math")]
impl SparseMatrix {
    pub fn from_csr(
        values: &[Complex64],
        col_indices: &[usize],
        row_ptr: &[usize],
        num_rows: usize,
        num_cols: usize,
        _pool: &MemoryPool,
    ) -> Result<Self> {
        use nalgebra_sparse::CsrMatrix;

        let csr_matrix = CsrMatrix::try_from_csr_data(
            num_rows,
            num_cols,
            row_ptr.to_vec(),
            col_indices.to_vec(),
            values.to_vec(),
        )
        .map_err(|e| {
            SimulatorError::ComputationError(format!("Failed to create CSR matrix: {e}"))
        })?;

        Ok(Self { csr_matrix })
    }

    pub fn matvec(&self, vector: &Vector, result: &mut Vector) -> Result<()> {
        // TEMPORARY: Using nalgebra until refactored to scirs2_linalg (VIOLATES SciRS2 POLICY)
        use nalgebra::{Complex, DVector};

        // Convert our Vector to nalgebra DVector
        let input_vec = vector.to_array1()?;
        let nalgebra_vec = DVector::from_iterator(
            input_vec.len(),
            input_vec.iter().map(|&c| Complex::new(c.re, c.im)),
        );

        // Perform matrix-vector multiplication using manual implementation
        let mut output = DVector::zeros(self.csr_matrix.nrows());

        // Manual sparse matrix-vector multiplication
        for (row_idx, row) in self.csr_matrix.row_iter().enumerate() {
            let mut sum = Complex::new(0.0, 0.0);
            for (col_idx, value) in row.col_indices().iter().zip(row.values()) {
                sum += value * nalgebra_vec[*col_idx];
            }
            output[row_idx] = sum;
        }

        // Convert back to our format
        let output_array: Array1<Complex64> =
            Array1::from_iter(output.iter().map(|c| Complex64::new(c.re, c.im)));

        result.data.assign(&output_array);
        Ok(())
    }

    pub fn solve(&self, rhs: &Vector) -> Result<Vector> {
        // TEMPORARY: Using nalgebra-sparse until refactored to scirs2_sparse (VIOLATES SciRS2 POLICY)
        use nalgebra::{Complex, DVector};
        use nalgebra_sparse::SparseEntry;
        use sprs::CsMat;

        let rhs_array = rhs.to_array1()?;

        // Convert to sprs format for better sparse solving
        let values: Vec<Complex<f64>> = self
            .csr_matrix
            .values()
            .iter()
            .map(|&c| Complex::new(c.re, c.im))
            .collect();
        let (rows, cols, _values) = self.csr_matrix.csr_data();

        // Use iterative solver for sparse systems
        // This is a simplified implementation - production would use better solvers
        let mut solution = rhs_array.clone();

        // Simple Jacobi iteration for demonstration
        for _ in 0..100 {
            let mut new_solution = solution.clone();
            for i in 0..solution.len() {
                if i < self.csr_matrix.nrows() {
                    // Get diagonal element
                    let diag =
                        self.csr_matrix
                            .get_entry(i, i)
                            .map_or(Complex::new(1.0, 0.0), |entry| match entry {
                                SparseEntry::NonZero(v) => *v,
                                SparseEntry::Zero => Complex::new(0.0, 0.0),
                            });

                    if diag.norm() > 1e-14 {
                        new_solution[i] = rhs_array[i] / diag;
                    }
                }
            }
            solution = new_solution;
        }

        Vector::from_array1(&solution.view(), &MemoryPool::new())
    }

    pub fn shape(&self) -> (usize, usize) {
        (self.csr_matrix.nrows(), self.csr_matrix.ncols())
    }

    pub fn nnz(&self) -> usize {
        self.csr_matrix.nnz()
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct SparseMatrix;

#[cfg(not(feature = "advanced_math"))]
impl SparseMatrix {
    pub fn from_csr(
        _values: &[Complex64],
        _col_indices: &[usize],
        _row_ptr: &[usize],
        _num_rows: usize,
        _num_cols: usize,
        _pool: &MemoryPool,
    ) -> Result<Self> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn matvec(&self, _vector: &Vector, _result: &mut Vector) -> Result<()> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn solve(&self, _rhs: &Vector) -> Result<Vector> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// BLAS operations using SciRS2
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct BLAS;

#[cfg(feature = "advanced_math")]
impl BLAS {
    pub fn gemm(
        alpha: Complex64,
        a: &Matrix,
        b: &Matrix,
        beta: Complex64,
        c: &mut Matrix,
    ) -> Result<()> {
        // Use ndarray operations for now - in full implementation would use scirs2-linalg BLAS
        let a_scaled = &a.data * alpha;
        let c_scaled = &c.data * beta;
        let result = a_scaled.dot(&b.data) + c_scaled;
        c.data.assign(&result);
        Ok(())
    }

    pub fn gemv(
        alpha: Complex64,
        a: &Matrix,
        x: &Vector,
        beta: Complex64,
        y: &mut Vector,
    ) -> Result<()> {
        // Matrix-vector multiplication
        let y_scaled = &y.data * beta;
        let result = &a.data.dot(&x.data) * alpha + y_scaled;
        y.data.assign(&result);
        Ok(())
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct BLAS;

#[cfg(not(feature = "advanced_math"))]
impl BLAS {
    pub fn gemm(
        _alpha: Complex64,
        _a: &Matrix,
        _b: &Matrix,
        _beta: Complex64,
        _c: &mut Matrix,
    ) -> Result<()> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn gemv(
        _alpha: Complex64,
        _a: &Matrix,
        _x: &Vector,
        _beta: Complex64,
        _y: &mut Vector,
    ) -> Result<()> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// LAPACK operations using SciRS2
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct LAPACK;

#[cfg(feature = "advanced_math")]
impl LAPACK {
    pub fn svd(matrix: &Matrix) -> Result<SvdResult> {
        // Use ndarray-linalg SVD for complex matrices
        use scirs2_core::ndarray::ndarray_linalg::SVD; // SciRS2 POLICY compliant

        let svd_result = matrix
            .data
            .svd(true, true)
            .map_err(|_| SimulatorError::ComputationError("SVD computation failed".to_string()))?;

        // Extract U, S, Vt from the SVD result
        let pool = MemoryPool::new();

        let u_data = svd_result.0;
        let s_data = svd_result.1;
        let vt_data = svd_result.2;

        let u = Matrix::from_array2(&u_data.view(), &pool)?;
        // Convert real singular values to complex for consistency
        let s_complex: Array1<Complex64> = s_data.mapv(|x| Complex64::new(x, 0.0));
        let s = Vector::from_array1(&s_complex.view(), &pool)?;
        let vt = Matrix::from_array2(&vt_data.view(), &pool)?;

        Ok(SvdResult { u, s, vt })
    }

    pub fn eig(matrix: &Matrix) -> Result<EigResult> {
        // Eigenvalue decomposition using SciRS2
        use scirs2_core::ndarray::ndarray_linalg::Eig; // SciRS2 POLICY compliant

        let (eigenvalues_array, eigenvectors_array) = matrix.data.eig().map_err(|_| {
            SimulatorError::ComputationError("Eigenvalue decomposition failed".to_string())
        })?;

        let pool = MemoryPool::new();
        let values = Vector::from_array1(&eigenvalues_array.view(), &pool)?;
        let vectors = Matrix::from_array2(&eigenvectors_array.view(), &pool)?;

        Ok(EigResult { values, vectors })
    }

    pub fn lu(matrix: &Matrix) -> Result<(Matrix, Matrix, Vec<usize>)> {
        // Simplified LU decomposition - for production use, would need proper LU with pivoting
        let n = matrix.data.nrows();
        let pool = MemoryPool::new();

        // Initialize L as identity and U as copy of input
        let mut l_data = Array2::eye(n);
        let mut u_data = matrix.data.clone();
        let mut perm_vec: Vec<usize> = (0..n).collect();

        // Simplified Gaussian elimination
        for k in 0..n.min(n) {
            // Find pivot
            let mut max_row = k;
            let mut max_val = u_data[[k, k]].norm();
            for i in k + 1..n {
                let val = u_data[[i, k]].norm();
                if val > max_val {
                    max_val = val;
                    max_row = i;
                }
            }

            // Swap rows if needed
            if max_row != k {
                for j in 0..n {
                    let temp = u_data[[k, j]];
                    u_data[[k, j]] = u_data[[max_row, j]];
                    u_data[[max_row, j]] = temp;
                }
                perm_vec.swap(k, max_row);
            }

            // Eliminate column
            if u_data[[k, k]].norm() > 1e-10 {
                for i in k + 1..n {
                    let factor = u_data[[i, k]] / u_data[[k, k]];
                    l_data[[i, k]] = factor;
                    for j in k..n {
                        let u_kj = u_data[[k, j]];
                        u_data[[i, j]] -= factor * u_kj;
                    }
                }
            }
        }

        let l_matrix = Matrix::from_array2(&l_data.view(), &pool)?;
        let u_matrix = Matrix::from_array2(&u_data.view(), &pool)?;

        Ok((l_matrix, u_matrix, perm_vec))
    }

    pub fn qr(matrix: &Matrix) -> Result<(Matrix, Matrix)> {
        // QR decomposition using ndarray-linalg
        use scirs2_core::ndarray::ndarray_linalg::QR; // SciRS2 POLICY compliant

        let (q, r) = matrix
            .data
            .qr()
            .map_err(|_| SimulatorError::ComputationError("QR decomposition failed".to_string()))?;

        let pool = MemoryPool::new();
        let q_matrix = Matrix::from_array2(&q.view(), &pool)?;
        let r_matrix = Matrix::from_array2(&r.view(), &pool)?;

        Ok((q_matrix, r_matrix))
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct LAPACK;

#[cfg(not(feature = "advanced_math"))]
impl LAPACK {
    pub fn svd(_matrix: &Matrix) -> Result<SvdResult> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }

    pub fn eig(_matrix: &Matrix) -> Result<EigResult> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// SVD decomposition result
#[cfg(feature = "advanced_math")]
#[derive(Debug, Clone)]
pub struct SvdResult {
    /// U matrix (left singular vectors)
    pub u: Matrix,
    /// Singular values
    pub s: Vector,
    /// V^T matrix (right singular vectors)
    pub vt: Matrix,
}

/// Eigenvalue decomposition result
#[cfg(feature = "advanced_math")]
#[derive(Debug, Clone)]
pub struct EigResult {
    /// Eigenvalues
    pub values: Vector,
    /// Eigenvectors (as columns of matrix)
    pub vectors: Matrix,
}

#[cfg(feature = "advanced_math")]
impl EigResult {
    pub fn to_array1(&self) -> Result<Array1<Complex64>> {
        self.values.to_array1()
    }

    pub const fn eigenvalues(&self) -> &Vector {
        &self.values
    }

    pub const fn eigenvectors(&self) -> &Matrix {
        &self.vectors
    }
}

#[cfg(feature = "advanced_math")]
impl SvdResult {
    pub fn to_array2(&self) -> Result<Array2<Complex64>> {
        self.u.data.to_owned().into_dimensionality().map_err(|_| {
            SimulatorError::ComputationError("Failed to convert SVD result to array2".to_string())
        })
    }

    pub const fn u_matrix(&self) -> &Matrix {
        &self.u
    }

    pub const fn singular_values(&self) -> &Vector {
        &self.s
    }

    pub const fn vt_matrix(&self) -> &Matrix {
        &self.vt
    }
}

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct SvdResult;

#[cfg(not(feature = "advanced_math"))]
#[derive(Debug)]
pub struct EigResult;

#[cfg(not(feature = "advanced_math"))]
impl EigResult {
    pub fn to_array1(&self) -> Result<Array1<Complex64>> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

#[cfg(not(feature = "advanced_math"))]
impl SvdResult {
    pub fn to_array2(&self) -> Result<Array2<Complex64>> {
        Err(SimulatorError::UnsupportedOperation(
            "SciRS2 integration requires 'advanced_math' feature".to_string(),
        ))
    }
}

/// Advanced FFT operations for quantum simulation
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct AdvancedFFT;

#[cfg(feature = "advanced_math")]
impl AdvancedFFT {
    /// Multidimensional FFT for quantum state processing
    pub fn fft_nd(input: &Array2<Complex64>) -> Result<Array2<Complex64>> {
        use ndrustfft::{ndfft, FftHandler};

        let (rows, cols) = input.dim();
        let mut result = input.clone();

        // FFT along each dimension
        for i in 0..rows {
            let row = input.row(i).to_owned();
            let mut row_out = row.clone();
            let mut handler = FftHandler::new(cols);
            ndfft(&row, &mut row_out, &handler, 0);
            result.row_mut(i).assign(&row_out);
        }

        for j in 0..cols {
            let col = result.column(j).to_owned();
            let mut col_out = col.clone();
            let mut handler = FftHandler::new(rows);
            ndfft(&col, &mut col_out, &handler, 0);
            result.column_mut(j).assign(&col_out);
        }

        Ok(result)
    }

    /// Windowed FFT for spectral analysis
    pub fn windowed_fft(
        input: &Vector,
        window_size: usize,
        overlap: usize,
    ) -> Result<Array2<Complex64>> {
        let array = input.to_array1()?;
        let step_size = window_size - overlap;
        let num_windows = (array.len() - overlap) / step_size;

        let mut result = Array2::zeros((num_windows, window_size));

        for (i, mut row) in result.outer_iter_mut().enumerate() {
            let start = i * step_size;
            let end = (start + window_size).min(array.len());

            if end - start == window_size {
                let window = array.slice(s![start..end]);

                // Apply Hann window
                let windowed: Array1<Complex64> = window
                    .iter()
                    .enumerate()
                    .map(|(j, &val)| {
                        let hann =
                            0.5 * (1.0 - (2.0 * PI * j as f64 / (window_size - 1) as f64).cos());
                        val * Complex64::new(hann, 0.0)
                    })
                    .collect();

                // Compute FFT
                let mut handler = FftHandler::new(window_size);
                let mut fft_result = windowed.clone();
                ndrustfft::ndfft(&windowed, &mut fft_result, &handler, 0);

                row.assign(&fft_result);
            }
        }

        Ok(result)
    }

    /// Convolution using FFT
    pub fn convolution(a: &Vector, b: &Vector) -> Result<Vector> {
        let a_array = a.to_array1()?;
        let b_array = b.to_array1()?;

        let n = a_array.len() + b_array.len() - 1;
        let fft_size = n.next_power_of_two();

        // Zero-pad inputs
        let mut a_padded = Array1::zeros(fft_size);
        let mut b_padded = Array1::zeros(fft_size);
        a_padded.slice_mut(s![..a_array.len()]).assign(&a_array);
        b_padded.slice_mut(s![..b_array.len()]).assign(&b_array);

        // FFT
        let mut handler = FftHandler::new(fft_size);
        let mut a_fft = a_padded.clone();
        let mut b_fft = b_padded.clone();
        ndrustfft::ndfft(&a_padded, &mut a_fft, &handler, 0);
        ndrustfft::ndfft(&b_padded, &mut b_fft, &handler, 0);

        // Multiply in frequency domain
        let mut product = Array1::zeros(fft_size);
        for i in 0..fft_size {
            product[i] = a_fft[i] * b_fft[i];
        }

        // IFFT
        let mut result = product.clone();
        ndrustfft::ndifft(&product, &mut result, &handler, 0);

        // Truncate to correct size and create Vector
        let truncated = result.slice(s![..n]).to_owned();
        Vector::from_array1(&truncated.view(), &MemoryPool::new())
    }
}

/// Advanced sparse linear algebra solvers
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct SparseSolvers;

#[cfg(feature = "advanced_math")]
impl SparseSolvers {
    /// Conjugate Gradient solver for Ax = b
    pub fn conjugate_gradient(
        matrix: &SparseMatrix,
        b: &Vector,
        x0: Option<&Vector>,
        tolerance: f64,
        max_iterations: usize,
    ) -> Result<Vector> {
        // TEMPORARY: Using nalgebra until refactored to scirs2_linalg (VIOLATES SciRS2 POLICY)
        use nalgebra::{Complex, DVector};

        let b_array = b.to_array1()?;
        let b_vec = DVector::from_iterator(
            b_array.len(),
            b_array.iter().map(|&c| Complex::new(c.re, c.im)),
        );

        let mut x = if let Some(x0_vec) = x0 {
            let x0_array = x0_vec.to_array1()?;
            DVector::from_iterator(
                x0_array.len(),
                x0_array.iter().map(|&c| Complex::new(c.re, c.im)),
            )
        } else {
            DVector::zeros(b_vec.len())
        };

        // Initial residual: r = b - Ax
        let pool = MemoryPool::new();
        let x_vector = Vector::from_array1(
            &Array1::from_vec(x.iter().map(|c| Complex64::new(c.re, c.im)).collect()).view(),
            &pool,
        )?;
        let mut ax_vector = Vector::zeros(x.len(), &pool)?;
        matrix.matvec(&x_vector, &mut ax_vector)?;

        // Convert back to DVector for computation
        let ax_array = ax_vector.to_array1()?;
        let ax = DVector::from_iterator(
            ax_array.len(),
            ax_array.iter().map(|&c| Complex::new(c.re, c.im)),
        );

        let mut r = &b_vec - &ax;
        let mut p = r.clone();
        let mut rsold = r.dot(&r).re;

        for _ in 0..max_iterations {
            // Ap = A * p
            let p_vec = Vector::from_array1(
                &Array1::from_vec(p.iter().map(|c| Complex64::new(c.re, c.im)).collect()).view(),
                &MemoryPool::new(),
            )?;
            let mut ap_vec =
                Vector::from_array1(&Array1::zeros(p.len()).view(), &MemoryPool::new())?;
            matrix.matvec(&p_vec, &mut ap_vec)?;
            let ap_array = ap_vec.to_array1()?;
            let ap = DVector::from_iterator(
                ap_array.len(),
                ap_array.iter().map(|&c| Complex::new(c.re, c.im)),
            );

            let alpha = rsold / p.dot(&ap).re;
            let alpha_complex = Complex::new(alpha, 0.0);
            x += &p * alpha_complex;
            r -= &ap * alpha_complex;

            let rsnew = r.dot(&r).re;
            if rsnew.sqrt() < tolerance {
                break;
            }

            let beta = rsnew / rsold;
            let beta_complex = Complex::new(beta, 0.0);
            p = &r + &p * beta_complex;
            rsold = rsnew;
        }

        let result_array = Array1::from_vec(x.iter().map(|c| Complex64::new(c.re, c.im)).collect());
        Vector::from_array1(&result_array.view(), &MemoryPool::new())
    }

    /// GMRES solver for non-symmetric systems
    pub fn gmres(
        matrix: &SparseMatrix,
        b: &Vector,
        x0: Option<&Vector>,
        tolerance: f64,
        max_iterations: usize,
        restart: usize,
    ) -> Result<Vector> {
        let b_array = b.to_array1()?;
        let n = b_array.len();

        let mut x = if let Some(x0_vec) = x0 {
            x0_vec.to_array1()?.to_owned()
        } else {
            Array1::zeros(n)
        };

        for _restart_iter in 0..(max_iterations / restart) {
            // Calculate initial residual
            let mut ax = Array1::zeros(n);
            let x_vec = Vector::from_array1(&x.view(), &MemoryPool::new())?;
            let mut ax_vec = Vector::from_array1(&ax.view(), &MemoryPool::new())?;
            matrix.matvec(&x_vec, &mut ax_vec)?;
            ax = ax_vec.to_array1()?;

            let mut r = &b_array - &ax;
            let beta = r.norm_l2()?;

            if beta < tolerance {
                break;
            }

            r = r.mapv(|x| x / Complex64::new(beta, 0.0));

            // Arnoldi process
            let mut v = Vec::new();
            v.push(r.clone());

            let mut h = Array2::zeros((restart + 1, restart));

            for j in 0..restart.min(max_iterations) {
                let v_vec = Vector::from_array1(&v[j].view(), &MemoryPool::new())?;
                let mut av = Array1::zeros(n);
                let mut av_vec = Vector::from_array1(&av.view(), &MemoryPool::new())?;
                matrix.matvec(&v_vec, &mut av_vec)?;
                av = av_vec.to_array1()?;

                // Modified Gram-Schmidt orthogonalization
                for i in 0..=j {
                    h[[i, j]] = v[i].dot(&av);
                    av = av - h[[i, j]] * &v[i];
                }

                h[[j + 1, j]] = Complex64::new(av.norm_l2()?, 0.0);

                if h[[j + 1, j]].norm() < tolerance {
                    break;
                }

                av /= h[[j + 1, j]];
                v.push(av);
            }

            // Solve least squares problem using the constructed Hessenberg matrix
            // Simplified implementation - would use proper QR factorization in production
            let krylov_dim = v.len() - 1;
            if krylov_dim > 0 {
                let mut e1 = Array1::zeros(krylov_dim + 1);
                e1[0] = Complex64::new(beta, 0.0);

                // Simple back-substitution for upper triangular solve
                let mut y = Array1::zeros(krylov_dim);
                for i in (0..krylov_dim).rev() {
                    let mut sum = Complex64::new(0.0, 0.0);
                    for j in (i + 1)..krylov_dim {
                        sum += h[[i, j]] * y[j];
                    }
                    y[i] = (e1[i] - sum) / h[[i, i]];
                }

                // Update solution
                for i in 0..krylov_dim {
                    x = x + y[i] * &v[i];
                }
            }
        }

        Vector::from_array1(&x.view(), &MemoryPool::new())
    }

    /// BiCGSTAB solver for complex systems
    pub fn bicgstab(
        matrix: &SparseMatrix,
        b: &Vector,
        x0: Option<&Vector>,
        tolerance: f64,
        max_iterations: usize,
    ) -> Result<Vector> {
        let b_array = b.to_array1()?;
        let n = b_array.len();

        let mut x = if let Some(x0_vec) = x0 {
            x0_vec.to_array1()?.to_owned()
        } else {
            Array1::zeros(n)
        };

        // Calculate initial residual
        let mut ax = Array1::zeros(n);
        let x_vec = Vector::from_array1(&x.view(), &MemoryPool::new())?;
        let mut ax_vec = Vector::from_array1(&ax.view(), &MemoryPool::new())?;
        matrix.matvec(&x_vec, &mut ax_vec)?;
        ax = ax_vec.to_array1()?;

        let mut r = &b_array - &ax;
        let r0 = r.clone();

        let mut rho = Complex64::new(1.0, 0.0);
        let mut alpha = Complex64::new(1.0, 0.0);
        let mut omega = Complex64::new(1.0, 0.0);

        let mut p = Array1::zeros(n);
        let mut v = Array1::zeros(n);

        for _ in 0..max_iterations {
            let rho_new = r0.dot(&r);
            let beta = (rho_new / rho) * (alpha / omega);

            p = &r + beta * (&p - omega * &v);

            // v = A * p
            let p_vec = Vector::from_array1(&p.view(), &MemoryPool::new())?;
            let mut v_vec = Vector::from_array1(&v.view(), &MemoryPool::new())?;
            matrix.matvec(&p_vec, &mut v_vec)?;
            v = v_vec.to_array1()?;

            alpha = rho_new / r0.dot(&v);
            let s = &r - alpha * &v;

            if s.norm_l2()? < tolerance {
                x = x + alpha * &p;
                break;
            }

            // t = A * s
            let s_vec = Vector::from_array1(&s.view(), &MemoryPool::new())?;
            let mut t_vec = Vector::from_array1(&Array1::zeros(n).view(), &MemoryPool::new())?;
            matrix.matvec(&s_vec, &mut t_vec)?;
            let t = t_vec.to_array1()?;

            omega = t.dot(&s) / t.dot(&t);
            x = x + alpha * &p + omega * &s;
            r = s - omega * &t;

            if r.norm_l2()? < tolerance {
                break;
            }

            rho = rho_new;
        }

        Vector::from_array1(&x.view(), &MemoryPool::new())
    }
}

/// Advanced eigenvalue solvers for large sparse matrices
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct AdvancedEigensolvers;

#[cfg(feature = "advanced_math")]
impl AdvancedEigensolvers {
    /// Lanczos algorithm for finding a few eigenvalues of large sparse symmetric matrices
    pub fn lanczos(
        matrix: &SparseMatrix,
        num_eigenvalues: usize,
        max_iterations: usize,
        tolerance: f64,
    ) -> Result<EigResult> {
        let n = matrix.csr_matrix.nrows();
        let m = num_eigenvalues.min(max_iterations);

        // Initialize random starting vector
        let mut q = Array1::from_vec(
            (0..n)
                .map(|_| {
                    Complex64::new(
                        thread_rng().gen::<f64>() - 0.5,
                        thread_rng().gen::<f64>() - 0.5,
                    )
                })
                .collect(),
        );
        let q_norm = q.norm_l2()?;
        q = q.mapv(|x| x / Complex64::new(q_norm, 0.0));

        let mut q_vectors = Vec::new();
        q_vectors.push(q.clone());

        let mut alpha = Vec::new();
        let mut beta = Vec::new();

        let mut q_prev = Array1::<Complex64>::zeros(n);

        for j in 0..m {
            // Av = A * q[j]
            let q_vec = Vector::from_array1(&q_vectors[j].view(), &MemoryPool::new())?;
            let mut av_vec = Vector::from_array1(&Array1::zeros(n).view(), &MemoryPool::new())?;
            matrix.matvec(&q_vec, &mut av_vec)?;
            let mut av = av_vec.to_array1()?;

            // Alpha computation
            let alpha_j = q_vectors[j].dot(&av);
            alpha.push(alpha_j);

            // Orthogonalization
            av = av - alpha_j * &q_vectors[j];
            if j > 0 {
                av = av - Complex64::new(beta[j - 1], 0.0) * &q_prev;
            }

            let beta_j = av.norm_l2()?;

            if beta_j.abs() < tolerance {
                break;
            }

            beta.push(beta_j);
            q_prev = q_vectors[j].clone();

            if j + 1 < m {
                q = av / beta_j;
                q_vectors.push(q.clone());
            }
        }

        // Solve the tridiagonal eigenvalue problem
        let dim = alpha.len();
        let mut tridiag = Array2::zeros((dim, dim));

        for i in 0..dim {
            tridiag[[i, i]] = alpha[i];
            if i > 0 {
                tridiag[[i - 1, i]] = Complex64::new(beta[i - 1], 0.0);
                tridiag[[i, i - 1]] = Complex64::new(beta[i - 1], 0.0);
            }
        }

        // Use simple power iteration for the tridiagonal system (simplified)
        let mut eigenvalues = Array1::zeros(num_eigenvalues.min(dim));
        for i in 0..eigenvalues.len() {
            eigenvalues[i] = tridiag[[i, i]]; // Simplified - would use proper tridiagonal solver
        }

        // Construct approximate eigenvectors
        let mut eigenvectors = Array2::zeros((n, eigenvalues.len()));
        for (i, mut col) in eigenvectors
            .columns_mut()
            .into_iter()
            .enumerate()
            .take(eigenvalues.len())
        {
            if i < q_vectors.len() {
                col.assign(&q_vectors[i]);
            }
        }

        let values = Vector::from_array1(&eigenvalues.view(), &MemoryPool::new())?;
        let vectors = Matrix::from_array2(&eigenvectors.view(), &MemoryPool::new())?;

        Ok(EigResult { values, vectors })
    }

    /// Arnoldi iteration for non-symmetric matrices
    pub fn arnoldi(
        matrix: &SparseMatrix,
        num_eigenvalues: usize,
        max_iterations: usize,
        tolerance: f64,
    ) -> Result<EigResult> {
        let n = matrix.csr_matrix.nrows();
        let m = num_eigenvalues.min(max_iterations);

        // Initialize random starting vector
        let mut q = Array1::from_vec(
            (0..n)
                .map(|_| {
                    Complex64::new(
                        thread_rng().gen::<f64>() - 0.5,
                        thread_rng().gen::<f64>() - 0.5,
                    )
                })
                .collect(),
        );
        let q_norm = q.norm_l2()?;
        q = q.mapv(|x| x / Complex64::new(q_norm, 0.0));

        let mut q_vectors = Vec::new();
        q_vectors.push(q.clone());

        let mut h = Array2::zeros((m + 1, m));

        for j in 0..m {
            // v = A * q[j]
            let q_vec = Vector::from_array1(&q_vectors[j].view(), &MemoryPool::new())?;
            let mut v_vec = Vector::from_array1(&Array1::zeros(n).view(), &MemoryPool::new())?;
            matrix.matvec(&q_vec, &mut v_vec)?;
            let mut v = v_vec.to_array1()?;

            // Modified Gram-Schmidt orthogonalization
            for i in 0..=j {
                h[[i, j]] = q_vectors[i].dot(&v);
                v = v - h[[i, j]] * &q_vectors[i];
            }

            h[[j + 1, j]] = Complex64::new(v.norm_l2()?, 0.0);

            if h[[j + 1, j]].norm() < tolerance {
                break;
            }

            if j + 1 < m {
                q = v / h[[j + 1, j]];
                q_vectors.push(q.clone());
            }
        }

        // Extract eigenvalues from upper Hessenberg matrix (simplified)
        let dim = q_vectors.len();
        let mut eigenvalues = Array1::zeros(num_eigenvalues.min(dim));
        for i in 0..eigenvalues.len() {
            eigenvalues[i] = h[[i, i]]; // Simplified extraction
        }

        // Construct eigenvectors
        let mut eigenvectors = Array2::zeros((n, eigenvalues.len()));
        for (i, mut col) in eigenvectors
            .columns_mut()
            .into_iter()
            .enumerate()
            .take(eigenvalues.len())
        {
            if i < q_vectors.len() {
                col.assign(&q_vectors[i]);
            }
        }

        let values = Vector::from_array1(&eigenvalues.view(), &MemoryPool::new())?;
        let vectors = Matrix::from_array2(&eigenvectors.view(), &MemoryPool::new())?;

        Ok(EigResult { values, vectors })
    }
}

/// Enhanced linear algebra operations
#[cfg(feature = "advanced_math")]
#[derive(Debug)]
pub struct AdvancedLinearAlgebra;

#[cfg(feature = "advanced_math")]
impl AdvancedLinearAlgebra {
    /// QR decomposition with pivoting
    pub fn qr_decomposition(matrix: &Matrix) -> Result<QRResult> {
        use scirs2_core::ndarray::ndarray_linalg::QR; // SciRS2 POLICY compliant

        let qr_result = matrix
            .data
            .qr()
            .map_err(|_| SimulatorError::ComputationError("QR decomposition failed".to_string()))?;

        let pool = MemoryPool::new();
        let q = Matrix::from_array2(&qr_result.0.view(), &pool)?;
        let r = Matrix::from_array2(&qr_result.1.view(), &pool)?;

        Ok(QRResult { q, r })
    }

    /// Cholesky decomposition for positive definite matrices
    pub fn cholesky_decomposition(matrix: &Matrix) -> Result<Matrix> {
        use scirs2_core::ndarray::ndarray_linalg::{Cholesky, UPLO}; // SciRS2 POLICY compliant

        let chol_result = matrix.data.cholesky(UPLO::Lower).map_err(|_| {
            SimulatorError::ComputationError("Cholesky decomposition failed".to_string())
        })?;

        Matrix::from_array2(&chol_result.view(), &MemoryPool::new())
    }

    /// Matrix exponential for quantum evolution
    pub fn matrix_exponential(matrix: &Matrix, t: f64) -> Result<Matrix> {
        let scaled_matrix = &matrix.data * Complex64::new(0.0, -t);

        // Matrix exponential using scaling and squaring with Pad approximation
        let mut result = Array2::eye(scaled_matrix.nrows());
        let mut term = Array2::eye(scaled_matrix.nrows());

        // Simple series expansion (would use more sophisticated methods in production)
        for k in 1..20 {
            term = term.dot(&scaled_matrix) / Complex64::new(k as f64, 0.0);
            result += &term;

            if term.norm_l2().unwrap_or(f64::INFINITY) < 1e-12 {
                break;
            }
        }

        Matrix::from_array2(&result.view(), &MemoryPool::new())
    }

    /// Pseudoinverse using SVD
    pub fn pseudoinverse(matrix: &Matrix, tolerance: f64) -> Result<Matrix> {
        let svd_result = LAPACK::svd(matrix)?;

        let u = svd_result.u.data;
        let s = svd_result.s.to_array1()?;
        let vt = svd_result.vt.data;

        // Create pseudoinverse of singular values
        let mut s_pinv = Array1::zeros(s.len());
        for (i, &sigma) in s.iter().enumerate() {
            if sigma.norm() > tolerance {
                s_pinv[i] = Complex64::new(1.0, 0.0) / sigma;
            }
        }

        // Construct pseudoinverse: V * S^+ * U^T
        let s_pinv_diag = Array2::from_diag(&s_pinv);
        let result = vt.t().dot(&s_pinv_diag).dot(&u.t());

        Matrix::from_array2(&result.view(), &MemoryPool::new())
    }

    /// Condition number estimation
    pub fn condition_number(matrix: &Matrix) -> Result<f64> {
        let svd_result = LAPACK::svd(matrix)?;
        let s = svd_result.s.to_array1()?;

        let mut min_singular = f64::INFINITY;
        let mut max_singular: f64 = 0.0;

        for &sigma in &s {
            let sigma_norm = sigma.norm();
            if sigma_norm > 1e-15 {
                min_singular = min_singular.min(sigma_norm);
                max_singular = max_singular.max(sigma_norm);
            }
        }

        Ok(max_singular / min_singular)
    }
}

/// QR decomposition result
#[cfg(feature = "advanced_math")]
#[derive(Debug, Clone)]
pub struct QRResult {
    /// Q matrix (orthogonal)
    pub q: Matrix,
    /// R matrix (upper triangular)
    pub r: Matrix,
}

/// Performance benchmarking for `SciRS2` integration
pub fn benchmark_scirs2_integration() -> Result<HashMap<String, f64>> {
    let mut results = HashMap::new();

    // FFT benchmarks
    #[cfg(feature = "advanced_math")]
    {
        let start = std::time::Instant::now();
        let engine = FftEngine::new();
        let test_vector = Vector::from_array1(
            &Array1::from_vec((0..1024).map(|i| Complex64::new(i as f64, 0.0)).collect()).view(),
            &MemoryPool::new(),
        )?;

        for _ in 0..100 {
            let _ = engine.forward(&test_vector)?;
        }

        let fft_time = start.elapsed().as_millis() as f64;
        results.insert("fft_1024_100_iterations".to_string(), fft_time);
    }

    // Sparse solver benchmarks
    #[cfg(feature = "advanced_math")]
    {
        use nalgebra_sparse::CsrMatrix;

        let start = std::time::Instant::now();

        // Create test sparse matrix
        let mut row_indices = [0; 1000];
        let mut col_indices = [0; 1000];
        let mut values = [Complex64::new(0.0, 0.0); 1000];

        for i in 0..100 {
            for j in 0..10 {
                let idx = i * 10 + j;
                row_indices[idx] = i;
                col_indices[idx] = (i + j) % 100;
                values[idx] = Complex64::new(1.0, 0.0);
            }
        }

        let csr = CsrMatrix::try_from_csr_data(
            100,
            100,
            row_indices.to_vec(),
            col_indices.to_vec(),
            values.to_vec(),
        )
        .map_err(|_| {
            SimulatorError::ComputationError("Failed to create test matrix".to_string())
        })?;

        let sparse_matrix = SparseMatrix { csr_matrix: csr };
        let b = Vector::from_array1(&Array1::ones(100).view(), &MemoryPool::new())?;

        let _ = SparseSolvers::conjugate_gradient(&sparse_matrix, &b, None, 1e-6, 100)?;

        let sparse_solver_time = start.elapsed().as_millis() as f64;
        results.insert("cg_solver_100x100".to_string(), sparse_solver_time);
    }

    // Linear algebra benchmarks
    #[cfg(feature = "advanced_math")]
    {
        let start = std::time::Instant::now();

        let test_matrix = Matrix::from_array2(&Array2::eye(50).view(), &MemoryPool::new())?;
        for _ in 0..10 {
            let _ = AdvancedLinearAlgebra::qr_decomposition(&test_matrix)?;
        }

        let qr_time = start.elapsed().as_millis() as f64;
        results.insert("qr_decomposition_50x50_10_iterations".to_string(), qr_time);
    }

    Ok(results)
}
