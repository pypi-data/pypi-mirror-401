# Performance Optimization Guide for Large-Scale Quantum ML

**QuantRS2-ML Performance Engineering**
Version 0.1.0-rc.2
Last Updated: 2025-12-05

---

## Table of Contents

1. [Introduction](#introduction)
2. [SciRS2 Integration Best Practices](#scirs2-integration-best-practices)
3. [SIMD Optimization](#simd-optimization)
4. [Parallel Processing](#parallel-processing)
5. [GPU Acceleration](#gpu-acceleration)
6. [Memory Management](#memory-management)
7. [Quantum Circuit Optimization](#quantum-circuit-optimization)
8. [Batch Processing](#batch-processing)
9. [Caching Strategies](#caching-strategies)
10. [Profiling and Benchmarking](#profiling-and-benchmarking)
11. [Production Deployment](#production-deployment)
12. [Common Pitfalls](#common-pitfalls)

---

## Introduction

This guide provides comprehensive strategies for optimizing quantum machine learning workloads in QuantRS2. Performance optimization is critical for:

- **Training Speed**: Reducing time-to-convergence for variational algorithms
- **Inference Latency**: Real-time predictions for production systems
- **Resource Utilization**: Efficient use of classical and quantum resources
- **Cost Efficiency**: Minimizing cloud quantum hardware costs
- **Scalability**: Handling large datasets and high-dimensional problems

### Performance Targets

| Workload Type | Target Performance | Best Practices |
|---------------|-------------------|----------------|
| VQE Training | < 1s per iteration (10 qubits) | Circuit caching, parallel gradient estimation |
| QAOA Optimization | < 5s per problem (20 qubits) | Graph partitioning, approximate gradients |
| QNN Inference | < 10ms per sample | Batch processing, compiled circuits |
| QSVM Training | < 1min (1000 samples) | Kernel caching, parallel kernel computation |
| Large-scale Training | Linear scaling to 10K+ samples | Distributed training, GPU acceleration |

---

## SciRS2 Integration Best Practices

### 1. Unified Import Pattern

**❌ WRONG - Fragmented Imports**
```rust
use ndarray::{Array2, array};
use scirs2_autograd::ndarray::ArrayView1;  // Fragmented!
use rand::thread_rng;
```

**✅ CORRECT - Unified SciRS2 Pattern**
```rust
use scirs2_core::ndarray::{Array1, Array2, array, s, Axis};  // Unified!
use scirs2_core::random::prelude::*;
use scirs2_core::{Complex64, Complex32};
```

**Performance Impact**: Unified imports enable compiler optimizations and avoid duplicate symbol resolution.

### 2. Use SciRS2 Optimized Operations

**❌ SLOW - Manual Loops**
```rust
// Inefficient manual matrix multiplication
let mut result = Array2::zeros((n, m));
for i in 0..n {
    for j in 0..m {
        for k in 0..p {
            result[[i, j]] += a[[i, k]] * b[[k, j]];
        }
    }
}
```

**✅ FAST - SciRS2 BLAS**
```rust
use scirs2_linalg::blas::gemm;

// Use optimized BLAS routine (10-100x faster)
let result = gemm(&a, &b);  // Calls LAPACK/MKL underneath
```

**Performance Impact**: 10-100x speedup for large matrices (> 100×100).

### 3. Leverage SciRS2 Parallel Operations

**❌ SLOW - Sequential Processing**
```rust
let results: Vec<f64> = samples.iter()
    .map(|sample| expensive_quantum_computation(sample))
    .collect();
```

**✅ FAST - SciRS2 Parallel**
```rust
use scirs2_core::parallel_ops::{par_iter, par_chunks};

let results: Vec<f64> = par_iter(&samples)
    .map(|sample| expensive_quantum_computation(sample))
    .collect();
```

**Performance Impact**: Near-linear scaling with CPU cores (8-16x on modern CPUs).

### 4. Use SciRS2 Random Number Generation

**❌ SLOW - External RNG**
```rust
use rand::{thread_rng, Rng};  // Not integrated with SciRS2!

let samples: Vec<f64> = (0..n)
    .map(|_| thread_rng().gen())
    .collect();
```

**✅ FAST - SciRS2 Random**
```rust
use scirs2_core::random::{thread_rng, distributions::Uniform};

let mut rng = thread_rng();
let uniform = Uniform::new(0.0, 1.0);
let samples = Array1::from_shape_fn(n, |_| rng.sample(&uniform));
```

**Performance Impact**: 2-5x faster due to SIMD random number generation and better cache locality.

---

## SIMD Optimization

### 1. Enable SIMD for Complex Arithmetic

```rust
use scirs2_core::simd_ops::{SimdOps, PlatformCapabilities};

// Check SIMD capabilities
let caps = PlatformCapabilities::current();
println!("AVX2: {}, AVX-512: {}", caps.has_avx2(), caps.has_avx512());

// Quantum state vector operations with SIMD
if caps.has_avx2() {
    // Use vectorized complex multiplication (4-8x faster)
    scirs2_core::simd_ops::vectorized_complex_multiply(
        &mut state_vector,
        &gate_matrix
    );
}
```

**Performance Impact**: 4-8x speedup for quantum gate applications on state vectors.

### 2. Batch Quantum Operations

```rust
use scirs2_core::simd_ops::batch_complex_ops;

// Process 8 quantum states simultaneously with AVX2
let batch_states = Array3::zeros((batch_size, 2_usize.pow(n_qubits), 1));
batch_complex_ops::apply_gates_batch(&mut batch_states, &gates);
```

**Performance Impact**: 8-16x speedup for batch quantum circuit execution.

### 3. Optimize Measurement Sampling

```rust
use scirs2_core::simd_ops::simd_sampling;

// SIMD-accelerated measurement sampling
let samples = simd_sampling::sample_measurement_outcomes(
    &state_vector,
    n_shots,
    &mut rng
);
```

**Performance Impact**: 10-20x faster measurement sampling for large shot counts.

---

## Parallel Processing

### 1. Parallel Gradient Estimation (Parameter Shift Rule)

```rust
use scirs2_core::parallel_ops::par_iter;
use rayon::prelude::*;

fn compute_gradients_parallel(
    circuit: &VariationalCircuit,
    parameters: &Array1<f64>,
    n_params: usize
) -> Array1<f64> {
    // Compute all parameter gradients in parallel
    let gradients: Vec<f64> = (0..n_params)
        .into_par_iter()
        .map(|i| {
            let mut params_plus = parameters.clone();
            params_plus[i] += std::f64::consts::PI / 2.0;
            let forward = circuit.evaluate(&params_plus);

            let mut params_minus = parameters.clone();
            params_minus[i] -= std::f64::consts::PI / 2.0;
            let backward = circuit.evaluate(&params_minus);

            (forward - backward) / 2.0
        })
        .collect();

    Array1::from_vec(gradients)
}
```

**Performance Impact**: Linear scaling with CPU cores (16x on 16-core CPU).

### 2. Parallel Kernel Matrix Computation (QSVM)

```rust
use scirs2_core::parallel_ops::par_chunks;

fn compute_kernel_matrix_parallel(
    samples: &Array2<f64>,
    quantum_kernel: &QuantumKernel
) -> Array2<f64> {
    let n = samples.shape()[0];
    let mut kernel_matrix = Array2::zeros((n, n));

    // Parallelize over rows
    kernel_matrix.axis_iter_mut(Axis(0))
        .into_par_iter()
        .enumerate()
        .for_each(|(i, mut row)| {
            for j in 0..n {
                row[j] = quantum_kernel.compute(&samples.row(i), &samples.row(j));
            }
        });

    kernel_matrix
}
```

**Performance Impact**: Near-linear scaling with cores for large kernel matrices.

### 3. Parallel Ensemble Training

```rust
use scirs2_core::parallel_ops::par_join;

// Train multiple quantum models in parallel
let models: Vec<QuantumModel> = par_join(
    || train_model_1(),
    || train_model_2(),
    || train_model_3(),
    || train_model_4(),
);
```

**Performance Impact**: 4x speedup for ensemble methods (4 models).

---

## GPU Acceleration

### 1. Enable GPU Backend (Metal on macOS)

```rust
#[cfg(feature = "gpu")]
use quantrs2_ml::gpu_backend_impl::{MetalBackend, GPUConfig};

let gpu_config = GPUConfig {
    device_index: 0,
    memory_pool_size: 1024 * 1024 * 1024,  // 1GB
    enable_mixed_precision: true,
};

let gpu_backend = MetalBackend::new(gpu_config)?;
```

### 2. GPU-Accelerated State Vector Simulation

```rust
use quantrs2_sim::gpu_metal::MetalSimulator;

// Simulate up to 30+ qubits on GPU
let simulator = MetalSimulator::new(n_qubits, &gpu_backend)?;

// Apply gates on GPU (100-1000x faster than CPU)
simulator.apply_circuit_gpu(&circuit)?;

let state_vector = simulator.get_state_vector()?;
```

**Performance Impact**: 100-1000x speedup for large state vectors (> 20 qubits).

### 3. GPU Batch Inference

```rust
// Process 1000s of samples simultaneously on GPU
let batch_results = simulator.run_batch_inference_gpu(
    &circuit,
    &input_samples,  // Shape: (batch_size, n_features)
    batch_size: 512
)?;
```

**Performance Impact**: 1000x throughput improvement for batch inference.

---

## Memory Management

### 1. Avoid Unnecessary Clones

**❌ MEMORY WASTEFUL**
```rust
fn apply_gates(state: &Array1<Complex64>) -> Array1<Complex64> {
    let mut new_state = state.clone();  // Expensive copy!
    // ... apply gates ...
    new_state
}
```

**✅ MEMORY EFFICIENT**
```rust
fn apply_gates_inplace(state: &mut Array1<Complex64>) {
    // Modify in-place, no allocation
    // ... apply gates ...
}
```

**Performance Impact**: 2-5x reduction in memory allocations and garbage collection.

### 2. Use Memory-Mapped Arrays for Large Datasets

```rust
use scirs2_core::memory_efficient::MemoryMappedArray;

// Load 100GB dataset without loading into RAM
let large_dataset = MemoryMappedArray::from_file(
    "training_data.bin",
    (n_samples, n_features)
)?;

// Process in chunks
for chunk in large_dataset.chunks(1000) {
    train_on_batch(chunk);
}
```

**Performance Impact**: Handle datasets 100x larger than available RAM.

### 3. Sparse Representations for High-Dimensional Problems

```rust
use scirs2_sparse::{CsrMatrix, CscMatrix};

// Use sparse matrices for sparse Hamiltonians
let sparse_hamiltonian = CsrMatrix::from_dense(&hamiltonian);

// 10-100x memory reduction for sparse operators (> 95% zeros)
let expectation = sparse_hamiltonian.expectation_value(&state_vector);
```

**Performance Impact**: 10-100x memory reduction for sparse problems.

### 4. Memory Pooling for Frequent Allocations

```rust
use scirs2_core::memory_efficient::MemoryPool;

// Pre-allocate memory pool
let pool = MemoryPool::new(1024 * 1024 * 1024);  // 1GB pool

// Reuse allocations
for iteration in 0..n_iterations {
    let temp_buffer = pool.allocate::<Complex64>(2_usize.pow(n_qubits));
    // ... computation ...
    pool.deallocate(temp_buffer);  // Fast, no syscall
}
```

**Performance Impact**: 5-10x reduction in allocation overhead for iterative algorithms.

---

## Quantum Circuit Optimization

### 1. Circuit Compilation and Caching

```rust
use quantrs2_circuit::optimization::CircuitOptimizer;

// Compile circuit once, reuse many times
let optimizer = CircuitOptimizer::new();
let optimized_circuit = optimizer.compile(&circuit, OptimizationLevel::High)?;

// Cache compiled circuits
let cache = CircuitCache::new(capacity: 100);
cache.insert(circuit_hash, optimized_circuit);
```

**Performance Impact**: 10-100x speedup by avoiding repeated compilation.

### 2. Gate Fusion

```rust
use quantrs2_circuit::optimization::GateFusion;

// Fuse consecutive single-qubit gates
let fused_circuit = GateFusion::fuse_single_qubit_gates(&circuit)?;

// Fuse two-qubit gate blocks
let fused_circuit = GateFusion::fuse_two_qubit_blocks(&fused_circuit)?;
```

**Performance Impact**: 30-50% reduction in gate count, 2-3x faster execution.

### 3. Transpilation for Target Hardware

```rust
use quantrs2_circuit::transpiler::Transpiler;

// Optimize for target device topology
let transpiler = Transpiler::new(target_device);
let transpiled_circuit = transpiler.transpile(&circuit)?;
```

**Performance Impact**: 2-5x reduction in circuit depth on real quantum hardware.

---

## Batch Processing

### 1. Batch Training Data

```rust
use scirs2_core::ndarray::Array2;

// Process 128 samples per batch (optimal for GPU)
const BATCH_SIZE: usize = 128;

for batch in training_data.axis_chunks_iter(Axis(0), BATCH_SIZE) {
    let predictions = model.predict_batch(&batch);
    let loss = compute_batch_loss(&predictions, &labels);
    model.update_parameters(&compute_gradients(&loss));
}
```

**Performance Impact**: 10-50x speedup over single-sample processing.

### 2. Vectorized Quantum Encoding

```rust
use quantrs2_ml::utils::encoding::batch_amplitude_encode;

// Encode 1000 samples simultaneously
let encoded_states = batch_amplitude_encode(
    &training_samples,  // Shape: (1000, n_features)
    n_qubits
)?;
```

**Performance Impact**: 100x faster than encoding samples one-by-one.

---

## Caching Strategies

### 1. Kernel Matrix Caching (QSVM)

```rust
use std::collections::HashMap;

struct KernelCache {
    cache: HashMap<(usize, usize), f64>,
}

impl KernelCache {
    fn get_or_compute(
        &mut self,
        i: usize,
        j: usize,
        samples: &Array2<f64>,
        kernel: &QuantumKernel
    ) -> f64 {
        *self.cache.entry((i.min(j), i.max(j)))
            .or_insert_with(|| {
                kernel.compute(&samples.row(i), &samples.row(j))
            })
    }
}
```

**Performance Impact**: 2x speedup for training, avoid recomputing symmetric kernel entries.

### 2. Expectation Value Caching

```rust
use lru::LruCache;

// Cache recent expectation value computations
let mut expectation_cache = LruCache::new(1000);

fn get_expectation_cached(
    circuit: &Circuit,
    parameters: &Array1<f64>,
    cache: &mut LruCache<u64, f64>
) -> f64 {
    let hash = compute_hash(circuit, parameters);
    *cache.get_or_insert(hash, || {
        circuit.compute_expectation(parameters)
    })
}
```

**Performance Impact**: 5-10x speedup when evaluating similar parameter configurations.

---

## Profiling and Benchmarking

### 1. Use QuantRS2-ML Performance Profiler

```rust
use quantrs2_ml::performance_profiler::{QuantumMLProfiler, ProfilerConfig};

let config = ProfilerConfig {
    track_memory: true,
    track_simd_usage: true,
    track_parallel_efficiency: true,
    sampling_interval_ms: 10,
};

let mut profiler = QuantumMLProfiler::new(config);

profiler.start_profiling();

// Your quantum ML workload
train_quantum_model();

profiler.stop_profiling();

let report = profiler.generate_report();
println!("{}", report);
```

**Output Example:**
```
Performance Report
==================
Total Time: 125.3s
  - Circuit Compilation: 12.1s (9.7%)
  - Gate Application: 89.2s (71.2%)
  - Measurement Sampling: 18.5s (14.8%)
  - Classical Processing: 5.5s (4.4%)

Memory Usage:
  - Peak: 2.4 GB
  - Average: 1.8 GB
  - Allocations: 1,245,123

SIMD Utilization: 87.3%
Parallel Efficiency: 92.1% (15.2x speedup on 16 cores)

Bottlenecks:
  1. Gate application on large state vectors (71.2% time)
     Recommendation: Use GPU acceleration for > 20 qubits
  2. Memory allocations in gradient computation
     Recommendation: Implement memory pooling
```

### 2. Benchmark Against Classical Baselines

```rust
use quantrs2_ml::quantum_advantage_validator::{
    QuantumAdvantageValidator, ValidationConfig
};

let config = ValidationConfig {
    n_trials: 100,
    confidence_level: 0.95,
    metrics: vec![
        ComparisonMetric::Accuracy,
        ComparisonMetric::TrainingTime,
        ComparisonMetric::SampleComplexity,
    ],
};

let validator = QuantumAdvantageValidator::new(config);

let quantum_result = validator.benchmark_quantum(&quantum_model, &test_data);
let classical_result = validator.benchmark_classical(&classical_model, &test_data);

let advantage = validator.validate_advantage(&quantum_result, &classical_result)?;

println!("Quantum Advantage: {}", advantage);
```

---

## Production Deployment

### 1. Use Release Builds with Optimizations

```toml
# Cargo.toml
[profile.release]
opt-level = 3
lto = "fat"              # Link-time optimization
codegen-units = 1        # Better optimization, slower compile
panic = "abort"          # Smaller binaries
strip = true             # Remove debug symbols
```

**Performance Impact**: 20-40% faster execution vs default release build.

### 2. Target-Specific Compilation

```bash
# Compile for native CPU with all features
RUSTFLAGS="-C target-cpu=native -C target-feature=+avx2,+fma" \
cargo build --release

# For Apple Silicon (M1/M2/M3)
RUSTFLAGS="-C target-cpu=apple-m1" cargo build --release
```

**Performance Impact**: 10-30% speedup by using CPU-specific instructions.

### 3. Production Monitoring

```rust
use quantrs2_ml::performance_profiler::ProductionMonitor;

// Continuously monitor performance in production
let monitor = ProductionMonitor::new();

monitor.track_inference_latency(|| {
    model.predict(&input)
});

// Alert if performance degrades
if monitor.p95_latency_ms() > 100.0 {
    alert!("High inference latency detected!");
}
```

---

## Common Pitfalls

### ❌ Pitfall 1: Not Using SciRS2 Properly

**Problem**: Mixing direct ndarray/rand usage with SciRS2
```rust
use ndarray::Array2;  // ❌ Direct ndarray
use scirs2_core::Complex64;  // ✅ SciRS2
```

**Solution**: Always use unified SciRS2 patterns
```rust
use scirs2_core::ndarray::Array2;  // ✅ Unified
use scirs2_core::Complex64;        // ✅ Unified
```

### ❌ Pitfall 2: Small Batch Sizes

**Problem**: Processing 1 sample at a time
```rust
for sample in dataset {
    model.train_single(sample);  // ❌ Inefficient!
}
```

**Solution**: Use batching
```rust
for batch in dataset.chunks(128) {
    model.train_batch(batch);  // ✅ 100x faster
}
```

### ❌ Pitfall 3: Recompiling Circuits Repeatedly

**Problem**: Compiling same circuit every iteration
```rust
for params in parameter_space {
    let circuit = build_circuit();  // ❌ Recompiling!
    circuit.evaluate(params);
}
```

**Solution**: Compile once, parameterize
```rust
let circuit = build_circuit();  // ✅ Compile once
for params in parameter_space {
    circuit.evaluate(params);
}
```

### ❌ Pitfall 4: Not Using Parallel Processing

**Problem**: Sequential gradient computation
```rust
let gradients = params.iter()
    .map(|p| compute_gradient(p))  // ❌ Sequential
    .collect();
```

**Solution**: Parallelize
```rust
let gradients = params.par_iter()
    .map(|p| compute_gradient(p))  // ✅ Parallel
    .collect();
```

### ❌ Pitfall 5: Ignoring Memory Allocations

**Problem**: Allocating in hot loops
```rust
for _ in 0..1000000 {
    let temp = vec![0.0; large_size];  // ❌ 1M allocations!
    // ...
}
```

**Solution**: Pre-allocate or use memory pools
```rust
let mut temp = vec![0.0; large_size];  // ✅ Allocate once
for _ in 0..1000000 {
    // Reuse temp
}
```

---

## Performance Optimization Checklist

Before deploying to production, verify:

- [ ] Using unified SciRS2 patterns (no direct ndarray/rand/num-complex)
- [ ] Enabled SIMD operations for quantum gate applications
- [ ] Using parallel processing for independent computations
- [ ] Batch size optimized (128-512 for GPU, 32-128 for CPU)
- [ ] Circuit compilation and caching implemented
- [ ] Memory allocations minimized in hot paths
- [ ] GPU acceleration enabled for large problems (> 20 qubits)
- [ ] Profile-guided optimization performed
- [ ] Release build with LTO and native CPU features
- [ ] Benchmarked against classical baselines
- [ ] Production monitoring in place

---

## Performance Target Summary

| Optimization | Expected Speedup | Difficulty | Priority |
|--------------|-----------------|------------|----------|
| SciRS2 Integration | 2-5x | Low | **Critical** |
| SIMD Operations | 4-8x | Medium | **High** |
| Parallel Processing | 8-16x | Low | **High** |
| GPU Acceleration | 100-1000x | High | High |
| Circuit Caching | 10-100x | Low | **High** |
| Batch Processing | 10-50x | Low | **High** |
| Memory Pooling | 2-5x | Medium | Medium |
| Gate Fusion | 2-3x | Medium | Medium |

**Priority Legend:**
- **Critical**: Must implement for any production deployment
- **High**: Implement for performance-sensitive applications
- Medium: Implement if bottleneck identified

---

## Conclusion

Performance optimization in quantum machine learning requires:

1. **Proper SciRS2 integration** - Foundation for all optimizations
2. **Hardware-aware programming** - Leverage SIMD, parallel, GPU capabilities
3. **Algorithmic efficiency** - Circuit optimization, caching, batching
4. **Continuous profiling** - Identify and eliminate bottlenecks
5. **Production monitoring** - Ensure performance doesn't degrade over time

Following this guide can achieve **100-1000x speedup** for typical quantum ML workloads compared to naive implementations.

For questions or advanced optimization techniques, consult:
- [QuantRS2 Documentation](https://docs.rs/quantrs2)
- [SciRS2 Performance Guide](https://docs.rs/scirs2-core)
- [GitHub Issues](https://github.com/cool-japan/quantrs)

---

**Last Updated**: 2025-12-05
**QuantRS2 Version**: 0.1.0-rc.2
**SciRS2 Version**: 0.1.0-rc.2
