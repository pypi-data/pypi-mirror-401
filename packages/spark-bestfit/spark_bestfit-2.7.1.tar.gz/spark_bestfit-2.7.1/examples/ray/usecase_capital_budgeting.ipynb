{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Capital Budgeting Monte Carlo Simulation with Ray\n",
    "\n",
    "This notebook demonstrates how to use spark-bestfit with **RayBackend** for **capital budgeting decisions** under uncertainty using Monte Carlo simulation.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Model uncertain project parameters** (revenue growth, costs, discount rates)\n",
    "2. **Fit distributions** to historical/expert data using FitterConfigBuilder\n",
    "3. **Run distributed Monte Carlo simulation** with Ray\n",
    "4. **Calculate investment metrics**: NPV, IRR, Payback Period\n",
    "5. **Perform risk analysis**: VaR, probability of positive NPV, sensitivity analysis\n",
    "\n",
    "## Business Context\n",
    "\n",
    "A company is evaluating a **$5M manufacturing plant investment** with:\n",
    "- **10-year project life**\n",
    "- **Uncertain revenue growth** (based on market conditions)\n",
    "- **Variable operating costs** (labor, materials, energy)\n",
    "- **Uncertain discount rate** (reflects financing risk)\n",
    "\n",
    "Traditional DCF analysis uses single \"best estimate\" values. Monte Carlo simulation instead:\n",
    "- Fits probability distributions to each uncertain parameter\n",
    "- Generates thousands of scenarios\n",
    "- Provides a **distribution of outcomes** rather than a single number\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install spark-bestfit[ray] pandas numpy matplotlib scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import brentq\n",
    "import ray\n",
    "\n",
    "from spark_bestfit import (\n",
    "    DistributionFitter,\n",
    "    FitterConfigBuilder,\n",
    "    RayBackend,\n",
    "    GaussianCopula\n",
    ")\n",
    "\n",
    "# Initialize Ray\n",
    "if not ray.is_initialized():\n",
    "    ray.init()\n",
    "\n",
    "backend = RayBackend()\n",
    "print(f\"RayBackend initialized with {backend.get_parallelism()} CPUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1: Define Project Parameters\n",
    "\n",
    "Our capital budgeting model has the following structure:\n",
    "\n",
    "**Fixed Parameters:**\n",
    "- Initial investment: $5,000,000\n",
    "- Project life: 10 years\n",
    "- Base year revenue: $1,500,000\n",
    "- Salvage value: $500,000 (year 10)\n",
    "\n",
    "**Uncertain Parameters (to be fitted):**\n",
    "- Revenue growth rate (annual %)\n",
    "- Operating cost ratio (% of revenue)\n",
    "- Discount rate (WACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed project parameters\n",
    "INITIAL_INVESTMENT = 5_000_000  # $5M upfront investment\n",
    "PROJECT_YEARS = 10\n",
    "BASE_REVENUE = 1_500_000  # Year 1 revenue: $1.5M\n",
    "SALVAGE_VALUE = 500_000  # End of project salvage: $500K\n",
    "TAX_RATE = 0.25  # 25% corporate tax rate\n",
    "DEPRECIATION = INITIAL_INVESTMENT / PROJECT_YEARS  # Straight-line\n",
    "\n",
    "print(\"Project Parameters:\")\n",
    "print(f\"  Initial Investment: ${INITIAL_INVESTMENT:,.0f}\")\n",
    "print(f\"  Project Life: {PROJECT_YEARS} years\")\n",
    "print(f\"  Base Year Revenue: ${BASE_REVENUE:,.0f}\")\n",
    "print(f\"  Annual Depreciation: ${DEPRECIATION:,.0f}\")\n",
    "print(f\"  Salvage Value: ${SALVAGE_VALUE:,.0f}\")\n",
    "print(f\"  Tax Rate: {TAX_RATE:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Part 2: Generate Historical Data for Uncertain Parameters\n",
    "\n",
    "In practice, you would use:\n",
    "- **Historical revenue growth** from comparable projects or industry data\n",
    "- **Operating cost ratios** from financial statements\n",
    "- **Historical WACC** or required returns from similar investments\n",
    "\n",
    "Here we simulate realistic historical data to demonstrate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n_historical = 500  # Historical observations\n",
    "\n",
    "# Revenue Growth Rate: Slightly right-skewed (good years have high growth)\n",
    "# Mean ~8%, Std ~5%, bounded above 0\n",
    "revenue_growth = np.clip(\n",
    "    stats.skewnorm.rvs(a=2, loc=0.08, scale=0.05, size=n_historical),\n",
    "    -0.10, 0.30  # -10% to +30% range\n",
    ")\n",
    "\n",
    "# Operating Cost Ratio: Concentrated around 60% with some variation\n",
    "# Lower is better (more efficient operations)\n",
    "cost_ratio = np.clip(\n",
    "    stats.beta.rvs(a=12, b=8, size=n_historical),\n",
    "    0.40, 0.80  # 40% to 80% range\n",
    ")\n",
    "\n",
    "# Discount Rate (WACC): Right-skewed reflecting risk premium uncertainty\n",
    "# Mean ~10%, represents cost of capital\n",
    "discount_rate = np.clip(\n",
    "    stats.lognorm.rvs(s=0.3, scale=0.10, size=n_historical),\n",
    "    0.05, 0.20  # 5% to 20% range\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "historical_pdf = pd.DataFrame({\n",
    "    'revenue_growth': revenue_growth,\n",
    "    'cost_ratio': cost_ratio,\n",
    "    'discount_rate': discount_rate\n",
    "})\n",
    "\n",
    "# Convert to Ray Dataset\n",
    "historical_ds = ray.data.from_pandas(historical_pdf)\n",
    "\n",
    "print(f\"Historical data: {historical_ds.count()} observations\")\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(historical_pdf.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize historical distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Revenue Growth\n",
    "axes[0].hist(revenue_growth * 100, bins=40, density=True, alpha=0.7, edgecolor='black', color='steelblue')\n",
    "axes[0].axvline(np.mean(revenue_growth) * 100, color='red', linestyle='--', label=f'Mean: {np.mean(revenue_growth)*100:.1f}%')\n",
    "axes[0].set_xlabel('Annual Growth Rate (%)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Revenue Growth Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Operating Cost Ratio\n",
    "axes[1].hist(cost_ratio * 100, bins=40, density=True, alpha=0.7, edgecolor='black', color='coral')\n",
    "axes[1].axvline(np.mean(cost_ratio) * 100, color='red', linestyle='--', label=f'Mean: {np.mean(cost_ratio)*100:.1f}%')\n",
    "axes[1].set_xlabel('Cost Ratio (% of Revenue)')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Operating Cost Ratio Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "# Discount Rate\n",
    "axes[2].hist(discount_rate * 100, bins=40, density=True, alpha=0.7, edgecolor='black', color='seagreen')\n",
    "axes[2].axvline(np.mean(discount_rate) * 100, color='red', linestyle='--', label=f'Mean: {np.mean(discount_rate)*100:.1f}%')\n",
    "axes[2].set_xlabel('Discount Rate (%)')\n",
    "axes[2].set_ylabel('Density')\n",
    "axes[2].set_title('Discount Rate (WACC) Distribution')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.suptitle('Historical Distributions of Uncertain Parameters', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 3: Fit Distributions Using FitterConfigBuilder\n",
    "\n",
    "We use the **FitterConfigBuilder** pattern to create a reusable configuration for distribution fitting. This is especially useful when:\n",
    "- Fitting multiple columns with the same settings\n",
    "- Ensuring bounded distributions (our parameters have natural bounds)\n",
    "- Managing complex configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fitting configuration using the builder pattern\n",
    "fit_config = (\n",
    "    FitterConfigBuilder()\n",
    "    .with_bins(50)  # 50 bins for histogram\n",
    "    .with_sampling(enabled=False)  # Small dataset, no sampling needed\n",
    "    .with_lazy_metrics(False)  # Compute all metrics for comparison\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"FitterConfig created:\")\n",
    "print(f\"  bins={fit_config.bins}\")\n",
    "print(f\"  enable_sampling={fit_config.enable_sampling}\")\n",
    "print(f\"  lazy_metrics={fit_config.lazy_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit distributions to all parameters\n",
    "fitter = DistributionFitter(backend=backend)\n",
    "\n",
    "results = fitter.fit(\n",
    "    historical_ds,\n",
    "    columns=['revenue_growth', 'cost_ratio', 'discount_rate'],\n",
    "    config=fit_config,\n",
    "    max_distributions=30  # Focus on common distributions\n",
    ")\n",
    "\n",
    "print(f\"Fitted {results.count()} distribution-parameter combinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best distributions for each parameter\n",
    "best_per_param = results.best_per_column(n=3, metric='aic')\n",
    "\n",
    "print(\"Best Distributions by AIC:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_fits = {}\n",
    "for param, fits in best_per_param.items():\n",
    "    print(f\"\\n{param.upper().replace('_', ' ')}:\")\n",
    "    for i, fit in enumerate(fits, 1):\n",
    "        marker = \"→\" if i == 1 else \" \"\n",
    "        print(f\"  {marker} {i}. {fit.distribution}: AIC={fit.aic:.2f}, BIC={fit.bic:.2f}\")\n",
    "    best_fits[param] = fits[0]  # Store best fit\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Selected distributions marked with →\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fitted distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "params = ['revenue_growth', 'cost_ratio', 'discount_rate']\n",
    "titles = ['Revenue Growth', 'Cost Ratio', 'Discount Rate']\n",
    "colors = ['steelblue', 'coral', 'seagreen']\n",
    "\n",
    "for i, (param, title, color) in enumerate(zip(params, titles, colors)):\n",
    "    fit = best_fits[param]\n",
    "    data = historical_pdf[param]\n",
    "    \n",
    "    # Histogram\n",
    "    axes[i].hist(data, bins=40, density=True, alpha=0.6, edgecolor='black', color=color, label='Historical')\n",
    "    \n",
    "    # Fitted PDF\n",
    "    x = np.linspace(data.min(), data.max(), 200)\n",
    "    frozen = fit.get_scipy_dist()\n",
    "    axes[i].plot(x, frozen.pdf(x), 'r-', linewidth=2, label=f'Fitted: {fit.distribution}')\n",
    "    \n",
    "    axes[i].set_xlabel(param.replace('_', ' ').title())\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].set_title(f'{title}\\n({fit.distribution})')\n",
    "    axes[i].legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Fitted Distributions for Monte Carlo Simulation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Part 4: Model Parameter Correlations\n",
    "\n",
    "Economic parameters are often correlated:\n",
    "- High revenue growth may come with higher costs (expansion expenses)\n",
    "- Economic uncertainty affects both discount rates and growth prospects\n",
    "\n",
    "We use a **Gaussian Copula** to capture these dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Gaussian Copula to capture correlations\n",
    "copula = GaussianCopula.fit(\n",
    "    results,\n",
    "    historical_ds,\n",
    "    columns=['revenue_growth', 'cost_ratio', 'discount_rate'],\n",
    "    backend=backend\n",
    ")\n",
    "\n",
    "print(\"Parameter Correlation Matrix:\")\n",
    "print(\"-\" * 50)\n",
    "corr_df = pd.DataFrame(\n",
    "    copula.correlation_matrix,\n",
    "    index=['revenue_growth', 'cost_ratio', 'discount_rate'],\n",
    "    columns=['revenue_growth', 'cost_ratio', 'discount_rate']\n",
    ")\n",
    "print(corr_df.round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "im = plt.imshow(copula.correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "plt.colorbar(im, label='Correlation')\n",
    "labels = ['Revenue\\nGrowth', 'Cost\\nRatio', 'Discount\\nRate']\n",
    "plt.xticks(range(3), labels)\n",
    "plt.yticks(range(3), labels)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.text(j, i, f'{copula.correlation_matrix[i,j]:.2f}', \n",
    "                ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "plt.title('Parameter Correlations')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Part 5: Define Financial Metric Functions\n",
    "\n",
    "We need functions to calculate:\n",
    "- **Net Present Value (NPV)**: Sum of discounted cash flows minus initial investment\n",
    "- **Internal Rate of Return (IRR)**: Discount rate that makes NPV = 0\n",
    "- **Payback Period**: Time to recover initial investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cash_flows(revenue_growth, cost_ratio, years=PROJECT_YEARS):\n",
    "    \"\"\"\n",
    "    Calculate annual after-tax cash flows for the project.\n",
    "    \n",
    "    Cash Flow = (Revenue - Operating Costs - Depreciation) × (1 - Tax Rate) + Depreciation\n",
    "    \"\"\"\n",
    "    cash_flows = []\n",
    "    revenue = BASE_REVENUE\n",
    "    \n",
    "    for year in range(1, years + 1):\n",
    "        # Revenue grows each year\n",
    "        if year > 1:\n",
    "            revenue = revenue * (1 + revenue_growth)\n",
    "        \n",
    "        # Operating costs as percentage of revenue\n",
    "        operating_costs = revenue * cost_ratio\n",
    "        \n",
    "        # EBITDA\n",
    "        ebitda = revenue - operating_costs\n",
    "        \n",
    "        # EBIT (after depreciation)\n",
    "        ebit = ebitda - DEPRECIATION\n",
    "        \n",
    "        # After-tax operating income\n",
    "        after_tax_income = ebit * (1 - TAX_RATE)\n",
    "        \n",
    "        # Add back depreciation (non-cash expense)\n",
    "        cash_flow = after_tax_income + DEPRECIATION\n",
    "        \n",
    "        # Add salvage value in final year (after tax)\n",
    "        if year == years:\n",
    "            cash_flow += SALVAGE_VALUE * (1 - TAX_RATE)\n",
    "        \n",
    "        cash_flows.append(cash_flow)\n",
    "    \n",
    "    return np.array(cash_flows)\n",
    "\n",
    "\n",
    "def calculate_npv(cash_flows, discount_rate):\n",
    "    \"\"\"\n",
    "    Calculate Net Present Value.\n",
    "    \n",
    "    NPV = -Initial Investment + Σ(CF_t / (1+r)^t)\n",
    "    \"\"\"\n",
    "    years = np.arange(1, len(cash_flows) + 1)\n",
    "    discount_factors = (1 + discount_rate) ** years\n",
    "    pv_cash_flows = cash_flows / discount_factors\n",
    "    return -INITIAL_INVESTMENT + np.sum(pv_cash_flows)\n",
    "\n",
    "\n",
    "def calculate_irr(cash_flows, initial_investment=INITIAL_INVESTMENT):\n",
    "    \"\"\"\n",
    "    Calculate Internal Rate of Return using root finding.\n",
    "    \n",
    "    IRR is the rate r where NPV = 0\n",
    "    \"\"\"\n",
    "    all_flows = np.concatenate([[-initial_investment], cash_flows])\n",
    "    \n",
    "    def npv_at_rate(r):\n",
    "        years = np.arange(len(all_flows))\n",
    "        return np.sum(all_flows / (1 + r) ** years)\n",
    "    \n",
    "    try:\n",
    "        # Find IRR between -50% and 100%\n",
    "        irr = brentq(npv_at_rate, -0.5, 1.0)\n",
    "        return irr\n",
    "    except ValueError:\n",
    "        # No valid IRR found\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def calculate_payback_period(cash_flows):\n",
    "    \"\"\"\n",
    "    Calculate simple payback period (undiscounted).\n",
    "    \n",
    "    Returns years to recover initial investment.\n",
    "    \"\"\"\n",
    "    cumulative = np.cumsum(cash_flows)\n",
    "    recovered_idx = np.where(cumulative >= INITIAL_INVESTMENT)[0]\n",
    "    \n",
    "    if len(recovered_idx) == 0:\n",
    "        return np.inf  # Never recovers investment\n",
    "    \n",
    "    first_recovery_year = recovered_idx[0] + 1\n",
    "    \n",
    "    # Interpolate for fractional year\n",
    "    if first_recovery_year == 1:\n",
    "        return INITIAL_INVESTMENT / cash_flows[0]\n",
    "    else:\n",
    "        remaining = INITIAL_INVESTMENT - cumulative[first_recovery_year - 2]\n",
    "        fraction = remaining / cash_flows[first_recovery_year - 1]\n",
    "        return first_recovery_year - 1 + fraction\n",
    "\n",
    "\n",
    "# Test with mean parameter values\n",
    "test_growth = historical_pdf['revenue_growth'].mean()\n",
    "test_cost = historical_pdf['cost_ratio'].mean()\n",
    "test_discount = historical_pdf['discount_rate'].mean()\n",
    "\n",
    "test_cf = calculate_cash_flows(test_growth, test_cost)\n",
    "test_npv = calculate_npv(test_cf, test_discount)\n",
    "test_irr = calculate_irr(test_cf)\n",
    "test_payback = calculate_payback_period(test_cf)\n",
    "\n",
    "print(\"Base Case Analysis (Mean Parameter Values):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Revenue Growth:  {test_growth:.1%}\")\n",
    "print(f\"Cost Ratio:      {test_cost:.1%}\")\n",
    "print(f\"Discount Rate:   {test_discount:.1%}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"NPV:             ${test_npv:,.0f}\")\n",
    "print(f\"IRR:             {test_irr:.1%}\")\n",
    "print(f\"Payback Period:  {test_payback:.1f} years\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Decision:        {'ACCEPT ✓' if test_npv > 0 else 'REJECT ✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Part 6: Run Monte Carlo Simulation\n",
    "\n",
    "Now we generate thousands of scenarios using the fitted distributions and copula to get a **distribution of outcomes** rather than a single point estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated parameter scenarios using the copula\n",
    "N_SCENARIOS = 10_000\n",
    "\n",
    "print(f\"Generating {N_SCENARIOS:,} Monte Carlo scenarios...\")\n",
    "\n",
    "# Sample correlated parameters from the copula\n",
    "scenarios = copula.sample(n=N_SCENARIOS, random_state=42)\n",
    "\n",
    "print(f\"Generated {len(scenarios)} parameter sets\")\n",
    "print(\"\\nScenario Statistics:\")\n",
    "print(pd.DataFrame(scenarios).describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate financial metrics for all scenarios\n",
    "print(f\"\\nCalculating NPV, IRR, and Payback Period for {N_SCENARIOS:,} scenarios...\")\n",
    "\n",
    "npv_results = []\n",
    "irr_results = []\n",
    "payback_results = []\n",
    "\n",
    "for i in range(N_SCENARIOS):\n",
    "    growth = scenarios['revenue_growth'][i]\n",
    "    cost = scenarios['cost_ratio'][i]\n",
    "    discount = scenarios['discount_rate'][i]\n",
    "    \n",
    "    # Calculate cash flows\n",
    "    cf = calculate_cash_flows(growth, cost)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    npv_results.append(calculate_npv(cf, discount))\n",
    "    irr_results.append(calculate_irr(cf))\n",
    "    payback_results.append(calculate_payback_period(cf))\n",
    "\n",
    "# Convert to arrays\n",
    "npv_results = np.array(npv_results)\n",
    "irr_results = np.array(irr_results)\n",
    "payback_results = np.array(payback_results)\n",
    "\n",
    "# Create results DataFrame\n",
    "simulation_results = pd.DataFrame({\n",
    "    'revenue_growth': scenarios['revenue_growth'],\n",
    "    'cost_ratio': scenarios['cost_ratio'],\n",
    "    'discount_rate': scenarios['discount_rate'],\n",
    "    'npv': npv_results,\n",
    "    'irr': irr_results,\n",
    "    'payback_period': payback_results\n",
    "})\n",
    "\n",
    "print(\"\\nSimulation complete!\")\n",
    "print(simulation_results[['npv', 'irr', 'payback_period']].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Part 7: Analyze NPV Distribution\n",
    "\n",
    "The NPV distribution tells us the range of possible outcomes and their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPV Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "n, bins, patches = ax1.hist(npv_results / 1e6, bins=80, density=True, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Color bars: green for positive NPV, red for negative\n",
    "for patch, left_edge in zip(patches, bins[:-1]):\n",
    "    if left_edge < 0:\n",
    "        patch.set_facecolor('indianred')\n",
    "    else:\n",
    "        patch.set_facecolor('seagreen')\n",
    "\n",
    "# Add vertical lines for key percentiles\n",
    "p5 = np.percentile(npv_results, 5) / 1e6\n",
    "p50 = np.percentile(npv_results, 50) / 1e6\n",
    "p95 = np.percentile(npv_results, 95) / 1e6\n",
    "mean_npv = np.mean(npv_results) / 1e6\n",
    "\n",
    "ax1.axvline(0, color='black', linewidth=2, linestyle='-', label='Break-even')\n",
    "ax1.axvline(p5, color='orange', linewidth=2, linestyle='--', label=f'5th %ile: ${p5:.2f}M')\n",
    "ax1.axvline(p50, color='blue', linewidth=2, linestyle='--', label=f'Median: ${p50:.2f}M')\n",
    "ax1.axvline(p95, color='purple', linewidth=2, linestyle='--', label=f'95th %ile: ${p95:.2f}M')\n",
    "\n",
    "ax1.set_xlabel('NPV ($ Millions)', fontsize=12)\n",
    "ax1.set_ylabel('Density', fontsize=12)\n",
    "ax1.set_title('NPV Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right', fontsize=9)\n",
    "\n",
    "# Cumulative Distribution (S-curve)\n",
    "ax2 = axes[1]\n",
    "sorted_npv = np.sort(npv_results) / 1e6\n",
    "cumulative = np.arange(1, len(sorted_npv) + 1) / len(sorted_npv)\n",
    "\n",
    "ax2.plot(sorted_npv, cumulative, 'b-', linewidth=2)\n",
    "ax2.axvline(0, color='black', linewidth=2, linestyle='-')\n",
    "ax2.axhline(0.5, color='gray', linewidth=1, linestyle=':')\n",
    "\n",
    "# Probability of positive NPV\n",
    "prob_positive = (npv_results > 0).mean()\n",
    "ax2.fill_between(sorted_npv[sorted_npv < 0], 0, cumulative[:np.sum(sorted_npv < 0)], \n",
    "                 alpha=0.3, color='red', label=f'P(NPV < 0) = {1-prob_positive:.1%}')\n",
    "ax2.fill_between(sorted_npv[sorted_npv >= 0], \n",
    "                 cumulative[np.sum(sorted_npv < 0):], 1, \n",
    "                 alpha=0.3, color='green', label=f'P(NPV > 0) = {prob_positive:.1%}')\n",
    "\n",
    "ax2.set_xlabel('NPV ($ Millions)', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Probability', fontsize=12)\n",
    "ax2.set_title('NPV Cumulative Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='lower right', fontsize=10)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed NPV Statistics\n",
    "prob_positive_npv = (npv_results > 0).mean()\n",
    "var_5 = np.percentile(npv_results, 5)  # Value at Risk (5%)\n",
    "cvar_5 = npv_results[npv_results <= var_5].mean()  # Conditional VaR (Expected Shortfall)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NPV ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nCentral Tendency:\")\n",
    "print(f\"  Mean NPV:         ${np.mean(npv_results):>12,.0f}\")\n",
    "print(f\"  Median NPV:       ${np.median(npv_results):>12,.0f}\")\n",
    "print(f\"  Std Deviation:    ${np.std(npv_results):>12,.0f}\")\n",
    "print(f\"\\nDistribution Range:\")\n",
    "print(f\"  Minimum:          ${np.min(npv_results):>12,.0f}\")\n",
    "print(f\"  5th Percentile:   ${np.percentile(npv_results, 5):>12,.0f}\")\n",
    "print(f\"  25th Percentile:  ${np.percentile(npv_results, 25):>12,.0f}\")\n",
    "print(f\"  75th Percentile:  ${np.percentile(npv_results, 75):>12,.0f}\")\n",
    "print(f\"  95th Percentile:  ${np.percentile(npv_results, 95):>12,.0f}\")\n",
    "print(f\"  Maximum:          ${np.max(npv_results):>12,.0f}\")\n",
    "print(f\"\\nRisk Metrics:\")\n",
    "print(f\"  P(NPV > 0):       {prob_positive_npv:>12.1%}\")\n",
    "print(f\"  P(NPV < 0):       {1-prob_positive_npv:>12.1%}\")\n",
    "print(f\"  VaR (5%):         ${var_5:>12,.0f}\")\n",
    "print(f\"  CVaR/ES (5%):     ${cvar_5:>12,.0f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Part 8: Analyze IRR Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter valid IRR values\n",
    "valid_irr = irr_results[~np.isnan(irr_results)]\n",
    "valid_irr = valid_irr[(valid_irr > -0.5) & (valid_irr < 1.0)]  # Remove extreme outliers\n",
    "\n",
    "print(f\"Valid IRR calculations: {len(valid_irr):,} of {N_SCENARIOS:,} ({len(valid_irr)/N_SCENARIOS:.1%})\")\n",
    "\n",
    "# IRR Distribution Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "n, bins, patches = ax.hist(valid_irr * 100, bins=60, density=True, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Color bars based on hurdle rate (assume 10% WACC as hurdle)\n",
    "hurdle_rate = 0.10\n",
    "for patch, left_edge in zip(patches, bins[:-1]):\n",
    "    if left_edge < hurdle_rate * 100:\n",
    "        patch.set_facecolor('indianred')\n",
    "    else:\n",
    "        patch.set_facecolor('seagreen')\n",
    "\n",
    "# Key statistics\n",
    "ax.axvline(hurdle_rate * 100, color='black', linewidth=2, linestyle='-', label=f'Hurdle Rate: {hurdle_rate:.0%}')\n",
    "ax.axvline(np.median(valid_irr) * 100, color='blue', linewidth=2, linestyle='--', \n",
    "           label=f'Median IRR: {np.median(valid_irr):.1%}')\n",
    "ax.axvline(np.mean(valid_irr) * 100, color='orange', linewidth=2, linestyle='--', \n",
    "           label=f'Mean IRR: {np.mean(valid_irr):.1%}')\n",
    "\n",
    "ax.set_xlabel('IRR (%)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Internal Rate of Return (IRR) Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# IRR Statistics\n",
    "prob_irr_above_hurdle = (valid_irr > hurdle_rate).mean()\n",
    "print(f\"\\nIRR Statistics:\")\n",
    "print(f\"  Mean IRR:              {np.mean(valid_irr):.1%}\")\n",
    "print(f\"  Median IRR:            {np.median(valid_irr):.1%}\")\n",
    "print(f\"  P(IRR > {hurdle_rate:.0%}):          {prob_irr_above_hurdle:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Part 9: Analyze Payback Period Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter reasonable payback periods\n",
    "valid_payback = payback_results[payback_results < PROJECT_YEARS + 1]\n",
    "\n",
    "print(f\"Scenarios with payback ≤ {PROJECT_YEARS} years: {len(valid_payback):,} of {N_SCENARIOS:,} ({len(valid_payback)/N_SCENARIOS:.1%})\")\n",
    "\n",
    "# Payback Period Distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Target payback of 6 years\n",
    "target_payback = 6\n",
    "\n",
    "n, bins, patches = ax.hist(valid_payback, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "\n",
    "# Color bars based on target payback\n",
    "for patch, left_edge in zip(patches, bins[:-1]):\n",
    "    if left_edge <= target_payback:\n",
    "        patch.set_facecolor('seagreen')\n",
    "    else:\n",
    "        patch.set_facecolor('goldenrod')\n",
    "\n",
    "ax.axvline(target_payback, color='black', linewidth=2, linestyle='-', \n",
    "           label=f'Target: {target_payback} years')\n",
    "ax.axvline(np.median(valid_payback), color='blue', linewidth=2, linestyle='--', \n",
    "           label=f'Median: {np.median(valid_payback):.1f} years')\n",
    "\n",
    "ax.set_xlabel('Payback Period (Years)', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Payback Period Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Payback Statistics\n",
    "prob_meet_target = (valid_payback <= target_payback).mean()\n",
    "print(f\"\\nPayback Period Statistics:\")\n",
    "print(f\"  Mean Payback:          {np.mean(valid_payback):.1f} years\")\n",
    "print(f\"  Median Payback:        {np.median(valid_payback):.1f} years\")\n",
    "print(f\"  P(Payback ≤ {target_payback} yrs):   {prob_meet_target:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Part 10: Sensitivity Analysis\n",
    "\n",
    "Which parameters have the greatest impact on NPV? Understanding sensitivity helps focus risk management efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between inputs and NPV\n",
    "correlations = simulation_results[['revenue_growth', 'cost_ratio', 'discount_rate', 'npv']].corr()['npv'].drop('npv')\n",
    "\n",
    "# Tornado chart (sensitivity analysis)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "params = correlations.index.tolist()\n",
    "values = correlations.values\n",
    "colors = ['seagreen' if v > 0 else 'indianred' for v in values]\n",
    "\n",
    "# Sort by absolute value\n",
    "sorted_idx = np.argsort(np.abs(values))\n",
    "params = [params[i] for i in sorted_idx]\n",
    "values = [values[i] for i in sorted_idx]\n",
    "colors = [colors[i] for i in sorted_idx]\n",
    "\n",
    "y_pos = np.arange(len(params))\n",
    "ax.barh(y_pos, values, color=colors, edgecolor='black', height=0.6)\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels([p.replace('_', ' ').title() for p in params])\n",
    "ax.set_xlabel('Correlation with NPV', fontsize=12)\n",
    "ax.set_title('Sensitivity Analysis: What Drives NPV?', fontsize=14, fontweight='bold')\n",
    "ax.axvline(0, color='black', linewidth=1)\n",
    "\n",
    "# Add value labels\n",
    "for i, (v, p) in enumerate(zip(values, params)):\n",
    "    offset = 0.02 if v > 0 else -0.02\n",
    "    ha = 'left' if v > 0 else 'right'\n",
    "    ax.text(v + offset, i, f'{v:.2f}', va='center', ha=ha, fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSensitivity Ranking (correlation with NPV):\")\n",
    "print(\"-\" * 50)\n",
    "for p, v in zip(reversed(params), reversed(values)):\n",
    "    direction = \"↑\" if v > 0 else \"↓\"\n",
    "    print(f\"  {p.replace('_', ' ').title():<20}: {v:>6.3f}  {direction} Higher = {'Higher' if v > 0 else 'Lower'} NPV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots of key drivers\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "params_to_plot = ['revenue_growth', 'cost_ratio', 'discount_rate']\n",
    "titles = ['Revenue Growth vs NPV', 'Cost Ratio vs NPV', 'Discount Rate vs NPV']\n",
    "\n",
    "# Sample for visualization (10k points is too many)\n",
    "sample_idx = np.random.choice(len(simulation_results), size=min(2000, len(simulation_results)), replace=False)\n",
    "sample_df = simulation_results.iloc[sample_idx]\n",
    "\n",
    "for i, (param, title) in enumerate(zip(params_to_plot, titles)):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Color by NPV (green = positive, red = negative)\n",
    "    colors = ['seagreen' if npv > 0 else 'indianred' for npv in sample_df['npv']]\n",
    "    \n",
    "    ax.scatter(sample_df[param], sample_df['npv'] / 1e6, \n",
    "               c=colors, alpha=0.3, s=10)\n",
    "    \n",
    "    ax.axhline(0, color='black', linewidth=1, linestyle='--')\n",
    "    ax.set_xlabel(param.replace('_', ' ').title(), fontsize=11)\n",
    "    ax.set_ylabel('NPV ($ Millions)', fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Parameter Impact on NPV', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "## Part 11: Executive Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate executive summary\n",
    "prob_positive = (npv_results > 0).mean()\n",
    "prob_irr_hurdle = (valid_irr > 0.10).mean()\n",
    "prob_payback_target = (valid_payback <= 6).mean()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"                    CAPITAL BUDGETING ANALYSIS REPORT\")\n",
    "print(\"                    Manufacturing Plant Investment\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n┌─────────────────────────────────────────────────────────────────────┐\")\n",
    "print(\"│                        PROJECT OVERVIEW                             │\")\n",
    "print(\"├─────────────────────────────────────────────────────────────────────┤\")\n",
    "print(f\"│  Initial Investment:        ${INITIAL_INVESTMENT:>12,}                       │\")\n",
    "print(f\"│  Project Life:              {PROJECT_YEARS:>12} years                       │\")\n",
    "print(f\"│  Monte Carlo Scenarios:     {N_SCENARIOS:>12,}                             │\")\n",
    "print(\"└─────────────────────────────────────────────────────────────────────┘\")\n",
    "\n",
    "print(\"\\n┌─────────────────────────────────────────────────────────────────────┐\")\n",
    "print(\"│                     KEY INVESTMENT METRICS                          │\")\n",
    "print(\"├─────────────────────────────────────────────────────────────────────┤\")\n",
    "print(f\"│                           Mean         Median         5th %ile     │\")\n",
    "print(f\"│  NPV:              ${np.mean(npv_results)/1e6:>7.2f}M    ${np.median(npv_results)/1e6:>7.2f}M    ${np.percentile(npv_results, 5)/1e6:>7.2f}M     │\")\n",
    "print(f\"│  IRR:                  {np.mean(valid_irr)*100:>6.1f}%       {np.median(valid_irr)*100:>6.1f}%       {np.percentile(valid_irr, 5)*100:>6.1f}%      │\")\n",
    "print(f\"│  Payback:              {np.mean(valid_payback):>6.1f} yrs    {np.median(valid_payback):>6.1f} yrs    {np.percentile(valid_payback, 95):>6.1f} yrs    │\")\n",
    "print(\"└─────────────────────────────────────────────────────────────────────┘\")\n",
    "\n",
    "print(\"\\n┌─────────────────────────────────────────────────────────────────────┐\")\n",
    "print(\"│                       RISK ASSESSMENT                               │\")\n",
    "print(\"├─────────────────────────────────────────────────────────────────────┤\")\n",
    "print(f\"│  Probability of Positive NPV:           {prob_positive:>6.1%}                      │\")\n",
    "print(f\"│  Probability IRR > 10% hurdle:          {prob_irr_hurdle:>6.1%}                      │\")\n",
    "print(f\"│  Probability Payback ≤ 6 years:         {prob_payback_target:>6.1%}                      │\")\n",
    "print(f\"│  Value at Risk (5%):                    ${var_5/1e6:>6.2f}M                     │\")\n",
    "print(f\"│  Expected Shortfall (5%):               ${cvar_5/1e6:>6.2f}M                     │\")\n",
    "print(\"└─────────────────────────────────────────────────────────────────────┘\")\n",
    "\n",
    "print(\"\\n┌─────────────────────────────────────────────────────────────────────┐\")\n",
    "print(\"│                      KEY RISK DRIVERS                               │\")\n",
    "print(\"├─────────────────────────────────────────────────────────────────────┤\")\n",
    "print(f\"│  1. Cost Ratio:        {correlations['cost_ratio']:.2f} correlation (most impactful)         │\")\n",
    "print(f\"│  2. Discount Rate:     {correlations['discount_rate']:.2f} correlation                         │\")\n",
    "print(f\"│  3. Revenue Growth:    {correlations['revenue_growth']:.2f} correlation                         │\")\n",
    "print(\"└─────────────────────────────────────────────────────────────────────┘\")\n",
    "\n",
    "# Investment Decision\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if prob_positive > 0.7 and prob_irr_hurdle > 0.6:\n",
    "    decision = \"RECOMMEND APPROVAL\"\n",
    "    emoji = \"✅\"\n",
    "    reason = \"Strong probability of positive returns with acceptable risk profile.\"\n",
    "elif prob_positive > 0.5:\n",
    "    decision = \"CONDITIONAL APPROVAL\"\n",
    "    emoji = \"⚠️\"\n",
    "    reason = \"Positive expected value but significant downside risk. Consider risk mitigation.\"\n",
    "else:\n",
    "    decision = \"RECOMMEND REJECTION\"\n",
    "    emoji = \"❌\"\n",
    "    reason = \"High probability of negative NPV. Risk exceeds potential reward.\"\n",
    "\n",
    "print(f\"  INVESTMENT DECISION: {emoji} {decision}\")\n",
    "print(f\"  Rationale: {reason}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a complete **Monte Carlo capital budgeting workflow** using spark-bestfit with RayBackend:\n",
    "\n",
    "### Workflow Steps\n",
    "\n",
    "1. **Parameter Modeling**: Defined uncertain project parameters (growth, costs, discount rate)\n",
    "2. **Distribution Fitting**: Used `FitterConfigBuilder` to fit distributions to historical data\n",
    "3. **Correlation Capture**: Applied `GaussianCopula` to model parameter dependencies\n",
    "4. **Monte Carlo Simulation**: Generated 10,000 correlated scenarios\n",
    "5. **Financial Metrics**: Calculated NPV, IRR, and Payback Period for each scenario\n",
    "6. **Risk Analysis**: Computed probabilities, VaR, CVaR, and sensitivity rankings\n",
    "\n",
    "### Key spark-bestfit Features Used\n",
    "\n",
    "| Feature | Purpose |\n",
    "|---------|----------|\n",
    "| `FitterConfigBuilder` | Create reusable fitting configuration |\n",
    "| `DistributionFitter` | Fit 90+ distributions to uncertain parameters |\n",
    "| `GaussianCopula` | Model correlations between economic parameters |\n",
    "| `RayBackend` | Distributed computation for large-scale simulation |\n",
    "\n",
    "### Business Value\n",
    "\n",
    "Monte Carlo simulation provides:\n",
    "- **Distribution of outcomes** instead of single point estimates\n",
    "- **Probability-based decision making** (P(NPV > 0), P(IRR > hurdle))\n",
    "- **Risk quantification** (VaR, Expected Shortfall)\n",
    "- **Sensitivity insights** to focus risk management efforts\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- Add more uncertain parameters (tax rates, salvage value, project timing)\n",
    "- Model time-varying correlations (regime-switching)\n",
    "- Include real options (abandonment, expansion)\n",
    "- Compare multiple investment alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
