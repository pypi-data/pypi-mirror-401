{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Drift Detection with spark-bestfit\n",
    "\n",
    "This notebook demonstrates **data drift detection** using distribution fitting to monitor\n",
    "feature distributions over time and alert when significant changes occur.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Establish baseline distributions** from historical data\n",
    "2. **Monitor distributions** across time periods using KS tests\n",
    "3. **Detect gradual and abrupt drift** in feature distributions\n",
    "4. **Set alert thresholds** based on statistical significance\n",
    "5. **Track multi-feature drift** to identify which features are changing\n",
    "\n",
    "## Business Context\n",
    "\n",
    "Production ML models degrade when underlying data distributions shift. This \"data drift\"\n",
    "can occur due to:\n",
    "- Seasonal patterns or trends\n",
    "- Changes in user behavior\n",
    "- Data pipeline issues\n",
    "- External market conditions\n",
    "\n",
    "**Drift detection enables:**\n",
    "- Proactive model retraining triggers\n",
    "- Data quality issue identification\n",
    "- Early warning for changing business conditions\n",
    "- SLA compliance for model accuracy\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install spark-bestfit pandas numpy matplotlib scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from spark_bestfit import DistributionFitter\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Drift-Detection\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Synthetic Time Series Data\n",
    "\n",
    "We'll simulate a realistic drift scenario:\n",
    "- **Month 1 (Baseline)**: Stable Normal distribution N(100, 15)\n",
    "- **Months 2-4**: Gradual mean shift (100 → 105 → 110 → 115)\n",
    "- **Month 5**: Abrupt distribution change (switches to Gamma)\n",
    "- **Month 6**: Recovery toward baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Baseline parameters\n",
    "baseline_mu = 100\n",
    "baseline_sigma = 15\n",
    "samples_per_month = 10000\n",
    "\n",
    "# Generate data for each period\n",
    "periods = {\n",
    "    'Month 1 (Baseline)': np.random.normal(100, 15, samples_per_month),\n",
    "    'Month 2': np.random.normal(105, 15, samples_per_month),  # Gradual shift\n",
    "    'Month 3': np.random.normal(110, 15, samples_per_month),  # More shift\n",
    "    'Month 4': np.random.normal(115, 16, samples_per_month),  # Shift + variance change\n",
    "    'Month 5': np.random.gamma(5, 20, samples_per_month),     # Abrupt change!\n",
    "    'Month 6': np.random.normal(105, 15, samples_per_month),  # Recovery\n",
    "}\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"Generated Data Summary:\")\n",
    "print(f\"{'Period':<20} {'Mean':>10} {'Std':>10} {'Skew':>10}\")\n",
    "print(\"-\" * 52)\n",
    "for period, data in periods.items():\n",
    "    print(f\"{period:<20} {data.mean():>10.2f} {data.std():>10.2f} {stats.skew(data):>10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (period, data) in enumerate(periods.items()):\n",
    "    ax = axes[i]\n",
    "    ax.hist(data, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(data.mean(), color='red', linestyle='--', lw=2, label=f'Mean: {data.mean():.1f}')\n",
    "    ax.set_title(period)\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Feature Distribution Over Time', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Establish Baseline Distribution\n",
    "\n",
    "Fit distributions to the baseline period to create a reference for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fitter\n",
    "fitter = DistributionFitter(spark)\n",
    "\n",
    "# Create Spark DataFrame for baseline\n",
    "baseline_data = periods['Month 1 (Baseline)']\n",
    "baseline_df = spark.createDataFrame(pd.DataFrame({'value': baseline_data}))\n",
    "\n",
    "# Fit distributions with full metrics (lazy_metrics=False for KS/AD)\n",
    "baseline_results = fitter.fit(\n",
    "    baseline_df,\n",
    "    column='value',\n",
    "    max_distributions=15,\n",
    "    lazy_metrics=False  # Need KS statistics for drift detection\n",
    ")\n",
    "\n",
    "print(f\"Fitted {baseline_results.count()} distributions to baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best baseline fit\n",
    "baseline_fit = baseline_results.best(n=1, metric='aic')[0]\n",
    "baseline_samples = baseline_data  # Store raw samples for KS comparison\n",
    "\n",
    "print(\"Baseline Distribution:\")\n",
    "print(f\"  Best fit: {baseline_fit.distribution}\")\n",
    "print(f\"  AIC: {baseline_fit.aic:.2f}\")\n",
    "print(f\"  KS statistic: {baseline_fit.ks_statistic:.4f}\")\n",
    "print(f\"  Parameters: {baseline_fit.parameters}\")\n",
    "\n",
    "# Show top 5 candidates\n",
    "print(\"\\nTop 5 Baseline Candidates:\")\n",
    "for i, fit in enumerate(baseline_results.best(n=5, metric='aic'), 1):\n",
    "    print(f\"  {i}. {fit.distribution}: AIC={fit.aic:.1f}, KS={fit.ks_statistic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Monitor Periods with KS Test\n",
    "\n",
    "Compare each monitoring period against baseline using the two-sample KS test.\n",
    "This directly compares samples without assuming a specific distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor each period\n",
    "drift_results = []\n",
    "\n",
    "for period, data in periods.items():\n",
    "    # Two-sample KS test: compare this period to baseline\n",
    "    ks_stat, p_value = stats.ks_2samp(baseline_samples, data)\n",
    "    \n",
    "    # Also track distribution statistics\n",
    "    mean_shift = abs(data.mean() - baseline_samples.mean())\n",
    "    std_ratio = data.std() / baseline_samples.std()\n",
    "    \n",
    "    drift_results.append({\n",
    "        'period': period,\n",
    "        'ks_statistic': ks_stat,\n",
    "        'p_value': p_value,\n",
    "        'mean_shift': mean_shift,\n",
    "        'std_ratio': std_ratio,\n",
    "        'drift_detected': p_value < 0.05\n",
    "    })\n",
    "\n",
    "drift_df = pd.DataFrame(drift_results)\n",
    "print(\"Drift Detection Results (KS Test vs Baseline):\")\n",
    "print(drift_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize drift detection\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# KS statistic over time\n",
    "months = range(1, 7)\n",
    "ax1 = axes[0]\n",
    "bars = ax1.bar(months, drift_df['ks_statistic'], \n",
    "               color=['green' if not d else 'red' for d in drift_df['drift_detected']],\n",
    "               edgecolor='black', alpha=0.7)\n",
    "ax1.axhline(0.05, color='orange', linestyle='--', lw=2, label='Typical drift threshold')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('KS Statistic')\n",
    "ax1.set_title('Drift Magnitude Over Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# P-value over time (log scale for visibility)\n",
    "ax2 = axes[1]\n",
    "ax2.semilogy(months, drift_df['p_value'], 'bo-', lw=2, markersize=10)\n",
    "ax2.axhline(0.05, color='red', linestyle='--', lw=2, label='Significance threshold (p=0.05)')\n",
    "ax2.fill_between(months, 0, 0.05, alpha=0.2, color='red', label='Drift detected zone')\n",
    "ax2.set_xlabel('Month')\n",
    "ax2.set_ylabel('p-value (log scale)')\n",
    "ax2.set_title('Statistical Significance of Drift')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(1e-100, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Distribution Fitting for Drift Characterization\n",
    "\n",
    "Beyond detecting drift, we can characterize *how* the distribution changed\n",
    "by fitting distributions to each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit distributions to each period and track best fit\n",
    "period_fits = {}\n",
    "\n",
    "for period, data in periods.items():\n",
    "    df = spark.createDataFrame(pd.DataFrame({'value': data}))\n",
    "    results = fitter.fit(\n",
    "        df,\n",
    "        column='value',\n",
    "        max_distributions=10,\n",
    "        lazy_metrics=False\n",
    "    )\n",
    "    best = results.best(n=1, metric='aic')[0]\n",
    "    period_fits[period] = {\n",
    "        'distribution': best.distribution,\n",
    "        'aic': best.aic,\n",
    "        'ks_statistic': best.ks_statistic,\n",
    "        'parameters': best.parameters\n",
    "    }\n",
    "\n",
    "# Show distribution changes\n",
    "print(\"Best-Fit Distribution by Period:\")\n",
    "print(f\"{'Period':<20} {'Distribution':<15} {'AIC':<12} {'KS Stat'}\")\n",
    "print(\"-\" * 60)\n",
    "for period, fit_info in period_fits.items():\n",
    "    print(f\"{period:<20} {fit_info['distribution']:<15} {fit_info['aic']:<12.1f} {fit_info['ks_statistic']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Multi-Feature Drift Monitoring\n",
    "\n",
    "Real ML models have multiple features. Let's extend to monitor drift across\n",
    "multiple features simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Generate multi-feature data with varying drift patterns\n",
    "n_samples = 5000\n",
    "\n",
    "# Baseline period\n",
    "baseline_multi = pd.DataFrame({\n",
    "    'feature_a': np.random.normal(50, 10, n_samples),   # Will drift\n",
    "    'feature_b': np.random.exponential(20, n_samples),  # Stable\n",
    "    'feature_c': np.random.normal(0, 1, n_samples),     # Will drift severely\n",
    "})\n",
    "\n",
    "# Monitoring period (with drift in features A and C)\n",
    "monitor_multi = pd.DataFrame({\n",
    "    'feature_a': np.random.normal(55, 10, n_samples),   # Mean shifted +5\n",
    "    'feature_b': np.random.exponential(20, n_samples),  # Stable\n",
    "    'feature_c': np.random.gamma(2, 2, n_samples),      # Distribution change!\n",
    "})\n",
    "\n",
    "print(\"Multi-Feature Drift Detection:\")\n",
    "print(f\"{'Feature':<12} {'Baseline Mean':>15} {'Monitor Mean':>15} {'KS Stat':>12} {'p-value':>12} {'Drift?'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "multi_drift = []\n",
    "for col in baseline_multi.columns:\n",
    "    ks_stat, p_val = stats.ks_2samp(baseline_multi[col], monitor_multi[col])\n",
    "    drift_detected = p_val < 0.05\n",
    "    multi_drift.append({\n",
    "        'feature': col,\n",
    "        'ks_statistic': ks_stat,\n",
    "        'p_value': p_val,\n",
    "        'drift': drift_detected\n",
    "    })\n",
    "    print(f\"{col:<12} {baseline_multi[col].mean():>15.2f} {monitor_multi[col].mean():>15.2f} \"\n",
    "          f\"{ks_stat:>12.4f} {p_val:>12.4e} {'YES' if drift_detected else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate drift score\n",
    "drifting_features = sum(1 for d in multi_drift if d['drift'])\n",
    "total_features = len(multi_drift)\n",
    "drift_score = drifting_features / total_features\n",
    "\n",
    "print(f\"\\nAggregate Drift Assessment:\")\n",
    "print(f\"  Features with drift: {drifting_features}/{total_features}\")\n",
    "print(f\"  Drift score: {drift_score:.1%}\")\n",
    "\n",
    "if drift_score > 0.5:\n",
    "    print(f\"  ALERT: Significant drift detected - consider model retraining\")\n",
    "elif drift_score > 0:\n",
    "    print(f\"  WARNING: Partial drift detected - monitor closely\")\n",
    "else:\n",
    "    print(f\"  OK: No significant drift detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Alerting Dashboard\n",
    "\n",
    "Create a comprehensive drift monitoring dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create drift monitoring dashboard\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Feature-wise drift comparison\nax1 = axes[0, 0]\nfeatures = [d['feature'] for d in multi_drift]\nks_stats = [d['ks_statistic'] for d in multi_drift]\ncolors = ['red' if d['drift'] else 'green' for d in multi_drift]\nax1.barh(features, ks_stats, color=colors, edgecolor='black', alpha=0.7)\nax1.axvline(0.05, color='orange', linestyle='--', lw=2, label='Alert threshold')\nax1.set_xlabel('KS Statistic')\nax1.set_title('Feature-wise Drift Magnitude')\nax1.legend()\n\n# 2. Time series drift tracking (using earlier data)\nax2 = axes[0, 1]\nax2.plot(range(1, 7), drift_df['ks_statistic'], 'bo-', lw=2, markersize=8)\nax2.fill_between(range(1, 7), 0, drift_df['ks_statistic'], alpha=0.3)\nax2.axhline(0.05, color='red', linestyle='--', lw=2, label='Alert threshold')\nfor i, row in drift_df.iterrows():\n    if row['drift_detected']:\n        ax2.scatter(i+1, row['ks_statistic'], color='red', s=200, zorder=5, marker='X')\nax2.set_xlabel('Month')\nax2.set_ylabel('KS Statistic')\nax2.set_title('Drift Evolution Over Time')\nax2.legend()\n\n# 3. Distribution overlay (baseline vs drifted)\nax3 = axes[1, 0]\nx = np.linspace(baseline_multi['feature_c'].min(), \n                max(baseline_multi['feature_c'].max(), monitor_multi['feature_c'].max()), 100)\nax3.hist(baseline_multi['feature_c'], bins=40, density=True, alpha=0.5, \n         label='Baseline', color='blue', edgecolor='black')\nax3.hist(monitor_multi['feature_c'], bins=40, density=True, alpha=0.5, \n         label='Monitor', color='red', edgecolor='black')\nax3.set_xlabel('Feature C Value')\nax3.set_ylabel('Density')\nax3.set_title('Feature C: Distribution Shift (Severe Drift)')\nax3.legend()\n\n# 4. Mean shift tracking\nax4 = axes[1, 1]\nmeans = [periods[p].mean() for p in periods.keys()]\nax4.plot(range(1, 7), means, 'go-', lw=2, markersize=10)\nax4.axhline(baseline_mu, color='blue', linestyle='--', lw=2, label=f'Baseline mean ({baseline_mu})')\nax4.fill_between(range(1, 7), baseline_mu - baseline_sigma, baseline_mu + baseline_sigma, \n                 alpha=0.2, color='blue', label='Baseline ±1 std')\nax4.set_xlabel('Month')\nax4.set_ylabel('Mean Value')\nax4.set_title('Mean Drift Over Time')\nax4.legend()\n\nplt.suptitle('Drift Monitoring Dashboard', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Streaming Drift Detection Pattern\n",
    "\n",
    "For real-time monitoring, you can apply the same pattern to streaming data\n",
    "using Spark Structured Streaming's `foreachBatch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming drift detection pattern (for reference)\n",
    "# This shows HOW to integrate drift detection with streaming data\n",
    "\n",
    "def create_drift_monitor(fitter, baseline_samples, threshold=0.05):\n",
    "    \"\"\"Factory function that returns a streaming batch processor.\"\"\"\n",
    "    \n",
    "    def monitor_batch(batch_df, batch_id):\n",
    "        \"\"\"Process each streaming batch for drift detection.\"\"\"\n",
    "        if batch_df.count() == 0:\n",
    "            return\n",
    "        \n",
    "        # Convert batch to pandas for KS test\n",
    "        batch_data = batch_df.toPandas()['value'].values\n",
    "        \n",
    "        # Two-sample KS test against baseline\n",
    "        ks_stat, p_value = stats.ks_2samp(baseline_samples, batch_data)\n",
    "        \n",
    "        # Optionally fit distribution to batch\n",
    "        results = fitter.fit(batch_df, column='value', lazy_metrics=True)\n",
    "        best_fit = results.best(n=1, metric='aic')[0]\n",
    "        \n",
    "        # Alert on drift\n",
    "        if p_value < threshold:\n",
    "            print(f\"DRIFT ALERT [Batch {batch_id}]: KS={ks_stat:.4f}, p={p_value:.4e}\")\n",
    "            print(f\"  Distribution changed to: {best_fit.distribution}\")\n",
    "            # In production: send to monitoring system, trigger retraining, etc.\n",
    "        else:\n",
    "            print(f\"[Batch {batch_id}] OK: KS={ks_stat:.4f}, p={p_value:.4f}\")\n",
    "    \n",
    "    return monitor_batch\n",
    "\n",
    "# Example usage (commented out - requires active stream)\n",
    "# drift_monitor = create_drift_monitor(fitter, baseline_samples)\n",
    "# stream_df.writeStream.foreachBatch(drift_monitor).start()\n",
    "\n",
    "print(\"Streaming pattern defined. In production:\")\n",
    "print(\"  1. Create baseline from historical data\")\n",
    "print(\"  2. Apply foreachBatch with drift_monitor function\")\n",
    "print(\"  3. Monitor alerts in real-time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate streaming batch processing\n",
    "print(\"Simulated Streaming Drift Detection:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "drift_monitor = create_drift_monitor(fitter, baseline_samples, threshold=0.05)\n",
    "\n",
    "# Process each \"month\" as if it were a streaming batch\n",
    "for batch_id, (period, data) in enumerate(periods.items()):\n",
    "    batch_df = spark.createDataFrame(pd.DataFrame({'value': data}))\n",
    "    print(f\"\\nProcessing {period}:\")\n",
    "    drift_monitor(batch_df, batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Business Impact Assessment\n",
    "\n",
    "Link detected drift to potential model performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate relationship between drift and model accuracy\n",
    "# In practice, you'd track actual model performance alongside drift\n",
    "\n",
    "# Hypothetical model accuracy degradation with drift\n",
    "baseline_accuracy = 0.92\n",
    "drift_impact = -0.15  # Each unit of KS stat reduces accuracy by 15%\n",
    "\n",
    "print(\"Business Impact Assessment:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Baseline model accuracy: {baseline_accuracy:.1%}\")\n",
    "print(f\"Assumed drift impact: {drift_impact:.0%} accuracy per unit KS statistic\")\n",
    "print()\n",
    "print(f\"{'Period':<20} {'KS Stat':>10} {'Est. Accuracy':>15} {'Revenue Impact'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "monthly_revenue = 1_000_000  # $1M monthly revenue depends on model\n",
    "\n",
    "for i, row in drift_df.iterrows():\n",
    "    ks = row['ks_statistic']\n",
    "    est_accuracy = max(baseline_accuracy + drift_impact * ks, 0.5)  # Floor at 50%\n",
    "    accuracy_drop = baseline_accuracy - est_accuracy\n",
    "    revenue_impact = monthly_revenue * accuracy_drop\n",
    "    \n",
    "    print(f\"{row['period']:<20} {ks:>10.4f} {est_accuracy:>14.1%} ${revenue_impact:>12,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate retraining decision\n",
    "retraining_cost = 50_000  # Cost to retrain model\n",
    "drift_threshold_for_retrain = 0.10  # Retrain if KS > 0.10\n",
    "\n",
    "print(\"\\nRetraining Decision Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, row in drift_df.iterrows():\n",
    "    ks = row['ks_statistic']\n",
    "    est_accuracy = max(baseline_accuracy + drift_impact * ks, 0.5)\n",
    "    monthly_loss = monthly_revenue * (baseline_accuracy - est_accuracy)\n",
    "    \n",
    "    if ks > drift_threshold_for_retrain and monthly_loss > retraining_cost:\n",
    "        decision = \"RETRAIN\"\n",
    "        reason = f\"Loss ${monthly_loss:,.0f} > Retrain cost ${retraining_cost:,.0f}\"\n",
    "    elif ks > drift_threshold_for_retrain:\n",
    "        decision = \"MONITOR\"\n",
    "        reason = f\"Drift detected but loss ${monthly_loss:,.0f} < ${retraining_cost:,.0f}\"\n",
    "    else:\n",
    "        decision = \"OK\"\n",
    "        reason = f\"Drift within acceptable bounds\"\n",
    "    \n",
    "    print(f\"{row['period']}: {decision} - {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated data drift detection with spark-bestfit:\n",
    "\n",
    "1. **Baseline establishment**: Fit distributions to historical data for reference\n",
    "2. **KS test for drift**: Two-sample KS test to detect distribution changes\n",
    "3. **Distribution fitting**: Characterize *how* distributions changed\n",
    "4. **Multi-feature monitoring**: Track drift across multiple features\n",
    "5. **Alerting patterns**: Set thresholds and visualize drift evolution\n",
    "6. **Streaming integration**: `foreachBatch` pattern for real-time monitoring\n",
    "7. **Business impact**: Link drift to model performance and ROI\n",
    "\n",
    "### Key spark-bestfit Features Used\n",
    "\n",
    "| Feature | Purpose |\n",
    "|---------|---------|\n",
    "| `lazy_metrics=False` | Compute KS statistics for validation |\n",
    "| `DistributionFitter` | Fit distributions to each period |\n",
    "| `results.best()` | Identify best-fit distribution |\n",
    "| `scipy.stats.ks_2samp` | Direct sample comparison for drift |\n",
    "\n",
    "### Drift Detection Thresholds\n",
    "\n",
    "| KS Statistic | p-value | Interpretation |\n",
    "|--------------|---------|----------------|\n",
    "| < 0.05 | > 0.05 | No significant drift |\n",
    "| 0.05 - 0.10 | < 0.05 | Moderate drift - monitor |\n",
    "| > 0.10 | << 0.05 | Significant drift - investigate/retrain |\n",
    "\n",
    "### Production Recommendations\n",
    "\n",
    "1. **Store baselines**: Serialize fitted distributions for comparison\n",
    "2. **Track trends**: Monitor KS statistic over time, not just point-in-time\n",
    "3. **Set tiered alerts**: Warning (yellow) and critical (red) thresholds\n",
    "4. **Automate response**: Trigger retraining pipelines on critical drift\n",
    "5. **Root cause analysis**: When drift occurs, investigate which features changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
