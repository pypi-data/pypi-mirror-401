{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Event Simulation with spark-bestfit (RayBackend)\n",
    "\n",
    "This notebook demonstrates how to use **distribution fitting** to power realistic\n",
    "**discrete event simulations** for operational decision-making.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Fit distributions** to real operational data (arrivals, service times)\n",
    "2. **Validate assumptions** - is it really Poisson? Test with KS!\n",
    "3. **Build queue simulations** using fitted distributions\n",
    "4. **Run what-if scenarios** to guide staffing decisions\n",
    "5. **Quantify uncertainty** with confidence intervals\n",
    "\n",
    "## Business Context\n",
    "\n",
    "Operations teams often need to answer questions like:\n",
    "- \"If we add 2 more agents, how much will wait times decrease?\"\n",
    "- \"What happens to service levels if call volume increases 20%?\"\n",
    "- \"Is investing in training (reducing handle time) worth it?\"\n",
    "\n",
    "**The Problem**: These decisions are expensive and hard to reverse. You can't\n",
    "easily experiment with real operations.\n",
    "\n",
    "**The Solution**: Fit distributions to historical data, then simulate scenarios\n",
    "to predict outcomes before committing resources.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install spark-bestfit[ray] pandas numpy matplotlib scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nimport ray\nfrom spark_bestfit import DistributionFitter, DiscreteDistributionFitter\nfrom spark_bestfit.backends.ray import RayBackend\n\n# Initialize Ray (skip if already initialized)\nif not ray.is_initialized():\n    ray.init(ignore_reinit_error=True)\n\n# Create RayBackend\nbackend = RayBackend()\nprint(f\"RayBackend initialized with {backend.get_parallelism()} CPUs\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generate Realistic Call Center Data\n",
    "\n",
    "In production, this would be historical data from your systems. We'll simulate\n",
    "realistic call center operations with:\n",
    "\n",
    "- **Arrivals**: Non-homogeneous Poisson (higher rates during business hours)\n",
    "- **Service times**: Lognormal (right-skewed, some long calls)\n",
    "- **Abandonment**: Customers who hang up after waiting too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def generate_call_center_data(n_days=30, base_rate=50):\n",
    "    \"\"\"\n",
    "    Generate realistic call center data.\n",
    "    \n",
    "    Returns DataFrame with: timestamp, inter_arrival_time, service_time, \n",
    "    hour_of_day, day_of_week, abandoned\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    \n",
    "    for day in range(n_days):\n",
    "        day_of_week = day % 7  # 0=Monday, 6=Sunday\n",
    "        \n",
    "        # Simulate each hour of operation (8 AM to 8 PM)\n",
    "        for hour in range(8, 20):\n",
    "            # Arrival rate varies by hour (peak at 10-11 AM and 2-3 PM)\n",
    "            hour_factor = 1.0\n",
    "            if hour in [10, 11]:\n",
    "                hour_factor = 1.8  # Morning peak\n",
    "            elif hour in [14, 15]:\n",
    "                hour_factor = 1.5  # Afternoon peak\n",
    "            elif hour in [8, 19]:\n",
    "                hour_factor = 0.6  # Start/end of day slower\n",
    "            \n",
    "            # Weekend factor\n",
    "            if day_of_week >= 5:\n",
    "                hour_factor *= 0.4  # Much lower on weekends\n",
    "            \n",
    "            # Number of calls this hour (Poisson)\n",
    "            hourly_rate = base_rate * hour_factor\n",
    "            n_calls = np.random.poisson(hourly_rate)\n",
    "            \n",
    "            # Generate inter-arrival times (exponential with some burstiness)\n",
    "            # Real data often shows slight overdispersion\n",
    "            if n_calls > 0:\n",
    "                # Use Weibull instead of pure exponential for slight burstiness\n",
    "                inter_arrivals = stats.weibull_min.rvs(c=0.9, scale=60/hourly_rate*60, size=n_calls)\n",
    "                \n",
    "                # Service times: lognormal (right-skewed)\n",
    "                # Average ~5 minutes, but some calls much longer\n",
    "                service_times = stats.lognorm.rvs(s=0.6, scale=300, size=n_calls)  # seconds\n",
    "                \n",
    "                # Abandonment probability increases with expected wait\n",
    "                # (simplified - in reality depends on queue state)\n",
    "                abandon_prob = 0.05 + 0.02 * (hourly_rate / base_rate - 1)\n",
    "                abandoned = np.random.binomial(1, abandon_prob, n_calls)\n",
    "                \n",
    "                for i in range(n_calls):\n",
    "                    records.append({\n",
    "                        'day': day,\n",
    "                        'hour': hour,\n",
    "                        'day_of_week': day_of_week,\n",
    "                        'inter_arrival_seconds': inter_arrivals[i],\n",
    "                        'service_time_seconds': service_times[i],\n",
    "                        'abandoned': abandoned[i]\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Generate 30 days of call center data\n",
    "call_data = generate_call_center_data(n_days=30, base_rate=50)\n",
    "\n",
    "print(f\"Generated {len(call_data):,} call records over 30 days\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(call_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Call Center Data Summary:\")\n",
    "print(f\"\\nTotal calls: {len(call_data):,}\")\n",
    "print(f\"Abandoned calls: {call_data['abandoned'].sum():,} ({call_data['abandoned'].mean():.1%})\")\n",
    "print(f\"\\nInter-arrival times (seconds):\")\n",
    "print(f\"  Mean: {call_data['inter_arrival_seconds'].mean():.1f}\")\n",
    "print(f\"  Median: {call_data['inter_arrival_seconds'].median():.1f}\")\n",
    "print(f\"  Std: {call_data['inter_arrival_seconds'].std():.1f}\")\n",
    "print(f\"\\nService times (seconds):\")\n",
    "print(f\"  Mean: {call_data['service_time_seconds'].mean():.1f} ({call_data['service_time_seconds'].mean()/60:.1f} min)\")\n",
    "print(f\"  Median: {call_data['service_time_seconds'].median():.1f} ({call_data['service_time_seconds'].median()/60:.1f} min)\")\n",
    "print(f\"  Std: {call_data['service_time_seconds'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis\n",
    "\n",
    "Before fitting distributions, let's understand our data patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Calls by hour\n",
    "hourly_calls = call_data.groupby('hour').size()\n",
    "axes[0, 0].bar(hourly_calls.index, hourly_calls.values, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Hour of Day')\n",
    "axes[0, 0].set_ylabel('Total Calls')\n",
    "axes[0, 0].set_title('Call Volume by Hour')\n",
    "axes[0, 0].set_xticks(range(8, 20))\n",
    "\n",
    "# Calls by day of week\n",
    "daily_calls = call_data.groupby('day_of_week').size()\n",
    "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0, 1].bar(range(7), daily_calls.values, color='coral', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Total Calls')\n",
    "axes[0, 1].set_title('Call Volume by Day of Week')\n",
    "axes[0, 1].set_xticks(range(7))\n",
    "axes[0, 1].set_xticklabels(day_names)\n",
    "\n",
    "# Inter-arrival time distribution\n",
    "axes[1, 0].hist(call_data['inter_arrival_seconds'], bins=50, density=True, \n",
    "                alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Inter-Arrival Time (seconds)')\n",
    "axes[1, 0].set_ylabel('Density')\n",
    "axes[1, 0].set_title('Inter-Arrival Time Distribution')\n",
    "axes[1, 0].set_xlim(0, 200)\n",
    "\n",
    "# Service time distribution\n",
    "axes[1, 1].hist(call_data['service_time_seconds'] / 60, bins=50, density=True,\n",
    "                alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[1, 1].set_xlabel('Service Time (minutes)')\n",
    "axes[1, 1].set_ylabel('Density')\n",
    "axes[1, 1].set_title('Service Time Distribution')\n",
    "axes[1, 1].axvline(call_data['service_time_seconds'].mean()/60, color='red', \n",
    "                   linestyle='--', label=f\"Mean: {call_data['service_time_seconds'].mean()/60:.1f} min\")\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.suptitle('Call Center Data Exploration', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fit Distributions to Operational Processes\n",
    "\n",
    "Now we'll use spark-bestfit to identify the best distributions for:\n",
    "\n",
    "1. **Inter-arrival times** (continuous) - How long between calls?\n",
    "2. **Service times** (continuous) - How long does each call take?\n",
    "3. **Hourly call volume** (discrete) - How many calls per hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hourly aggregates for discrete fitting\n",
    "hourly_volumes = call_data.groupby(['day', 'hour']).size().reset_index(name='call_count')\n",
    "\n",
    "print(f\"Call-level data: {len(call_data):,} records\")\n",
    "print(f\"Hourly aggregates: {len(hourly_volumes):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit continuous distributions to inter-arrival and service times\n",
    "cont_fitter = DistributionFitter(backend=backend)\n",
    "\n",
    "# Inter-arrival times\n",
    "interarrival_results = cont_fitter.fit(\n",
    "    call_data,\n",
    "    column='inter_arrival_seconds',\n",
    "    max_distributions=20,\n",
    "    lazy_metrics=False  # We want KS for validation\n",
    ")\n",
    "\n",
    "# Service times\n",
    "service_results = cont_fitter.fit(\n",
    "    call_data,\n",
    "    column='service_time_seconds',\n",
    "    max_distributions=20,\n",
    "    lazy_metrics=False\n",
    ")\n",
    "\n",
    "print(f\"Fitted {interarrival_results.count()} distributions to inter-arrival times\")\n",
    "print(f\"Fitted {service_results.count()} distributions to service times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fits for inter-arrival times\n",
    "print(\"INTER-ARRIVAL TIMES - Best Distributions:\")\n",
    "print(\"\\nBy AIC (prediction):\")\n",
    "for i, fit in enumerate(interarrival_results.best(n=5, metric='aic'), 1):\n",
    "    print(f\"  {i}. {fit.distribution}: AIC={fit.aic:.1f}\")\n",
    "\n",
    "print(\"\\nBy KS (goodness-of-fit):\")\n",
    "for i, fit in enumerate(interarrival_results.best(n=5, metric='ks_statistic'), 1):\n",
    "    pval = fit.pvalue if fit.pvalue else 0\n",
    "    print(f\"  {i}. {fit.distribution}: KS={fit.ks_statistic:.4f}, p={pval:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best fits for service times\n",
    "print(\"SERVICE TIMES - Best Distributions:\")\n",
    "print(\"\\nBy AIC (prediction):\")\n",
    "for i, fit in enumerate(service_results.best(n=5, metric='aic'), 1):\n",
    "    print(f\"  {i}. {fit.distribution}: AIC={fit.aic:.1f}\")\n",
    "\n",
    "print(\"\\nBy KS (goodness-of-fit):\")\n",
    "for i, fit in enumerate(service_results.best(n=5, metric='ks_statistic'), 1):\n",
    "    pval = fit.pvalue if fit.pvalue else 0\n",
    "    print(f\"  {i}. {fit.distribution}: KS={fit.ks_statistic:.4f}, p={pval:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit discrete distributions to hourly call volumes\n",
    "disc_fitter = DiscreteDistributionFitter(backend=backend)\n",
    "\n",
    "volume_results = disc_fitter.fit(\n",
    "    hourly_volumes,\n",
    "    column='call_count'\n",
    ")\n",
    "\n",
    "print(\"HOURLY CALL VOLUME - Best Distributions:\")\n",
    "print(\"\\nBy AIC:\")\n",
    "for i, fit in enumerate(volume_results.best(n=5, metric='aic'), 1):\n",
    "    print(f\"  {i}. {fit.distribution}: AIC={fit.aic:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Validate Common Assumptions\n",
    "\n",
    "Operations research often assumes:\n",
    "- Arrivals are **Poisson** -> inter-arrivals are **Exponential**\n",
    "- Service times are **Exponential** (for M/M/c queues)\n",
    "\n",
    "Let's test these assumptions with our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find exponential fit for inter-arrivals\n",
    "exp_interarrival = None\n",
    "for fit in interarrival_results.best(n=50, metric='aic'):\n",
    "    if fit.distribution == 'expon':\n",
    "        exp_interarrival = fit\n",
    "        break\n",
    "\n",
    "# Find exponential fit for service times\n",
    "exp_service = None\n",
    "for fit in service_results.best(n=50, metric='aic'):\n",
    "    if fit.distribution == 'expon':\n",
    "        exp_service = fit\n",
    "        break\n",
    "\n",
    "# Get best overall fits\n",
    "best_interarrival = interarrival_results.best(n=1, metric='aic')[0]\n",
    "best_service = service_results.best(n=1, metric='aic')[0]\n",
    "\n",
    "print(\"ASSUMPTION TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Inter-Arrival Times - Is Exponential appropriate?\")\n",
    "if exp_interarrival:\n",
    "    print(f\"   Exponential: AIC={exp_interarrival.aic:.1f}, KS p-value={exp_interarrival.pvalue:.4f}\")\n",
    "    print(f\"   Best fit ({best_interarrival.distribution}): AIC={best_interarrival.aic:.1f}\")\n",
    "    aic_diff = exp_interarrival.aic - best_interarrival.aic\n",
    "    if aic_diff < 10:\n",
    "        print(f\"   VERDICT: Exponential is ACCEPTABLE (AIC diff={aic_diff:.1f})\")\n",
    "    else:\n",
    "        print(f\"   VERDICT: Exponential is POOR (AIC diff={aic_diff:.1f})\")\n",
    "        print(f\"   RECOMMENDATION: Use {best_interarrival.distribution} instead\")\n",
    "\n",
    "print(\"\\n2. Service Times - Is Exponential appropriate?\")\n",
    "if exp_service:\n",
    "    print(f\"   Exponential: AIC={exp_service.aic:.1f}, KS p-value={exp_service.pvalue:.4f}\")\n",
    "    print(f\"   Best fit ({best_service.distribution}): AIC={best_service.aic:.1f}\")\n",
    "    aic_diff = exp_service.aic - best_service.aic\n",
    "    if aic_diff < 10:\n",
    "        print(f\"   VERDICT: Exponential is ACCEPTABLE (AIC diff={aic_diff:.1f})\")\n",
    "    else:\n",
    "        print(f\"   VERDICT: Exponential is POOR (AIC diff={aic_diff:.1f})\")\n",
    "        print(f\"   RECOMMENDATION: Use {best_service.distribution} instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize assumption testing\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Inter-arrival comparison\n",
    "x_ia = np.linspace(0, 150, 200)\n",
    "ia_data = call_data['inter_arrival_seconds']\n",
    "ia_data_plot = ia_data[ia_data < 150]\n",
    "\n",
    "axes[0].hist(ia_data_plot, bins=40, density=True, alpha=0.6, \n",
    "             color='steelblue', edgecolor='black', label='Observed')\n",
    "\n",
    "if exp_interarrival:\n",
    "    exp_dist = exp_interarrival.get_scipy_dist()\n",
    "    axes[0].plot(x_ia, exp_dist.pdf(x_ia), 'r--', lw=2, label=f'Exponential (assumed)')\n",
    "\n",
    "best_ia_dist = best_interarrival.get_scipy_dist()\n",
    "axes[0].plot(x_ia, best_ia_dist.pdf(x_ia), 'g-', lw=2, label=f'{best_interarrival.distribution} (best fit)')\n",
    "\n",
    "axes[0].set_xlabel('Inter-Arrival Time (seconds)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Inter-Arrival Times: Assumption vs Reality')\n",
    "axes[0].legend()\n",
    "\n",
    "# Service time comparison\n",
    "x_st = np.linspace(0, 1000, 200)\n",
    "st_data = call_data['service_time_seconds']\n",
    "st_data_plot = st_data[st_data < 1000]\n",
    "\n",
    "axes[1].hist(st_data_plot, bins=40, density=True, alpha=0.6,\n",
    "             color='coral', edgecolor='black', label='Observed')\n",
    "\n",
    "if exp_service:\n",
    "    exp_svc_dist = exp_service.get_scipy_dist()\n",
    "    axes[1].plot(x_st, exp_svc_dist.pdf(x_st), 'r--', lw=2, label=f'Exponential (assumed)')\n",
    "\n",
    "best_st_dist = best_service.get_scipy_dist()\n",
    "axes[1].plot(x_st, best_st_dist.pdf(x_st), 'g-', lw=2, label=f'{best_service.distribution} (best fit)')\n",
    "\n",
    "axes[1].set_xlabel('Service Time (seconds)')\n",
    "axes[1].set_ylabel('Density')\n",
    "axes[1].set_title('Service Times: Assumption vs Reality')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('Testing Common Queueing Theory Assumptions', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Build Queue Simulation\n",
    "\n",
    "Now we'll use our fitted distributions to simulate a call center queue.\n",
    "This is a simple G/G/c queue (general arrival, general service, c servers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_queue(n_agents, n_calls, arrival_dist, service_dist, seed=None):\n",
    "    \"\"\"\n",
    "    Simulate a G/G/c queue using fitted distributions.\n",
    "    \n",
    "    Args:\n",
    "        n_agents: Number of agents (servers)\n",
    "        n_calls: Number of calls to simulate\n",
    "        arrival_dist: Frozen scipy distribution for inter-arrival times\n",
    "        service_dist: Frozen scipy distribution for service times\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        dict with simulation results\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Generate arrivals and service times from fitted distributions\n",
    "    inter_arrivals = arrival_dist.rvs(size=n_calls)\n",
    "    service_times = service_dist.rvs(size=n_calls)\n",
    "    \n",
    "    # Ensure positive values\n",
    "    inter_arrivals = np.maximum(inter_arrivals, 0.1)\n",
    "    service_times = np.maximum(service_times, 1.0)\n",
    "    \n",
    "    # Calculate arrival times\n",
    "    arrival_times = np.cumsum(inter_arrivals)\n",
    "    \n",
    "    # Track when each agent becomes free\n",
    "    agent_free_at = np.zeros(n_agents)\n",
    "    \n",
    "    wait_times = []\n",
    "    \n",
    "    for i in range(n_calls):\n",
    "        arrival = arrival_times[i]\n",
    "        service = service_times[i]\n",
    "        \n",
    "        # Find the agent who becomes free first\n",
    "        next_free_agent = np.argmin(agent_free_at)\n",
    "        free_time = agent_free_at[next_free_agent]\n",
    "        \n",
    "        # Wait time = time until agent is free (0 if agent already free)\n",
    "        wait = max(0, free_time - arrival)\n",
    "        wait_times.append(wait)\n",
    "        \n",
    "        # Update when this agent will be free\n",
    "        start_service = max(arrival, free_time)\n",
    "        agent_free_at[next_free_agent] = start_service + service\n",
    "    \n",
    "    wait_times = np.array(wait_times)\n",
    "    \n",
    "    return {\n",
    "        'n_agents': n_agents,\n",
    "        'n_calls': n_calls,\n",
    "        'mean_wait': wait_times.mean(),\n",
    "        'median_wait': np.median(wait_times),\n",
    "        'p95_wait': np.percentile(wait_times, 95),\n",
    "        'pct_immediate': (wait_times == 0).mean() * 100,\n",
    "        'pct_under_60s': (wait_times < 60).mean() * 100,\n",
    "        'wait_times': wait_times\n",
    "    }\n",
    "\n",
    "# Get fitted distributions\n",
    "arrival_dist = best_interarrival.get_scipy_dist()\n",
    "service_dist = best_service.get_scipy_dist()\n",
    "\n",
    "print(f\"Using distributions:\")\n",
    "print(f\"  Arrivals: {best_interarrival.distribution}\")\n",
    "print(f\"  Service: {best_service.distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run baseline simulation (5 agents, peak hour volume)\n",
    "# Simulate 2000 calls (roughly 2 peak hours)\n",
    "baseline = simulate_queue(\n",
    "    n_agents=5,\n",
    "    n_calls=2000,\n",
    "    arrival_dist=arrival_dist,\n",
    "    service_dist=service_dist,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"BASELINE SIMULATION (5 Agents)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Calls simulated: {baseline['n_calls']:,}\")\n",
    "print(f\"\\nWait Time Metrics:\")\n",
    "print(f\"  Mean wait: {baseline['mean_wait']:.1f} seconds ({baseline['mean_wait']/60:.1f} min)\")\n",
    "print(f\"  Median wait: {baseline['median_wait']:.1f} seconds\")\n",
    "print(f\"  95th percentile: {baseline['p95_wait']:.1f} seconds ({baseline['p95_wait']/60:.1f} min)\")\n",
    "print(f\"\\nService Level:\")\n",
    "print(f\"  Answered immediately: {baseline['pct_immediate']:.1f}%\")\n",
    "print(f\"  Answered within 60s: {baseline['pct_under_60s']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: What-If Scenario Analysis\n",
    "\n",
    "Now the powerful part: simulate different scenarios to guide decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario_analysis(arrival_dist, service_dist, n_calls=2000, n_simulations=20):\n",
    "    \"\"\"\n",
    "    Run multiple scenarios with confidence intervals.\n",
    "    \"\"\"\n",
    "    scenarios = {\n",
    "        'Current (5 agents)': {'n_agents': 5, 'arrival_scale': 1.0, 'service_scale': 1.0},\n",
    "        'Add 1 agent (6)': {'n_agents': 6, 'arrival_scale': 1.0, 'service_scale': 1.0},\n",
    "        'Add 2 agents (7)': {'n_agents': 7, 'arrival_scale': 1.0, 'service_scale': 1.0},\n",
    "        '20% more calls': {'n_agents': 5, 'arrival_scale': 0.83, 'service_scale': 1.0},\n",
    "        '10% faster service': {'n_agents': 5, 'arrival_scale': 1.0, 'service_scale': 0.9},\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, config in scenarios.items():\n",
    "        scenario_waits = []\n",
    "        scenario_svc_levels = []\n",
    "        \n",
    "        for sim in range(n_simulations):\n",
    "            # Scale distributions if needed\n",
    "            if config['arrival_scale'] != 1.0:\n",
    "                scaled_arrivals = arrival_dist.rvs(size=n_calls) * config['arrival_scale']\n",
    "                class ScaledDist:\n",
    "                    def __init__(self, samples):\n",
    "                        self.samples = samples\n",
    "                    def rvs(self, size):\n",
    "                        return self.samples[:size]\n",
    "                arr_dist = ScaledDist(scaled_arrivals)\n",
    "            else:\n",
    "                arr_dist = arrival_dist\n",
    "            \n",
    "            if config['service_scale'] != 1.0:\n",
    "                scaled_service = service_dist.rvs(size=n_calls) * config['service_scale']\n",
    "                class ScaledDist2:\n",
    "                    def __init__(self, samples):\n",
    "                        self.samples = samples\n",
    "                    def rvs(self, size):\n",
    "                        return self.samples[:size]\n",
    "                svc_dist = ScaledDist2(scaled_service)\n",
    "            else:\n",
    "                svc_dist = service_dist\n",
    "            \n",
    "            result = simulate_queue(\n",
    "                n_agents=config['n_agents'],\n",
    "                n_calls=n_calls,\n",
    "                arrival_dist=arr_dist,\n",
    "                service_dist=svc_dist,\n",
    "                seed=sim * 100 + 42\n",
    "            )\n",
    "            scenario_waits.append(result['mean_wait'])\n",
    "            scenario_svc_levels.append(result['pct_under_60s'])\n",
    "        \n",
    "        results[name] = {\n",
    "            'mean_wait': np.mean(scenario_waits),\n",
    "            'wait_ci': (np.percentile(scenario_waits, 5), np.percentile(scenario_waits, 95)),\n",
    "            'service_level': np.mean(scenario_svc_levels),\n",
    "            'sl_ci': (np.percentile(scenario_svc_levels, 5), np.percentile(scenario_svc_levels, 95))\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Running scenario analysis (20 simulations each)...\")\n",
    "scenarios = run_scenario_analysis(arrival_dist, service_dist)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display scenario comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WHAT-IF SCENARIO ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Scenario':<25} {'Mean Wait (s)':<20} {'Service Level (<60s)':<25}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "baseline_wait = scenarios['Current (5 agents)']['mean_wait']\n",
    "baseline_sl = scenarios['Current (5 agents)']['service_level']\n",
    "\n",
    "for name, result in scenarios.items():\n",
    "    wait_str = f\"{result['mean_wait']:.1f} ({result['wait_ci'][0]:.1f}-{result['wait_ci'][1]:.1f})\"\n",
    "    sl_str = f\"{result['service_level']:.1f}% ({result['sl_ci'][0]:.1f}-{result['sl_ci'][1]:.1f}%)\"\n",
    "    \n",
    "    # Calculate change from baseline\n",
    "    if name != 'Current (5 agents)':\n",
    "        wait_change = ((result['mean_wait'] - baseline_wait) / baseline_wait) * 100\n",
    "        sl_change = result['service_level'] - baseline_sl\n",
    "        change_str = f\"  [Wait: {wait_change:+.0f}%, SL: {sl_change:+.1f}pp]\"\n",
    "    else:\n",
    "        change_str = \"  [BASELINE]\"\n",
    "    \n",
    "    print(f\"{name:<25} {wait_str:<20} {sl_str:<25}{change_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "scenario_names = list(scenarios.keys())\n",
    "x = np.arange(len(scenario_names))\n",
    "\n",
    "# Mean wait times with CI\n",
    "waits = [scenarios[s]['mean_wait'] for s in scenario_names]\n",
    "wait_errs = [[scenarios[s]['mean_wait'] - scenarios[s]['wait_ci'][0] for s in scenario_names],\n",
    "             [scenarios[s]['wait_ci'][1] - scenarios[s]['mean_wait'] for s in scenario_names]]\n",
    "\n",
    "colors = ['steelblue', 'green', 'green', 'red', 'orange']\n",
    "bars1 = axes[0].bar(x, waits, color=colors, edgecolor='black', alpha=0.7)\n",
    "axes[0].errorbar(x, waits, yerr=wait_errs, fmt='none', color='black', capsize=5)\n",
    "axes[0].axhline(waits[0], color='gray', linestyle='--', alpha=0.5, label='Baseline')\n",
    "axes[0].set_xlabel('Scenario')\n",
    "axes[0].set_ylabel('Mean Wait Time (seconds)')\n",
    "axes[0].set_title('Wait Time by Scenario')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels([s.replace(' ', '\\n') for s in scenario_names], fontsize=9)\n",
    "\n",
    "# Service levels with CI\n",
    "sls = [scenarios[s]['service_level'] for s in scenario_names]\n",
    "sl_errs = [[scenarios[s]['service_level'] - scenarios[s]['sl_ci'][0] for s in scenario_names],\n",
    "           [scenarios[s]['sl_ci'][1] - scenarios[s]['service_level'] for s in scenario_names]]\n",
    "\n",
    "bars2 = axes[1].bar(x, sls, color=colors, edgecolor='black', alpha=0.7)\n",
    "axes[1].errorbar(x, sls, yerr=sl_errs, fmt='none', color='black', capsize=5)\n",
    "axes[1].axhline(80, color='red', linestyle='--', alpha=0.7, label='80% Target')\n",
    "axes[1].set_xlabel('Scenario')\n",
    "axes[1].set_ylabel('Service Level (% < 60s)')\n",
    "axes[1].set_title('Service Level by Scenario')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([s.replace(' ', '\\n') for s in scenario_names], fontsize=9)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.suptitle('What-If Scenario Analysis Results', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Decision Support Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate decision support report\n",
    "print(\"=\"*70)\n",
    "print(\"OPERATIONS DECISION SUPPORT REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. DATA FOUNDATION\")\n",
    "print(f\"   Historical data: {len(call_data):,} calls over 30 days\")\n",
    "print(f\"   Inter-arrival model: {best_interarrival.distribution} (validated by KS test)\")\n",
    "print(f\"   Service time model: {best_service.distribution} (validated by KS test)\")\n",
    "\n",
    "print(f\"\\n2. CURRENT STATE ANALYSIS\")\n",
    "current = scenarios['Current (5 agents)']\n",
    "print(f\"   Agents: 5\")\n",
    "print(f\"   Mean wait: {current['mean_wait']:.1f}s\")\n",
    "print(f\"   Service level (<60s): {current['service_level']:.1f}%\")\n",
    "\n",
    "print(f\"\\n3. SCENARIO RECOMMENDATIONS\")\n",
    "\n",
    "# Hiring recommendation\n",
    "add1 = scenarios['Add 1 agent (6)']\n",
    "add2 = scenarios['Add 2 agents (7)']\n",
    "wait_reduction_1 = (current['mean_wait'] - add1['mean_wait']) / current['mean_wait'] * 100\n",
    "wait_reduction_2 = (current['mean_wait'] - add2['mean_wait']) / current['mean_wait'] * 100\n",
    "\n",
    "print(f\"\\n   OPTION A: Hire 1 Additional Agent\")\n",
    "print(f\"   - Wait time reduction: {wait_reduction_1:.0f}%\")\n",
    "print(f\"   - Service level improvement: +{add1['service_level'] - current['service_level']:.1f}pp\")\n",
    "\n",
    "print(f\"\\n   OPTION B: Hire 2 Additional Agents\")\n",
    "print(f\"   - Wait time reduction: {wait_reduction_2:.0f}%\")\n",
    "print(f\"   - Service level improvement: +{add2['service_level'] - current['service_level']:.1f}pp\")\n",
    "\n",
    "# Training recommendation\n",
    "training = scenarios['10% faster service']\n",
    "print(f\"\\n   OPTION C: Invest in Training (10% handle time reduction)\")\n",
    "print(f\"   - Wait time reduction: {(current['mean_wait'] - training['mean_wait']) / current['mean_wait'] * 100:.0f}%\")\n",
    "print(f\"   - Service level improvement: +{training['service_level'] - current['service_level']:.1f}pp\")\n",
    "print(f\"   - No additional headcount required\")\n",
    "\n",
    "# Risk assessment\n",
    "growth = scenarios['20% more calls']\n",
    "print(f\"\\n4. RISK ASSESSMENT\")\n",
    "print(f\"   If call volume increases 20%:\")\n",
    "print(f\"   - Mean wait would increase to {growth['mean_wait']:.0f}s (+{(growth['mean_wait']/current['mean_wait']-1)*100:.0f}%)\")\n",
    "print(f\"   - Service level would drop to {growth['service_level']:.1f}%\")\n",
    "\n",
    "print(f\"\\n5. RECOMMENDATION\")\n",
    "if current['service_level'] < 80:\n",
    "    print(\"   Current service level is BELOW 80% target.\")\n",
    "    print(\"   RECOMMEND: Hire 1-2 additional agents or invest in training.\")\n",
    "else:\n",
    "    print(\"   Current service level MEETS 80% target.\")\n",
    "    print(\"   RECOMMEND: Monitor call volume growth; plan for contingency staffing.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the full workflow for simulation-based decision making using RayBackend:\n",
    "\n",
    "1. **Data Collection**: Loaded operational data (arrivals, service times)\n",
    "2. **Distribution Fitting**: Used spark-bestfit to identify the best distributions\n",
    "3. **Assumption Validation**: Tested whether common assumptions (exponential) hold\n",
    "4. **Queue Simulation**: Built a realistic G/G/c queue using fitted distributions\n",
    "5. **Scenario Analysis**: Ran what-if simulations with confidence intervals\n",
    "6. **Decision Support**: Generated actionable recommendations\n",
    "\n",
    "### Key spark-bestfit Features Used\n",
    "\n",
    "| Feature | Purpose |\n",
    "|---------|----------|\n",
    "| `RayBackend` | Distributed parallel processing |\n",
    "| `DistributionFitter` | Fit service times, inter-arrival times |\n",
    "| `DiscreteDistributionFitter` | Fit hourly call volumes |\n",
    "| `lazy_metrics=False` | Validate with KS/AD tests |\n",
    "| `get_scipy_dist()` | Sample from fitted distributions |\n",
    "| `metric='aic'` | Select best predictive model |\n",
    "\n",
    "### Business Value\n",
    "\n",
    "- **Avoid costly experiments**: Test scenarios in simulation first\n",
    "- **Quantify uncertainty**: Confidence intervals on predictions\n",
    "- **Validate assumptions**: Don't blindly assume exponential distributions\n",
    "- **Data-driven decisions**: Replace intuition with evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "# ray.shutdown()  # Uncomment to shutdown Ray when done\n",
    "print(\"Discrete event simulation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
