{
  "OpenGVLab/InternVL3-8B": {
    "model_class": "VLLM",
    "max_tokens_limit": 32000,
    "num_params_billions": 8,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      },
      "2": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.7
        }
      }
    }
  },
  "OpenGVLab/InternVL3-38B": {
    "model_class": "VLLM",
    "max_tokens_limit": 32000,
    "num_params_billions": 38,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 4096,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
    "OpenGVLab/InternVL3-14B": {
    "model_class": "VLLM",
    "max_tokens_limit": 32000,
    "num_params_billions": 14,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 4096,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "Qwen/Qwen2.5-VL-7B-Instruct": {
    "model_class": "VLLM",
    "max_tokens_limit": 16000,
    "num_params_billions": 3,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
    "Qwen/Qwen2.5-VL-32B-Instruct": {
    "model_class": "VLLM",
    "max_tokens_limit": 32768,
    "num_params_billions": 32,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 4096,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "Qwen/Qwen2.5-VL-3B-Instruct": {
    "model_class": "VLLM",
    "max_tokens_limit": 16000,
    "num_params_billions": 3,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 1824,
        "max_output_tokens": 512,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": true,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "Qwen/Qwen2.5-VL-1B-Instruct": {
    "model_class": "VLLM",
    "max_tokens_limit": 8000,
    "num_params_billions": 3,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 2048,
        "max_output_tokens": 1024,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "Qwen/Qwen2.5-VL-72B-Instruct":{
    "model_class": "VLLM",
    "max_tokens_limit": 32768,
    "num_params_billions": 72,
    "gpu_split": true,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 4096,
        "limit_mm_per_prompt": 4,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 4,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "model_class": "LLMJudge",
    "max_tokens_limit": 32768,
    "num_params_billions": 7,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.0,
        "max_tokens": 4096,
        "max_output_tokens": 2048,
        "chat_template_path": "src/technical/chat_templates/mistral_template.jinja",
        "limit_mm_per_prompt": 0,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      },
      "2": {
        "temperature": 0.5,
        "max_tokens": 4096,
        "max_output_tokens": 2048,
        "chat_template_path": "src/technical/chat_templates/mistral_template.jinja",
        "limit_mm_per_prompt": 0,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "microsoft/Phi-3.5-mini-instruct": {
    "model_class": "LLMJudge",
    "max_tokens_limit": 32768,
    "num_params_billions": 3.8,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.0,
        "max_tokens": 2048,
        "max_output_tokens": 1024,
        "limit_mm_per_prompt": 0,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9,
          "disable_sliding_window": true
        }
      },
      "2": {
        "temperature": 0.5,
        "max_tokens": 4096,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 0,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9,
          "disable_sliding_window": true
        }
      }
    }
  },
  "llava-hf/llava-onevision-qwen2-72b-ov-hf":{
    "model_class": "VLLM",
    "max_tokens_limit": 32768,
    "num_params_billions": 72,
    "gpu_split": true,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 4096,
        "limit_mm_per_prompt": 4,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 4,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "OpenGVLab/InternVL3-78B":{
    "model_class": "VLLM",
    "max_tokens_limit": 32768,
    "num_params_billions": 78,
    "gpu_split": true,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 4096,
        "limit_mm_per_prompt": 4,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 4,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  },
  "llava-hf/llava-v1.6-mistral-7b-hf":{
    "model_class": "VLLM",
    "max_tokens_limit": 32768,
    "num_params_billions": 7,
    "gpu_split": false,
    "param_sets": {
      "1": {
        "temperature": 0.5,
        "max_tokens": 16384,
        "max_output_tokens": 2048,
        "limit_mm_per_prompt": 2,
        "cpu_local_testing": false,
        "custom_args": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.9
        }
      }
    }
  }
}