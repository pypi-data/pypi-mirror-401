"""Workflow management services.

This module provides services for managing workflows, pipelines, and stages.
Approval flow functionality is handled by the django-approval-workflow package.
"""

import logging
from typing import Any, Dict, List, Optional, Type

from django.contrib.auth import get_user_model
from django.db.models import Model
from django.utils import timezone

from approval_workflow.choices import RoleSelectionStrategy
from approval_workflow.models import ApprovalFlow

from .choices import (
    DEFAULT_ACTIONS,
    ActionType,
    ApprovalTypes,
    WorkflowAttachmentStatus,
)
from .constants import ERROR_MESSAGES, LOG_MESSAGES
from .models import (
    Pipeline,
    Stage,
    WorkFlow,
    WorkflowAction,
    WorkflowAttachment,
    WorkflowConfiguration,
)
from .settings import (
    get_auto_start_workflows,
    get_default_workflow_status_field,
    get_department_model_mapping,
    get_workflow_model_mappings,
)
from .settings import is_model_workflow_enabled as is_model_enabled_in_settings

logger = logging.getLogger(__name__)

User = get_user_model()


def set_pipeline_department(pipeline: Pipeline, department_id: int):
    """Set department for a pipeline using the configured department model.

    Args:
        pipeline: Pipeline instance
        department_id: ID of the department object
    """
    department_model_string = get_department_model_mapping()
    if not department_model_string:
        # No department model configured, skip
        return

    try:
        # Parse model string
        app_label, model_name = department_model_string.split(".")

        # Get the content type
        from django.contrib.contenttypes.models import ContentType

        # ContentType.model is always lowercase
        content_type = ContentType.objects.get(
            app_label=app_label, model=model_name.lower()
        )

        # Set the generic foreign key fields
        pipeline.department_content_type = content_type
        pipeline.department_id = department_id

    except (ValueError, ContentType.DoesNotExist) as e:
        logger.warning(f"Could not set department for pipeline {pipeline.id}: {str(e)}")


def log_workflow_action(
    action: str,
    workflow_id: int = None,
    user_id: int = None,
    object_type: str = None,
    object_id: str = None,
    **kwargs,
):
    """Log workflow actions with structured data for monitoring and debugging."""
    logger.info(
        f"WORKFLOW_ACTION: {action}",
        extra={
            "action": action,
            "workflow_id": workflow_id,
            "user_id": user_id,
            "object_type": object_type,
            "object_id": object_id,
            "timestamp": timezone.now().isoformat(),
            **kwargs,
        },
    )


# Workflow management services


def create_workflow(
    company,
    name_en: str,
    name_ar: str,
    created_by: User,
    pipelines_data: List[Dict[str, Any]],
) -> WorkFlow:
    """Create a new workflow with pipelines and stages.

    Args:
        company: Company instance
        name_en: English name
        name_ar: Arabic name
        created_by: User creating the workflow
        pipelines_data: List of pipeline configurations

    Returns:
        The created WorkFlow instance
    """
    workflow = WorkFlow.objects.create(
        company=company, name_en=name_en, name_ar=name_ar, created_by=created_by
    )

    log_workflow_action(
        action="workflow_created",
        workflow_id=workflow.id,
        user_id=created_by.id,
        company_id=company.id,
        pipeline_count=len(pipelines_data),
    )

    # Auto-generate orders if all pipelines have order = 0 or None
    all_orders_zero_or_none = all(
        pipeline_data.get("order") in (0, None) for pipeline_data in pipelines_data
    )

    if all_orders_zero_or_none and len(pipelines_data) > 0:
        logger.info(
            "Auto-generating pipeline orders for workflow '%s' (ID: %s)",
            name_en,
            workflow.id,
        )
        for index, pipeline_data in enumerate(pipelines_data):
            pipeline_data["order"] = index

    for pipeline_data in pipelines_data:
        create_pipeline(workflow, pipeline_data, created_by)

    logger.info(
        "Workflow created - ID: %s, Name: %s, Pipelines: %d",
        workflow.id,
        name_en,
        len(pipelines_data),
    )

    return workflow


def create_pipeline(
    workflow: WorkFlow, pipeline_data: Dict[str, Any], created_by: User
) -> Pipeline:
    """Create a pipeline within a workflow.

    Args:
        workflow: The WorkFlow to attach the pipeline to
        pipeline_data: Pipeline configuration
        created_by: User creating the pipeline

    Returns:
        The created Pipeline instance
    """
    pipeline = Pipeline.objects.create(
        workflow=workflow,
        company=workflow.company,
        name_en=pipeline_data["name_en"],
        name_ar=pipeline_data["name_ar"],
        created_by=created_by,
        order=pipeline_data.get("order", 0),
    )

    # Set department if provided
    department_id = pipeline_data.get("department_id")
    if department_id:
        set_pipeline_department(pipeline, department_id)
        pipeline.save()

    # Create stages for the pipeline
    number_of_stages = pipeline_data.get("number_of_stages", 1)
    for i in range(number_of_stages):
        Stage.objects.create(
            pipeline=pipeline,
            company=workflow.company,
            name_en=f"Stage {i + 1}",
            name_ar=f"المرحلة {i + 1}",
            created_by=created_by,
            order=i,
        )

    logger.info(
        "Pipeline created - ID: %s, Workflow: %s, Stages: %d",
        pipeline.id,
        workflow.name_en,
        number_of_stages,
    )

    return pipeline


def get_workflow_progress(workflow: WorkFlow, obj: Model) -> Dict[str, Any]:
    """Get the progress of an object through a workflow.

    Args:
        workflow: The WorkFlow to check progress for
        obj: The object progressing through the workflow

    Returns:
        Dictionary containing progress information
    """
    try:
        from django.contrib.contenttypes.models import ContentType

        content_type = ContentType.objects.get_for_model(obj)

        # Optimize query with prefetch_related to avoid N+1 queries in progress_percentage
        attachment = (
            WorkflowAttachment.objects.select_related(
                "workflow", "current_stage", "current_pipeline"
            )
            .prefetch_related("workflow__pipelines__stages")
            .get(content_type=content_type, object_id=str(obj.pk))
        )

        return attachment.get_progress_info()
    except WorkflowAttachment.DoesNotExist:
        return {
            "current_stage": None,
            "current_pipeline": None,
            "status": WorkflowAttachmentStatus.NOT_STARTED,
            "progress_percentage": 0,
            "started_at": None,
            "completed_at": None,
            "next_stage": None,
        }


# Workflow Attachment Services


def attach_workflow_to_object(
    obj: Model,
    workflow: WorkFlow,
    user: User = None,
    auto_start: bool = True,
    metadata: Dict[str, Any] = None,
    disable_clone: bool = False,
) -> WorkflowAttachment:
    """Attach a workflow to any model instance.

    IMPORTANT: This function automatically clones the workflow by default to ensure
    workflow immutability. Any changes to the original workflow will not affect
    running workflows, ensuring data integrity and preventing corruption of active processes.

    Args:
        obj: The model instance to attach workflow to
        workflow: The WorkFlow to attach (will be cloned unless disable_clone=True)
        user: User who is attaching the workflow
        auto_start: Whether to automatically start the workflow
        metadata: Additional metadata to store
        disable_clone: If True, uses original workflow instead of cloning (default: False)
                      WARNING: Setting this to True may cause workflow corruption
                      if the original workflow is modified after attachment.

    Returns:
        WorkflowAttachment instance with cloned workflow (or original if disable_clone=True)
    """
    from django.contrib.contenttypes.models import ContentType
    from django.utils import timezone

    if not workflow.is_active:
        raise ValueError(
            ERROR_MESSAGES["workflow_inactive"].format(workflow_name=workflow.name_en)
        )

    # Clone the workflow to ensure immutability (unless disabled)
    if disable_clone:
        logger.warning(
            f"Using original workflow '{workflow.name_en}' (ID: {workflow.id}) for object {obj} - cloning disabled"
        )
        workflow_to_use = workflow
    else:
        logger.info(
            f"Cloning workflow '{workflow.name_en}' (ID: {workflow.id}) for object {obj}"
        )
        # Prefetch related data for efficient cloning
        workflow_with_relations = WorkFlow.objects.prefetch_related(
            "pipelines__stages"
        ).get(id=workflow.id)
        workflow_to_use = workflow_with_relations.clone()
        logger.info(
            f"Workflow cloned successfully. Original ID: {workflow.id}, Cloned ID: {workflow_to_use.id}"
        )

    content_type = ContentType.objects.get_for_model(obj)

    # Create or get existing attachment using the workflow (cloned or original)
    attachment, created = WorkflowAttachment.objects.get_or_create(
        content_type=content_type,
        object_id=str(obj.pk),
        defaults={
            "workflow": workflow_to_use,
            "metadata": metadata or {},
            "started_by": user,
        },
    )

    if not created:
        # Update existing attachment with workflow (cloned or original)
        attachment.workflow = workflow_to_use
        attachment.metadata.update(metadata or {})
        attachment.save()

    log_workflow_action(
        action="workflow_attached" if created else "workflow_updated",
        workflow_id=workflow_to_use.id,
        user_id=user.id if user else None,
        object_type=content_type.model,
        object_id=str(obj.pk),
        auto_start=auto_start,
        original_workflow_id=(
            workflow.id if not disable_clone else None
        ),  # Track original workflow for audit
    )

    if disable_clone:
        logger.info(
            f"Original workflow '{workflow.name_en}' {'attached' if created else 'updated'} to {obj._meta.label}({obj.pk})"
        )
    else:
        logger.info(
            f"Cloned workflow '{workflow_to_use.name_en}' (from '{workflow.name_en}') {'attached' if created else 'updated'} to {obj._meta.label}({obj.pk})"
        )

    # Auto-start if requested
    if auto_start and attachment.status == WorkflowAttachmentStatus.NOT_STARTED:
        attachment = start_workflow_for_object(obj, user)

    return attachment


def start_workflow_for_object(obj: Model, user: User = None) -> WorkflowAttachment:
    """Start workflow execution for an object (strategy-aware).

    Strategy 1: Full hierarchy - starts at first stage of first pipeline
    Strategy 2: Pipeline only - starts at first pipeline (no stages)
    Strategy 3: Workflow only - starts immediately (no pipelines/stages)

    Args:
        obj: The model instance to start workflow for
        user: User who is starting the workflow

    Returns:
        Updated WorkflowAttachment instance
    """
    from django.contrib.contenttypes.models import ContentType
    from django.utils import timezone

    from .choices import WorkflowStrategy

    content_type = ContentType.objects.get_for_model(obj)

    try:
        attachment = (
            WorkflowAttachment.objects.select_related("workflow")
            .prefetch_related("workflow__pipelines__stages")
            .get(content_type=content_type, object_id=str(obj.pk))
        )
    except WorkflowAttachment.DoesNotExist:
        raise ValueError(f"No workflow attached to {obj._meta.label}({obj.pk})")

    if attachment.status != WorkflowAttachmentStatus.NOT_STARTED:
        raise ValueError(
            ERROR_MESSAGES["workflow_already_started"].format(status=attachment.status)
        )

    strategy = attachment.workflow.strategy
    first_pipeline = None
    first_stage = None

    # Handle each strategy differently
    if strategy == WorkflowStrategy.WORKFLOW_PIPELINE_STAGE:
        # Strategy 1: Full hierarchy - need pipeline and stage
        first_pipeline = attachment.workflow.pipelines.order_by("order").first()
        if not first_pipeline:
            raise ValueError(
                ERROR_MESSAGES["no_pipelines"].format(
                    workflow_name=attachment.workflow.name_en
                )
            )

        first_stage = first_pipeline.stages.order_by("order").first()
        if not first_stage:
            raise ValueError(
                ERROR_MESSAGES["no_stages"].format(pipeline_name=first_pipeline.name_en)
            )

    elif strategy == WorkflowStrategy.WORKFLOW_PIPELINE:
        # Strategy 2: Pipeline only - need pipeline but NO stage
        first_pipeline = attachment.workflow.pipelines.order_by("order").first()
        if not first_pipeline:
            raise ValueError(
                ERROR_MESSAGES["no_pipelines"].format(
                    workflow_name=attachment.workflow.name_en
                )
            )
        # first_stage remains None - this is expected for Strategy 2

    elif strategy == WorkflowStrategy.WORKFLOW_ONLY:
        # Strategy 3: Workflow only - NO pipeline or stage needed
        # first_pipeline and first_stage remain None - this is expected for Strategy 3
        pass

    # Update attachment
    attachment.status = WorkflowAttachmentStatus.IN_PROGRESS
    attachment.current_stage = first_stage  # Will be None for strategies 2 and 3
    attachment.current_pipeline = first_pipeline  # Will be None for strategy 3
    attachment.started_at = timezone.now()
    attachment.started_by = user
    attachment.save()

    # Start approval flow based on strategy
    from approval_workflow.services import start_flow

    from .constants import LOG_MESSAGES
    from .utils import build_approval_steps, get_user_for_approval

    # Get user for approval steps using centralized utility
    approval_user = get_user_for_approval(obj, user, attachment)

    # Build approval steps based on strategy
    steps = []
    if strategy == WorkflowStrategy.WORKFLOW_PIPELINE_STAGE:
        # Strategy 1: Build steps from stage
        steps = build_approval_steps(first_stage, approval_user)
        location = f"stage '{first_stage.name_en}'"
    elif strategy == WorkflowStrategy.WORKFLOW_PIPELINE:
        # Strategy 2: Build steps from pipeline (extract directly from pipeline_info)
        from .utils import build_approval_steps_from_config

        pipeline_info = first_pipeline.pipeline_info or {}
        approvals = pipeline_info.get("approvals", [])

        steps = build_approval_steps_from_config(
            approvals=approvals,
            approval_user=approval_user,
            extra_fields={"pipeline_id": first_pipeline.id},
            start_step=1,
        )

        location = f"pipeline '{first_pipeline.name_en}'"
    elif strategy == WorkflowStrategy.WORKFLOW_ONLY:
        # Strategy 3: Build steps from workflow (extract from workflow_info)
        from .utils import build_approval_steps_from_config

        workflow_info = attachment.workflow.workflow_info or {}
        approvals = workflow_info.get("approvals", [])

        steps = build_approval_steps_from_config(
            approvals=approvals,
            approval_user=approval_user,
            extra_fields={"workflow_id": attachment.workflow.id},
            start_step=1,
        )

        location = f"workflow '{attachment.workflow.name_en}'"

    if steps:
        logger.info(
            LOG_MESSAGES["approval_flow_started"].format(
                stage_name=location, step_count=len(steps)
            )
        )
        start_flow(obj, steps)
    else:
        logger.warning(LOG_MESSAGES["no_approval_steps"].format(stage_name=location))

    # Trigger workflow start actions AFTER approval setup
    # This ensures current_approver context is available
    trigger_workflow_event(
        attachment,
        ActionType.ON_WORKFLOW_START,
        initial_stage=first_stage,  # Will be None for strategies 2 and 3
        initial_pipeline=first_pipeline,  # Will be None for strategy 3
        user=user,
    )

    logger.info(f"Workflow started for {obj._meta.label}({obj.pk}) at {location}")

    return attachment


def move_to_next_stage(obj: Model, user: User = None) -> WorkflowAttachment:
    """Move object to the next stage/pipeline in workflow (strategy-aware).

    Note: This method should only be called internally by approval handlers
    (on_final_approve), not directly by API endpoints.

    Strategy 1: Moves from stage to stage
    Strategy 2: Moves from pipeline to pipeline
    Strategy 3: No movement (completes immediately)

    Args:
        obj: The model instance to move
        user: User performing the move

    Returns:
        Updated WorkflowAttachment instance
    """
    from django.contrib.contenttypes.models import ContentType

    from .choices import WorkflowStrategy

    content_type = ContentType.objects.get_for_model(obj)

    try:
        attachment = WorkflowAttachment.objects.get(
            content_type=content_type, object_id=str(obj.pk)
        )
    except WorkflowAttachment.DoesNotExist:
        raise ValueError(
            ERROR_MESSAGES["no_workflow_attached"].format(
                obj_label=obj._meta.label, obj_pk=obj.pk
            )
        )

    if attachment.status != WorkflowAttachmentStatus.IN_PROGRESS:
        raise ValueError(
            ERROR_MESSAGES["workflow_not_in_progress"].format(status=attachment.status)
        )

    strategy = attachment.workflow.strategy
    next_item = (
        attachment.next_stage
    )  # May be a Stage (strategy 1) or Pipeline (strategy 2) or None (strategy 3)

    if not next_item:
        # Workflow complete (happens for all strategies when no more items)
        logger.info(
            ERROR_MESSAGES["no_next_stage"].format(
                obj_label=obj._meta.label, obj_pk=obj.pk
            )
        )
        return complete_workflow(obj, user)

    # Strategy-specific handling
    if strategy == WorkflowStrategy.WORKFLOW_PIPELINE_STAGE:
        # Strategy 1: Full hierarchy - next_item is a Stage
        next_stage = next_item
        current_stage = attachment.current_stage
        next_pipeline = next_stage.pipeline
        current_pipeline = attachment.current_pipeline

        pipeline_changed = (
            current_pipeline
            and next_pipeline
            and current_pipeline.id != next_pipeline.id
        )

        # Update attachment
        old_stage = attachment.current_stage
        old_pipeline = attachment.current_pipeline

        attachment.current_stage = next_stage
        attachment.current_pipeline = next_pipeline
        attachment.save()

        logger.debug(
            f"Strategy 1: Moving {obj._meta.label}({obj.pk}) from stage '{old_stage.name_en if old_stage else 'None'}' "
            f"to '{next_stage.name_en}' (pipeline: {next_pipeline.name_en if next_pipeline else 'None'})"
        )

        # Trigger workflow actions
        if pipeline_changed:
            logger.info(
                f"Pipeline changed from '{old_pipeline.name_en}' to '{next_pipeline.name_en}'"
            )
            trigger_workflow_event(
                attachment,
                ActionType.AFTER_MOVE_PIPELINE,
                from_pipeline=old_pipeline,
                to_pipeline=next_pipeline,
                user=user,
            )

        trigger_workflow_event(
            attachment,
            ActionType.AFTER_MOVE_STAGE,
            from_stage=old_stage,
            to_stage=next_stage,
            user=user,
        )

        # Extend approval flow for next stage
        from approval_workflow.models import ApprovalFlow
        from approval_workflow.services import extend_flow

        from .constants import LOG_MESSAGES
        from .utils import build_approval_steps, get_user_for_approval

        approval_user = get_user_for_approval(obj, user, attachment)
        steps = build_approval_steps(next_stage, approval_user)

        if steps:
            content_type = ContentType.objects.get_for_model(obj)
            try:
                flow = ApprovalFlow.objects.get(
                    content_type=content_type, object_id=str(obj.pk)
                )

                existing_instances = flow.instances.all()
                max_step = (
                    max([inst.step_number for inst in existing_instances])
                    if existing_instances
                    else 0
                )

                for step_data in steps:
                    step_data["step"] = max_step + step_data["step"]

                extend_flow(flow, steps)

                logger.info(
                    LOG_MESSAGES["approval_flow_started"].format(
                        stage_name=next_stage.name_en, step_count=len(steps)
                    )
                    + f" (steps {max_step + 1} onwards)"
                )
            except ApprovalFlow.DoesNotExist:
                logger.error(
                    f"No existing approval flow found for {obj._meta.label}({obj.pk}). "
                    "Cannot extend flow for next stage."
                )
        else:
            logger.warning(
                LOG_MESSAGES["no_approval_steps"].format(stage_name=next_stage.name_en)
            )

        logger.info(
            LOG_MESSAGES["stage_moved"].format(
                obj_label=obj._meta.label,
                obj_pk=obj.pk,
                from_stage=old_stage.name_en if old_stage else "None",
                to_stage=next_stage.name_en,
            )
        )

    elif strategy == WorkflowStrategy.WORKFLOW_PIPELINE:
        # Strategy 2: Pipeline only - next_item is a Pipeline
        next_pipeline = next_item
        current_pipeline = attachment.current_pipeline

        # Update attachment
        old_pipeline = attachment.current_pipeline

        attachment.current_pipeline = next_pipeline
        attachment.current_stage = None  # No stages in Strategy 2
        attachment.save()

        logger.debug(
            f"Strategy 2: Moving {obj._meta.label}({obj.pk}) from pipeline '{old_pipeline.name_en if old_pipeline else 'None'}' "
            f"to '{next_pipeline.name_en}'"
        )

        # Trigger pipeline move actions
        trigger_workflow_event(
            attachment,
            ActionType.AFTER_MOVE_PIPELINE,
            from_pipeline=old_pipeline,
            to_pipeline=next_pipeline,
            user=user,
        )

        # Extend approval flow for next pipeline (extract from pipeline_info)
        from approval_workflow.models import ApprovalFlow
        from approval_workflow.services import extend_flow

        from .constants import LOG_MESSAGES
        from .utils import build_approval_steps_from_config, get_user_for_approval

        approval_user = get_user_for_approval(obj, user, attachment)

        # Build steps from pipeline_info using helper
        pipeline_info = next_pipeline.pipeline_info or {}
        approvals = pipeline_info.get("approvals", [])

        steps = build_approval_steps_from_config(
            approvals=approvals,
            approval_user=approval_user,
            extra_fields={"pipeline_id": next_pipeline.id},
            start_step=1,  # Will be adjusted below with max_step
        )

        if steps:
            content_type = ContentType.objects.get_for_model(obj)
            try:
                flow = ApprovalFlow.objects.get(
                    content_type=content_type, object_id=str(obj.pk)
                )

                existing_instances = flow.instances.all()
                max_step = (
                    max([inst.step_number for inst in existing_instances])
                    if existing_instances
                    else 0
                )

                for step_data in steps:
                    step_data["step"] = max_step + step_data["step"]

                extend_flow(flow, steps)

                logger.info(
                    f"Strategy 2: Extended approval flow for pipeline '{next_pipeline.name_en}' with {len(steps)} steps "
                    f"(steps {max_step + 1} onwards)"
                )
            except ApprovalFlow.DoesNotExist:
                logger.error(
                    f"No existing approval flow found for {obj._meta.label}({obj.pk}). "
                    "Cannot extend flow for next pipeline."
                )
        else:
            logger.warning(
                f"Strategy 2: No approval steps found for pipeline '{next_pipeline.name_en}'"
            )

        logger.info(
            f"Strategy 2: Pipeline moved from '{old_pipeline.name_en if old_pipeline else 'None'}' "
            f"to '{next_pipeline.name_en}' for {obj._meta.label}({obj.pk})"
        )

    elif strategy == WorkflowStrategy.WORKFLOW_ONLY:
        # Strategy 3: No stages or pipelines - this shouldn't be called as next_stage returns None
        # But handle gracefully just in case
        logger.warning(
            f"Strategy 3: move_to_next_stage called for workflow-only strategy. Completing workflow."
        )
        return complete_workflow(obj, user)

    return attachment


def reject_workflow_stage(
    obj: Model, stage, user: User = None, reason: str = None
) -> WorkflowAttachment:
    """Reject workflow at current stage.

    Args:
        obj: The model instance
        stage: The stage being rejected
        user: User performing the rejection
        reason: Rejection reason

    Returns:
        Updated WorkflowAttachment instance
    """
    from django.contrib.contenttypes.models import ContentType
    from django.utils import timezone

    content_type = ContentType.objects.get_for_model(obj)

    try:
        attachment = WorkflowAttachment.objects.get(
            content_type=content_type, object_id=str(obj.pk)
        )
    except WorkflowAttachment.DoesNotExist:
        raise ValueError(f"No workflow attached to {obj._meta.label}({obj.pk})")

    # Update attachment status
    attachment.status = WorkflowAttachmentStatus.REJECTED
    attachment.completed_at = timezone.now()
    if reason:
        attachment.metadata["rejection_reason"] = reason
        attachment.metadata["rejected_by"] = user.username if user else "system"
    attachment.save()

    # Update the content object's status field if configured
    try:
        config = WorkflowConfiguration.objects.get(content_type=content_type)
        if config.rejection_status_value:
            update_object_status(obj, config.rejection_status_value, "rejection")
    except WorkflowConfiguration.DoesNotExist:
        pass

    # Trigger reject actions
    trigger_workflow_event(
        attachment, ActionType.AFTER_REJECT, stage=stage, reason=reason, user=user
    )

    logger.info(
        f"Workflow rejected for {obj._meta.label}({obj.pk}) at stage '{stage.name_en}'"
    )

    return attachment


def update_object_status(
    obj: Model, status_value: str, event_type: str = "completion"
) -> bool:
    """Update the status field on the content object based on workflow configuration.

    Args:
        obj: The model instance to update
        status_value: The status value to set
        event_type: Type of event (completion or rejection) for logging

    Returns:
        True if status was updated, False otherwise
    """
    from django.contrib.contenttypes.models import ContentType

    content_type = ContentType.objects.get_for_model(obj)

    try:
        config = WorkflowConfiguration.objects.get(content_type=content_type)

        # Check if status_field is configured
        if not config.status_field:
            logger.debug(
                f"No status_field configured for {obj._meta.label}, skipping status update"
            )
            return False

        # Check if the object has the status field
        if not hasattr(obj, config.status_field):
            logger.warning(
                f"Model {obj._meta.label} does not have field '{config.status_field}', "
                f"cannot update status on {event_type}"
            )
            return False

        # Update the status field
        old_status = getattr(obj, config.status_field, None)
        setattr(obj, config.status_field, status_value)
        obj.save(update_fields=[config.status_field])

        logger.info(
            f"Updated {obj._meta.label}({obj.pk}).{config.status_field} "
            f"from '{old_status}' to '{status_value}' on workflow {event_type}"
        )
        return True

    except WorkflowConfiguration.DoesNotExist:
        logger.debug(
            f"No WorkflowConfiguration found for {obj._meta.label}, skipping status update"
        )
        return False


def complete_workflow(obj: Model, user: User = None) -> WorkflowAttachment:
    """Complete workflow for an object.

    Args:
        obj: The model instance
        user: User completing the workflow

    Returns:
        Updated WorkflowAttachment instance
    """
    from django.contrib.contenttypes.models import ContentType
    from django.utils import timezone

    content_type = ContentType.objects.get_for_model(obj)

    try:
        attachment = WorkflowAttachment.objects.get(
            content_type=content_type, object_id=str(obj.pk)
        )
    except WorkflowAttachment.DoesNotExist:
        raise ValueError(f"No workflow attached to {obj._meta.label}({obj.pk})")

    # Update attachment
    attachment.status = WorkflowAttachmentStatus.COMPLETED
    attachment.completed_at = timezone.now()
    attachment.current_stage = None
    attachment.current_pipeline = None
    attachment.save()

    # Update the content object's status field if configured
    try:
        config = WorkflowConfiguration.objects.get(content_type=content_type)
        if config.completion_status_value:
            update_object_status(obj, config.completion_status_value, "completion")
    except WorkflowConfiguration.DoesNotExist:
        pass

    # Trigger workflow complete actions
    trigger_workflow_event(attachment, ActionType.ON_WORKFLOW_COMPLETE, user=user)

    logger.info(f"Workflow completed for {obj._meta.label}({obj.pk})")

    return attachment


def register_model_for_workflow(
    model_class: Type[Model],
    auto_start: bool = False,
    default_workflow: WorkFlow = None,
    status_field: str = None,
    stage_field: str = None,
    pre_start_hook: str = None,
    post_complete_hook: str = None,
) -> WorkflowConfiguration:
    """Register a model to support workflow functionality.

    Args:
        model_class: The Django model class to register
        auto_start: Whether to auto-start workflows for new instances
        default_workflow: Default workflow to use
        status_field: Field name to update with workflow status
        stage_field: Field name to update with current stage
        pre_start_hook: Hook called before workflow starts
        post_complete_hook: Hook called after workflow completes

    Returns:
        WorkflowConfiguration instance
    """
    from django.contrib.contenttypes.models import ContentType

    content_type = ContentType.objects.get_for_model(model_class)

    config, created = WorkflowConfiguration.objects.get_or_create(
        content_type=content_type,
        defaults={
            "auto_start_workflow": auto_start,
            "default_workflow": default_workflow,
            "status_field": status_field or "",
            "stage_field": stage_field or "",
            "pre_start_hook": pre_start_hook or "",
            "post_complete_hook": post_complete_hook or "",
        },
    )

    if not created:
        # Update existing config
        config.auto_start_workflow = auto_start
        config.default_workflow = default_workflow
        config.status_field = status_field or config.status_field
        config.stage_field = stage_field or config.stage_field
        config.pre_start_hook = pre_start_hook or config.pre_start_hook
        config.post_complete_hook = post_complete_hook or config.post_complete_hook
        config.save()

    logger.info(
        f"Model {model_class._meta.label} {'registered' if created else 'updated'} for workflow functionality"
    )

    return config


def get_workflow_attachment(
    obj: Model, optimize_for_progress: bool = False
) -> Optional[WorkflowAttachment]:
    """Get workflow attachment for an object.

    Args:
        obj: The model instance
        optimize_for_progress: If True, prefetches related data for progress calculation.
                             Use this when you plan to access progress_percentage property.

    Returns:
        WorkflowAttachment instance or None
    """
    from django.contrib.contenttypes.models import ContentType

    content_type = ContentType.objects.get_for_model(obj)

    try:
        if optimize_for_progress:
            # Prefetch workflow, pipelines, and stages to avoid N+1 queries
            # Use this when you plan to access progress_percentage property
            return (
                WorkflowAttachment.objects.select_related(
                    "workflow", "current_stage", "current_pipeline"
                )
                .prefetch_related("workflow__pipelines__stages")
                .get(content_type=content_type, object_id=str(obj.pk))
            )
        else:
            return WorkflowAttachment.objects.select_related(
                "workflow", "current_stage", "current_pipeline"
            ).get(content_type=content_type, object_id=str(obj.pk))
    except WorkflowAttachment.DoesNotExist:
        return None


def is_model_workflow_enabled(model_class: Type[Model]) -> bool:
    """Check if a model is enabled for workflow functionality.

    Args:
        model_class: The Django model class

    Returns:
        True if enabled, False otherwise
    """
    from django.contrib.contenttypes.models import ContentType

    try:
        content_type = ContentType.objects.get_for_model(model_class)
        config = WorkflowConfiguration.objects.get(content_type=content_type)
        return config.is_enabled
    except WorkflowConfiguration.DoesNotExist:
        return False


# Action execution services


def get_actions_for_event(
    attachment: WorkflowAttachment, action_type: str
) -> List[WorkflowAction]:
    """Get all actions for a specific event type using inheritance system.

    Priority order: Stage -> Pipeline -> Workflow -> Default

    Args:
        attachment: The WorkflowAttachment instance
        action_type: The ActionType to get actions for

    Returns:
        List of WorkflowAction instances ordered by priority and execution order
    """
    actions = []

    # Stage-level actions (highest priority)
    if attachment.current_stage:
        stage_actions = WorkflowAction.objects.filter(
            stage=attachment.current_stage, action_type=action_type, is_active=True
        ).order_by("order")
        actions.extend(stage_actions)

    # Pipeline-level actions (if no stage actions found)
    if not actions and attachment.current_pipeline:
        pipeline_actions = WorkflowAction.objects.filter(
            pipeline=attachment.current_pipeline,
            action_type=action_type,
            is_active=True,
        ).order_by("order")
        actions.extend(pipeline_actions)

    # Workflow-level actions (if no pipeline actions found)
    if not actions and attachment.workflow:
        workflow_actions = WorkflowAction.objects.filter(
            workflow=attachment.workflow, action_type=action_type, is_active=True
        ).order_by("order")
        actions.extend(workflow_actions)

    # No default actions - if no actions configured, return empty list
    logger.debug(f"Found {len(actions)} actions for {action_type}")
    return actions


def execute_action_function(
    function_path: str, context: Dict[str, Any], parameters: Dict[str, Any] = None
) -> Any:
    """Execute an action function by its path.

    This function first attempts to use the secure action registry. If the action
    is not registered, it falls back to legacy dynamic import for backward
    compatibility.

    Args:
        function_path: Python path to the function (e.g., 'myapp.actions.send_email')
                       or registered action name
        context: Context data to pass to the function
        parameters: Additional parameters from WorkflowAction.parameters

    Returns:
        Function result or None if execution failed
    """
    from .action_registry import (
        ActionExecutionError,
        ActionNotRegisteredError,
        registry,
    )

    # Try secure registry first
    try:
        # Strategy 1: Direct action name
        if registry.is_registered(function_path):
            logger.info(f"Executing action '{function_path}' via secure registry")
            return registry.execute_action(
                action_name=function_path,
                workflow_attachment=context.get("attachment"),
                action_parameters=parameters or {},
                **{k: v for k, v in context.items() if k != "attachment"},
            )

        # Strategy 2: Extract action name from function path
        action_name = function_path.split(".")[-1]
        if registry.is_registered(action_name):
            logger.info(
                f"Executing action '{action_name}' via secure registry "
                f"(resolved from {function_path})"
            )
            return registry.execute_action(
                action_name=action_name,
                workflow_attachment=context.get("attachment"),
                action_parameters=parameters or {},
                **{k: v for k, v in context.items() if k != "attachment"},
            )

        # Strategy 3: Fall back to legacy import (with warning)
        logger.warning(
            f"Action '{function_path}' not in secure registry. "
            f"Using legacy dynamic import (not recommended)."
        )
        return _execute_action_function_legacy(function_path, context, parameters)

    except (ActionNotRegisteredError, ActionExecutionError) as e:
        # Registry-specific errors - try legacy as fallback
        logger.warning(f"Registry execution failed for '{function_path}': {e}")
        return _execute_action_function_legacy(function_path, context, parameters)


def _execute_action_function_legacy(
    function_path: str, context: Dict[str, Any], parameters: Dict[str, Any] = None
) -> Any:
    """Legacy action execution using dynamic import.

    This function is maintained for backward compatibility but should not be used
    for new implementations. Use the secure action registry instead.

    Args:
        function_path: Python path to the function (e.g., 'myapp.actions.send_email')
        context: Context data to pass to the function
        parameters: Additional parameters from WorkflowAction.parameters

    Returns:
        Function result or None if execution failed
    """
    import importlib

    try:
        # Parse the function path
        module_path, function_name = function_path.rsplit(".", 1)

        # Import the module
        module = importlib.import_module(module_path)

        # Get the function
        function = getattr(module, function_name)

        # Prepare arguments
        kwargs = context.copy()
        if parameters:
            kwargs.update(parameters)

        # Execute the function
        result = function(**kwargs)

        logger.info(f"Successfully executed action function: {function_path} (legacy)")
        return result

    except ImportError as e:
        logger.error(
            f"Failed to import module for action function {function_path}: {str(e)}"
        )
        return None
    except AttributeError as e:
        logger.error(
            f"Function {function_name} not found in module {module_path}: {str(e)}"
        )
        return None
    except Exception as e:
        logger.error(f"Error executing action function {function_path}: {str(e)}")
        return None


def execute_workflow_actions(
    attachment: WorkflowAttachment, action_type: str, context: Dict[str, Any]
) -> List[Any]:
    """Execute all actions for a workflow event.

    Args:
        attachment: The WorkflowAttachment instance
        action_type: The ActionType to execute actions for
        context: Context data to pass to action functions

    Returns:
        List of action results
    """
    actions = get_actions_for_event(attachment, action_type)
    results = []

    for action in actions:
        try:
            result = execute_action_function(
                function_path=action.function_path,
                context=context,
                parameters=action.parameters,
            )
            results.append(result)

        except Exception as e:
            logger.error(
                f"Failed to execute action {action.function_path} for {action_type}: {str(e)}"
            )
            results.append(None)

    return results


def trigger_workflow_event(
    attachment: WorkflowAttachment, action_type: str, **context_kwargs
) -> List[Any]:
    """Trigger a workflow event and execute associated actions.

    Args:
        attachment: The WorkflowAttachment instance
        action_type: The ActionType to trigger
        **context_kwargs: Additional context data

    Returns:
        List of action results
    """
    # Build context
    context = {
        "attachment": attachment,
        "obj": attachment.target,
        "workflow": attachment.workflow,
        "current_stage": attachment.current_stage,
        "current_pipeline": attachment.current_pipeline,
        "action_type": action_type,
        **context_kwargs,
    }

    logger.info(
        f"Triggering workflow event {action_type} for {attachment.target._meta.label}({attachment.target.pk})"
    )

    # Execute legacy workflow actions
    results = execute_workflow_actions(attachment, action_type, context)

    # Execute new email notification actions with inheritance support
    try:
        from .action_executor import execute_workflow_actions as execute_email_actions

        email_results = execute_email_actions(
            action_type=action_type, workflow_attachment=attachment, **context_kwargs
        )

        logger.debug(
            f"Email notification actions executed - "
            f"Succeeded: {email_results.get('succeeded', 0)}, "
            f"Failed: {email_results.get('failed', 0)}"
        )
    except Exception as e:
        logger.error(
            f"Failed to execute email notification actions: {e}", exc_info=True
        )

    return results


# New functions for workflow-to-model mapping and settings integration


def get_workflows_for_model(model_class: Type[Model]) -> List[WorkFlow]:
    """
    Get all available workflows for a specific model class.

    Args:
        model_class: Django model class

    Returns:
        List of WorkFlow instances available for this model

    Example:
        workflows = get_workflows_for_model(PurchaseRequest)
        for workflow in workflows:
            print(f"Available workflow: {workflow.name_en}")
    """
    # Check if model is enabled for workflows
    if not is_model_enabled_in_settings(model_class):
        logger.warning(
            f"Model {model_class._meta.label} is not enabled for workflows. "
            "Add it to DJANGO_WORKFLOW_ENGINE['ENABLED_MODELS'] in settings."
        )
        return []

    model_string = f"{model_class._meta.app_label}.{model_class.__name__}"
    mappings = get_workflow_model_mappings()

    # If specific mappings exist, filter by them
    if model_string in mappings:
        workflow_names = mappings[model_string]
        workflows = WorkFlow.objects.filter(
            name_en__in=workflow_names, is_active=True
        ).order_by("name_en")

        log_workflow_action(
            action="get_workflows_for_model",
            object_type=model_string,
            workflow_count=len(workflows),
            workflow_names=workflow_names,
        )

        return list(workflows)

    # If no specific mappings, return all active workflows
    # (This maintains backward compatibility)
    workflows = WorkFlow.objects.filter(is_active=True).order_by("name_en")

    log_workflow_action(
        action="get_workflows_for_model",
        object_type=model_string,
        workflow_count=len(workflows),
        note="No specific mappings configured, returning all active workflows",
    )

    return list(workflows)


def get_workflows_for_object(obj: Model) -> List[WorkFlow]:
    """
    Get all available workflows for a specific object instance.

    Args:
        obj: Django model instance

    Returns:
        List of WorkFlow instances available for this object

    Example:
        purchase_request = PurchaseRequest.objects.get(id=1)
        workflows = get_workflows_for_object(purchase_request)
        for workflow in workflows:
            print(f"Available workflow: {workflow.name_en}")
    """
    return get_workflows_for_model(obj.__class__)


def get_auto_start_workflow_for_object(obj: Model) -> Optional[WorkFlow]:
    """
    Get the auto-start workflow for an object if configured.

    Args:
        obj: Django model instance

    Returns:
        WorkFlow instance if auto-start is configured, None otherwise

    Example:
        purchase_request = PurchaseRequest.objects.create(...)
        auto_workflow = get_auto_start_workflow_for_object(purchase_request)
        if auto_workflow:
            attach_workflow_to_object(purchase_request, auto_workflow, user, auto_start=True)
    """
    if not is_model_enabled_in_settings(obj.__class__):
        return None

    model_string = f"{obj._meta.app_label}.{obj.__class__.__name__}"
    auto_start_config = get_auto_start_workflows()

    if model_string not in auto_start_config:
        return None

    config = auto_start_config[model_string]
    workflow_name = config.get("workflow_name")
    conditions = config.get("conditions", {})

    if not workflow_name:
        logger.warning(
            f"Auto-start configuration for {model_string} missing 'workflow_name'"
        )
        return None

    # Check conditions if specified
    if conditions:
        for field_lookup, expected_value in conditions.items():
            # Handle Django field lookups (e.g., 'amount__gte': 1000)
            field_parts = field_lookup.split("__")
            field_name = field_parts[0]
            lookup_type = field_parts[1] if len(field_parts) > 1 else "exact"

            if not hasattr(obj, field_name):
                logger.warning(
                    f"Field '{field_name}' not found on {model_string} for auto-start condition"
                )
                continue

            field_value = getattr(obj, field_name)

            # Apply lookup type
            condition_met = False
            if lookup_type == "exact":
                condition_met = field_value == expected_value
            elif lookup_type == "gte":
                condition_met = field_value >= expected_value
            elif lookup_type == "lte":
                condition_met = field_value <= expected_value
            elif lookup_type == "gt":
                condition_met = field_value > expected_value
            elif lookup_type == "lt":
                condition_met = field_value < expected_value
            elif lookup_type == "in":
                condition_met = field_value in expected_value
            elif lookup_type == "isnull":
                condition_met = (field_value is None) == expected_value
            else:
                logger.warning(
                    f"Unsupported lookup type '{lookup_type}' in auto-start condition"
                )
                continue

            if not condition_met:
                log_workflow_action(
                    action="auto_start_condition_not_met",
                    object_type=model_string,
                    object_id=str(obj.pk),
                    condition=field_lookup,
                    expected=expected_value,
                    actual=field_value,
                )
                return None

    # Get the workflow
    try:
        workflow = WorkFlow.objects.get(name_en=workflow_name, is_active=True)

        log_workflow_action(
            action="auto_start_workflow_found",
            object_type=model_string,
            object_id=str(obj.pk),
            workflow_id=workflow.id,
            workflow_name=workflow_name,
        )

        return workflow

    except WorkFlow.DoesNotExist:
        logger.error(
            f"Auto-start workflow '{workflow_name}' not found for {model_string}"
        )
        return None


def is_model_enabled_for_workflows(model_class: Type[Model]) -> bool:
    """
    Check if a model is enabled for workflow functionality.
    Alias for is_model_workflow_enabled for better naming consistency.

    Args:
        model_class: Django model class

    Returns:
        bool: True if model is enabled for workflows
    """
    return is_model_enabled_in_settings(model_class)


def get_available_workflows_for_selection(
    model_class: Type[Model],
) -> List[Dict[str, Any]]:
    """
    Get workflows formatted for UI selection (forms, API responses, etc).

    Args:
        model_class: Django model class

    Returns:
        List of workflow dictionaries with id, name, and description

    Example:
        workflows = get_available_workflows_for_selection(PurchaseRequest)
        # Returns: [
        #     {'id': 1, 'name': 'Purchase Approval', 'description': '...', 'slug': 'purchase_approval'},
        #     {'id': 2, 'name': 'Emergency Approval', 'description': '...', 'slug': 'emergency_approval'}
        # ]
    """
    workflows = get_workflows_for_model(model_class)

    return [
        {
            "id": workflow.id,
            "name": workflow.name_en,
            "name_ar": workflow.name_ar,
            "description": getattr(workflow, "description", ""),
            "slug": workflow.name_en.lower().replace(" ", "_"),
            "pipeline_count": workflow.pipelines.count(),
            "is_active": workflow.is_active,
        }
        for workflow in workflows
    ]


def get_detailed_workflow_data(
    workflow_id: int = None, company_id: int = None, include_inactive: bool = False
) -> Dict[str, Any]:
    """
    Get detailed workflow data with optimized database queries.

    This function retrieves complete workflow information including all nested
    pipelines and stages with approval configurations in a single optimized query.

    Args:
        workflow_id: Specific workflow ID to retrieve (optional)
        company_id: Filter by company ID (optional)
        include_inactive: Include inactive workflows (default: False)

    Returns:
        Dictionary containing:
        - If workflow_id provided: Single workflow with complete nested data
        - If workflow_id not provided: List of workflows with summary data

    Example:
        # Get specific workflow with full details
        workflow_data = get_detailed_workflow_data(workflow_id=1)

        # Get all active workflows for a company
        workflows_data = get_detailed_workflow_data(company_id=1)

        # Get all workflows including inactive
        all_workflows = get_detailed_workflow_data(include_inactive=True)
    """
    # Base queryset with optimized prefetching
    queryset = WorkFlow.objects.select_related("company").prefetch_related(
        "pipelines__stages"
    )

    # Apply filters
    if company_id:
        queryset = queryset.filter(company_id=company_id)

    if not include_inactive:
        queryset = queryset.filter(is_active=True)

    if workflow_id:
        try:
            workflow = queryset.get(id=workflow_id)
            return _build_detailed_workflow_dict(workflow)
        except WorkFlow.DoesNotExist:
            return None
    else:
        workflows = list(queryset)
        return {
            "workflows": [
                _build_workflow_summary_dict(workflow) for workflow in workflows
            ],
            "total_count": len(workflows),
            "statistics": _calculate_workflow_statistics(workflows),
        }


def get_workflow_pipeline_structure(workflow_id: int) -> Dict[str, Any]:
    """
    Get optimized pipeline structure for a specific workflow.

    Args:
        workflow_id: Workflow ID

    Returns:
        Dictionary with pipeline structure data
    """
    try:
        workflow = (
            WorkFlow.objects.select_related("company")
            .prefetch_related("pipelines__stages")
            .get(id=workflow_id)
        )

        return _build_pipeline_structure_dict(workflow)
    except WorkFlow.DoesNotExist:
        return None


def get_workflow_approval_summary(workflow_id: int) -> Dict[str, Any]:
    """
    Get approval summary statistics for a specific workflow.

    Args:
        workflow_id: Workflow ID

    Returns:
        Dictionary with approval statistics
    """
    try:
        workflow = WorkFlow.objects.prefetch_related("pipelines__stages").get(
            id=workflow_id
        )

        return _build_approval_summary_dict(workflow)
    except WorkFlow.DoesNotExist:
        return None


def get_workflow_statistics(company_id: int = None) -> Dict[str, Any]:
    """
    Get system-wide workflow statistics.

    Args:
        company_id: Filter by company ID (optional)

    Returns:
        Dictionary with comprehensive workflow statistics
    """
    queryset = WorkFlow.objects.select_related("company").prefetch_related(
        "pipelines__stages"
    )

    if company_id:
        queryset = queryset.filter(company_id=company_id)

    workflows = list(queryset)
    return _calculate_workflow_statistics(workflows)


# Private helper functions for optimized data building


def _build_detailed_workflow_dict(workflow: WorkFlow) -> Dict[str, Any]:
    """Build detailed workflow dictionary with all nested data."""
    pipelines_data = []
    total_stages = 0
    total_approvals = 0

    for pipeline in workflow.pipelines.all():
        stages_data = []
        pipeline_approvals = 0

        for stage in pipeline.stages.all():
            approvals = stage.stage_info.get("approvals", [])
            stage_approvals = len(approvals)
            pipeline_approvals += stage_approvals
            total_approvals += stage_approvals

            # Enrich approval data
            enriched_approvals = []
            for approval in approvals:
                enriched_approval = approval.copy()

                # Add human-readable approval type
                approval_type = approval.get("approval_type", "")
                if approval_type == ApprovalTypes.ROLE:
                    enriched_approval["approval_type_display"] = "Role-based Approval"
                elif approval_type == ApprovalTypes.USER:
                    enriched_approval["approval_type_display"] = (
                        "User-specific Approval"
                    )
                elif approval_type == ApprovalTypes.SELF:
                    enriched_approval["approval_type_display"] = "Self Approval"
                else:
                    enriched_approval["approval_type_display"] = approval_type

                # Add human-readable strategy
                strategy = approval.get("role_selection_strategy", "")
                if strategy == RoleSelectionStrategy.ANYONE:
                    enriched_approval["strategy_display"] = (
                        "Any user with role can approve"
                    )
                elif strategy == RoleSelectionStrategy.CONSENSUS:
                    enriched_approval["strategy_display"] = (
                        "All users with role must approve"
                    )
                elif strategy == RoleSelectionStrategy.ROUND_ROBIN:
                    enriched_approval["strategy_display"] = (
                        "Rotate approval among role users"
                    )
                else:
                    enriched_approval["strategy_display"] = strategy

                enriched_approvals.append(enriched_approval)

            stages_data.append(
                {
                    "id": stage.id,
                    "name_en": stage.name_en,
                    "name_ar": stage.name_ar,
                    "order": stage.order,
                    "is_active": stage.is_active,
                    "stage_info": stage.stage_info,
                    "approvals_count": stage_approvals,
                    "has_approvals": stage_approvals > 0,
                    "approval_configuration": {
                        "approvals": enriched_approvals,
                        "color": stage.stage_info.get("color", "#3498db"),
                        "total_approvals": stage_approvals,
                    },
                    "created_at": stage.created_at,
                    "modified_at": stage.modified_at,
                }
            )

        total_stages += len(stages_data)

        pipelines_data.append(
            {
                "id": pipeline.id,
                "name_en": pipeline.name_en,
                "name_ar": pipeline.name_ar,
                "order": pipeline.order,
                "department": pipeline.department_name,
                "department_name": pipeline.department_name,
                "stages": stages_data,
                "stages_count": len(stages_data),
                "created_at": pipeline.created_at,
                "modified_at": pipeline.modified_at,
            }
        )

    # Build pipeline breakdown for summary
    pipeline_breakdown = []
    for pipeline_data in pipelines_data:
        pipeline_breakdown.append(
            {
                "pipeline_name": pipeline_data["name_en"],
                "pipeline_order": pipeline_data["order"],
                "stages_count": pipeline_data["stages_count"],
                "approvals_count": sum(
                    stage["approvals_count"] for stage in pipeline_data["stages"]
                ),
            }
        )

    return {
        "id": workflow.id,
        "name_en": workflow.name_en,
        "name_ar": workflow.name_ar,
        "company": workflow.company.username if workflow.company else None,
        "company_name": workflow.company.username if workflow.company else None,
        "is_active": workflow.is_active,
        "description": workflow.description,
        "pipelines": pipelines_data,
        "pipelines_count": len(pipelines_data),
        "total_stages_count": total_stages,
        "workflow_summary": {
            "total_pipelines": len(pipelines_data),
            "total_stages": total_stages,
            "total_approvals": total_approvals,
            "pipeline_breakdown": pipeline_breakdown,
        },
        "created_at": workflow.created_at,
        "modified_at": workflow.modified_at,
    }


def _build_workflow_summary_dict(workflow: WorkFlow) -> Dict[str, Any]:
    """Build workflow summary dictionary for list views."""
    pipelines_count = workflow.pipelines.count()
    total_stages_count = sum(
        pipeline.stages.count() for pipeline in workflow.pipelines.all()
    )

    return {
        "id": workflow.id,
        "name_en": workflow.name_en,
        "name_ar": workflow.name_ar,
        "company": workflow.company.username if workflow.company else None,
        "company_name": workflow.company.username if workflow.company else None,
        "is_active": workflow.is_active,
        "description": workflow.description,
        "pipelines_count": pipelines_count,
        "total_stages_count": total_stages_count,
        "created_at": workflow.created_at,
        "modified_at": workflow.modified_at,
    }


def _build_pipeline_structure_dict(workflow: WorkFlow) -> Dict[str, Any]:
    """Build pipeline structure dictionary."""
    pipelines_data = []
    total_stages = 0

    for pipeline in workflow.pipelines.all():
        stages_data = []
        for stage in pipeline.stages.all():
            approvals = stage.stage_info.get("approvals", [])

            # Count approvals by type
            approval_counts = {
                ApprovalTypes.ROLE: 0,
                ApprovalTypes.USER: 0,
                ApprovalTypes.SELF: 0,
            }
            for approval in approvals:
                approval_type = approval.get("approval_type", "")
                if approval_type in approval_counts:
                    approval_counts[approval_type] += 1

            stages_data.append(
                {
                    "id": stage.id,
                    "name_en": stage.name_en,
                    "name_ar": stage.name_ar,
                    "order": stage.order,
                    "is_active": stage.is_active,
                    "approvals_count": len(approvals),
                    "approval_types": approval_counts,
                    "color": stage.stage_info.get("color", "#3498db"),
                    "has_forms": any(
                        approval.get("required_form") for approval in approvals
                    ),
                }
            )

        total_stages += len(stages_data)

        pipelines_data.append(
            {
                "id": pipeline.id,
                "name_en": pipeline.name_en,
                "name_ar": pipeline.name_ar,
                "order": pipeline.order,
                "department": pipeline.department_name,
                "stages": stages_data,
                "stages_count": len(stages_data),
            }
        )

    return {
        "workflow_id": workflow.id,
        "workflow_name": workflow.name_en,
        "pipelines": pipelines_data,
        "total_pipelines": len(pipelines_data),
        "total_stages": total_stages,
    }


def _build_approval_summary_dict(workflow: WorkFlow) -> Dict[str, Any]:
    """Build approval summary dictionary."""
    approval_stats = {
        "total_approvals": 0,
        "by_type": {
            ApprovalTypes.ROLE: 0,
            ApprovalTypes.USER: 0,
            ApprovalTypes.SELF: 0,
        },
        "by_strategy": {
            RoleSelectionStrategy.ANYONE: 0,
            RoleSelectionStrategy.CONSENSUS: 0,
            RoleSelectionStrategy.ROUND_ROBIN: 0,
        },
        "stages_with_forms": 0,
        "pipeline_breakdown": [],
    }

    for pipeline in workflow.pipelines.all():
        pipeline_stats = {
            "pipeline_name": pipeline.name_en,
            "pipeline_order": pipeline.order,
            "stages": [],
            "total_approvals": 0,
        }

        for stage in pipeline.stages.all():
            approvals = stage.stage_info.get("approvals", [])
            stage_approvals = len(approvals)
            pipeline_stats["total_approvals"] += stage_approvals
            approval_stats["total_approvals"] += stage_approvals

            # Count by type and strategy
            has_forms = False
            for approval in approvals:
                approval_type = approval.get("approval_type", "")
                if approval_type in approval_stats["by_type"]:
                    approval_stats["by_type"][approval_type] += 1

                strategy = approval.get("role_selection_strategy", "")
                if strategy in approval_stats["by_strategy"]:
                    approval_stats["by_strategy"][strategy] += 1

                if approval.get("required_form"):
                    has_forms = True

            if has_forms:
                approval_stats["stages_with_forms"] += 1

            pipeline_stats["stages"].append(
                {
                    "stage_name": stage.name_en,
                    "stage_order": stage.order,
                    "approvals_count": stage_approvals,
                    "has_forms": has_forms,
                }
            )

        approval_stats["pipeline_breakdown"].append(pipeline_stats)

    return approval_stats


def _calculate_workflow_statistics(workflows: List[WorkFlow]) -> Dict[str, Any]:
    """Calculate comprehensive workflow statistics."""
    total_workflows = len(workflows)
    active_workflows = sum(1 for w in workflows if w.is_active)

    total_pipelines = 0
    total_stages = 0
    total_approvals = 0
    company_stats = {}

    for workflow in workflows:
        company_name = workflow.company.username if workflow.company else "No Company"
        if company_name not in company_stats:
            company_stats[company_name] = {
                "workflows": 0,
                "pipelines": 0,
                "stages": 0,
                "approvals": 0,
            }

        workflow_pipelines = workflow.pipelines.count()
        workflow_stages = sum(
            pipeline.stages.count() for pipeline in workflow.pipelines.all()
        )
        workflow_approvals = 0

        for pipeline in workflow.pipelines.all():
            for stage in pipeline.stages.all():
                approvals = stage.stage_info.get("approvals", [])
                workflow_approvals += len(approvals)

        total_pipelines += workflow_pipelines
        total_stages += workflow_stages
        total_approvals += workflow_approvals

        company_stats[company_name]["workflows"] += 1
        company_stats[company_name]["pipelines"] += workflow_pipelines
        company_stats[company_name]["stages"] += workflow_stages
        company_stats[company_name]["approvals"] += workflow_approvals

    return {
        "overview": {
            "total_workflows": total_workflows,
            "active_workflows": active_workflows,
            "inactive_workflows": total_workflows - active_workflows,
            "total_pipelines": total_pipelines,
            "total_stages": total_stages,
            "total_approvals": total_approvals,
            "avg_pipelines_per_workflow": (
                round(total_pipelines / total_workflows, 2)
                if total_workflows > 0
                else 0
            ),
            "avg_stages_per_workflow": (
                round(total_stages / total_workflows, 2) if total_workflows > 0 else 0
            ),
        },
        "by_company": company_stats,
    }
