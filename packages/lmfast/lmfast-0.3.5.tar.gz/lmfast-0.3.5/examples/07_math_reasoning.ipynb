{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üßÆ LMFast: Math Reasoning Specialty\n",
                "\n",
                "**Train an SLM to be a math genius!**\n",
                "\n",
                "## What You'll Learn\n",
                "- Fine-tune on math datasets (GSM8K, MathInstruct)\n",
                "- Format data with Chain-of-Thought (CoT)\n",
                "- Use `ReasoningConfig` for specialized training\n",
                "- Evaluate using pass@1 metrics\n",
                "\n",
                "## Why Math?\n",
                "Math reasoning is a proxy for general intelligence. Small models that excel at math often reason better in other domains.\n",
                "\n",
                "**Time to complete:** ~20 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q lmfast[all] datasets\n",
                "\n",
                "import lmfast\n",
                "lmfast.setup_colab_env()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Data Preparation (CoT)\n",
                "\n",
                "We need data that shows the *steps*, not just the answer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "# Load a small subset of GSM8K (Grade School Math)\n",
                "# Real training would use the full set\n",
                "dataset = load_dataset(\"gsm8k\", \"main\", split=\"train[:100]\")\n",
                "\n",
                "print(\"Example:\")\n",
                "print(f\"Q: {dataset[0]['question']}\")\n",
                "print(f\"A: {dataset[0]['answer']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Formatting for Training\n",
                "\n",
                "We format it as a conversation where the assistant provides the CoT."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def format_math(example):\n",
                "    # Standard Alpaca/Chat format\n",
                "    return {\n",
                "        \"text\": f\"### Question:\\n{example['question']}\\n\\n### Solution:\\nLet's think step by step.\\n{example['answer']}\"\n",
                "    }\n",
                "\n",
                "train_ds = dataset.map(format_math)\n",
                "print(train_ds[0]['text'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Training with Math Optimization\n",
                "\n",
                "Math training often benefits from:\n",
                "- Low learning rate decay\n",
                "- Packing multiple short examples\n",
                "- NEFTune (optional for stability)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast import train\n",
                "\n",
                "print(\"üöÄ Starting Math Fine-Tuning...\")\n",
                "\n",
                "trainer = train(\n",
                "    model=\"HuggingFaceTB/SmolLM-135M\",\n",
                "    dataset=train_ds,\n",
                "    output_dir=\"./math_solver\",\n",
                "    max_steps=50,\n",
                "    learning_rate=2e-4,\n",
                "    packing=True,  # Pack shorter math problems for efficiency\n",
                "    neftune_noise_alpha=5, # Improves generalization\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Training initiated...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Test with ThinkingAgent\n",
                "\n",
                "Use our new `ThinkingAgent` to check performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast.reasoning import ThinkingAgent, reason\n",
                "from lmfast.inference import SLMServer\n",
                "\n",
                "# Load our trained model\n",
                "model = SLMServer(\"./math_solver\")\n",
                "\n",
                "problem = \"Janet has 5 apples. She gives 2 to Tom and buys 3 more. How many?\"\n",
                "\n",
                "# Use Best-of-N to boost accuracy further\n",
                "answer = reason(\n",
                "    model_fn=lambda p: model.generate(p, max_new_tokens=100), \n",
                "    problem=problem,\n",
                "    method=\"best_of_n\", \n",
                "    n=3\n",
                ")\n",
                "\n",
                "print(f\"Question: {problem}\")\n",
                "print(f\"Model Answer: {answer}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ Summary\n",
                "\n",
                "You've learned how to:\n",
                "- ‚úÖ Prepare math datasets with CoT\n",
                "- ‚úÖ Fine-tune for reasoning\n",
                "- ‚úÖ Combine fine-tuning with test-time compute\n",
                "\n",
                "### Next Steps\n",
                "- `10_reasoning_agents.ipynb`: Dive deeper into inference strategies."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}