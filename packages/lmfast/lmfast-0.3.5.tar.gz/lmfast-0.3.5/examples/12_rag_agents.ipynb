{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“š LMFast: RAG-Augmented Agents\n",
                "\n",
                "**Build knowledge-grounded AI agents with Retrieval-Augmented Generation!**\n",
                "\n",
                "## What You'll Learn\n",
                "- Create a RAG system with LMFast\n",
                "- Index documents (PDF, TXT, MD)\n",
                "- Query with context-aware generation\n",
                "- Build a RAG-powered agent\n",
                "- Save and load RAG indexes\n",
                "\n",
                "## Why RAG for SLMs?\n",
                "- Reduces hallucinations by grounding responses\n",
                "- Enables domain-specific knowledge without fine-tuning\n",
                "- Works great with small models (even 135M!)\n",
                "- Low memory footprint\n",
                "\n",
                "**Time to complete:** ~10 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install LMFast with RAG dependencies\n",
                "!pip install -q lmfast[all] sentence-transformers faiss-cpu\n",
                "\n",
                "import lmfast\n",
                "lmfast.setup_colab_env()\n",
                "\n",
                "import torch\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
                "print(f\"LMFast version: {lmfast.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ Create a RAG System\n",
                "\n",
                "LMFast's `LightweightRAG` is designed for:\n",
                "- Colab T4 compatibility (low memory)\n",
                "- Simple, intuitive API\n",
                "- Automatic chunking and indexing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast.rag import LightweightRAG, create_rag\n",
                "\n",
                "# Sample documents about our fictional company\n",
                "documents = [\n",
                "    \"\"\"\n",
                "    TechCorp AI Solutions - Company Overview\n",
                "    \n",
                "    TechCorp is a leading provider of AI solutions for enterprise customers.\n",
                "    Founded in 2020, we specialize in:\n",
                "    - Natural Language Processing\n",
                "    - Computer Vision\n",
                "    - Predictive Analytics\n",
                "    \n",
                "    Our flagship product is SmartAssist, an AI-powered customer service platform\n",
                "    that reduces support costs by 40% while improving customer satisfaction.\n",
                "    \"\"\",\n",
                "    \"\"\"\n",
                "    TechCorp Products and Pricing\n",
                "    \n",
                "    1. SmartAssist Basic - $99/month\n",
                "       - Up to 1,000 conversations/month\n",
                "       - Email support\n",
                "       - Basic analytics\n",
                "    \n",
                "    2. SmartAssist Pro - $299/month\n",
                "       - Unlimited conversations\n",
                "       - 24/7 support\n",
                "       - Advanced analytics\n",
                "       - Custom integrations\n",
                "    \n",
                "    3. SmartAssist Enterprise - Custom pricing\n",
                "       - On-premise deployment\n",
                "       - Dedicated account manager\n",
                "       - SLA guarantees\n",
                "    \"\"\",\n",
                "    \"\"\"\n",
                "    TechCorp Technical Documentation\n",
                "    \n",
                "    API Integration Guide:\n",
                "    \n",
                "    To integrate SmartAssist with your application:\n",
                "    \n",
                "    1. Get your API key from the dashboard\n",
                "    2. Install the SDK: pip install smartassist-sdk\n",
                "    3. Initialize the client:\n",
                "       ```python\n",
                "       from smartassist import Client\n",
                "       client = Client(api_key=\"your-key\")\n",
                "       ```\n",
                "    4. Send messages:\n",
                "       ```python\n",
                "       response = client.chat(\"Hello, I need help\")\n",
                "       ```\n",
                "    \n",
                "    Rate Limits:\n",
                "    - Basic: 100 requests/minute\n",
                "    - Pro: 1000 requests/minute\n",
                "    - Enterprise: Unlimited\n",
                "    \"\"\",\n",
                "    \"\"\"\n",
                "    TechCorp Support FAQ\n",
                "    \n",
                "    Q: How do I reset my password?\n",
                "    A: Go to Settings > Security > Reset Password\n",
                "    \n",
                "    Q: Can I export my conversation history?\n",
                "    A: Yes, go to Analytics > Export > Select date range\n",
                "    \n",
                "    Q: What languages does SmartAssist support?\n",
                "    A: Currently: English, Spanish, French, German, Japanese, Chinese\n",
                "    \n",
                "    Q: How do I upgrade my plan?\n",
                "    A: Go to Billing > Change Plan > Select new plan\n",
                "    \"\"\"\n",
                "]\n",
                "\n",
                "print(f\"Prepared {len(documents)} documents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create RAG system\n",
                "# We'll use SmolLM for generation and MiniLM for embeddings\n",
                "\n",
                "rag = LightweightRAG(\n",
                "    model=\"HuggingFaceTB/SmolLM-360M-Instruct\",\n",
                "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
                "    chunk_size=512,\n",
                "    chunk_overlap=50,\n",
                "    top_k=3  # Retrieve top 3 chunks\n",
                ")\n",
                "\n",
                "print(\"RAG system created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add documents to the knowledge base\n",
                "num_chunks = rag.add_documents(\n",
                "    documents,\n",
                "    metadata=[{\"source\": f\"doc_{i}\"} for i in range(len(documents))]\n",
                ")\n",
                "\n",
                "print(f\"Indexed {num_chunks} chunks\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ Query the RAG System"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple query\n",
                "questions = [\n",
                "    \"What is the pricing for SmartAssist Pro?\",\n",
                "    \"How do I integrate the API?\",\n",
                "    \"What languages are supported?\",\n",
                "    \"What does TechCorp specialize in?\"\n",
                "]\n",
                "\n",
                "print(\"ðŸ“š RAG Queries\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for question in questions:\n",
                "    print(f\"\\nâ“ Question: {question}\")\n",
                "    \n",
                "    answer = rag.query(question, max_new_tokens=150)\n",
                "    print(f\"ðŸ’¡ Answer: {answer}\")\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ Query with Sources"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get answer with source chunks\n",
                "question = \"What are the rate limits for the API?\"\n",
                "\n",
                "answer, sources = rag.query(question, return_sources=True)\n",
                "\n",
                "print(f\"â“ Question: {question}\")\n",
                "print(f\"\\nðŸ’¡ Answer: {answer}\")\n",
                "print(f\"\\nðŸ“„ Sources used ({len(sources)} chunks):\")\n",
                "for i, source in enumerate(sources):\n",
                "    print(f\"\\n--- Source {i+1} ---\")\n",
                "    print(source[:200] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ Retrieval Only"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Just retrieve relevant chunks without generation\n",
                "results = rag.retrieve(\"pricing plans\", top_k=2)\n",
                "\n",
                "print(\"ðŸ” Retrieval Results\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for chunk, score, metadata in results:\n",
                "    print(f\"\\nScore: {score:.3f}\")\n",
                "    print(f\"Metadata: {metadata}\")\n",
                "    print(f\"Content: {chunk[:200]}...\")\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6ï¸âƒ£ Add Files to RAG\n",
                "\n",
                "You can also add files directly (TXT, MD, PDF)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a sample file\n",
                "sample_content = \"\"\"\n",
                "# TechCorp Release Notes - v2.5\n",
                "\n",
                "## New Features\n",
                "- Multi-language support for 6 new languages\n",
                "- Real-time sentiment analysis\n",
                "- Advanced conversation routing\n",
                "- Webhook notifications\n",
                "\n",
                "## Bug Fixes\n",
                "- Fixed issue with conversation export\n",
                "- Improved response latency by 30%\n",
                "- Resolved authentication timeout errors\n",
                "\n",
                "## Breaking Changes\n",
                "- API v1 deprecated (sunset date: 2025-06-01)\n",
                "- New authentication flow required for Enterprise\n",
                "\"\"\"\n",
                "\n",
                "with open(\"release_notes.md\", \"w\") as f:\n",
                "    f.write(sample_content)\n",
                "\n",
                "# Add file to RAG\n",
                "rag.add_file(\"release_notes.md\")\n",
                "print(\"Added release_notes.md to knowledge base\")\n",
                "\n",
                "# Query about release notes\n",
                "answer = rag.query(\"What's new in version 2.5?\")\n",
                "print(f\"\\nâ“ What's new in v2.5?\")\n",
                "print(f\"ðŸ’¡ {answer}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7ï¸âƒ£ One-Line RAG Creation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick setup with create_rag\n",
                "quick_rag = create_rag(\n",
                "    model=\"HuggingFaceTB/SmolLM-135M\",\n",
                "    documents=[\n",
                "        \"Python is a programming language.\",\n",
                "        \"JavaScript is used for web development.\",\n",
                "        \"Rust is known for memory safety.\"\n",
                "    ],\n",
                "    top_k=2\n",
                ")\n",
                "\n",
                "answer = quick_rag.query(\"What is Python?\")\n",
                "print(f\"Quick RAG answer: {answer}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8ï¸âƒ£ Save and Load RAG"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save RAG state\n",
                "rag.save(\"./my_rag_index\")\n",
                "print(\"RAG saved to ./my_rag_index\")\n",
                "\n",
                "# List saved files\n",
                "import os\n",
                "for f in os.listdir(\"./my_rag_index\"):\n",
                "    print(f\"  - {f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load RAG state\n",
                "loaded_rag = LightweightRAG(\"HuggingFaceTB/SmolLM-360M-Instruct\")\n",
                "loaded_rag.load(\"./my_rag_index\")\n",
                "\n",
                "# Verify it works\n",
                "answer = loaded_rag.query(\"What is SmartAssist?\")\n",
                "print(f\"Loaded RAG answer: {answer[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9ï¸âƒ£ Build a RAG-Powered Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast.agents.core import Agent, Tool\n",
                "from lmfast.inference import SLMServer\n",
                "\n",
                "# Create base model for agent\n",
                "model = SLMServer(\"HuggingFaceTB/SmolLM-360M-Instruct\")\n",
                "\n",
                "# Create RAG as a tool\n",
                "def search_knowledge_base(query: str) -> str:\n",
                "    \"\"\"Search the company knowledge base for information.\"\"\"\n",
                "    results = rag.retrieve(query, top_k=2)\n",
                "    if results:\n",
                "        return \"\\n\".join([r[0] for r in results])\n",
                "    return \"No relevant information found.\"\n",
                "\n",
                "def get_pricing(plan: str) -> str:\n",
                "    \"\"\"Get pricing information for a specific plan.\"\"\"\n",
                "    prices = {\n",
                "        \"basic\": \"$99/month\",\n",
                "        \"pro\": \"$299/month\",\n",
                "        \"enterprise\": \"Custom pricing - contact sales\"\n",
                "    }\n",
                "    return prices.get(plan.lower(), \"Unknown plan\")\n",
                "\n",
                "# Create agent with RAG tool\n",
                "support_agent = Agent(\n",
                "    model_generate_fn=model.generate,\n",
                "    tools=[search_knowledge_base, get_pricing],\n",
                "    system_prompt=\"\"\"You are a helpful TechCorp support agent.\n",
                "Use the search_knowledge_base tool to find information.\n",
                "Use the get_pricing tool for pricing questions.\n",
                "Always be helpful and accurate.\"\"\"\n",
                ")\n",
                "\n",
                "print(\"RAG-powered support agent created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test the RAG agent\n",
                "queries = [\n",
                "    \"How do I integrate the SmartAssist API?\",\n",
                "    \"What's the price of the Pro plan?\",\n",
                "    \"What languages does your product support?\"\n",
                "]\n",
                "\n",
                "print(\"ðŸ¤– RAG-Powered Support Agent\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for query in queries:\n",
                "    print(f\"\\nðŸ‘¤ Customer: {query}\")\n",
                "    response = support_agent.run(query)\n",
                "    print(f\"ðŸ¤– Agent: {response}\")\n",
                "    print(\"-\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ‰ Summary\n",
                "\n",
                "You've learned how to:\n",
                "- âœ… Create a RAG system with `LightweightRAG`\n",
                "- âœ… Index documents and files\n",
                "- âœ… Query with context-grounded generation\n",
                "- âœ… Retrieve sources for transparency\n",
                "- âœ… Save and load RAG indexes\n",
                "- âœ… Build RAG-powered agents\n",
                "\n",
                "### RAG Tips\n",
                "\n",
                "| Tip | Why |\n",
                "|-----|-----|\n",
                "| Smaller chunks (256-512) | Better retrieval precision |\n",
                "| Overlap (50-100 chars) | Avoid cutting context |\n",
                "| Higher top_k for complex Q | More context helps |\n",
                "| Domain-specific embeddings | Better matching |\n",
                "\n",
                "### Next Steps\n",
                "- `13_guardrails.ipynb` - Add safety to your RAG\n",
                "- `15_browser_deployment.ipynb` - Deploy RAG in browser"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}