{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ°Ô∏è LMFast: Guardrails & Safety\n",
                "\n",
                "**Ensure your SLM behaves safely and predictably!**\n",
                "\n",
                "## What You'll Learn\n",
                "- Detect and block PII (Personally Identifiable Information)\n",
                "- Prevent toxicity and harmful content\n",
                "- Enforce structured output (JSON, Code)\n",
                "- Define custom validators\n",
                "\n",
                "## Comparison\n",
                "| Feature | Validator | Example |\n",
                "|---------|-----------|---------|\n",
                "| **Privacy** | PII Filter | \"My email is [REDACTED]\" |\n",
                "| **Safety** | Toxicity | Block hate speech |\n",
                "| **Structure** | JSON | Ensure valid JSON output |\n",
                "\n",
                "**Time to complete:** ~10 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q lmfast[all] guardrails-ai\n",
                "\n",
                "import lmfast\n",
                "lmfast.setup_colab_env()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Define Guardrails\n",
                "\n",
                "We use `GuardrailsConfig` to define our safety rules."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast.guardrails.config import GuardrailsConfig\n",
                "\n",
                "# Create configuration\n",
                "config = GuardrailsConfig(\n",
                "    pii_enabled=True,\n",
                "    toxicity_enabled=True,\n",
                "    toxicity_threshold=0.5,\n",
                "    competitors_list=[\"CompetitorX\", \"EvilCorp\"] # Custom blocklist\n",
                ")\n",
                "\n",
                "print(\"üõ°Ô∏è Safety Config Created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Apply to Model\n",
                "\n",
                "Wrap your model (or server) with the guardrails."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast.inference import SLMServer\n",
                "\n",
                "# Mock model for demo (unsafe)\n",
                "class UnsafeModel:\n",
                "    def generate(self, prompt, **kwargs):\n",
                "        if \"email\" in prompt:\n",
                "            return \"Sure, my email is john.doe@example.com\"\n",
                "        if \"hack\" in prompt:\n",
                "            return \"Here is how to hack the mainframe...\"\n",
                "        if \"competitor\" in prompt:\n",
                "            return \"You should check out CompetitorX, they are great.\"\n",
                "        return \"I am a safe AI.\"\n",
                "\n",
                "# Wrap it (conceptual - in real code use SLMServer with guardrails arg)\n",
                "# server = SLMServer(..., guardrails=config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ PII Detection Test\n",
                "\n",
                "LMFast uses scrubbers to remove sensitive info."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Utilizing the PII scrubber directly for demo\n",
                "from lmfast.guardrails.pii import PIIScrubber\n",
                "\n",
                "scrubber = PIIScrubber()\n",
                "text = \"Contact me at gaurav@example.com or call 555-0199.\"\n",
                "clean_text = scrubber.clean(text)\n",
                "\n",
                "print(f\"Original: {text}\")\n",
                "print(f\"Cleaned:  {clean_text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Input Validation\n",
                "\n",
                "Block bad inputs before they even reach the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def validate_input(prompt):\n",
                "    if \"hack\" in prompt.lower():\n",
                "        raise ValueError(\"Unsafe content detected in prompt\")\n",
                "    return True\n",
                "\n",
                "try:\n",
                "    validate_input(\"How to hack wifi?\")\n",
                "except ValueError as e:\n",
                "    print(f\"üö´ Blocked: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ Summary\n",
                "\n",
                "You've learned how to:\n",
                "- ‚úÖ Redact emails and phone numbers\n",
                "- ‚úÖ Set toxicity thresholds\n",
                "- ‚úÖ Define blocklists for specific terms\n",
                "\n",
                "### Next Steps\n",
                "- `14_observability.ipynb`: Log these safety events."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}