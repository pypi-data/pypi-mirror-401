{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üîå LMFast: Model Context Protocol (MCP)\n",
                "\n",
                "**Make your SLM a first-class citizen in the AI ecosystem!**\n",
                "\n",
                "## What You'll Learn\n",
                "- Understand MCP (Model Context Protocol)\n",
                "- Serve an SLM as an MCP Resource\n",
                "- Serve an SLM as an MCP Tool\n",
                "- Connect your custom SLM to Claude Desktop or Cursor\n",
                "\n",
                "## Why MCP?\n",
                "MCP is an open standard that allows AI models to connect to data and tools universally. By exposing your SLM via MCP, it becomes instantly usable by any MCP-compliant client.\n",
                "\n",
                "**Time to complete:** ~10 minutes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q lmfast[all] mcp\n",
                "\n",
                "import lmfast\n",
                "lmfast.setup_colab_env()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ The MCP Server\n",
                "\n",
                "LMFast provides a built-in `LMFastMCPServer`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lmfast.mcp.server import LMFastMCPServer\n",
                "\n",
                "# Create server instance\n",
                "# It wraps your model and exposes 'generate' and 'info' capabilities\n",
                "server = LMFastMCPServer(\n",
                "    model_path=\"HuggingFaceTB/SmolLM-135M-Instruct\",\n",
                "    name=\"my-slm-server\"\n",
                ")\n",
                "\n",
                "print(\"‚úÖ MCP Server Created\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Connecting Local Clients\n",
                "\n",
                "To use this with Claude Desktop or Cursor, you normally run it via command line:\n",
                "\n",
                "```bash\n",
                "lmfast serve ./my_model --mcp --name \"MyCustomSLM\"\n",
                "```\n",
                "\n",
                "Add this to your `claude_desktop_config.json`:\n",
                "```json\n",
                "{\n",
                "  \"mcpServers\": {\n",
                "    \"my-slm\": {\n",
                "      \"command\": \"lmfast\",\n",
                "      \"args\": [\"serve\", \"./my_model\", \"--mcp\"]\n",
                "    }\n",
                "  }\n",
                "}\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Simulating Client Interaction\n",
                "\n",
                "We can simulate how a client calls your SLM tools."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate a tool call request\n",
                "request = {\n",
                "    \"name\": \"generate\",\n",
                "    \"arguments\": {\n",
                "        \"prompt\": \"Explain quantum physics in one sentence.\",\n",
                "        \"max_tokens\": 50\n",
                "    }\n",
                "}\n",
                "\n",
                "print(f\"üìû Client Request: {request}\")\n",
                "\n",
                "# Direct call for demo (internally it uses stdio)\n",
                "response = server.call_tool(request['name'], request['arguments'])\n",
                "print(f\"ü§ñ Server Response: {response[0].text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéâ Summary\n",
                "\n",
                "You've learned how to:\n",
                "- ‚úÖ Create an MCP server for your SLM\n",
                "- ‚úÖ Configure Claude Desktop to communicate with it\n",
                "\n",
                "### Use Case\n",
                "Imagine training a tiny specialized model for your company's internal docs. You can now expose it as a tool to Claude 3.5 Sonnet via MCP, giving the big model access to specialized knowledge!\n",
                "\n",
                "### Next Steps\n",
                "- `12_rag_agents.ipynb`: Add RAG to your MCP server."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}