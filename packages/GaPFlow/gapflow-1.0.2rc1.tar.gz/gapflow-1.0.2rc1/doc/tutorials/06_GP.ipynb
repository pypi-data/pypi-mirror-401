{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Gaussian process regression and active learning\n",
    "\n",
    "Now we'll look at the same problem as in the previous tutorial, but replace the hardcoded constitutive laws with purely data-driven ones.\n",
    "In multiscale simulations, this data comes from molecular dynamics (MD) simulations.\n",
    "For illustrative purposes, we sample the training data from the same hard-coded constituive laws as before and pretend it comes from an MD run.\n",
    "Thus, we generate a *Mock* of an actual MD simulation. Real MD data is noisy, so we'll add some random noise to our mock-up data as well.\n",
    "As in the previous example, we start with the *YAML* input file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_gp_input = \"\"\"\n",
    "options:\n",
    "    output: data/journal_gp\n",
    "    write_freq: 100\n",
    "    use_tstamp: True\n",
    "grid:\n",
    "    dx: 1.e-5\n",
    "    dy: 1.\n",
    "    Nx: 100\n",
    "    Ny: 1\n",
    "    xE: ['D', 'N', 'N']\n",
    "    xW: ['D', 'N', 'N']\n",
    "    yS: ['P', 'P', 'P']\n",
    "    yN: ['P', 'P', 'P']\n",
    "    xE_D: 877.7007\n",
    "    xW_D: 877.7007\n",
    "geometry:\n",
    "    type: journal\n",
    "    CR: 1.e-2\n",
    "    eps: 0.7\n",
    "    U: 0.1\n",
    "    V: 0.\n",
    "numerics:\n",
    "    CFL: 0.25\n",
    "    adaptive: 1\n",
    "    tol: 1e-9\n",
    "    dt: 1e-10\n",
    "    max_it: 2_500\n",
    "properties:\n",
    "    shear: 0.0794\n",
    "    bulk: 0.\n",
    "    EOS: DH\n",
    "    P0: 101325\n",
    "    rho0: 877.7007\n",
    "    T0: 323.15\n",
    "    C1: 3.5e10\n",
    "    C2: 1.23\n",
    "gp:\n",
    "    press:\n",
    "        fix_noise: True\n",
    "        atol: 1.\n",
    "        rtol: 0.1\n",
    "        obs_stddev: 100.\n",
    "        max_steps: 5\n",
    "    shear:\n",
    "        fix_noise: True\n",
    "        atol: 1.\n",
    "        rtol: 0.1\n",
    "        obs_stddev: 1.\n",
    "        max_steps: 5\n",
    "db:\n",
    "    dtool: True\n",
    "    init_size: 5\n",
    "    init_method: lhc\n",
    "    init_width: 1.e-6\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "The first part is identical, but we recognize two new sections, `gp` and `db`, which control the settings for the Gaussian process regression and the underlying training database, respectively. We start by loading the problem as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GaPFlow import Problem\n",
    "myProblem = Problem.from_string(journal_gp_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Before we unpack what we see here, a word of caution regarding wording and notation.\n",
    "\n",
    "There are two types of models, which can be replaced by a GP: the pressure/normal stress and the viscous shear stress.\n",
    "Here, we sometimes use the terms *pressure* and *normal stress* synonymously, although they are strictly speaking different things.\n",
    "For instance, the normal stress component is given by $\\sigma_{zz} = -p(\\rho) + \\tau_{zz}$, but we assume that viscous \n",
    "contributions to the normal stress (here: $\\tau_{zz}$) are small. \n",
    "This is not a bad assumption as we have seen in [Tutorial 2](02_stress_sympy.ipynb).\n",
    "\n",
    "In this example, where we make use of hard-coded constitutive laws, we would be able to include both effects separately,\n",
    "but with actual MD data this is not the case. Thus, in this example, what we call pressure is the actual thermodynamic pressure, \n",
    "and we explicitly set viscous normal stresses to zero. In contrast, with *actual* MD data, what we call pressure is the normal stress $\\sigma_{zz}$,\n",
    "but we assume that it is the same in the other two directions (thus we handle it numerically as it was the pressure).\n",
    "Similarly, we ignore all viscous shear stress components except $\\tau_{xz}$ and $\\tau_{yz}$, whenever we use GPs, since these are the only\n",
    "ones we measure in an MD run.\n",
    "\n",
    "---\n",
    "\n",
    "Upon loading the problem, the sanitized configuration of the GP settings look like this:\n",
    "```\n",
    "- gp:\n",
    "  - press_gp                 : True\n",
    "  - shear_gp                 : True\n",
    "  - press:\n",
    "    - atol                   : 1.0\n",
    "    - rtol                   : 0.1\n",
    "    - obs_stddev             : 100.0\n",
    "    - fix_noise              : True\n",
    "    - max_steps              : 5\n",
    "    - pause_steps            : 100\n",
    "    - active_learning        : True\n",
    "    - active_dims            : [0, 3]\n",
    "  - shear:\n",
    "    - atol                   : 1.0\n",
    "    - rtol                   : 0.1\n",
    "    - obs_stddev             : 1.0\n",
    "    - fix_noise              : True\n",
    "    - max_steps              : 5\n",
    "    - pause_steps            : 100\n",
    "    - active_learning        : True\n",
    "    - active_dims_x          : [0, 1, 3]\n",
    "    - active_dims_y          : [0, 2, 3]\n",
    "```\n",
    "\n",
    "The first two entries `press_gp` and `shear_gp` indicate that both GP models are active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pressure GP: ', myProblem.pressure.is_gp_model)\n",
    "print('Wall shear stress (xz) GP: ', myProblem.wall_stress_xz.is_gp_model)\n",
    "print('Wall shear stress (yz) GP: ', myProblem.wall_stress_yz.is_gp_model)\n",
    "print('Bulk viscous stress GP: ', myProblem.bulk_stress.is_gp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Since we are looking at a one-dimensional problem, the wall shear stress in $y$ direction is irrelevant and therefore not replaced with a surrogate. \n",
    "The gap-averaged viscous stress components (`bulk_stress`) are never replaced by a GP model, and are set to zero in this example (see remark above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "GP models are connected to a database, which is configured with the following settings:\n",
    "```\n",
    "- db:\n",
    "  - dtool_path               : None\n",
    "  - init_size                : 5\n",
    "  - init_method              : lhc\n",
    "  - init_width               : 1e-06\n",
    "  - init_seed                : 0\n",
    "```\n",
    "\n",
    "Both models read from and write to the same database, which is initially empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both models are connected to the same database...\n",
    "print(myProblem.pressure.database)\n",
    "print(myProblem.wall_stress_xz.database)\n",
    "\n",
    "# ...but the database is initially empty\n",
    "print(myProblem.pressure.database.size)\n",
    "print(myProblem.pressure.database.Xtrain)\n",
    "print(myProblem.pressure.database.Ytrain)\n",
    "print(myProblem.pressure.database.training_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The database configurations specifies that 5 (`init_size`) datapoints should be initialized via Latin hypercube sampling (`lhc`).\n",
    "The bounds for the LHC sampling are determined autmatically from the initial conditions, but we can modify the bounds for the density\n",
    "individually wiht the `init_width` argument, which gives the half width of the density interval relative to the initial condition (the default is $\\pm1\\%$). \n",
    "Here, it is quite small due to the nearly incompressible fluid. Before we can run a simulation, we have to initialize the database.\n",
    "Usually, this is done automatically when we call `GaPFlow.problem.Problem.run()`. Here, since we want to run the simulation 'manually', we have to call `GaPFlow.problem.Problem._pre_run()` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "myProblem._pre_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The output tells us that five *Mock* MD simulations \"ran\" with the inputs as specified.\n",
    "Let's check the size of the database again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Database size: ', myProblem.pressure.database.size)\n",
    "print('Database features: ', myProblem.pressure.database.num_features)\n",
    "print('X (shape)', myProblem.pressure.database.Xtrain.shape)\n",
    "print('Y (shape)', myProblem.pressure.database.Ytrain.shape)\n",
    "print('Y error (shape)', myProblem.pressure.database.Ytrain_err.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "We see that the database has been filled with the requested five datapoints. Each point is determined by seven features:\n",
    "\n",
    "- the density $\\rho$\n",
    "- the flux in x direction $j_x$\n",
    "- the flux in y direction $j_y$\n",
    "- the gap height $h$\n",
    "- the x gradient of the gap $\\partial h/\\partial x$\n",
    "- the y gradient of the gap $\\partial h/\\partial y$\n",
    "- an extra feature (by default zero)\n",
    "\n",
    "We can append an arbitrary number of extra features. By default there is just one but it is not used. \n",
    "You can check [the example on wall slip](../../examples/slip_1d_lj_mock.py) to see how the extra arguments can be used in a simulation.\n",
    "\n",
    "We also see, that there are in total 13 outputs (or observations) stored within the database.\n",
    "The outputs are stored in the following order:\n",
    "\n",
    "- $p$\n",
    "- $\\textcolor{grey}{\\tau_{xx}^\\mathrm{bot}}$\n",
    "- $\\textcolor{grey}{\\tau_{yy}^\\mathrm{bot}}$\n",
    "- $\\textcolor{grey}{\\tau_{zz}^\\mathrm{bot}}$\n",
    "- $\\tau_{yz}^\\mathrm{bot}$\n",
    "- $\\tau_{xz}^\\mathrm{bot}$\n",
    "- $\\textcolor{grey}{\\tau_{xy}^\\mathrm{bot}}$\n",
    "- $\\textcolor{grey}{\\tau_{xx}^\\mathrm{top}}$\n",
    "- $\\textcolor{grey}{\\tau_{yy}^\\mathrm{top}}$\n",
    "- $\\textcolor{grey}{\\tau_{zz}^\\mathrm{top}}$\n",
    "- $\\tau_{yz}^\\mathrm{top}$\n",
    "- $\\tau_{xz}^\\mathrm{top}$\n",
    "- $\\textcolor{grey}{\\tau_{xy}^\\mathrm{top}}$\n",
    "\n",
    "As mentioned above, most of the slots (in gray) are not used, because these stress components are not measured and thus zero. \n",
    "The individual training data of a single \"MD\" run is also stored in a local `dtool` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for f in sorted(os.listdir(myProblem.pressure.database.training_path)):\n",
    "    print(os.path.abspath(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The training data is stored as metadata in `README.yml`, which can be loaded directly into a list of dicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_list = myProblem.pressure.database.get_readme_list_local()\n",
    "readme_list[0]['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The `pre_run()` initialization also runs a first hyperparameter fit of the GP models. \n",
    "The output data used in the pressure and shear stress models is fixed, but we can change which features will be used via the `active_dims` settings.\n",
    "The defaults are density and gap height (`active_dims: [0, 3]`) for pressure, and density, gap height, and flux for shear stress (e.g. `active_dims_x: [0, 1, 3]`).\n",
    "The models are now ready to make a first prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_predict = myProblem.pressure.predict(predictor=False)\n",
    "shear_predict = myProblem.wall_stress_xz.predict(predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from GaPFlow.viz.plotting import _plot_sol_from_field_1d\n",
    "\n",
    "_sx, _sy = plt.rcParams['figure.figsize']\n",
    "fig, ax = plt.subplots(2, 3, figsize=(2*_sx, 2*_sy))\n",
    "\n",
    "_plot_sol_from_field_1d(myProblem.q,\n",
    "                        press_predict[0],\n",
    "                        shear_predict[0][0],\n",
    "                        shear_predict[0][1],\n",
    "                        press_predict[1],\n",
    "                        shear_predict[1][0],\n",
    "                        myProblem.pressure.variance_tol,\n",
    "                        myProblem.wall_stress_xz.variance_tol,\n",
    "                        ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The uncertainty tolerance is controlled via the `atol` and `rtol` parameters.\n",
    "Here, we see that the pressure prediction is very good (which is expected, as pressure only depends on density and the density is constant in the beginning).\n",
    "However, the shear stress prediction exceeds the uncertainty tolerance, such that active learning is necessary to augment the database and thereby the fit. Let's run the simulations for a few steps and see how the predictions evolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is usually what happens within the run() method but we can also trigger it manually\n",
    "for _ in range(50):\n",
    "    myProblem.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simulation step: ', myProblem.step)\n",
    "print('Database size: ', myProblem.pressure.database.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Let's plot the current prediction again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(2*_sx, 2*_sy))\n",
    "myProblem.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Looks good. We now run the simulation again up to 2500 steps as specified in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "myProblem.run(keep_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "The active learning simulation continued to extend the database. Let's check its growth as a function of the simulation time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(myProblem.pressure.history['step'],\n",
    "         myProblem.pressure.history['database_size'])\n",
    "\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Database size');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(2*_sx, 2*_sy))\n",
    "myProblem.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "After 2500 steps, the simulation results looks close to what we expect for the journal bearing case, but has not yet converged. Feel free to run it for longer (by modifying the `max_it` parameter)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
