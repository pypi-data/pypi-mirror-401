import json
from typing import TYPE_CHECKING, Any, cast

from anthropic.types import (
    ContentBlockDeltaEvent,
    ContentBlockStartEvent,
    ContentBlockStopEvent,
    Message,
    MessageStopEvent,
)
from anthropic.types.model_info import ModelInfo as AnthropicModelInfo

from any_llm.exceptions import UnsupportedParameterError
from any_llm.logging import logger
from any_llm.types.completion import (
    ChatCompletion,
    ChatCompletionChunk,
    ChatCompletionMessage,
    ChatCompletionMessageFunctionToolCall,
    ChatCompletionMessageToolCall,
    Choice,
    CompletionParams,
    CompletionUsage,
    Function,
    Reasoning,
)
from any_llm.types.model import Model

if TYPE_CHECKING:
    from openai.types.chat.chat_completion_message_custom_tool_call import (
        ChatCompletionMessageCustomToolCall,
    )
    from openai.types.chat.chat_completion_message_function_tool_call import (
        ChatCompletionMessageFunctionToolCall as OpenAIChatCompletionMessageFunctionToolCall,
    )

    ChatCompletionMessageToolCallType = (
        OpenAIChatCompletionMessageFunctionToolCall | ChatCompletionMessageCustomToolCall
    )

DEFAULT_MAX_TOKENS = 8192
REASONING_EFFORT_TO_THINKING_BUDGETS = {"minimal": 1024, "low": 2048, "medium": 8192, "high": 24576}


def _is_tool_call(message: dict[str, Any]) -> bool:
    """Check if the message is a tool call message."""
    return message["role"] == "assistant" and message.get("tool_calls") is not None


def _convert_images_for_anthropic(content: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """Convert images from OpenAI format to Anthropic format.
    - Parse the "content" field block by block
    - Convert image blocks to Anthropic format
    """
    converted_content = []
    for block in content:
        if block.get("type") == "image_url":
            converted_block: dict[str, Any] = {"type": "image"}
            url = block.get("image_url", {}).get("url", "")
            if url[:5] == "data:":
                mime_part = url[5:]
                semi_idx = mime_part.find(";")
                media_type = mime_part[:semi_idx] if semi_idx != -1 else mime_part
                converted_block["source"] = {
                    "type": "base64",
                    "media_type": media_type,
                    "data": url.split("base64,")[1],
                }
            else:
                converted_block["source"] = {"type": "url", "url": url}
            converted_content.append(converted_block)
        else:
            converted_content.append(block)
    return converted_content


def _convert_messages_for_anthropic(messages: list[dict[str, Any]]) -> tuple[str | None, list[dict[str, Any]]]:
    """Convert messages to Anthropic format.

    - Extract messages with `role=system`.
    - Replace `role=tool` with `role=user`, according to examples in https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/.
    - Handle multiple tool calls in a single assistant message.
    - Merge consecutive tool results into a single user message.
    """
    system_message = None
    filtered_messages: list[dict[str, Any]] = []

    for message in messages:
        if message["role"] == "system":
            if system_message is None:
                system_message = message["content"]
            else:
                system_message += "\n" + message["content"]
        else:
            # Handle messages inside agent loop.
            # See https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview#tool-use-examples
            if _is_tool_call(message):
                # Convert ALL tool calls from the assistant message
                tool_use_blocks = []
                for tool_call in message["tool_calls"]:
                    tool_use_blocks.append(
                        {
                            "type": "tool_use",
                            "id": tool_call["id"],
                            "name": tool_call["function"]["name"],
                            "input": json.loads(tool_call["function"]["arguments"]),
                        }
                    )
                message = {
                    "role": "assistant",
                    "content": tool_use_blocks,
                }
            elif message["role"] == "tool":
                # Use tool_call_id from the message itself
                tool_use_id = message.get("tool_call_id", "")
                tool_result = {"type": "tool_result", "tool_use_id": tool_use_id, "content": message["content"]}

                # Check if the previous message is already a user message with tool_results
                # If so, merge this tool_result into it
                if (
                    filtered_messages
                    and filtered_messages[-1]["role"] == "user"
                    and isinstance(filtered_messages[-1]["content"], list)
                    and filtered_messages[-1]["content"]
                    and filtered_messages[-1]["content"][0].get("type") == "tool_result"
                ):
                    filtered_messages[-1]["content"].append(tool_result)
                    continue

                message = {
                    "role": "user",
                    "content": [tool_result],
                }

            if "content" in message and isinstance(message["content"], list):
                message["content"] = _convert_images_for_anthropic(message["content"])

            filtered_messages.append(message)

    return system_message, filtered_messages


def _create_openai_chunk_from_anthropic_chunk(chunk: Any, model_id: str) -> ChatCompletionChunk:
    """Convert Anthropic streaming chunk to OpenAI ChatCompletionChunk format."""
    chunk_dict = {
        "id": f"chatcmpl-{hash(str(chunk))}",
        "object": "chat.completion.chunk",
        "created": 0,
        "model": model_id,
        "choices": [],
        "usage": None,
    }

    delta: dict[str, Any] = {}
    finish_reason = None

    if isinstance(chunk, ContentBlockStartEvent):
        if chunk.content_block.type == "text":
            delta = {"content": ""}
        elif chunk.content_block.type == "tool_use":
            delta = {
                "tool_calls": [
                    {
                        "index": 0,
                        "id": chunk.content_block.id,
                        "type": "function",
                        "function": {"name": chunk.content_block.name, "arguments": ""},
                    }
                ]
            }
        elif chunk.content_block.type == "thinking":
            delta = {"reasoning": {"content": ""}}

    elif isinstance(chunk, ContentBlockDeltaEvent):
        if chunk.delta.type == "text_delta":
            delta = {"content": chunk.delta.text}
        elif chunk.delta.type == "input_json_delta":
            delta = {
                "tool_calls": [
                    {
                        "index": 0,
                        "function": {"arguments": chunk.delta.partial_json},
                    }
                ]
            }
        elif chunk.delta.type == "thinking_delta":
            delta = {"reasoning": {"content": chunk.delta.thinking}}

    elif isinstance(chunk, ContentBlockStopEvent):
        if hasattr(chunk, "content_block") and chunk.content_block.type == "tool_use":
            finish_reason = "tool_calls"
        else:
            finish_reason = None

    elif isinstance(chunk, MessageStopEvent):
        finish_reason = "stop"
        if hasattr(chunk, "message") and chunk.message.usage:
            chunk_dict["usage"] = {
                "prompt_tokens": chunk.message.usage.input_tokens,
                "completion_tokens": chunk.message.usage.output_tokens,
                "total_tokens": chunk.message.usage.input_tokens + chunk.message.usage.output_tokens,
            }

    choice = {
        "index": 0,
        "delta": delta,
        "finish_reason": finish_reason,
        "logprobs": None,
    }

    chunk_dict["choices"] = [choice]

    return ChatCompletionChunk.model_validate(chunk_dict)


def _convert_response(response: Message) -> ChatCompletion:
    """Convert Anthropic Message to OpenAI ChatCompletion format."""
    finish_reason_raw = response.stop_reason or "end_turn"
    finish_reason_map = {"end_turn": "stop", "max_tokens": "length", "tool_use": "tool_calls"}
    finish_reason = finish_reason_map.get(finish_reason_raw, "stop")

    content_parts: list[str] = []
    tool_calls: list[ChatCompletionMessageFunctionToolCall | ChatCompletionMessageToolCall] = []
    reasoning_content: str | None = None
    for content_block in response.content:
        if content_block.type == "text":
            content_parts.append(content_block.text)
        elif content_block.type == "tool_use":
            tool_calls.append(
                ChatCompletionMessageFunctionToolCall(
                    id=content_block.id,
                    type="function",
                    function=Function(
                        name=content_block.name,
                        arguments=json.dumps(content_block.input),
                    ),
                )
            )
        elif content_block.type == "thinking":
            if reasoning_content is None:
                reasoning_content = content_block.thinking
            else:
                reasoning_content += content_block.thinking
        else:
            msg = f"Unsupported content block type: {content_block.type}"
            raise ValueError(msg)

    message = ChatCompletionMessage(
        role="assistant",
        content="".join(content_parts),
        reasoning=Reasoning(content=reasoning_content) if reasoning_content else None,
        tool_calls=cast("list[ChatCompletionMessageToolCallType] | None", tool_calls or None),
    )

    usage = CompletionUsage(
        completion_tokens=response.usage.output_tokens,
        prompt_tokens=response.usage.input_tokens,
        total_tokens=response.usage.input_tokens + response.usage.output_tokens,
    )

    from typing import Literal

    choice = Choice(
        index=0,
        finish_reason=cast(
            "Literal['stop', 'length', 'tool_calls', 'content_filter', 'function_call']", finish_reason or "stop"
        ),
        message=message,
    )

    created_ts = int(response.created_at.timestamp()) if hasattr(response, "created_at") else 0

    return ChatCompletion(
        id=response.id,
        model=response.model,
        created=created_ts,
        object="chat.completion",
        choices=[choice],
        usage=usage,
    )


def _convert_tool_spec(openai_tools: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """Convert OpenAI tool specification to Anthropic format."""
    generic_tools = []

    for tool in openai_tools:
        if tool.get("type") != "function":
            continue

        function = tool["function"]
        generic_tool = {
            "name": function["name"],
            "description": function.get("description", ""),
            "parameters": function.get("parameters", {}),
        }
        generic_tools.append(generic_tool)

    anthropic_tools = []
    for tool in generic_tools:
        anthropic_tool = {
            "name": tool["name"],
            "description": tool["description"],
            "input_schema": {
                "type": "object",
                "properties": tool["parameters"]["properties"],
                "required": tool["parameters"].get("required", []),
            },
        }
        anthropic_tools.append(anthropic_tool)

    return anthropic_tools


def _convert_tool_choice(params: CompletionParams) -> dict[str, Any]:
    parallel_tool_calls = params.parallel_tool_calls
    if parallel_tool_calls is None:
        parallel_tool_calls = True
    tool_choice = params.tool_choice or "any"
    if tool_choice == "required":
        tool_choice = "any"
    elif isinstance(tool_choice, dict):
        if tool_choice_type := tool_choice.get("type"):
            if tool_choice_type in ("custom", "function"):
                return {"type": "tool", "name": tool_choice[tool_choice_type]["name"]}
        msg = f"Unsupported tool_choice format: {tool_choice}"
        raise ValueError(msg)
    return {"type": tool_choice, "disable_parallel_tool_use": not parallel_tool_calls}


def _convert_params(params: CompletionParams, **kwargs: Any) -> dict[str, Any]:
    """Convert CompletionParams to kwargs for Anthropic API."""
    provider_name: str = kwargs.pop("provider_name")
    result_kwargs: dict[str, Any] = kwargs.copy()

    if params.response_format:
        msg = "response_format"
        raise UnsupportedParameterError(
            msg,
            provider_name,
            "Check the following links:\n- https://docs.anthropic.com/en/docs/test-and-evaluate/strengthen-guardrails/increase-consistency\n- https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview#json-mode",
        )
    if params.max_tokens is None:
        logger.warning(f"max_tokens is required for Anthropic, setting to {DEFAULT_MAX_TOKENS}")
        params.max_tokens = DEFAULT_MAX_TOKENS

    if params.tools:
        params.tools = _convert_tool_spec(params.tools)

    if params.tool_choice or params.parallel_tool_calls:
        params.tool_choice = _convert_tool_choice(params)

    if params.reasoning_effort is None or params.reasoning_effort == "none":
        result_kwargs["thinking"] = {"type": "disabled"}
    elif params.reasoning_effort != "auto":
        result_kwargs["thinking"] = {
            "type": "enabled",
            "budget_tokens": REASONING_EFFORT_TO_THINKING_BUDGETS[params.reasoning_effort],
        }

    result_kwargs.update(
        params.model_dump(
            exclude_none=True,
            exclude={
                "model_id",
                "messages",
                "reasoning_effort",
                "response_format",
                "parallel_tool_calls",
            },
        )
    )
    result_kwargs["model"] = params.model_id

    system_message, filtered_messages = _convert_messages_for_anthropic(params.messages)
    if system_message:
        result_kwargs["system"] = system_message
    result_kwargs["messages"] = filtered_messages

    return result_kwargs


def _convert_models_list(models_list: list[AnthropicModelInfo]) -> list[Model]:
    """Convert Anthropic models list to OpenAI format."""
    return [
        Model(id=model.id, object="model", created=int(model.created_at.timestamp()), owned_by="anthropic")
        for model in models_list
    ]
