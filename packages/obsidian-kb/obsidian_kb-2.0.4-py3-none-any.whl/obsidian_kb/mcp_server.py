"""MCP —Å–µ—Ä–≤–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Claude Desktop."""

import asyncio
import json
import logging
from contextlib import asynccontextmanager
from functools import wraps
from pathlib import Path
from typing import AsyncIterator

from fastmcp import FastMCP

from obsidian_kb.config import settings
from obsidian_kb.diagnostics import send_notification
from obsidian_kb.embedding_cache import EmbeddingCache
from obsidian_kb.indexing_utils import index_with_cache
from obsidian_kb.search_optimizer import AgentQueryNormalizer
from obsidian_kb.service_container import get_service_container
from obsidian_kb.interfaces import RipgrepMatch
from obsidian_kb.types import (
    HealthStatus,
    RetrievalGranularity,
    SearchRequest,
    VaultNotFoundError,
)
from obsidian_kb.vault_indexer import VaultIndexer

logger = logging.getLogger(__name__)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å–µ—Ä–≤–∏—Å–æ–≤ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ª–µ–Ω–∏–≤–æ —á–µ—Ä–µ–∑ get_service_container()
# –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–±–µ–∂–∞—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è

# MCP —Å–µ—Ä–≤–µ—Ä —Å–æ–∑–¥–∞—ë—Ç—Å—è –Ω–∏–∂–µ –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è lifespan —Ñ—É–Ω–∫—Ü–∏–∏
# –ó–¥–µ—Å—å —Ç–æ–ª—å–∫–æ forward declaration –¥–ª—è type hints
# Rate limiter –∏ job_queue —Ç–µ–ø–µ—Ä—å —É–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —á–µ—Ä–µ–∑ ServiceContainer
# –°–º. get_service_container().mcp_rate_limiter –∏ get_service_container().job_queue


def get_job_queue():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á.

    Returns:
        BackgroundJobQueue –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞
    """
    return get_service_container().job_queue


def set_job_queue(job_queue):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á.

    Args:
        job_queue: –≠–∫–∑–µ–º–ø–ª—è—Ä BackgroundJobQueue
    """
    get_service_container().set_job_queue(job_queue)


def with_rate_limit(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è rate limiting –∫ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º.
    
    Args:
        func: –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—ë—Ä—Ç–∫–∏
        
    Returns:
        –û–±—ë—Ä–Ω—É—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å rate limiting
    """
    @wraps(func)
    async def wrapper(*args, **kwargs):
        if get_service_container().mcp_rate_limiter:
            await get_service_container().mcp_rate_limiter.acquire()
        return await func(*args, **kwargs)
    return wrapper


@asynccontextmanager
async def lifespan(app: FastMCP) -> AsyncIterator[None]:
    """Lifespan context manager –¥–ª—è MCP —Å–µ—Ä–≤–µ—Ä–∞.

    –£–ø—Ä–∞–≤–ª—è–µ—Ç –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º —Ñ–æ–Ω–æ–≤—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤:
    - BackgroundJobQueue
    - ChangeMonitorService
    """
    from obsidian_kb.indexing.job_queue import BackgroundJobQueue
    from obsidian_kb.indexing.change_monitor import ChangeMonitorService
    from obsidian_kb.config.manager import get_config_manager

    job_queue = None
    change_monitor = None

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–∫ task (—Ñ—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –Ω–∏–∂–µ)
        asyncio.create_task(_background_startup_checks())

        # –°–æ–∑–¥–∞—ë–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á
        job_queue = BackgroundJobQueue(max_workers=2)
        await job_queue.start()

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—á–µ—Ä–µ–¥—å –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∏–∑ MCP –∫–æ–º–∞–Ω–¥
        set_job_queue(job_queue)

        # –°–æ–∑–¥–∞—ë–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä –∏–∑–º–µ–Ω–µ–Ω–∏–π
        config_manager = get_config_manager()
        change_monitor = ChangeMonitorService(
            job_queue=job_queue,
            config_manager=config_manager,
            enabled=True,
            polling_interval=300,  # 5 –º–∏–Ω—É—Ç
            debounce_seconds=10.0,  # 10 —Å–µ–∫—É–Ω–¥
        )
        await change_monitor.start()

        logger.info("Background services (JobQueue, ChangeMonitor) started")

        yield  # –°–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç

    finally:
        # Graceful shutdown
        if change_monitor:
            await change_monitor.stop()
        if job_queue:
            await job_queue.stop()
        set_job_queue(None)

        # Cleanup service container resources (close aiohttp sessions/connectors)
        await get_service_container().cleanup()

        logger.info("Background services stopped")


# –°–æ–∑–¥–∞—ë–º MCP —Å–µ—Ä–≤–µ—Ä —Å lifespan
mcp = FastMCP("obsidian-kb", lifespan=lifespan)

# ============================================================================
# Auto-registration of MCPTool classes from mcp/tools/ directory
# ============================================================================
# New tools should be added as MCPTool subclasses in src/obsidian_kb/mcp/tools/
# They will be automatically discovered and registered here.
# ============================================================================

from obsidian_kb.mcp.registry import ToolRegistry

# Create registry and discover tools from mcp/tools/ directory
_tool_registry = ToolRegistry()
_discovered_tools_count = _tool_registry.discover()
logger.info(f"Auto-discovered {_discovered_tools_count} MCP tools from mcp/tools/")

# Register all discovered tools with FastMCP
_tool_registry.register_all(mcp)

# ============================================================================
# Legacy tool registration (for backward compatibility)
# These tools are registered using the old pattern and will be migrated
# to MCPTool classes incrementally.
# ============================================================================

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º indexing tools
from obsidian_kb.mcp_tools.indexing_tools import (
    enrich_document,
    index_documents,
    index_status,
    preview_chunks,
    reindex_vault,
    register_mcp,
)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º provider tools
from obsidian_kb.mcp_tools.provider_tools import (
    estimate_cost,
    list_providers,
    list_yandex_models,
    provider_health,
    set_provider,
    test_provider,
)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º quality tools
from obsidian_kb.mcp_tools.quality_tools import (
    audit_index,
    cost_report,
    index_coverage,
    performance_report,
    test_retrieval,
)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç mcp –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ indexing_tools
register_mcp(mcp)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
# Indexing tools
mcp.tool()(index_documents)
mcp.tool()(reindex_vault)
mcp.tool()(index_status)
mcp.tool()(preview_chunks)
mcp.tool()(enrich_document)

# Provider tools
mcp.tool()(list_providers)
mcp.tool()(list_yandex_models)
mcp.tool()(set_provider)
mcp.tool()(test_provider)
mcp.tool()(provider_health)
mcp.tool()(estimate_cost)

# Quality tools
mcp.tool()(index_coverage)
mcp.tool()(test_retrieval)
mcp.tool()(audit_index)
mcp.tool()(cost_report)
mcp.tool()(performance_report)


@mcp.tool()
async def search_vault(vault_name: str, query: str, limit: int = 10, search_type: str = "hybrid", detail_level: str = "auto") -> str:
    """–ü–æ–∏—Å–∫ –≤ Obsidian vault (v5).

    Args:
        vault_name: –ò–º—è vault'–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (—Ç–µ–∫—Å—Ç + —Ñ–∏–ª—å—Ç—Ä—ã tags:, type:, created:)
        limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: 10)
        search_type: "vector" | "fts" | "hybrid" (default: hybrid)
        detail_level: –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            - "auto": –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
            - "full": –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            - "snippets": –¢–æ–ª—å–∫–æ snippets
            - "metadata": –¢–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ Markdown
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    from obsidian_kb.validation import validate_search_params
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    validate_search_params(query=query, vault_name=vault_name, limit=limit, search_type=search_type)
    
    try:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞–≥–µ–Ω—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        normalized_query = AgentQueryNormalizer.normalize(query)
        if normalized_query != query:
            logger.debug(f"Normalized agent query: '{query}' -> '{normalized_query}'")
        
        # –ú–∞–ø–ø–∏–Ω–≥ detail_level ‚Üí RetrievalGranularity
        granularity_map = {
            "auto": RetrievalGranularity.AUTO,
            "full": RetrievalGranularity.DOCUMENT,
            "snippets": RetrievalGranularity.CHUNK,
            "metadata": RetrievalGranularity.DOCUMENT,
        }
        granularity = granularity_map.get(detail_level, RetrievalGranularity.AUTO)
        
        # –°–æ–∑–¥–∞—ë–º SearchRequest
        request = SearchRequest(
            vault_name=vault_name,
            query=normalized_query,
            limit=limit,
            search_type=search_type,
            granularity=granularity,
            include_content=(detail_level not in ("metadata", "snippets")),
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ SearchService
        response = await get_service_container().search_service.search(request)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É –ø–æ–∏—Å–∫–∞
        try:
            avg_relevance = sum(r.score.value for r in response.results) / len(response.results) if response.results else 0.0
            await get_service_container().metrics_collector.record_search(
                vault_name=vault_name,
                query=query,
                search_type=search_type,
                result_count=response.total_found,
                execution_time_ms=response.execution_time_ms,
                avg_relevance_score=avg_relevance,
            )
        except Exception as e:
            logger.warning(f"Failed to record search metric: {e}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ö –∏–∑ response
            filters_info = response.filters_applied.copy() if response.filters_applied else {}
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É vault'–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            vault_stats_info = None
            try:
                stats = await get_service_container().db_manager.get_vault_stats(vault_name)
                vault_stats_info = {
                    "file_count": stats.file_count,
                    "chunk_count": stats.chunk_count,
                    "total_size_bytes": stats.total_size_bytes,
                    "tags_count": len(stats.tags),
                }
            except Exception as e:
                logger.debug(f"Failed to get vault stats for logging: {e}")
            
            get_service_container().search_logger.log_search(
                original_query=query,
                normalized_query=normalized_query,
                vault_name=vault_name,
                search_type=search_type,
                result_count=response.total_found,
                execution_time_ms=response.execution_time_ms,
                avg_relevance_score=avg_relevance if response.results else 0.0,
                empty_results=len(response.results) == 0,
                used_optimizer=False,  # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Ç–µ–ø–µ—Ä—å –≤–Ω—É—Ç—Ä–∏ SearchService
                source="mcp",
                requested_search_type=search_type,
                was_fallback=False,
                ollama_available=True,  # SearchService –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —ç—Ç–æ –≤–Ω—É—Ç—Ä–∏
                filters=filters_info if filters_info else None,
                limit=limit,
                vault_stats=vault_stats_info,
                embedding_model=settings.embedding_model,
            )
        except Exception as e:
            logger.warning(f"Failed to log search query: {e}")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–µ—Ä–µ–∑ Formatter
        return get_service_container().formatter.format_markdown(response)

    except VaultNotFoundError:
        logger.error(f"Vault not found: {vault_name}", exc_info=True)
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `index_vault` –¥–ª—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è."
    except Exception as e:
        logger.error(f"Error in search_vault: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}"


@mcp.tool()
async def search_multi_vault(vault_names: list[str], query: str, limit: int = 10) -> str:
    """–ü–æ–∏—Å–∫ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º vault'–∞–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ (v5).

    Args:
        vault_names: –°–ø–∏—Å–æ–∫ –∏–º—ë–Ω vault'–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: 10)

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–∑ –≤—Å–µ—Ö vault'–æ–≤
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    
    try:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞–≥–µ–Ω—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        normalized_query = AgentQueryNormalizer.normalize(query)
        if normalized_query != query:
            logger.debug(f"Normalized agent query: '{query}' -> '{normalized_query}'")
        
        # –°–æ–∑–¥–∞—ë–º SearchRequest
        request = SearchRequest(
            vault_name="",  # –ë—É–¥–µ—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω –¥–ª—è –∫–∞–∂–¥–æ–≥–æ vault
            query=normalized_query,
            limit=limit,
            search_type="hybrid",
            granularity=RetrievalGranularity.AUTO,
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ SearchService
        response = await get_service_container().search_service.search_multi_vault(vault_names, request)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É –ø–æ–∏—Å–∫–∞
        try:
            avg_relevance = sum(r.score.value for r in response.results) / len(response.results) if response.results else 0.0
            await get_service_container().metrics_collector.record_search(
                vault_name=None,  # None –¥–ª—è multi-vault –ø–æ–∏—Å–∫–∞
                query=query,
                search_type=response.strategy_used,
                result_count=response.total_found,
                execution_time_ms=response.execution_time_ms,
                avg_relevance_score=avg_relevance,
            )
        except Exception as e:
            logger.warning(f"Failed to record search metric: {e}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        try:
            filters_info = response.filters_applied.copy() if response.filters_applied else {}
            
            get_service_container().search_logger.log_search(
                original_query=query,
                normalized_query=normalized_query,
                vault_name=None,  # None –¥–ª—è multi-vault
                search_type=response.strategy_used,
                result_count=response.total_found,
                execution_time_ms=response.execution_time_ms,
                avg_relevance_score=avg_relevance if response.results else 0.0,
                empty_results=len(response.results) == 0,
                used_optimizer=False,
                source="mcp",
                requested_search_type="hybrid",
                was_fallback=False,
                ollama_available=True,
                filters=filters_info if filters_info else None,
                limit=limit,
                embedding_model=settings.embedding_model,
            )
        except Exception as e:
            logger.warning(f"Failed to log search query: {e}")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —á–µ—Ä–µ–∑ Formatter
        return get_service_container().formatter.format_markdown(response)

    except Exception as e:
        logger.error(f"Error in search_multi_vault: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}"


# NOTE: list_vaults and vault_stats are now auto-registered via MCPTool classes
# See: src/obsidian_kb/mcp/tools/list_vaults_tool.py and vault_stats_tool.py


@mcp.tool()
async def index_vault(vault_name: str, vault_path: str) -> str:
    """–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å vault (–∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å).

    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∞–≥–µ–Ω—Ç–∞.

    Args:
        vault_name: –ò–º—è vault'–∞
        vault_path: –ü—É—Ç—å –∫ vault'—É

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (ID –∑–∞–¥–∞—á–∏ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è)
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    try:
        vault_path_obj = Path(vault_path)
        if not vault_path_obj.exists():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å '{vault_path}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."

        if not vault_path_obj.is_dir():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å '{vault_path}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π."

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ
        indexed_files = None
        try:
            indexed_files = await get_service_container().db_manager.get_indexed_files(vault_name)
            only_changed = len(indexed_files) > 0
        except Exception as e:
            logger.debug(f"Failed to get indexed files, using full indexing: {e}")
            only_changed = False

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ
        job_queue = get_job_queue()
        if job_queue:
            from obsidian_kb.indexing.job_queue import JobPriority
            try:
                job = await job_queue.enqueue(
                    vault_name=vault_name,
                    vault_path=vault_path_obj,
                    operation="index_vault",
                    params={"only_changed": only_changed},
                    priority=JobPriority.NORMAL,
                )
                
                lines = [f"## –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è vault '{vault_name}' –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–µ\n"]
                lines.append(f"- **ID –∑–∞–¥–∞—á–∏:** `{job.id}`")
                lines.append(f"- **–°—Ç–∞—Ç—É—Å:** {job.status.value}")
                lines.append(f"- **–†–µ–∂–∏–º:** {'–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ' if only_changed else '–ü–æ–ª–Ω–æ–µ'}")
                lines.append(f"\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `get_job_status` –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.")
                return "\n".join(lines)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ñ–æ–Ω–æ–≤–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}", exc_info=True)
                return f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}"
        else:
            # Fallback: —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
            logger.warning("Job queue –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –≤—ã–ø–æ–ª–Ω—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é")
            indexer = VaultIndexer(vault_path_obj, vault_name)
            embedding_cache = EmbeddingCache()
            chunks, embeddings, stats = await index_with_cache(
                vault_name=vault_name,
                indexer=indexer,
                embedding_service=get_service_container().embedding_service,
                db_manager=get_service_container().db_manager,
                embedding_cache=embedding_cache,
                only_changed=only_changed,
                indexed_files=indexed_files,
            )

            if not chunks:
                if only_changed:
                    return f"Vault '{vault_name}': –≤—Å–µ —Ñ–∞–π–ª—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã, –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è."
                return f"Vault '{vault_name}' –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è."

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            await get_service_container().db_manager.upsert_chunks(vault_name, chunks, embeddings)

            file_count = len(set(c.file_path for c in chunks))
            cache_info = f" (–∫—ç—à: {stats.get('cached', 0)}, –≤—ã—á–∏—Å–ª–µ–Ω–æ: {stats.get('computed', 0)})" if stats else ""
            return f"Vault '{vault_name}' —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω: {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {file_count} —Ñ–∞–π–ª–æ–≤{cache_info}."

    except Exception as e:
        logger.error(f"Error in index_vault: {e}")
        return f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è: {e}"


@mcp.tool()
async def get_job_status(job_id: str | None = None, vault_name: str | None = None) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.

    Args:
        job_id: ID –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        vault_name: –§–∏–ª—å—Ç—Ä –ø–æ vault'—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏(–µ–π) –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        job_queue = get_job_queue()
        if not job_queue:
            return "–û—à–∏–±–∫–∞: –û—á–µ—Ä–µ–¥—å —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."

        if job_id:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É
            job = await job_queue.get_job_status(job_id)
            if not job:
                return f"–ó–∞–¥–∞—á–∞ —Å ID '{job_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."

            lines = [f"## –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏: {job_id}\n"]
            lines.append(f"- **Vault:** {job.vault_name}")
            lines.append(f"- **–û–ø–µ—Ä–∞—Ü–∏—è:** {job.operation}")
            lines.append(f"- **–°—Ç–∞—Ç—É—Å:** {job.status.value}")
            lines.append(f"- **–ü—Ä–æ–≥—Ä–µ—Å—Å:** {job.progress * 100:.1f}%")
            lines.append(f"- **–ú–æ–∂–Ω–æ –æ—Ç–º–µ–Ω–∏—Ç—å:** {'–¥–∞' if job.cancellable else '–Ω–µ—Ç'}")
            lines.append(f"- **–°–æ–∑–¥–∞–Ω–∞:** {job.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
            
            if job.started_at:
                lines.append(f"- **–ù–∞—á–∞—Ç–∞:** {job.started_at.strftime('%Y-%m-%d %H:%M:%S')}")
            if job.completed_at:
                lines.append(f"- **–ó–∞–≤–µ—Ä—à–µ–Ω–∞:** {job.completed_at.strftime('%Y-%m-%d %H:%M:%S')}")
            if job.error:
                lines.append(f"- **–û—à–∏–±–∫–∞:** {job.error}")
            if job.result:
                result = job.result
                lines.append(f"\n### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                lines.append(f"- **–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {result.documents_processed}/{result.documents_total}")
                lines.append(f"- **–ß–∞–Ω–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ:** {result.chunks_created}")
                lines.append(f"- **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {result.duration_seconds:.1f} —Å–µ–∫")
                if result.errors:
                    lines.append(f"- **–û—à–∏–±–æ–∫:** {len(result.errors)}")
                    for error in result.errors[:3]:
                        lines.append(f"  - {error[:100]}")
                    if len(result.errors) > 3:
                        lines.append(f"  - ... –∏ –µ—â—ë {len(result.errors) - 3}")
                if result.warnings:
                    lines.append(f"- **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π:** {len(result.warnings)}")
                    for warning in result.warnings[:3]:
                        lines.append(f"  - {warning}")

            # Phase 2: Enrichment —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            enrichment_stats = job.enrichment_stats or (job.result.enrichment_stats if job.result else None)
            if enrichment_stats:
                lines.append(f"\n### –û–±–æ–≥–∞—â–µ–Ω–∏–µ (Enrichment)")
                lines.append(f"- **–í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤:** {enrichment_stats.total_chunks}")
                lines.append(f"- **–£—Å–ø–µ—à–Ω–æ –æ–±–æ–≥–∞—â–µ–Ω–æ:** {enrichment_stats.enriched_ok}")
                if enrichment_stats.enriched_fallback > 0:
                    fallback_pct = (enrichment_stats.enriched_fallback / enrichment_stats.total_chunks * 100) if enrichment_stats.total_chunks > 0 else 0
                    lines.append(f"- **‚ö†Ô∏è Fallback (–±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞):** {enrichment_stats.enriched_fallback} ({fallback_pct:.1f}%)")
                lines.append(f"- **–£—Å–ø–µ—à–Ω–æ—Å—Ç—å:** {enrichment_stats.success_rate:.1f}%")
                if enrichment_stats.errors:
                    lines.append(f"- **–û—à–∏–±–æ–∫ enrichment:** {len(enrichment_stats.errors)}")
                    for error in enrichment_stats.errors[:3]:
                        lines.append(f"  - {error[:80]}")
                    if len(enrichment_stats.errors) > 3:
                        lines.append(f"  - ... –∏ –µ—â—ë {len(enrichment_stats.errors) - 3}")

            return "\n".join(lines)
        else:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
            from obsidian_kb.indexing.job_queue import JobStatus
            jobs = await job_queue.list_jobs(vault_name=vault_name)
            
            if not jobs:
                filter_text = f" –¥–ª—è vault '{vault_name}'" if vault_name else ""
                return f"## –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏{filter_text}\n\n*–ó–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ*"

            lines = [f"## –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏"]
            if vault_name:
                lines[0] += f" (vault: {vault_name})"
            lines.append("")

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
            status_groups: dict[JobStatus, list] = {}
            for job in jobs:
                if job.status not in status_groups:
                    status_groups[job.status] = []
                status_groups[job.status].append(job)

            status_order = [JobStatus.RUNNING, JobStatus.PENDING, JobStatus.COMPLETED, JobStatus.FAILED, JobStatus.CANCELLED]
            status_names = {
                JobStatus.RUNNING: "–í—ã–ø–æ–ª–Ω—è—é—Ç—Å—è",
                JobStatus.PENDING: "–û–∂–∏–¥–∞—é—Ç",
                JobStatus.COMPLETED: "–ó–∞–≤–µ—Ä—à–µ–Ω—ã",
                JobStatus.FAILED: "–û—à–∏–±–∫–∏",
                JobStatus.CANCELLED: "–û—Ç–º–µ–Ω–µ–Ω—ã",
            }

            for status in status_order:
                if status not in status_groups:
                    continue
                
                jobs_list = status_groups[status]
                lines.append(f"### {status_names[status]} ({len(jobs_list)})")
                
                for job in jobs_list[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 –∑–∞–¥–∞—á –Ω–∞ —Å—Ç–∞—Ç—É—Å
                    lines.append(f"\n**{job.id}**")
                    lines.append(f"- Vault: {job.vault_name}")
                    lines.append(f"- –û–ø–µ—Ä–∞—Ü–∏—è: {job.operation}")
                    lines.append(f"- –ü—Ä–æ–≥—Ä–µ—Å—Å: {job.progress * 100:.1f}%")
                    lines.append(f"- –ú–æ–∂–Ω–æ –æ—Ç–º–µ–Ω–∏—Ç—å: {'–¥–∞' if job.cancellable else '–Ω–µ—Ç'}")
                    lines.append(f"- –°–æ–∑–¥–∞–Ω–∞: {job.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
                    if job.error:
                        lines.append(f"- –û—à–∏–±–∫–∞: {job.error}")
                    # Phase 2: –ö—Ä–∞—Ç–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ enrichment –¥–ª—è —Å–ø–∏—Å–∫–∞
                    enrichment = job.enrichment_stats or (job.result.enrichment_stats if job.result else None)
                    if enrichment and enrichment.total_chunks > 0:
                        if enrichment.enriched_fallback > 0:
                            lines.append(f"- Enrichment: {enrichment.enriched_ok}/{enrichment.total_chunks} ‚ö†Ô∏è ({enrichment.enriched_fallback} fallback)")
                        else:
                            lines.append(f"- Enrichment: {enrichment.enriched_ok}/{enrichment.total_chunks} ‚úì")
                
                if len(jobs_list) > 10:
                    lines.append(f"\n*... –∏ –µ—â—ë {len(jobs_list) - 10} –∑–∞–¥–∞—á*")
                lines.append("")

            return "\n".join(lines)

    except Exception as e:
        logger.error(f"Error in get_job_status: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏: {e}"


@mcp.tool()
async def cancel_job(job_id: str) -> str:
    """–û—Ç–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.

    –†–µ–∞–ª–∏–∑—É–µ—Ç graceful shutdown:
    - –î–ª—è –æ–∂–∏–¥–∞—é—â–∏—Ö –∑–∞–¥–∞—á (pending): –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –æ—Ç–º–µ–Ω–∞
    - –î–ª—è –≤—ã–ø–æ–ª–Ω—è—é—â–∏—Ö—Å—è –∑–∞–¥–∞—á (running): –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è
    - –ß–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è (–Ω–µ –æ—Ç–∫–∞—Ç—ã–≤–∞—é—Ç—Å—è)

    Args:
        job_id: ID –∑–∞–¥–∞—á–∏ –∏–∑ get_job_status()

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–º–µ–Ω—ã –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        job_queue = get_job_queue()
        if not job_queue:
            return "–û—à–∏–±–∫–∞: –û—á–µ—Ä–µ–¥—å —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞."

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞—á–µ –¥–æ –æ—Ç–º–µ–Ω—ã
        job = await job_queue.get_job_status(job_id)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—Ç–º–µ–Ω—É
        result = await job_queue.cancel_job(job_id)

        if result == "not_found":
            return f"‚ùå –ó–∞–¥–∞—á–∞ `{job_id}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."

        if result == "already_completed":
            return (
                f"‚ö†Ô∏è –ó–∞–¥–∞—á–∞ `{job_id}` —É–∂–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n\n"
                f"–°—Ç–∞—Ç—É—Å: {job.status.value if job else 'unknown'}"
            )

        if result == "cancelled":
            lines = ["## –ó–∞–¥–∞—á–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞\n"]
            lines.append(f"- **Job ID:** `{job_id}`")
            if job:
                lines.append(f"- **Vault:** {job.vault_name}")
                lines.append(f"- **–û–ø–µ—Ä–∞—Ü–∏—è:** {job.operation}")
                lines.append(f"- **–ü—Ä–æ–≥—Ä–µ—Å—Å –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ:** {job.progress:.1%}")
                lines.append(f"- **–ú–æ–∂–Ω–æ –ª–∏ –æ—Ç–º–µ–Ω–∏—Ç—å (cancellable):** {job.cancellable}")
            lines.append("\n*–ß–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.*")
            return "\n".join(lines)

        return f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–º–µ–Ω—ã: {result}"

    except Exception as e:
        logger.error(f"Error in cancel_job: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –æ—Ç–º–µ–Ω—ã –∑–∞–¥–∞—á–∏: {e}"


# NOTE: system_health is now auto-registered via MCPTool class
# See: src/obsidian_kb/mcp/tools/system_health_tool.py


@mcp.tool()
async def get_metrics(days: int = 7, limit: int = 10, vault_name: str | None = None) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –∑–∞ –ø–µ—Ä–∏–æ–¥.

    Args:
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (default: 7)
        limit: –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤/vault'–æ–≤ (default: 10)
        vault_name: –§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É vault'—É (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–≤–æ–¥–∫–∞ –º–µ—Ç—Ä–∏–∫ –≤ markdown
    """
    try:
        summary = await get_service_container().metrics_collector.get_summary(days=days, limit=limit, vault_name=vault_name)

        vault_filter_text = f" –¥–ª—è vault '{vault_name}'" if vault_name else ""
        lines = [f"## üìä –ú–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è obsidian-kb{vault_filter_text}\n"]
        lines.append(f"**–ü–µ—Ä–∏–æ–¥:** {summary.period_start.strftime('%Y-%m-%d')} - {summary.period_end.strftime('%Y-%m-%d')}\n")

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        lines.append("### –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
        lines.append(f"- **–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤:** {summary.total_searches}")
        lines.append(f"- **–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {summary.avg_execution_time_ms:.2f} –º—Å")
        lines.append(f"- **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö vault'–æ–≤:** {summary.total_vaults_searched}")
        lines.append(f"- **–ü—É—Å—Ç—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:** {summary.empty_results_count} ({summary.empty_results_percentage:.1f}%)")
        lines.append(f"- **–°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å:** {summary.avg_relevance_score:.3f}\n")

        # –ü–æ —Ç–∏–ø–∞–º –ø–æ–∏—Å–∫–∞
        if summary.searches_by_type:
            lines.append("### –ü–æ —Ç–∏–ø–∞–º –ø–æ–∏—Å–∫–∞\n")
            for search_type, count in sorted(summary.searches_by_type.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / summary.total_searches * 100) if summary.total_searches > 0 else 0
                lines.append(f"- **{search_type}:** {count} ({percentage:.1f}%)")
            lines.append("")

        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        if summary.popular_queries:
            lines.append("### –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã\n")
            for idx, (query, count) in enumerate(summary.popular_queries, 1):
                lines.append(f"{idx}. `{query[:50]}{'...' if len(query) > 50 else ''}` ‚Äî {count} —Ä–∞–∑")
            lines.append("")

        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ vault'—ã
        if summary.popular_vaults:
            lines.append("### –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ vault'—ã\n")
            for idx, (vault, count) in enumerate(summary.popular_vaults, 1):
                lines.append(f"{idx}. **{vault}** ‚Äî {count} –∑–∞–ø—Ä–æ—Å–æ–≤")
            lines.append("")

        # –ó–∞–ø—Ä–æ—Å—ã –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if summary.queries_with_no_results:
            lines.append("### –ó–∞–ø—Ä–æ—Å—ã –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n")
            for idx, (query, count) in enumerate(summary.queries_with_no_results, 1):
                lines.append(f"{idx}. `{query[:50]}{'...' if len(query) > 50 else ''}` ‚Äî {count} —Ä–∞–∑")
            lines.append("")

        if summary.total_searches == 0:
            lines.append("*–ú–µ—Ç—Ä–∏–∫–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç*")

        return "\n".join(lines)

    except Exception as e:
        logger.error(f"Error getting metrics: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}"


@mcp.tool()
async def add_vault_to_config(vault_path: str, vault_name: str | None = None, auto_index: bool = True) -> str:
    """–î–æ–±–∞–≤–∏—Ç—å vault –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é obsidian-kb.

    Args:
        vault_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ vault'–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∏–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã–º)
        vault_name: –ò–º—è vault'–∞. –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –∏–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        auto_index: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å vault –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è (default: True)

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è vault'–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    """
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—É—Ç—å –≤ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π
        vault_path_obj = Path(vault_path).resolve()
        
        if not vault_path_obj.exists():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å '{vault_path_obj}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."
        
        if not vault_path_obj.is_dir():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å '{vault_path_obj}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π."
        
        # –ï—Å–ª–∏ –∏–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if vault_name is None:
            vault_name = vault_path_obj.name
        
        config_path = settings.vaults_config
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ñ–∏–≥ –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
        if config_path.exists():
            try:
                with open(config_path, "r", encoding="utf-8") as f:
                    config = json.load(f)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥–∞: {e}, —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π")
                config = {"vaults": []}
        else:
            config = {"vaults": []}
        
        vaults = config.get("vaults", [])
        vault_path_str = str(vault_path_obj)
        is_new_vault = True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–≥–æ vault'–∞
        for v in vaults:
            if v.get("name") == vault_name:
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ vault'–∞
                v["path"] = vault_path_str
                is_new_vault = False
                break
            if v.get("path") == vault_path_str:
                existing_name = v.get("name")
                return f"Vault —Å –ø—É—Ç—ë–º '{vault_path_str}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–∏–º—è: '{existing_name}')."
        
        if is_new_vault:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π vault
            vaults.append({"name": vault_name, "path": vault_path_str})
        
        config["vaults"] = vaults
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        result_lines = ["## Vault –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é\n"]
        result_lines.append(f"- **–ò–º—è:** {vault_name}")
        result_lines.append(f"- **–ü—É—Ç—å:** {vault_path_str}")
        result_lines.append(f"- **–ö–æ–Ω—Ñ–∏–≥:** {config_path}")
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ vault'–∞ –≤ —Ñ–æ–Ω–µ
        if auto_index and is_new_vault:
            job_queue = get_job_queue()
            if job_queue:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –≤ —Ñ–æ–Ω–µ
                from obsidian_kb.indexing.job_queue import JobPriority
                try:
                    job = await job_queue.enqueue(
                        vault_name=vault_name,
                        vault_path=vault_path_obj,
                        operation="index_vault",
                        params={"only_changed": False},
                        priority=JobPriority.NORMAL,
                    )
                    result_lines.append(f"\n‚úÖ **–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–µ**")
                    result_lines.append(f"- **ID –∑–∞–¥–∞—á–∏:** `{job.id}`")
                    result_lines.append(f"- **–°—Ç–∞—Ç—É—Å:** {job.status.value}")
                    result_lines.append(f"\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `get_job_status` –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Ñ–æ–Ω–æ–≤–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}", exc_info=True)
                    result_lines.append(f"\n‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏:** {e}")
            else:
                # Fallback: —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
                result_lines.append(f"\n[–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ vault '{vault_name}'...]")
                try:
                    indexer = VaultIndexer(vault_path_obj, vault_name)
                    embedding_cache = EmbeddingCache()
                    
                    chunks, embeddings, stats = await index_with_cache(
                        vault_name=vault_name,
                        indexer=indexer,
                        embedding_service=get_service_container().embedding_service,
                        db_manager=get_service_container().db_manager,
                        embedding_cache=embedding_cache,
                        only_changed=False,
                        indexed_files=None,
                    )
                    
                    if chunks:
                        await get_service_container().db_manager.upsert_chunks(vault_name, chunks, embeddings)
                        file_count = len(set(c.file_path for c in chunks))
                        cache_info = f" (–∫—ç—à: {stats.get('cached', 0)}, –≤—ã—á–∏—Å–ª–µ–Ω–æ: {stats.get('computed', 0)})" if stats else ""
                        result_lines.append(f"\n‚úÖ **–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ:** {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {file_count} —Ñ–∞–π–ª–æ–≤{cache_info}")
                    else:
                        result_lines.append("\n‚ö†Ô∏è –ù–µ—Ç —á–∞–Ω–∫–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è vault '{vault_name}': {e}", exc_info=True)
                    result_lines.append(f"\n‚ö†Ô∏è **–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è:** {e}")
        elif not is_new_vault:
            result_lines.append("\n‚ÑπÔ∏è –ü—É—Ç—å –æ–±–Ω–æ–≤–ª—ë–Ω –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ vault'–∞")
        
        return "\n".join(result_lines)
    
    except Exception as e:
        logger.error(f"Error in add_vault_to_config: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è vault'–∞: {e}"


@mcp.tool()
async def check_vault_in_config(vault_path: str | None = None, vault_name: str | None = None) -> str:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –µ—Å—Ç—å –ª–∏ vault –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ obsidian-kb.

    Args:
        vault_path: –ü—É—Ç—å –∫ vault'—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∏–ª–∏ –∞–±—Å–æ–ª—é—Ç–Ω—ã–º)
        vault_name: –ò–º—è vault'–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

    Returns:
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–ª–∏—á–∏–∏ vault'–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    """
    try:
        if not vault_path and not vault_name:
            return "–û—à–∏–±–∫–∞: –£–∫–∞–∂–∏—Ç–µ –ª–∏–±–æ vault_path, –ª–∏–±–æ vault_name –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏."
        
        config_path = settings.vaults_config
        
        if not config_path.exists():
            return "–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. Vault'—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã."
        
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        
        vaults = config.get("vaults", [])
        
        if vault_path:
            vault_path_obj = Path(vault_path).resolve()
            vault_path_str = str(vault_path_obj)
            
            for v in vaults:
                if v.get("path") == vault_path_str:
                    return f"‚úÖ Vault –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:\n- **–ò–º—è:** {v.get('name')}\n- **–ü—É—Ç—å:** {v.get('path')}"
            
            return f"‚ùå Vault —Å –ø—É—Ç—ë–º '{vault_path_str}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."
        
        if vault_name:
            for v in vaults:
                if v.get("name") == vault_name:
                    return f"‚úÖ Vault –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:\n- **–ò–º—è:** {v.get('name')}\n- **–ü—É—Ç—å:** {v.get('path')}"
            
            return f"‚ùå Vault —Å –∏–º–µ–Ω–µ–º '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."
        
        return "–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É."
    
    except Exception as e:
        logger.error(f"Error in check_vault_in_config: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ vault'–∞: {e}"


# NOTE: list_configured_vaults and list_tags are now auto-registered via MCPTool classes
# See: src/obsidian_kb/mcp/tools/list_configured_vaults_tool.py and list_tags_tool.py


@mcp.tool()
async def list_doc_types(vault_name: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ vault'–µ –¥–ª—è –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è.
    
    Args:
        vault_name: –ò–º—è vault'–∞
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        # –í —Å—Ö–µ–º–µ v4 —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —Ç–∞–±–ª–∏—Ü–µ document_properties —Å –∫–ª—é—á–æ–º "type"
        properties_table = await get_service_container().db_manager._ensure_table(vault_name, "document_properties")
        db = get_service_container().db_manager._get_db()
        
        def _get_types() -> list[str]:
            try:
                arrow_table = properties_table.search().where("property_key = 'type'").to_arrow()
                
                if arrow_table.num_rows == 0:
                    return []
                
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                doc_types = arrow_table["property_value"].to_pylist()
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –∏ –ø–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
                unique_types = set(t for t in doc_types if t and t.strip())
                return sorted(unique_types)
            except Exception as e:
                logger.error(f"Error getting doc types: {e}")
                return []
        
        types_list = await asyncio.to_thread(_get_types)
        
        if not types_list:
            return f"## –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ vault: {vault_name}\n\n*–¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*"
        
        lines = [f"## –¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ vault: {vault_name}\n"]
        lines.append(f"*–ù–∞–π–¥–µ–Ω–æ {len(types_list)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤*\n")
        
        for doc_type in types_list:
            lines.append(f"- `{doc_type}`")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in list_doc_types: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}"


@mcp.tool()
async def list_links(vault_name: str, limit: int = 100) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö wikilinks –≤ vault'–µ –¥–ª—è –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        limit: –ú–∞–∫—Å–∏–º—É–º links –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ (default: 100)
    
    Returns:
        –°–ø–∏—Å–æ–∫ links –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        # –í —Å—Ö–µ–º–µ v4 links —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ —Ç–∞–±–ª–∏—Ü–µ chunks
        chunks_table = await get_service_container().db_manager._ensure_table(vault_name, "chunks")
        db = get_service_container().db_manager._get_db()
        
        def _get_links() -> list[str]:
            try:
                arrow_table = chunks_table.to_arrow()
                
                if arrow_table.num_rows == 0:
                    return []
                
                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ links –∏–∑ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
                links_list = arrow_table["links"].to_pylist()
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ links –∏–∑ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
                all_links = set()
                for links in links_list:
                    if isinstance(links, list):
                        all_links.update(links)
                
                return sorted(list(all_links))[:limit]
            except Exception as e:
                logger.error(f"Error getting links: {e}")
                return []
        
        links = await asyncio.to_thread(_get_links)
        
        if not links:
            return f"## Wikilinks –≤ vault: {vault_name}\n\n*Wikilinks –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*"
        
        lines = [f"## Wikilinks –≤ vault: {vault_name}\n"]
        lines.append(f"*–ù–∞–π–¥–µ–Ω–æ {len(links)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö links*\n")
        
        for link in links:
            lines.append(f"- `{link}`")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in list_links: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è links: {e}"


# ============================================================================
# Extended Query API Tools (v6)
# ============================================================================


@mcp.tool()
async def get_frontmatter(vault_name: str, file_path: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å frontmatter –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç –∫–æ—Ä–Ω—è vault)
    
    Returns:
        YAML frontmatter —Ñ–∞–π–ª–∞ –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
    
    Examples:
        get_frontmatter("naumen-cto", "People/–ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤.md")
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    
    try:
        api = get_service_container().frontmatter_api
        result = await api.get_frontmatter(vault_name, file_path)
        
        if result is None:
            return f"–§–∞–π–ª '{file_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ vault '{vault_name}'"
        
        import yaml
        lines = [f"## Frontmatter: {file_path}\n"]
        lines.append("```yaml")
        lines.append(yaml.dump(result, allow_unicode=True, default_flow_style=False))
        lines.append("```")
        
        return "\n".join(lines)
    except Exception as e:
        logger.error(f"Error getting frontmatter: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è frontmatter: {e}"


@mcp.tool()
async def get_vault_schema(
    vault_name: str,
    doc_type: str | None = None,
    top_values: int = 10,
) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ö–µ–º—É frontmatter vault'–∞ ‚Äî –≤—Å–µ –ø–æ–ª—è, –∏—Ö —Ç–∏–ø—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è.
    
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö vault'–∞ –∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–æ–ª–µ–π
    –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        doc_type: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ç–∏–ø–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞
        top_values: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—è (default: 10)
    
    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ö–µ–º–∞ –ø–æ–ª–µ–π —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏–π
    
    Examples:
        get_vault_schema("naumen-cto")  # –í—Å–µ –ø–æ–ª—è vault'–∞
        get_vault_schema("naumen-cto", "person")  # –¢–æ–ª—å–∫–æ –¥–ª—è type:person
        get_vault_schema("naumen-cto", "1-1", top_values=5)
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    
    try:
        api = get_service_container().frontmatter_api
        schema = await api.get_schema(vault_name, doc_type, top_values)
        
        type_filter = f" (type: {doc_type})" if doc_type else ""
        lines = [f"## –°—Ö–µ–º–∞ vault: {vault_name}{type_filter}\n"]
        lines.append(f"**–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {schema.total_documents}\n")
        
        if not schema.fields:
            lines.append("*–ü–æ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        lines.append("### –ü–æ–ª—è frontmatter\n")
        lines.append("| –ü–æ–ª–µ | –¢–∏–ø | –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ | –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö | –ü—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π |")
        lines.append("|------|-----|------------|------------|------------------|")
        
        for field_name, info in sorted(schema.fields.items()):
            examples = ", ".join(f"`{v}`" for v in info.unique_values[:5])
            if info.unique_count > 5:
                examples += f" ... (+{info.unique_count - 5})"
            
            lines.append(
                f"| {field_name} | {info.field_type} | {info.document_count} | "
                f"{info.unique_count} | {examples} |"
            )
        
        if schema.common_patterns:
            lines.append("\n### –ß–∞—Å—Ç—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–æ–ª–µ–π\n")
            for pattern in schema.common_patterns:
                lines.append(f"- {pattern}")
        
        return "\n".join(lines)
    except Exception as e:
        logger.error(f"Error getting vault schema: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ö–µ–º—ã vault'–∞: {e}"


@mcp.tool()
async def list_by_property(
    vault_name: str,
    property_key: str,
    property_value: str | None = None,
    limit: int = 50,
) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é —Å–≤–æ–π—Å—Ç–≤–∞ frontmatter.
    
    –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫–∞—Ç—å –ø–æ –ª—é–±–æ–º—É –ø–æ–ª—é frontmatter, –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º
    (type, tags). –ï—Å–ª–∏ property_value –Ω–µ —É–∫–∞–∑–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    —Å —ç—Ç–∏–º –ø–æ–ª–µ–º.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        property_key: –ò–º—è —Å–≤–æ–π—Å—Ç–≤–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä "status", "role", "project", "priority")
        property_value: –ó–Ω–∞—á–µ–Ω–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ (–µ—Å–ª–∏ None ‚Äî –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å —ç—Ç–∏–º –ø–æ–ª–µ–º)
        limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: 50)
    
    Returns:
        –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–º —Å–≤–æ–π—Å—Ç–≤–æ–º
    
    Examples:
        list_by_property("vault", "status", "in-progress")  # –î–æ–∫—É–º–µ–Ω—Ç—ã —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º
        list_by_property("vault", "role")  # –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø–æ–ª–µ–º role
        list_by_property("vault", "priority", "high", limit=10)
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    
    try:
        api = get_service_container().frontmatter_api
        results = await api.list_by_property(vault_name, property_key, property_value, limit)
        
        value_filter = f" = {property_value}" if property_value else ""
        lines = [f"## –î–æ–∫—É–º–µ–Ω—Ç—ã: {property_key}{value_filter}\n"]
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n")
        
        if not results:
            lines.append("*–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        for doc in results:
            title = doc.get("title") or doc.get("file_path", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
            file_path = doc.get("file_path", "")
            modified = doc.get("modified_at")
            modified_str = modified.strftime("%Y-%m-%d") if modified else "‚Äî"
            
            lines.append(f"- **{title}**")
            lines.append(f"  - –ü—É—Ç—å: `{file_path}`")
            lines.append(f"  - –ò–∑–º–µ–Ω—ë–Ω: {modified_str}")
        
        return "\n".join(lines)
    except Exception as e:
        logger.error(f"Error listing by property: {e}")
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Å–≤–æ–π—Å—Ç–≤—É: {e}"


@mcp.tool()
async def aggregate_by_property(
    vault_name: str,
    property_key: str,
    doc_type: str | None = None,
) -> str:
    """–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ —Å–≤–æ–π—Å—Ç–≤—É ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è.
    
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ vault'—É: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º,
    –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º, —Ä–æ–ª—è–º –∏ —Ç.–¥.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        property_key: –ò–º—è —Å–≤–æ–π—Å—Ç–≤–∞ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (status, priority, role, etc.)
        doc_type: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ç–∏–ø–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞
    
    Returns:
        –¢–∞–±–ª–∏—Ü–∞: –∑–Ω–∞—á–µ–Ω–∏–µ ‚Üí –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    
    Examples:
        aggregate_by_property("vault", "status")  # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
        aggregate_by_property("vault", "priority", "task")  # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –∑–∞–¥–∞—á
        aggregate_by_property("vault", "role", "person")  # –†–æ–ª–∏ –ª—é–¥–µ–π
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    
    try:
        api = get_service_container().frontmatter_api
        result = await api.aggregate_by_property(vault_name, property_key, doc_type)
        
        type_filter = f" (type: {doc_type})" if doc_type else ""
        lines = [f"## –ê–≥—Ä–µ–≥–∞—Ü–∏—è: {property_key}{type_filter}\n"]
        lines.append(f"**–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {result.total_documents}\n")
        
        if not result.values:
            lines.append("*–ó–Ω–∞—á–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        lines.append("| –ó–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ | % |")
        lines.append("|----------|------------|---|")
        
        total = result.total_documents
        for value, count in sorted(result.values.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total * 100) if total > 0 else 0
            lines.append(f"| {value} | {count} | {percentage:.1f}% |")
        
        if result.null_count > 0:
            percentage = (result.null_count / total * 100) if total > 0 else 0
            lines.append(f"| *(–ø—É—Å—Ç–æ)* | {result.null_count} | {percentage:.1f}% |")
        
        return "\n".join(lines)
    except Exception as e:
        logger.error(f"Error aggregating by property: {e}")
        return f"–û—à–∏–±–∫–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ —Å–≤–æ–π—Å—Ç–≤—É: {e}"


@mcp.tool()
async def dataview_query(
    vault_name: str,
    query: str | None = None,
    select: str = "*",
    from_type: str | None = None,
    from_path: str | None = None,
    where: str | None = None,
    sort_by: str | None = None,
    sort_order: str = "desc",
    limit: int = 50,
) -> str:
    """SQL-–ø–æ–¥–æ–±–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º vault'–∞ (Dataview-style).
    
    –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏–±–æ –ø–æ–ª–Ω—ã–π SQL-like —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ `query`,
    –ª–∏–±–æ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        query: –ü–æ–ª–Ω—ã–π SQL-like –∑–∞–ø—Ä–æ—Å (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
               –ü—Ä–∏–º–µ—Ä: "SELECT title, status FROM type:task WHERE status != done SORT BY priority DESC"
        select: –ü–æ–ª—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "*")
        from_type: –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
        from_path: –§–∏–ª—å—Ç—Ä –ø–æ –ø—É—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "Projects/Alpha")
        where: –£—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (status != done, priority > 2)
        sort_by: –ü–æ–ª–µ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        sort_order: –ü–æ—Ä—è–¥–æ–∫ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (asc/desc)
        limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: 50)
    
    Returns:
        –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        # –ü–æ–ª–Ω—ã–π SQL-like —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
        dataview_query("vault", query="SELECT * FROM type:1-1 WHERE status != done SORT BY date DESC")
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        dataview_query("vault", from_type="person", where="role = manager", sort_by="name")
        
        # –ö–æ–º–±–∏–Ω–∞—Ü–∏—è
        dataview_query("vault", select="title,status", from_path="Projects", where="status = active")
    """
    if get_service_container().mcp_rate_limiter:
        await get_service_container().mcp_rate_limiter.acquire()
    
    try:
        service = get_service_container().dataview_service
        
        if query:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π SQL-like —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
            result = await service.query_string(vault_name, query)
        else:
            # –°–æ–±–∏—Ä–∞–µ–º DataviewQuery –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            from obsidian_kb.interfaces import DataviewQuery
            from obsidian_kb.query.where_parser import WhereParser
            
            select_fields = [s.strip() for s in select.split(",")] if select != "*" else ["*"]
            where_conditions = WhereParser.parse(where) if where else None
            
            dv_query = DataviewQuery(
                select=select_fields,
                from_type=from_type,
                from_path=from_path,
                where=where_conditions,
                sort_by=sort_by,
                sort_order=sort_order,
                limit=limit,
            )
            result = await service.query(vault_name, dv_query)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = ["## Dataview Query Results\n"]
        lines.append(f"**–ó–∞–ø—Ä–æ—Å:** `{result.query_string}`")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {result.total_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        lines.append(f"**–í—Ä–µ–º—è:** {result.query_time_ms:.1f} –º—Å\n")
        
        if not result.documents:
            lines.append("*–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
        if result.documents:
            columns = list(result.documents[0].keys())
            # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
            columns = [c for c in columns if not c.startswith("_") and c != "document_id"]
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—É
            lines.append("| " + " | ".join(columns) + " |")
            lines.append("| " + " | ".join(["---"] * len(columns)) + " |")
            
            for doc in result.documents:
                values = []
                for col in columns:
                    val = doc.get(col, "")
                    if isinstance(val, list):
                        val = ", ".join(str(v) for v in val)
                    elif val is None:
                        val = "‚Äî"
                    else:
                        val = str(val)[:50]  # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    values.append(val)
                lines.append("| " + " | ".join(values) + " |")
        
        return "\n".join(lines)
    except Exception as e:
        logger.error(f"Error executing dataview query: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Dataview –∑–∞–ø—Ä–æ—Å–∞: {e}"


# NOTE: search_help is now auto-registered via MCPTool class
# See: src/obsidian_kb/mcp/tools/search_help_tool.py


@mcp.tool()
async def delete_vault(vault_name: str) -> str:
    """–£–¥–∞–ª–∏—Ç—å vault –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ (—É–¥–∞–ª—è–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ vault'–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö).

    –í–Ω–∏–º–∞–Ω–∏–µ: –≠—Ç–æ —É–¥–∞–ª–∏—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ vault'–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –Ω–æ –Ω–µ –∑–∞—Ç—Ä–æ–Ω–µ—Ç —Ñ–∞–π–ª—ã –≤ vault'–µ.

    Args:
        vault_name: –ò–º—è vault'–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —É–¥–∞–ª–µ–Ω–∏—è
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ vault
        try:
            await get_service_container().db_manager.get_vault_stats(vault_name)
        except VaultNotFoundError:
            return f"Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∏–Ω–¥–µ–∫—Å–µ. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è."

        # –û—á–∏—â–∞–µ–º –∫—ç—à embeddings
        embedding_cache = EmbeddingCache()
        try:
            await embedding_cache.clear_vault_cache(vault_name)
            logger.info(f"Cleared embedding cache for vault '{vault_name}' before deletion")
        except Exception as e:
            logger.warning(f"Failed to clear cache for vault '{vault_name}': {e}")

        # –£–¥–∞–ª—è–µ–º vault –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        await get_service_container().db_manager.delete_vault(vault_name)
        
        return f"Vault '{vault_name}' —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª—ë–Ω –∏–∑ –∏–Ω–¥–µ–∫—Å–∞. –§–∞–π–ª—ã –≤ vault'–µ –Ω–µ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã."

    except VaultNotFoundError:
        return f"Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∏–Ω–¥–µ–∫—Å–µ."
    except Exception as e:
        logger.error(f"Error in delete_vault: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è vault'–∞: {e}"


async def quick_startup_check() -> None:
    """–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ."""
    logger.info("Starting obsidian-kb MCP server...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ Ollama —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ (–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
    try:
        ollama_check = await get_service_container().diagnostics_service.check_ollama()
        if ollama_check.status == HealthStatus.ERROR:
            logger.error(f"[ollama] {ollama_check.message}")
            raise SystemExit("Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ollama serve")
        logger.info(f"[ollama] {ollama_check.message}")
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Ollama: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–ø—É—Å–∫, –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞


async def background_startup_checks() -> None:
    """–§–æ–Ω–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞."""
    try:
        logger.info("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Å–∏—Å—Ç–µ–º—ã...")
        health = await get_service_container().diagnostics_service.full_check()

        if health.overall == HealthStatus.ERROR:
            for check in health.checks:
                if check.status == HealthStatus.ERROR:
                    logger.error(f"[{check.component}] {check.message}")
                    send_notification("obsidian-kb", f"–û—à–∏–±–∫–∞: {check.message}")

        elif health.overall == HealthStatus.WARNING:
            for check in health.checks:
                if check.status == HealthStatus.WARNING:
                    logger.warning(f"[{check.component}] {check.message}")

        logger.info(f"–§–æ–Ω–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã. –°—Ç–∞—Ç—É—Å: {health.overall.value}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ñ–æ–Ω–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫: {e}")


# –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (lifespan –∏—Å–ø–æ–ª—å–∑—É–µ—Ç _background_startup_checks)
_background_startup_checks = background_startup_checks


def main() -> None:
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ MCP —Å–µ—Ä–≤–µ—Ä–∞."""
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    # MCP Server –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç JSON –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
    from obsidian_kb.structured_logging import setup_structured_logging
    setup_structured_logging(level=logging.INFO, json_format=True)

    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –±—ã—Å—Ç—Ä—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    try:
        asyncio.run(quick_startup_check())
    except SystemExit:
        raise
    except Exception as e:
        logger.error(f"Startup error: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–ø—É—Å–∫ –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö startup

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä (lifespan —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–æ–Ω–æ–≤—ã–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏)
    mcp.run()


def _get_vault_path_from_name(vault_name: str) -> str | None:
    """–ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ vault'—É –ø–æ –µ–≥–æ –∏–º–µ–Ω–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
    
    Args:
        vault_name: –ò–º—è vault'–∞
    
    Returns:
        –ü—É—Ç—å –∫ vault'—É –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    try:
        config_path = settings.vaults_config
        if not config_path.exists():
            return None
        
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        
        vaults = config.get("vaults", [])
        for v in vaults:
            if v.get("name") == vault_name:
                return v.get("path")

        return None
    except Exception as e:
        logger.debug(f"Failed to get vault path from config for {vault_name}: {e}")
        return None


@mcp.tool()
@with_rate_limit
async def search_text(
    vault_name: str,
    query: str,
    case_sensitive: bool = False,
    whole_word: bool = False,
    context_lines: int = 2,
    file_pattern: str = "*.md",
    max_results: int = 100
) -> str:
    """–¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ —Ñ–∞–π–ª–∞–º vault'–∞ (ripgrep/grep/python fallback).
    
    –ü—Ä—è–º–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ripgrep –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω,
    –∏–Ω–∞—á–µ fallback –Ω–∞ grep –∏–ª–∏ pure Python –ø–æ–∏—Å–∫.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        query: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
        case_sensitive: –£—á–∏—Ç—ã–≤–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä (default: False)
        whole_word: –ò—Å–∫–∞—Ç—å —Ü–µ–ª—ã–µ —Å–ª–æ–≤–∞ (default: False)
        context_lines: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ/–ø–æ—Å–ª–µ (default: 2)
        file_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (default: "*.md")
        max_results: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: 100)
    
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        search_text("vault", "async def")
        search_text("vault", "TODO", whole_word=True, context_lines=3)
        search_text("vault", "test", file_pattern="*.py")
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ vault'—É
        vault_path = _get_vault_path_from_name(vault_name)
        if not vault_path:
            return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."
        
        vault_path_obj = Path(vault_path)
        if not vault_path_obj.exists():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å –∫ vault'—É '{vault_path}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        service = get_service_container().ripgrep_service
        result = await service.search_text(
            vault_path=str(vault_path_obj),
            query=query,
            case_sensitive=case_sensitive,
            whole_word=whole_word,
            context_lines=context_lines,
            file_pattern=file_pattern,
            max_results=max_results
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = ["## –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫\n"]
        lines.append(f"**–ó–∞–ø—Ä–æ—Å:** `{query}`")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {result.total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ {result.files_searched} —Ñ–∞–π–ª–∞—Ö")
        lines.append(f"**–í—Ä–µ–º—è:** {result.search_time_ms:.1f} –º—Å")
        lines.append(f"**–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** {'ripgrep' if service.is_ripgrep_available() else 'grep/python'}\n")
        
        if not result.matches:
            lines.append("*–°–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
        matches_by_file: dict[str, list[RipgrepMatch]] = {}
        for match in result.matches:
            if match.file_path not in matches_by_file:
                matches_by_file[match.file_path] = []
            matches_by_file[match.file_path].append(match)
        
        for file_path, file_matches in list(matches_by_file.items())[:20]:  # –ú–∞–∫—Å–∏–º—É–º 20 —Ñ–∞–π–ª–æ–≤
            lines.append(f"### {file_path}")
            
            for match in file_matches[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–∞ —Ñ–∞–π–ª
                lines.append(f"\n**–°—Ç—Ä–æ–∫–∞ {match.line_number}:**")
                
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ
                if match.context_before:
                    for ctx_line in match.context_before:
                        lines.append(f"  {ctx_line}")
                
                # –°—Ç—Ä–æ–∫–∞ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
                line_pre = match.line_content[:match.match_start]
                line_match = match.line_content[match.match_start:match.match_end]
                line_post = match.line_content[match.match_end:]
                lines.append(f"  {line_pre}**{line_match}**{line_post}")
                
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ
                if match.context_after:
                    for ctx_line in match.context_after:
                        lines.append(f"  {ctx_line}")
                
                lines.append("")
            
            if len(file_matches) > 10:
                lines.append(f"*... –∏ –µ—â—ë {len(file_matches) - 10} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ*\n")
        
        if len(matches_by_file) > 20:
            lines.append(f"\n*... –∏ –µ—â—ë {len(matches_by_file) - 20} —Ñ–∞–π–ª–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏*")
        
        return "\n".join(lines)
    
    except Exception as e:
        logger.error(f"Error in search_text: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}"


@mcp.tool()
@with_rate_limit
async def search_regex(
    vault_name: str,
    pattern: str,
    context_lines: int = 2,
    file_pattern: str = "*.md",
    max_results: int = 100
) -> str:
    """–ü–æ–∏—Å–∫ –ø–æ regex –ø–∞—Ç—Ç–µ—Ä–Ω—É –≤ —Ñ–∞–π–ª–∞—Ö vault'–∞.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        pattern: Regex –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞
        context_lines: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ/–ø–æ—Å–ª–µ (default: 2)
        file_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ (default: "*.md")
        max_results: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (default: 100)
    
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        search_regex("vault", r"def\\s+\\w+\\(")
        search_regex("vault", r"TODO|FIXME", file_pattern="*.py")
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ vault'—É
        vault_path = _get_vault_path_from_name(vault_name)
        if not vault_path:
            return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."
        
        vault_path_obj = Path(vault_path)
        if not vault_path_obj.exists():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å –∫ vault'—É '{vault_path}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        service = get_service_container().ripgrep_service
        result = await service.search_regex(
            vault_path=str(vault_path_obj),
            pattern=pattern,
            context_lines=context_lines,
            file_pattern=file_pattern,
            max_results=max_results
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = ["## Regex –ø–æ–∏—Å–∫\n"]
        lines.append(f"**–ü–∞—Ç—Ç–µ—Ä–Ω:** `{pattern}`")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {result.total_matches} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ {result.files_searched} —Ñ–∞–π–ª–∞—Ö")
        lines.append(f"**–í—Ä–µ–º—è:** {result.search_time_ms:.1f} –º—Å")
        lines.append(f"**–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç:** {'ripgrep' if service.is_ripgrep_available() else 'python'}\n")
        
        if not result.matches:
            lines.append("*–°–æ–≤–ø–∞–¥–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª–∞–º
        matches_by_file: dict[str, list[RipgrepMatch]] = {}
        for match in result.matches:
            if match.file_path not in matches_by_file:
                matches_by_file[match.file_path] = []
            matches_by_file[match.file_path].append(match)
        
        for file_path, file_matches in list(matches_by_file.items())[:20]:  # –ú–∞–∫—Å–∏–º—É–º 20 —Ñ–∞–π–ª–æ–≤
            lines.append(f"### {file_path}")
            
            for match in file_matches[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–∞ —Ñ–∞–π–ª
                lines.append(f"\n**–°—Ç—Ä–æ–∫–∞ {match.line_number}:**")
                
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ
                if match.context_before:
                    for ctx_line in match.context_before:
                        lines.append(f"  {ctx_line}")
                
                # –°—Ç—Ä–æ–∫–∞ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
                line_pre = match.line_content[:match.match_start]
                line_match = match.line_content[match.match_start:match.match_end]
                line_post = match.line_content[match.match_end:]
                lines.append(f"  {line_pre}**{line_match}**{line_post}")
                
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ
                if match.context_after:
                    for ctx_line in match.context_after:
                        lines.append(f"  {ctx_line}")
                
                lines.append("")
            
            if len(file_matches) > 10:
                lines.append(f"*... –∏ –µ—â—ë {len(file_matches) - 10} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ*\n")
        
        if len(matches_by_file) > 20:
            lines.append(f"\n*... –∏ –µ—â—ë {len(matches_by_file) - 20} —Ñ–∞–π–ª–æ–≤ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏*")
        
        return "\n".join(lines)
    
    except Exception as e:
        logger.error(f"Error in search_regex: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ regex –ø–æ–∏—Å–∫–∞: {e}"


@mcp.tool()
@with_rate_limit
async def find_files(
    vault_name: str,
    name_pattern: str,
    content_contains: str | None = None
) -> str:
    """–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –ø–æ –∏–º–µ–Ω–∏ –∏/–∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        name_pattern: –ü–∞—Ç—Ç–µ—Ä–Ω –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "*.md" –∏–ª–∏ "**/test*.md")
        content_contains: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å—Å—è –≤ —Ñ–∞–π–ª–µ
    
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        find_files("vault", "*.md")
        find_files("vault", "**/test*.py", content_contains="async def")
        find_files("vault", "README.md")
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ vault'—É
        vault_path = _get_vault_path_from_name(vault_name)
        if not vault_path:
            return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."
        
        vault_path_obj = Path(vault_path)
        if not vault_path_obj.exists():
            return f"–û—à–∏–±–∫–∞: –ü—É—Ç—å –∫ vault'—É '{vault_path}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        service = get_service_container().ripgrep_service
        files = await service.find_files(
            vault_path=str(vault_path_obj),
            name_pattern=name_pattern,
            content_contains=content_contains
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = ["## –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤\n"]
        lines.append(f"**–ü–∞—Ç—Ç–µ—Ä–Ω:** `{name_pattern}`")
        if content_contains:
            lines.append(f"**–°–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç:** `{content_contains}`")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(files)} —Ñ–∞–π–ª–æ–≤\n")
        
        if not files:
            lines.append("*–§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        for file_path in files[:100]:  # –ú–∞–∫—Å–∏–º—É–º 100 —Ñ–∞–π–ª–æ–≤
            lines.append(f"- `{file_path}`")
        
        if len(files) > 100:
            lines.append(f"\n*... –∏ –µ—â—ë {len(files) - 100} —Ñ–∞–π–ª–æ–≤*")
        
        return "\n".join(lines)
    
    except Exception as e:
        logger.error(f"Error in find_files: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤: {e}"


# ============================================================================
# Graph Query Service MCP Tools (v6 Phase 4)
# ============================================================================


@mcp.tool()
@with_rate_limit
async def find_connected(
    vault_name: str,
    document_path: str,
    direction: str = "both",
    depth: int = 1,
    limit: int = 50
) -> str:
    """–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º —á–µ—Ä–µ–∑ wikilinks.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        document_path: –ü—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç –∫–æ—Ä–Ω—è vault)
        direction: "incoming" (–∫—Ç–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è), "outgoing" (–Ω–∞ –∫–æ–≥–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è), "both"
        depth: –ì–ª—É–±–∏–Ω–∞ –ø–æ–∏—Å–∫–∞ (1 = –ø—Ä—è–º—ã–µ —Å–≤—è–∑–∏, 2 = —Å–≤—è–∑–∏ —Å–≤—è–∑–µ–π)
        limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        find_connected("vault", "People/–ò–≤–∞–Ω.md")  # –í—Å–µ —Å–≤—è–∑–∏
        find_connected("vault", "Projects/Alpha.md", "incoming")  # –ö—Ç–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –ø—Ä–æ–µ–∫—Ç
        find_connected("vault", "Notes/Meeting.md", "outgoing")  # –ù–∞ –∫–æ–≥–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è –≤—Å—Ç—Ä–µ—á–∞
    """
    try:
        service = get_service_container().graph_query_service
        result = await service.find_connected(
            vault_name=vault_name,
            document_path=document_path,
            direction=direction,
            depth=depth,
            limit=limit
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## –°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã: `{result.center_document}`\n"]
        lines.append(f"**–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:** {direction}")
        lines.append(f"**–ì–ª—É–±–∏–Ω–∞:** {depth}")
        lines.append(f"**–í—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏:** {result.total_incoming}")
        lines.append(f"**–ò—Å—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏:** {result.total_outgoing}")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(result.connected)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n")
        
        if not result.connected:
            lines.append("*–°–≤—è–∑–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—é
        incoming = [d for d in result.connected if d.direction == "incoming"]
        outgoing = [d for d in result.connected if d.direction == "outgoing"]
        
        if incoming:
            lines.append("### –í—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏ (–∫—Ç–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç)\n")
            for doc in incoming:
                lines.append(f"- **{doc.title}** (`{doc.file_path}`)")
                if doc.link_context:
                    lines.append(f"  > {doc.link_context}")
            lines.append("")
        
        if outgoing:
            lines.append("### –ò—Å—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏ (–Ω–∞ –∫–æ–≥–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç)\n")
            for doc in outgoing:
                lines.append(f"- **{doc.title}** (`{doc.file_path}`)")
                if doc.link_context:
                    lines.append(f"  > {doc.link_context}")
            lines.append("")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in find_connected: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}"


@mcp.tool()
@with_rate_limit
async def find_orphans(
    vault_name: str,
    doc_type: str | None = None
) -> str:
    """–ù–∞–π—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –±–µ–∑ –≤—Ö–æ–¥—è—â–∏—Ö —Å—Å—ã–ª–æ–∫ (orphans).
    
    –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞—É–¥–∏—Ç–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π ‚Äî orphans –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–±—ã—Ç—ã–º–∏
    –∏–ª–∏ —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        doc_type: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ç–∏–ø–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞
    
    Returns:
        –°–ø–∏—Å–æ–∫ orphan –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        find_orphans("vault")  # –í—Å–µ orphans
        find_orphans("vault", "note")  # –¢–æ–ª—å–∫–æ –∑–∞–º–µ—Ç–∫–∏ –±–µ–∑ —Å—Å—ã–ª–æ–∫
    """
    try:
        service = get_service_container().graph_query_service
        orphans = await service.find_orphans(
            vault_name=vault_name,
            doc_type=doc_type
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## Orphan –¥–æ–∫—É–º–µ–Ω—Ç—ã: {vault_name}\n"]
        if doc_type:
            lines.append(f"**–¢–∏–ø:** {doc_type}")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(orphans)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n")
        
        if not orphans:
            lines.append("*Orphan –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        for file_path in orphans[:100]:  # –ú–∞–∫—Å–∏–º—É–º 100
            lines.append(f"- `{file_path}`")
        
        if len(orphans) > 100:
            lines.append(f"\n*... –∏ –µ—â—ë {len(orphans) - 100} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in find_orphans: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ orphan –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}"


@mcp.tool()
@with_rate_limit
async def find_broken_links(
    vault_name: str
) -> str:
    """–ù–∞–π—Ç–∏ –±–∏—Ç—ã–µ wikilinks ‚Äî —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.
    
    Args:
        vault_name: –ò–º—è vault'–∞
    
    Returns:
        –°–ø–∏—Å–æ–∫ –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        find_broken_links("vault")  # –í—Å–µ –±–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏
    """
    try:
        service = get_service_container().graph_query_service
        broken_links = await service.find_broken_links(vault_name=vault_name)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## –ë–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏: {vault_name}\n"]
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(broken_links)} –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫\n")
        
        if not broken_links:
            lines.append("*–ë–∏—Ç—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª—É
        by_file: dict[str, list[str]] = {}
        for file_path, broken_link in broken_links:
            if file_path not in by_file:
                by_file[file_path] = []
            by_file[file_path].append(broken_link)
        
        for file_path, links in list(by_file.items())[:50]:  # –ú–∞–∫—Å–∏–º—É–º 50 —Ñ–∞–π–ª–æ–≤
            lines.append(f"### `{file_path}`\n")
            for link in links:
                lines.append(f"- `{link}`")
            lines.append("")
        
        if len(by_file) > 50:
            lines.append(f"*... –∏ –µ—â—ë {len(by_file) - 50} —Ñ–∞–π–ª–æ–≤ —Å –±–∏—Ç—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏*")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in find_broken_links: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫: {e}"


@mcp.tool()
@with_rate_limit
async def get_backlinks(
    vault_name: str,
    document_path: str
) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ backlinks (–≤—Ö–æ–¥—è—â–∏–µ —Å—Å—ã–ª–∫–∏) –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    
    –ê–Ω–∞–ª–æ–≥ –ø–∞–Ω–µ–ª–∏ Backlinks –≤ Obsidian.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        document_path: –ü—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É
    
    Returns:
        –°–ø–∏—Å–æ–∫ backlinks –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        get_backlinks("vault", "People/–ò–≤–∞–Ω.md")  # –í—Å–µ –∫—Ç–æ —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –ø—Ä–æ—Ñ–∏–ª—å
    """
    try:
        service = get_service_container().graph_query_service
        backlinks = await service.get_backlinks(
            vault_name=vault_name,
            document_path=document_path
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## Backlinks: `{document_path}`\n"]
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(backlinks)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n")
        
        if not backlinks:
            lines.append("*Backlinks –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        for doc in backlinks:
            lines.append(f"- **{doc.title}** (`{doc.file_path}`)")
            if doc.link_context:
                lines.append(f"  > {doc.link_context}")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in get_backlinks: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è backlinks: {e}"


# ============================================================================
# Timeline Service MCP Tools (v6 Phase 4)
# ============================================================================


@mcp.tool()
@with_rate_limit
async def timeline(
    vault_name: str,
    doc_type: str | None = None,
    date_field: str = "created",
    after: str | None = None,
    before: str | None = None,
    limit: int = 50
) -> str:
    """–•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ª–µ–Ω—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        doc_type: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É
        date_field: –ü–æ–ª–µ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ ("created", "modified" –∏–ª–∏ –∫–∞—Å—Ç–æ–º–Ω–æ–µ)
        after: –î–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ—Å–ª–µ –¥–∞—Ç—ã (ISO –∏–ª–∏ "last_week", "last_month")
        before: –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ –¥–∞—Ç—ã
        limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Returns:
        –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ª–µ–Ω—Ç–∞ –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        timeline("vault", "meeting", date_field="date", after="2024-12-01")
        timeline("vault", after="last_week")  # –°–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞ –Ω–µ–¥–µ–ª—é
        timeline("vault", doc_type="task", date_field="modified")  # –ò–∑–º–µ–Ω—ë–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
    """
    try:
        service = get_service_container().timeline_service
        results = await service.timeline(
            vault_name=vault_name,
            doc_type=doc_type,
            date_field=date_field,
            after=after,
            before=before,
            limit=limit
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## Timeline: {vault_name}\n"]
        if doc_type:
            lines.append(f"**–¢–∏–ø:** {doc_type}")
        lines.append(f"**–ü–æ–ª–µ –¥–∞—Ç—ã:** {date_field}")
        if after:
            lines.append(f"**–ü–æ—Å–ª–µ:** {after}")
        if before:
            lines.append(f"**–î–æ:** {before}")
        lines.append(f"**–ù–∞–π–¥–µ–Ω–æ:** {len(results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n")
        
        if not results:
            lines.append("*–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã*")
            return "\n".join(lines)
        
        for doc in results:
            date_value = doc.get(date_field) or doc.get("created_at") or doc.get("modified_at")
            lines.append(f"### {doc.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            lines.append(f"- **–§–∞–π–ª:** `{doc.get('file_path', '')}`")
            if date_value:
                lines.append(f"- **–î–∞—Ç–∞:** {date_value}")
            lines.append("")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in timeline: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è timeline: {e}"


@mcp.tool()
@with_rate_limit
async def recent_changes(
    vault_name: str,
    days: int = 7,
    doc_type: str | None = None
) -> str:
    """–î–æ–∫—É–º–µ–Ω—Ç—ã, –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π.
    
    –†–∞–∑–¥–µ–ª—è–µ—Ç –Ω–∞ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∏ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–µ.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π (default: 7)
        doc_type: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É
    
    Returns:
        –°–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        recent_changes("vault")  # –ò–∑–º–µ–Ω–µ–Ω–∏—è –∑–∞ –Ω–µ–¥–µ–ª—é
        recent_changes("vault", 30, "task")  # –ó–∞–¥–∞—á–∏ –∑–∞ –º–µ—Å—è—Ü
    """
    try:
        service = get_service_container().timeline_service
        result = await service.recent_changes(
            vault_name=vault_name,
            days=days,
            doc_type=doc_type
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## –ù–µ–¥–∞–≤–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: {vault_name}\n"]
        lines.append(f"**–ü–µ—Ä–∏–æ–¥:** –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π")
        if doc_type:
            lines.append(f"**–¢–∏–ø:** {doc_type}")
        lines.append(f"**–í—Å–µ–≥–æ:** {result.get('total', 0)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n")
        
        created = result.get("created", [])
        modified = result.get("modified", [])
        
        if created:
            lines.append(f"### –°–æ–∑–¥–∞–Ω–æ ({len(created)})\n")
            for doc in created[:20]:  # –ú–∞–∫—Å–∏–º—É–º 20
                lines.append(f"- **{doc.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}** (`{doc.get('file_path', '')}`)")
                if doc.get("created_at"):
                    lines.append(f"  > {doc.get('created_at')}")
            if len(created) > 20:
                lines.append(f"*... –∏ –µ—â—ë {len(created) - 20} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*")
            lines.append("")
        
        if modified:
            lines.append(f"### –ò–∑–º–µ–Ω–µ–Ω–æ ({len(modified)})\n")
            for doc in modified[:20]:  # –ú–∞–∫—Å–∏–º—É–º 20
                lines.append(f"- **{doc.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}** (`{doc.get('file_path', '')}`)")
                if doc.get("modified_at"):
                    lines.append(f"  > {doc.get('modified_at')}")
            if len(modified) > 20:
                lines.append(f"*... –∏ –µ—â—ë {len(modified) - 20} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*")
            lines.append("")
        
        if not created and not modified:
            lines.append("*–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ*")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in recent_changes: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–µ–¥–∞–≤–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π: {e}"


@mcp.tool()
@with_rate_limit
async def export_to_csv(
    vault_name: str,
    output_path: str | None = None,
    doc_type: str | None = None,
    fields: str | None = None,
    where: str | None = None
) -> str:
    """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö vault'–∞ –≤ CSV —Ñ–∞–π–ª.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω ‚Äî –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª)
        doc_type: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ ‚Äî —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É
        fields: –ü–æ–ª—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ ‚Äî –≤—Å–µ –ø–æ–ª—è)
        where: –£—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    
    Returns:
        –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É CSV —Ñ–∞–π–ª—É
    
    Examples:
        export_to_csv("vault", doc_type="person", fields="title,role,team")
        export_to_csv("vault", where="status = active")
        export_to_csv("vault", output_path="/tmp/export.csv", doc_type="task")
    """
    try:
        batch_ops = get_service_container().batch_operations
        csv_path = await batch_ops.export_to_csv(
            vault_name=vault_name,
            output_path=output_path,
            doc_type=doc_type,
            fields=fields,
            where=where
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = [f"## –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö: {vault_name}\n"]
        lines.append(f"**CSV —Ñ–∞–π–ª:** `{csv_path}`")
        if doc_type:
            lines.append(f"**–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:** {doc_type}")
        if fields:
            lines.append(f"**–ü–æ–ª—è:** {fields}")
        if where:
            lines.append(f"**–§–∏–ª—å—Ç—Ä:** {where}")
        lines.append(f"\n–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—É—Ç—å –≤—ã—à–µ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É.")
        
        return "\n".join(lines)
    
    except VaultNotFoundError:
        return f"–û—à–∏–±–∫–∞: Vault '{vault_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω."
    except Exception as e:
        logger.error(f"Error in export_to_csv: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ CSV: {e}"


@mcp.tool()
@with_rate_limit
async def compare_schemas(
    vault_names: list[str]
) -> str:
    """–°—Ä–∞–≤–Ω–∏—Ç—å —Å—Ö–µ–º—ã frontmatter –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö vault'–æ–≤.
    
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â–∏–µ –ø–æ–ª—è, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—è –∏ —Ä–∞–∑–ª–∏—á–∏—è –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö.
    
    Args:
        vault_names: –°–ø–∏—Å–æ–∫ –∏–º—ë–Ω vault'–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    
    Returns:
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ö–µ–º –≤ markdown —Ñ–æ—Ä–º–∞—Ç–µ
    
    Examples:
        compare_schemas(["vault1", "vault2"])
        compare_schemas(["vault1", "vault2", "vault3"])
    """
    try:
        batch_ops = get_service_container().batch_operations
        comparison = await batch_ops.compare_schemas(vault_names)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lines = ["## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ö–µ–º vault'–æ–≤\n"]
        lines.append(f"**Vault'—ã:** {', '.join(vault_names)}\n")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ vault'–∞–º
        lines.append("### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
        vault_stats = comparison.get("vault_stats", {})
        for vault_name, doc_count in vault_stats.items():
            lines.append(f"- **{vault_name}:** {doc_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        lines.append("")
        
        # –û–±—â–∏–µ –ø–æ–ª—è
        common_fields = comparison.get("common_fields", [])
        lines.append(f"### –û–±—â–∏–µ –ø–æ–ª—è ({len(common_fields)})\n")
        if common_fields:
            for field in common_fields:
                lines.append(f"- `{field}`")
        else:
            lines.append("*–û–±—â–∏—Ö –ø–æ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ*")
        lines.append("")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
        unique_fields = comparison.get("unique_fields", {})
        lines.append("### –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—è\n")
        if unique_fields:
            for vault_name, fields in unique_fields.items():
                if fields:
                    lines.append(f"**{vault_name}:**")
                    for field in fields:
                        lines.append(f"  - `{field}`")
                    lines.append("")
        else:
            lines.append("*–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ*")
            lines.append("")
        
        # –†–∞–∑–ª–∏—á–∏—è –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö
        field_differences = comparison.get("field_differences", {})
        if field_differences:
            lines.append("### –†–∞–∑–ª–∏—á–∏—è –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö –ø–æ–ª–µ–π\n")
            for field, vault_examples in field_differences.items():
                lines.append(f"**`{field}`:**")
                for vault_name, examples in vault_examples.items():
                    examples_str = ", ".join(str(e) for e in examples[:3])
                    lines.append(f"  - {vault_name}: {examples_str}")
                lines.append("")
        
        return "\n".join(lines)
    
    except VaultNotFoundError as e:
        return f"–û—à–∏–±–∫–∞: Vault –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}"
    except Exception as e:
        logger.error(f"Error in compare_schemas: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ö–µ–º: {e}"


if __name__ == "__main__":
    main()

