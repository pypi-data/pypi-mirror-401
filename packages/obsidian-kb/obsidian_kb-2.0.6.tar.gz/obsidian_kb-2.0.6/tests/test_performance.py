"""–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞ –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

–ò–∑–º–µ—Ä—è–µ—Ç –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ (P50, P95, P99) –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤:
- –ü—Ä–æ—Ü–µ–¥—É—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (—Ü–µ–ª—å: <1s)
- Known Item –∑–∞–ø—Ä–æ—Å—ã (—Ü–µ–ª—å: <200ms)
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (—Ü–µ–ª—å: <1s)
- –§–∏–ª—å—Ç—Ä—ã –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º (—Ü–µ–ª—å: <500ms)
"""

import asyncio
import json
import statistics
import time
from pathlib import Path
from typing import Any

from obsidian_kb.service_container import get_service_container, reset_service_container
from obsidian_kb.types import SearchRequest


# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
PERFORMANCE_TEST_QUERIES = {
    "procedural": [
        "how to install",
        "–∫–∞–∫ —Å–æ–∑–¥–∞—Ç—å ADR",
        "how to setup",
        "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ",
        "guide for beginners",
    ],
    "known_item": [
        "README.md",
        "SETUP_GUIDE.md",
        "ADR-001",
        "PROJ-123",
    ],
    "semantic": [
        "python programming",
        "database optimization",
        "machine learning algorithms",
        "web development best practices",
    ],
    "metadata_filter": [
        "tags:python",
        "type:person",
        "type:project",
        "tags:meeting tags:important",
    ],
}


def calculate_percentiles(times: list[float]) -> dict[str, float]:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
    
    Args:
        times: –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º–∏ (p50, p95, p99, avg, min, max)
    """
    if not times:
        return {}
    
    sorted_times = sorted(times)
    n = len(sorted_times)
    
    return {
        "p50": sorted_times[int(n * 0.50)],
        "p95": sorted_times[int(n * 0.95)],
        "p99": sorted_times[int(n * 0.99)],
        "avg": statistics.mean(times),
        "min": min(times),
        "max": max(times),
        "count": n,
    }


async def measure_query_performance(
    vault_name: str,
    query: str,
    search_type: str = "hybrid",
    iterations: int = 10,
    warmup_iterations: int = 2,
) -> dict[str, Any]:
    """–ò–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        search_type: –¢–∏–ø –ø–æ–∏—Å–∫–∞
        iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è
        warmup_iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è —Ä–∞–∑–æ–≥—Ä–µ–≤–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    reset_service_container()
    services = get_service_container()
    
    times = []
    results_count = []
    
    # –†–∞–∑–æ–≥—Ä–µ–≤
    for _ in range(warmup_iterations):
        try:
            request = SearchRequest(
                vault_name=vault_name,
                query=query,
                search_type=search_type,
            )
            await services.search_service.search(request)
        except Exception:
            pass
    
    # –ò–∑–º–µ—Ä–µ–Ω–∏–µ
    for _ in range(iterations):
        start_time = time.time()
        try:
            request = SearchRequest(
                vault_name=vault_name,
                query=query,
                search_type=search_type,
            )
            response = await services.search_service.search(request)
            elapsed = (time.time() - start_time) * 1000  # –í –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            times.append(elapsed)
            results_count.append(len(response.results))
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–º–µ—Ä–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ '{query}': {e}")
            continue
    
    if not times:
        return {}
    
    percentiles = calculate_percentiles(times)
    percentiles["avg_results"] = statistics.mean(results_count) if results_count else 0
    
    return {
        "query": query,
        "search_type": search_type,
        "times_ms": times,
        "percentiles": percentiles,
    }


async def run_performance_tests(
    vault_name: str,
    output_file: Path | None = None,
) -> dict[str, Any]:
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤.
    
    Args:
        vault_name: –ò–º—è vault'–∞
        output_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
    Returns:
        –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º —Ç–µ—Å—Ç–∞–º
    """
    print("\n" + "=" * 80)
    print("üöÄ –¢–ï–°–¢–´ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –ü–û–ò–°–ö–ê")
    print("=" * 80)
    print(f"Vault: {vault_name}\n")
    
    all_results = {}
    summary = {
        "vault_name": vault_name,
        "timestamp": time.time(),
        "test_results": {},
        "summary": {},
    }
    
    # –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö)
    targets = {
        "procedural": 1000,  # <1s
        "known_item": 200,   # <200ms
        "semantic": 1000,    # <1s
        "metadata_filter": 500,  # <500ms
    }
    
    for query_type, queries in PERFORMANCE_TEST_QUERIES.items():
        print(f"\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {query_type.upper()}")
        print("-" * 80)
        
        query_results = []
        all_times = []
        
        for query in queries:
            print(f"  –ó–∞–ø—Ä–æ—Å: '{query}'...", end=" ", flush=True)
            
            result = await measure_query_performance(
                vault_name=vault_name,
                query=query,
                search_type="hybrid" if query_type != "metadata_filter" else "hybrid",
                iterations=5,
            )
            
            if result and "percentiles" in result:
                p95 = result["percentiles"]["p95"]
                avg = result["percentiles"]["avg"]
                target = targets.get(query_type, 1000)
                status = "‚úÖ" if p95 < target else "‚ö†Ô∏è"
                
                print(f"{status} P95: {p95:.1f}ms (—Ü–µ–ª—å: <{target}ms)")
                
                query_results.append(result)
                all_times.extend(result["times_ms"])
            else:
                print("‚ùå –û—à–∏–±–∫–∞")
        
        if all_times:
            type_percentiles = calculate_percentiles(all_times)
            target = targets.get(query_type, 1000)
            
            print(f"\n  üìà –°–≤–æ–¥–∫–∞ –ø–æ —Ç–∏–ø—É '{query_type}':")
            print(f"     P50: {type_percentiles['p50']:.1f}ms")
            print(f"     P95: {type_percentiles['p95']:.1f}ms (—Ü–µ–ª—å: <{target}ms)")
            print(f"     P99: {type_percentiles['p99']:.1f}ms")
            print(f"     –°—Ä–µ–¥–Ω–µ–µ: {type_percentiles['avg']:.1f}ms")
            
            all_results[query_type] = {
                "queries": query_results,
                "summary": type_percentiles,
                "target": target,
                "meets_target": type_percentiles['p95'] < target,
            }
    
    # –û–±—â–∞—è —Å–≤–æ–¥–∫–∞
    print("\n" + "=" * 80)
    print("üìä –û–ë–©–ê–Ø –°–í–û–î–ö–ê")
    print("=" * 80)
    
    for query_type, result in all_results.items():
        summary_data = result["summary"]
        target = result["target"]
        meets = "‚úÖ" if result["meets_target"] else "‚ö†Ô∏è"
        
        print(f"{meets} {query_type.upper()}:")
        print(f"   P95: {summary_data['p95']:.1f}ms (—Ü–µ–ª—å: <{target}ms)")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ: {summary_data['avg']:.1f}ms")
    
    summary["test_results"] = all_results
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    try:
        services = get_service_container()
        await services.cleanup()
    except Exception:
        pass
    
    return summary


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤."""
    import sys
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print(f"  {sys.argv[0]} <vault_name> [output_file]")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print(f"  {sys.argv[0]} my-vault performance_results.json")
        sys.exit(1)
    
    vault_name = sys.argv[1]
    output_file = Path(sys.argv[2]) if len(sys.argv) > 2 else Path("performance_test_results.json")
    
    await run_performance_tests(vault_name, output_file)


if __name__ == "__main__":
    asyncio.run(main())

