# Проблемные моменты для тестирования на реальных данных

**Дата создания:** 2026-01-02  
**Последнее обновление:** 2026-01-02  
**Основа:** Отчет о тестировании Intent Detection — Раунд 5  
**Vault:** Naumen_CTO

> **Примечание:** Этот документ описывает проблемы на реальных данных. Для автоматического тестирования созданы тестовые данные и сценарии (см. [ROUND5_TEST_DATA.md](ROUND5_TEST_DATA.md) и [test_round5_issues.py](test_round5_issues.py)).

---

## Критические проблемы (P0) — требуют немедленного исправления

### 1. Поиск людей по полному имени ❌

**Проблема:** Поиск людей по полному имени не работает за 5 раундов тестирования.

**Примеры:**
- `Всеволод Шадрин` → `vshadrin.md` НЕ найден (должен быть в топ-3)
- `Шадрин` (FTS) → находит упоминания фамилии, но не профиль
- `Руководитель AI офиса` → `vshadrin.md` НЕ найден (должность из профиля)

**Диагностика:**
- Профиль существует и индексируется (`type:person` работает, находит 5 документов)
- FTS находит упоминания фамилии в других документах
- Но сам профиль (`vshadrin.md`, `amuratov.md`) не в результатах

**Вывод:** Контент профилей (заголовок `# Имя Фамилия`, frontmatter `name:`, `role:`, первый параграф с должностью) не индексируется или не ранжируется для текстового поиска.

**Тестовые сценарии для проверки:**
```python
# Тест 1: Поиск по полному имени
query = "Всеволод Шадрин"
expected_file = "vshadrin.md"
expected_position = 1  # Должен быть на позиции 1-3

# Тест 2: Поиск по фамилии
query = "Шадрин"
expected_file = "vshadrin.md"
expected_position = 1  # Профиль должен быть выше упоминаний

# Тест 3: Поиск по должности из профиля
query = "Руководитель AI офиса"
expected_file = "vshadrin.md"
expected_position = 1

# Тест 4: Поиск по имени и фамилии (разные варианты)
queries = [
    "Всеволод Шадрин",
    "Шадрин Всеволод",
    "vshadrin",  # ID профиля
    "Всеволод",  # Только имя
]
expected_file = "vshadrin.md"
expected_position = 1

# Тест 5: Поиск других людей
queries = [
    "Алексей Муратов",
    "Муратов",
    "amuratov",
]
expected_file = "amuratov.md"
expected_position = 1
```

**Критерии успеха:**
- ✅ Профиль находится в топ-3 результатов для всех вариантов запроса
- ✅ Профиль приоритизируется выше упоминаний в других документах
- ✅ Поиск по должности из профиля работает
- ✅ Поиск по ID профиля работает

---

## Высокоприоритетные проблемы (P1) — требуют исправления в ближайшее время

### 2. Фильтр дат работает некорректно ⚠️

**Проблема:** Фильтр дат `created:>2025-12-20` включает документы от 27.11 (фильтр не работает корректно).

**Примеры:**
- `created:>2025-12-20` → включает документы от 27.11 (не должно)
- `type:1-1 created:>2025-12-20` → включает документы от 27.11 (не должно)

**Тестовые сценарии для проверки:**
```python
# Тест 1: Фильтр "больше" даты
query = "created:>2025-12-20"
# Проверить, что НЕ включаются документы:
# - created_at = "2025-11-27"
# - created_at = "2025-12-09"
# Должны включаться только документы после 2025-12-20

# Тест 2: Фильтр "больше или равно"
query = "created:>=2025-12-01"
# Должны включаться документы от 2025-12-01 и позже

# Тест 3: Фильтр "меньше"
query = "created:<2025-12-01"
# Должны включаться только документы до 2025-12-01

# Тест 4: Фильтр "меньше или равно"
query = "created:<=2025-11-30"
# Должны включаться документы до 2025-11-30 включительно

# Тест 5: Комбинированные фильтры дат
query = "created:>=2025-12-01 created:<=2025-12-31"
# Должны включаться только документы за декабрь 2025

# Тест 6: Комбинация фильтра дат с другими фильтрами
query = "type:1-1 created:>2025-12-20"
# Должны быть только встречи 1-1 после 2025-12-20
```

**Критерии успеха:**
- ✅ Фильтр `created:>2025-12-20` корректно отсекает документы до указанной даты
- ✅ Все операторы дат (`>`, `>=`, `<`, `<=`) работают корректно
- ✅ Комбинированные фильтры дат работают корректно
- ✅ Фильтры дат работают в комбинации с другими фильтрами

---

### 3. Релевантность PROCEDURAL запросов ⚠️

**Проблема:** PROCEDURAL запросы не находят релевантные документы в топе.

**Примеры:**
- `как создать ADR` → `guide_adr.md` не в топ-5 (был #2 в R4)
- `как провести 1-1` → `template_1-1.md` не в топ-5

**Тестовые сценарии для проверки:**
```python
# Тест 1: Поиск гайда по созданию ADR
query = "как создать ADR"
expected_file = "guide_adr.md"
expected_position = 1  # Должен быть в топ-3

# Тест 2: Поиск шаблона для 1-1
query = "как провести 1-1"
expected_file = "template_1-1.md"
expected_position = 1  # Должен быть в топ-3

# Тест 3: Другие PROCEDURAL запросы
queries = [
    "как написать ADR",
    "инструкция по созданию ADR",
    "как провести встречу 1-1",
    "шаблон для 1-1",
]
# Проверить, что релевантные документы в топе

# Тест 4: Английские PROCEDURAL запросы
queries = [
    "how to create ADR",
    "how to conduct 1-1",
    "guide for ADR",
]
# Проверить релевантность
```

**Критерии успеха:**
- ✅ `guide_adr.md` находится в топ-3 для запросов про создание ADR
- ✅ `template_1-1.md` находится в топ-3 для запросов про 1-1
- ✅ PROCEDURAL запросы возвращают релевантные результаты в топе
- ✅ Релевантность PROCEDURAL >70%

---

## Среднеприоритетные проблемы (P2) — требуют улучшения

### 4. KNOWN_ITEM при отсутствии документа ⚠️

**Проблема:** `ADR-001` (не существует) показывает нерелевантные результаты вместо возврата 0 результатов.

**Тестовые сценарии для проверки:**
```python
# Тест 1: Несуществующий документ
query = "ADR-001"  # Не существует
expected_results = 0  # Должно быть 0 результатов или сообщение "не найден"

# Тест 2: Существующий документ
query = "smrm-ecosystem"  # Существует
expected_file = "smrm-ecosystem.md"
expected_position = 1

# Тест 3: Несуществующий ID человека
query = "nonexistent-person"  # Не существует
expected_results = 0

# Тест 4: Существующий ID человека
query = "amuratov"  # Существует
expected_file = "amuratov.md"
expected_position = 1
```

**Критерии успеха:**
- ✅ Несуществующие документы возвращают 0 результатов или сообщение "не найден"
- ✅ Существующие документы находятся корректно
- ✅ Нет fallback на нерелевантные результаты для KNOWN_ITEM

---

### 5. Релевантность EXPLORATORY запросов ⚠️

**Проблема:** EXPLORATORY запросы не находят релевантные документы в топе.

**Примеры:**
- `что такое Naumen SMP` → `smp.md` не в топ-5
- `зачем нужна централизация` → только 2/5 релевантных документов

**Тестовые сценарии для проверки:**
```python
# Тест 1: Поиск определения SMP
query = "что такое Naumen SMP"
expected_file = "smp.md"
expected_position = 1  # Должен быть в топ-3

# Тест 2: Поиск цели централизации
query = "зачем нужна централизация"
expected_files = ["centralization.md", "architecture.md"]  # Примерные файлы
expected_position = 1  # Релевантные документы в топе

# Тест 3: Другие EXPLORATORY запросы
queries = [
    "что такое экосистема SMRM",
    "в чём суть микросервисов",
    "почему нужна централизация",
]
# Проверить релевантность

# Тест 4: Английские EXPLORATORY запросы
queries = [
    "what is Naumen SMP",
    "what is the purpose of centralization",
    "why do we need microservices",
]
# Проверить релевантность
```

**Критерии успеха:**
- ✅ `smp.md` находится в топ-3 для запросов про SMP
- ✅ Релевантные документы находятся в топе для EXPLORATORY запросов
- ✅ Релевантность EXPLORATORY >70%

---

## Частично работающие функции (требуют улучшения)

### 6. Комбинированные фильтры ⚠️

**Проблема:** Некоторые комбинации фильтров возвращают 0 результатов, возможно корректно, но нужно проверить.

**Примеры:**
- `type:1-1 links:amuratov` → 0 документов (возможно, нет таких документов)

**Тестовые сценарии для проверки:**
```python
# Тест 1: Комбинация type и links
query = "type:1-1 links:amuratov"
# Проверить, действительно ли нет таких документов
# Если есть, должны находиться

# Тест 2: Комбинация type и tags
query = "type:project tags:active"
# Должны находиться активные проекты

# Тест 3: Комбинация type, links и дат
query = "type:1-1 links:amuratov created:>2025-12-01"
# Должны находиться встречи 1-1 с Муратовым после декабря
```

**Критерии успеха:**
- ✅ Комбинированные фильтры работают корректно
- ✅ Если документы существуют, они находятся
- ✅ Если документов нет, возвращается 0 результатов

---

## Метрики для отслеживания

### Текущие метрики (Round 5)

| Метрика | Значение | Целевое |
|---------|----------|---------|
| Intent Detection | 90% | >90% ✅ |
| Релевантность | 65% | >70% ⏳ |
| METADATA фильтры | 85% | >90% ⏳ |
| PROCEDURAL релевантность | Средняя | >70% ⏳ |
| EXPLORATORY релевантность | Средняя | >70% ⏳ |
| Поиск людей по имени | 0% | >80% ❌ |
| Фильтр дат | Некорректно | Корректно ⚠️ |

### Целевые метрики (Round 6)

| Метрика | Целевое значение |
|---------|------------------|
| Intent Detection | >90% (поддержать) |
| Релевантность | >70% |
| Поиск людей по имени | >80% |
| Фильтр дат | 100% корректность |
| PROCEDURAL релевантность | >70% |
| EXPLORATORY релевантность | >70% |
| KNOWN_ITEM при отсутствии | 0 результатов |

---

## Рекомендации по тестированию

### 1. Регулярное тестирование на реальных данных

- Тестирование должно проводиться после каждого раунда исправлений
- Использовать реальный vault `Naumen_CTO` для проверки
- Отслеживать метрики по каждому раунду

### 2. Автоматизация тестов

- Создать автоматические тесты для критических сценариев
- Добавить тесты в CI/CD pipeline
- Использовать тестовые данные для быстрой проверки, реальные данные для валидации

### 3. Документирование результатов

- Создавать отчет после каждого раунда тестирования
- Отслеживать динамику метрик по раундам
- Документировать исправленные и оставшиеся проблемы

### 4. Приоритизация исправлений

- Сначала исправлять критические проблемы (P0)
- Затем высокоприоритетные (P1)
- Затем среднеприоритетные (P2)

---

## Связанные документы

- [IMPROVEMENT_PLAN.md](../IMPROVEMENT_PLAN.md) — План улучшений (фаза V5.10)
- [TEST_RESULTS_ANALYSIS.md](TEST_RESULTS_ANALYSIS.md) — Анализ результатов тестирования на тестовых данных
- [test_cto_vault_scenarios.py](test_cto_vault_scenarios.py) — Автоматические тесты на тестовых данных

---

*Документ создан 2026-01-02 на основе отчета Round 5*

