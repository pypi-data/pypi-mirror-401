# coding: utf-8

"""
merged spec

merged spec

The version of the OpenAPI document: 1.0.0
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations

import json
import pprint
import re  # noqa: F401
from typing import Any, ClassVar, Dict, List, Optional, Set

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing_extensions import Self

from kubernetes.models.v1_csi_storage_capacity_capacity import (
    V1CSIStorageCapacityCapacity,
)
from kubernetes.models.v1_csi_storage_capacity_maximum_volume_size import (
    V1CSIStorageCapacityMaximumVolumeSize,
)
from kubernetes.models.v1_label_selector import V1LabelSelector
from kubernetes.models.v1_object_meta import V1ObjectMeta


class V1CSIStorageCapacity(BaseModel):
    """
    CSIStorageCapacity stores the result of one CSI GetCapacity call. For a given StorageClass, this describes the available capacity in a particular topology segment.  This can be used when considering where to instantiate new PersistentVolumes.  For example this can express things like: - StorageClass \"standard\" has \"1234 GiB\" available in \"topology.kubernetes.io/zone=us-east1\" - StorageClass \"localssd\" has \"10 GiB\" available in \"kubernetes.io/hostname=knode-abc123\"  The following three cases all imply that no capacity is available for a certain combination: - no object exists with suitable topology and storage class name - such an object exists, but the capacity is unset - such an object exists, but the capacity is zero  The producer of these objects can decide which approach is more suitable.  They are consumed by the kube-scheduler when a CSI driver opts into capacity-aware scheduling with CSIDriverSpec.StorageCapacity. The scheduler compares the MaximumVolumeSize against the requested size of pending volumes to filter out unsuitable nodes. If MaximumVolumeSize is unset, it falls back to a comparison against the less precise Capacity. If that is also unset, the scheduler assumes that capacity is insufficient and tries some other node.
    """  # noqa: E501

    api_version: Optional[StrictStr] = Field(
        default=None,
        description="APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources",
        alias="apiVersion",
    )
    capacity: Optional[V1CSIStorageCapacityCapacity] = None
    kind: Optional[StrictStr] = Field(
        default=None,
        description="Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds",
    )
    maximum_volume_size: Optional[V1CSIStorageCapacityMaximumVolumeSize] = Field(
        default=None, alias="maximumVolumeSize"
    )
    metadata: Optional[V1ObjectMeta] = Field(
        default=None,
        description="Standard object's metadata. The name has no particular meaning. It must be a DNS subdomain (dots allowed, 253 characters). To ensure that there are no conflicts with other CSI drivers on the cluster, the recommendation is to use csisc-<uuid>, a generated name, or a reverse-domain name which ends with the unique CSI driver name.  Objects are namespaced.  More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata",
    )
    node_topology: Optional[V1LabelSelector] = Field(
        default=None,
        description="nodeTopology defines which nodes have access to the storage for which capacity was reported. If not set, the storage is not accessible from any node in the cluster. If empty, the storage is accessible from all nodes. This field is immutable.",
        alias="nodeTopology",
    )
    storage_class_name: StrictStr = Field(
        description="storageClassName represents the name of the StorageClass that the reported capacity applies to. It must meet the same requirements as the name of a StorageClass object (non-empty, DNS subdomain). If that object no longer exists, the CSIStorageCapacity object is obsolete and should be removed by its creator. This field is immutable.",
        alias="storageClassName",
    )
    __properties: ClassVar[List[str]] = [
        "apiVersion",
        "capacity",
        "kind",
        "maximumVolumeSize",
        "metadata",
        "nodeTopology",
        "storageClassName",
    ]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of V1CSIStorageCapacity from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of capacity
        if self.capacity:
            _dict["capacity"] = self.capacity.to_dict()
        # override the default output from pydantic by calling `to_dict()` of maximum_volume_size
        if self.maximum_volume_size:
            _dict["maximumVolumeSize"] = self.maximum_volume_size.to_dict()
        # override the default output from pydantic by calling `to_dict()` of metadata
        if self.metadata:
            _dict["metadata"] = self.metadata.to_dict()
        # override the default output from pydantic by calling `to_dict()` of node_topology
        if self.node_topology:
            _dict["nodeTopology"] = self.node_topology.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of V1CSIStorageCapacity from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "apiVersion": obj.get("apiVersion"),
                "capacity": (
                    V1CSIStorageCapacityCapacity.from_dict(obj["capacity"])
                    if obj.get("capacity") is not None
                    else None
                ),
                "kind": obj.get("kind"),
                "maximumVolumeSize": (
                    V1CSIStorageCapacityMaximumVolumeSize.from_dict(
                        obj["maximumVolumeSize"]
                    )
                    if obj.get("maximumVolumeSize") is not None
                    else None
                ),
                "metadata": (
                    V1ObjectMeta.from_dict(obj["metadata"])
                    if obj.get("metadata") is not None
                    else None
                ),
                "nodeTopology": (
                    V1LabelSelector.from_dict(obj["nodeTopology"])
                    if obj.get("nodeTopology") is not None
                    else None
                ),
                "storageClassName": (
                    obj.get("storageClassName")
                    if obj.get("storageClassName") is not None
                    else ""
                ),
            }
        )
        return _obj
