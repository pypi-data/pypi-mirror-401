{
 "cells": [
  {
   "cell_type": "raw",
   "id": "main-content",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Why CANNs?\n",
    "==========\n",
    "\n",
    "**Estimated Reading Time**: 8 minutes\n",
    "\n",
    "**Target Audience**: Experimental neuroscientists, computational neuroscientists, AI researchers, engineers, and students interested in attractor networks\n",
    "\n",
    "----\n",
    "\n",
    "The Challenge: Modeling Continuous Neural Representations\n",
    "----------------------------------------------------------\n",
    "\n",
    "How does your brain know where you are in a room? How do hippocampal and entorhinal neurons maintain stable representations of your position, head direction, and navigation path‚Äîeven without external cues? These questions probe the core mechanisms of continuous attractor dynamics in neuroscience.\n",
    "\n",
    "Traditional neural networks process discrete inputs and outputs. In contrast, the brain handles **continuous state spaces**‚Äîposition, orientation, speed, and other variables that change smoothly over time. CANNs offer a computational framework for understanding how neural populations encode, maintain, and update these continuous representations through stable activity patterns called \"attractors.\"\n",
    "\n",
    ".. figure:: ../../docs/_static/smooth_tracking_1d.gif\n",
    "   :width: 400\n",
    "   :align: center\n",
    "\n",
    "   *A 1D CANN tracking a smoothly moving stimulus, demonstrating stable bump dynamics*\n",
    "\n",
    "Despite decades of theoretical progress, applying CANNs remains challenging:\n",
    "\n",
    "- **No standardized implementations** ‚Äì researchers build models from scratch for each study\n",
    "- **Fragmented tools** ‚Äì task generation, model simulation, and analysis require different codebases\n",
    "- **Reproducibility barriers** ‚Äì comparing results across studies is difficult without shared infrastructure\n",
    "- **Steep learning curve** ‚Äì students must implement complex dynamics before exploring ideas\n",
    "\n",
    "**This is where the CANNs library comes in.**\n",
    "\n",
    ".. figure:: ../../docs/_static/CANN2D_encoding.gif\n",
    "   :width: 400\n",
    "   :align: center\n",
    "\n",
    "   *2D spatial encoding patterns in CANN networks*\n",
    "\n",
    "----\n",
    "\n",
    "What Makes CANNs Special?\n",
    "--------------------------\n",
    "\n",
    "**Continuous Attractor Neural Networks** possess unique properties that bridge neuroscience and AI:\n",
    "\n",
    "1. **Stable Continuous Representations**\n",
    "\n",
    "   CANNs naturally maintain stable activity patterns (attractors) across continuous state spaces. Unlike Recurrent Neural Networks (RNNs) that require careful tuning, CANNs rest on strong theoretical foundations that ensure stability‚Äîactivity bumps persist without external input, enabling short-term memory and robust encoding.\n",
    "\n",
    "2. **Brain-Inspired Dynamics**\n",
    "\n",
    "   Compared to attention-based models like Transformers, CANNs operate through mechanisms closer to biological neural circuits. They excel at modeling:\n",
    "\n",
    "   - **Place cells** :cite:p:`o1971hippocampus` in the hippocampus (spatial position encoding)\n",
    "   - **Grid cells** :cite:p:`hafting2005microstructure` in the entorhinal cortex (periodic spatial maps)\n",
    "   - **Head direction cells** :cite:p:`taube1990head` (angular orientation)\n",
    "   - **Working memory** networks (persistent activity)\n",
    "\n",
    "3. **Continuous State Space Processing**\n",
    "\n",
    "   Traditional deep learning models discretize the world. CANNs process continuous variables natively‚Äîmatching how brains handle smooth changes in position, orientation, and sensory stimuli.\n",
    "\n",
    "4. **Path Integration and Navigation**\n",
    "\n",
    "   CANNs perform path integration naturally :cite:p:`mcnaughton2006path`: they integrate velocity signals over time to track position without external landmarks‚Äîa core computation in rodent navigation and human spatial cognition.\n",
    "\n",
    "The CANN models in this library are primarily based on the mathematically tractable and canonical continuous attractor neural network called the **Wu-Amari-Wong (WAW)** model :cite:p:`amari1977dynamics,wu2008dynamics,fung2010moving,wu2016continuous`. This canonical model provides an elegant theoretical framework for understanding continuous attractor dynamics, and its mathematical tractability enables researchers to deeply analyze network stability, dynamical properties, and encoding capabilities.\n",
    "\n",
    "In addition to guiding users through the implementation of the WAW model, this library also demonstrates how to implement a torus grid cell model with a donut-like topology.\n",
    "\n",
    "\n",
    "Building on this theoretical foundation, a recent advance combined **CANNs with neural adaptation** (A-CANN) :cite:p:`mi2014spike,li2025dynamics` to explain diverse hippocampal sequence replay patterns during rest and sleep :cite:p:`ji2025systems`. By introducing adaptation‚Äîa universal neural property‚Äîas a single control variable, researchers unified seemingly disparate phenomena: stationary replay, diffusive sequences, and super-diffusive sweeps.\n",
    "\n",
    "This work demonstrates CANN's power: **simple, biologically plausible mechanisms can explain complex neural dynamics with profound implications for memory encoding and retrieval.**\n",
    "\n",
    ".. figure:: ../../docs/_static/theta_sweep_animation.gif\n",
    "   :width: 600\n",
    "   :align: center\n",
    "\n",
    "   *Theta sweep dynamics in grid cell and head direction networks*\n",
    "\n",
    "----\n",
    "\n",
    "Who Should Use This Library?\n",
    "-----------------------------\n",
    "\n",
    "The CANNs library serves three main communities:\n",
    "\n",
    "üî¨ Experimental and Computational Neuroscientists\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Continuous attractor networks are gaining traction in systems neuroscience. Researchers want to:\n",
    "\n",
    "- **Analyze experimental data** for attractor signatures\n",
    "- **Build CANN models** to validate hypotheses against neural recordings\n",
    "- **Reproduce and extend** published CANN studies efficiently\n",
    "\n",
    "üõ†Ô∏è Engineers & Developers\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "As CANNs mature, they require **standardized development practices**‚Äîsimilar to how Transformers revolutionized NLP with consistent APIs and shared infrastructure. Engineers need unified tools to:\n",
    "\n",
    "- Implement bio-inspired navigation and memory systems\n",
    "- Benchmark CANN architectures systematically\n",
    "- Deploy CANN-based applications in robotics and AI\n",
    "\n",
    "üéì Students & Educators\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Learning CANNs shouldn't require implementing complex dynamics from scratch. Students benefit from:\n",
    "\n",
    "- **Ready-to-use models** for hands-on exploration\n",
    "- **Clear examples** demonstrating key concepts\n",
    "- **Modifiable code** to experiment with parameters and architectures\n",
    "\n",
    "**Without standardized tools, each group reinvents the wheel. The CANNs library changes that.**\n",
    "\n",
    "----\n",
    "\n",
    "Key Application Scenarios\n",
    "--------------------------\n",
    "\n",
    "1. CANN Neural Computational Modeling\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Take theta sweep modeling and analysis as an example.\n",
    "\n",
    "**The Challenge**: Hippocampal neurons exhibit rich sequential firing patterns during rest and sleep‚Äîstationary, diffusive, and super-diffusive‚Äîwith important cognitive functions. Understanding these \"theta sweeps\" :cite:p:`wang2015theta` is central to memory research.\n",
    "\n",
    "**The Solution**: The A-CANN framework (CANN + neural adaptation) :cite:p:`mi2014spike,li2025dynamics` explains these diverse patterns through a single variable. This library provides:\n",
    "\n",
    "- **Pre-built models**: ``HeadDirectionNetwork`` :cite:p:`ji2025phase` , ``GridCellNetwork`` :cite:p:`ji2025systems` , ``PlaceCellNetwork`` :cite:p:`chu2024firing`,\n",
    "- **Specialized visualization**: Theta sweep animation and analysis tools\n",
    "- **Reproducible pipelines**: ``ThetaSweepPipeline`` orchestrates simulation, analysis, and plotting\n",
    "\n",
    "**Impact**: Researchers can immediately build on this work without reimplementing models and analysis tools.\n",
    "\n",
    "2. Education and Research Training\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "**The Challenge**: Teaching CANNs traditionally requires students to implement models from scratch each semester, consuming weeks that could be spent on scientific exploration.\n",
    "\n",
    "**The Solution**: With this library, students can:\n",
    "\n",
    "- Instantiate CANN models in **3 lines of code**\n",
    "- Generate task data (smooth tracking, population coding) with **minimal setup**\n",
    "- Visualize dynamics with **built-in analysis tools**\n",
    "\n",
    "**Impact**: Students now focus on **understanding mechanisms** rather than debugging implementations.\n",
    "\n",
    "3. High-Performance Simulation\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "**The Challenge**: Long simulations and large-scale experiments (e.g., parameter sweeps, topological data analysis :cite:p:`carlsson2009topology,edelsbrunner2010computational`) are computationally expensive.\n",
    "\n",
    "**The Solution**: The companion **canns-lib** Rust library provides:\n",
    "\n",
    "- **700√ó speedup** for spatial navigation tasks vs. pure Python (RatInABox-compatible API)\n",
    "- **1.13√ó average, 1.82√ó peak speedup** for topological analysis (Ripser algorithm)\n",
    "- **Perfect accuracy** ‚Äì 100% result matching with reference implementations\n",
    "- **GPU/TPU support** ‚Äì via JAX :cite:p:`jax2018github` /BrainPy :cite:p:`wang2023brainpy` backends\n",
    "\n",
    "**Impact**: What once took hours now runs in minutes. Researchers can explore parameter spaces and analyze datasets at scale.\n",
    "\n",
    "+-----------------+-------------+------------------+---------+\n",
    "| Simulation Steps| Pure Python | canns-lib (Rust) | Speedup |\n",
    "+=================+=============+==================+=========+\n",
    "| 10¬≤             | 0.020 s     | <0.001 s         | 477√ó    |\n",
    "+-----------------+-------------+------------------+---------+\n",
    "| 10‚Å¥             | 1.928 s     | 0.003 s          | 732√ó    |\n",
    "+-----------------+-------------+------------------+---------+\n",
    "| 10‚Å∂             | 192.775 s   | 0.266 s          | 726√ó    |\n",
    "+-----------------+-------------+------------------+---------+\n",
    "\n",
    "----\n",
    "\n",
    "Why This Library? The Unified Ecosystem Advantage\n",
    "--------------------------------------------------\n",
    "\n",
    "The Problem: A Fragmented Landscape\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Currently, CANN research resembles **NLP before Transformers**‚Äîeach lab uses custom code, diverse implementations, and incompatible formats. This fragmentation causes:\n",
    "\n",
    "- **Reinvention overhead**: Researchers repeatedly re-implement basics\n",
    "- **Reproducibility issues**: Comparing studies requires reverse-engineering code\n",
    "- **Slow progress**: No shared models, benchmarks, or best practices\n",
    "\n",
    "The Vision: CANNs as the \"Hugging Face Transformers\" of Attractor Networks\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Just as Hugging Face standardized Transformer usage, **the CANNs library aims to unify CANN research**:\n",
    "\n",
    "1. **Standardized Model Zoo**\n",
    "\n",
    "   - Pre-built 1D/2D CANNs, SFA variants :cite:p:`mi2014spike,li2025dynamics`, hierarchical networks :cite:p:`chu2025localized`, grid cell models :cite:p:`burak2009accurate`\n",
    "   - Brain-inspired models: Hopfield networks :cite:p:`hopfield1982neural`, spike-based (LIF) models\n",
    "   - Hybrid architectures combining CANNs with ANNs\n",
    "\n",
    "2. **Unified Task API**\n",
    "\n",
    "   - Smooth tracking, population coding, closed/open-loop navigation\n",
    "   - Import experimental trajectories directly\n",
    "   - Consistent data formats across tasks\n",
    "\n",
    "3. **Complete Analysis Pipeline**\n",
    "\n",
    "   - Energy landscapes, tuning curves, firing fields, spike embeddings\n",
    "   - Topological data analysis (UMAP, TDA, persistent homology)\n",
    "   - Theta sweep and RNN dynamics analysis\n",
    "\n",
    "4. **Extensible Architecture**\n",
    "\n",
    "   - Base classes (``BasicModel``, ``Task``, ``Trainer``, ``Pipeline``) for custom components\n",
    "   - Built on BrainPy :cite:p:`wang2023brainpy` for JAX-powered JIT compilation and autodifferentiation\n",
    "   - GPU/TPU acceleration out of the box\n",
    "\n",
    "5. **Community & Sharing**\n",
    "\n",
    "   - Open-source foundation for model and benchmark sharing\n",
    "   - Unified evaluation protocols\n",
    "   - Growing ecosystem of examples and tutorials\n",
    "\n",
    "----\n",
    "\n",
    "Technical Foundations\n",
    "---------------------\n",
    "\n",
    "What makes this library powerful?\n",
    "\n",
    "üöÄ Performance Through BrainPy + Rust\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "- **BrainPy integration** :cite:p:`wang2023brainpy`: High-level dynamics API with JAX's JIT compilation, automatic differentiation, and GPU/TPU support\n",
    "- **canns-lib acceleration**: Rust-powered hot paths for task generation and topological analysis\n",
    "- **Efficient compilation**: Write models in simple Python, run at C++ speeds\n",
    "\n",
    "üß© Comprehensive Toolchain\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "- **Models**: 1D/2D CANNs, hierarchical networks, SFA variants, brain-inspired models\n",
    "- **Tasks**: Tracking, navigation, population coding, trajectory import\n",
    "- **Analyzers**: Visualization, TDA, bump fitting, dynamics analysis\n",
    "- **Trainers**: Hebbian learning, prediction workflows\n",
    "- **Pipelines**: End-to-end workflows (e.g., theta sweeps) in single calls\n",
    "\n",
    "üî¨ Research-Grade Quality\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "- **Validated implementations**: Models reproduce published results\n",
    "- **Comprehensive testing**: Pytest suite covering key behaviors\n",
    "- **Active development**: Regular updates, bug fixes, community contributions\n",
    "\n",
    "----\n",
    "\n",
    "Current Status & Future Directions\n",
    "-----------------------------------\n",
    "\n",
    "**Development Stage**: The library has been under active development for 4 months and is currently in **beta** (v0.x). It is being used internally by our research group, and we're actively expanding features based on user feedback.\n",
    "\n",
    "**Validation**:\n",
    "\n",
    "- ‚úÖ Models reproduce established CANN behaviors\n",
    "- ‚úÖ Performance benchmarks show significant speedups (canns-lib)\n",
    "- ‚úÖ Growing collection of working examples across models and tasks\n",
    "\n",
    "**Roadmap**:\n",
    "\n",
    "- Expand brain-inspired model collection (recurrent networks, spike-based models)\n",
    "- Add hybrid CANN-ANN architectures\n",
    "- Develop comprehensive benchmarking suite\n",
    "- Build community-contributed model zoo\n",
    "- Publish companion paper documenting library design\n",
    "\n",
    "**Limitations** (we believe in transparency):\n",
    "\n",
    "- Beta software ‚Äì APIs may evolve based on feedback\n",
    "- Documentation is actively expanding (your contributions welcome!)\n",
    "- Limited pre-trained models currently (we're building this out)\n",
    "- Smaller community compared to mature deep learning frameworks (but growing!)\n",
    "\n",
    "----\n",
    "\n",
    "Next Steps: Dive In!\n",
    "---------------------\n",
    "\n",
    "Quick Start\n",
    "~~~~~~~~~~~\n",
    "\n",
    "Ready to build your first CANN? Jump to our `Quick Start Guide <1_quick_starts/index.html>`_ for a hands-on walkthrough in <10 minutes.\n",
    "\n",
    "\n",
    "Learn More\n",
    "~~~~~~~~~~\n",
    "\n",
    "- `Core Concepts <2_core_concepts/index.html>`_: Understand the library's design philosophy\n",
    "- `Basic Tutorials <3_full_detail_tutorials/index.html>`_: Step-by-step guides for common tasks\n",
    "- `Full API Documentation <../autoapi/index.html>`_: Complete reference for all models and methods\n",
    "- `Examples Gallery <https://github.com/Routhleck/canns/tree/master/examples>`_: Ready-to-run scripts demonstrating key features\n",
    "\n",
    "Get Involved\n",
    "~~~~~~~~~~~~\n",
    "\n",
    "- üêõ **Report issues**: `GitHub Issues <https://github.com/routhleck/canns/issues>`_\n",
    "- üí¨ **Ask questions**: `GitHub Discussions <https://github.com/routhleck/canns/discussions>`_\n",
    "- ü§ù **Contribute**: Check our `Contributing Guide <https://github.com/routhleck/canns/blob/master/CONTRIBUTING.md>`_\n",
    "- ‚≠ê **Star the repo**: `github.com/routhleck/canns <https://github.com/routhleck/canns>`_\n",
    "\n",
    "----\n",
    "\n",
    "*Have questions or suggestions for this documentation? Open an issue or discussion on* `GitHub <https://github.com/routhleck/canns>`_ *!*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
