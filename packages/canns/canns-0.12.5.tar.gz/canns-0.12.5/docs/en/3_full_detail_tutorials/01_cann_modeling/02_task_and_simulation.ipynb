{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cell-0",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": "Tutorial 2: Task Generation and CANN Simulation\n================================================\n\n.. note::\n   **Reading Time**: 20-25 minutes\n   \n   **Difficulty**: Beginner\n   \n   **Prerequisites**: :doc:`Tutorial 1 <01_build_cann_model>`\n\nThis tutorial teaches you how to generate task data using the Task module and run simulations with CANN models.\n\n----"
  },
  {
   "cell_type": "raw",
   "id": "cell-2",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": ".. _task-module-overview-02:\n\n1. Task Module Overview\n-----------------------\n\nThe CANNs Task module generates experimental paradigms and input data. The relationship between Task and Model:\n\n- **Task**: Generates external stimulus sequences (input data)\n- **Model**: Consumes input data, runs in simulation loop\n\nTask Categories\n~~~~~~~~~~~~~~~\n\nCANNs provides two main task types:\n\n**Tracking Tasks**:\n\n- ``PopulationCoding1D/2D``—Population coding\n- ``TemplateMatching1D/2D``—Template matching\n- ``SmoothTracking1D/2D``—Smooth tracking\n\n**Navigation Tasks**:\n\n- ``ClosedLoopNavigation``—Closed-loop navigation\n- ``OpenLoopNavigation``—Open-loop navigation\n\n.. note::\n   This tutorial uses the simplest ``PopulationCoding1D`` as an example. Other tasks follow similar usage patterns with different initialization parameters. We'll demonstrate different tasks in later tutorials.\n\n----"
  },
  {
   "cell_type": "raw",
   "id": "cell-3",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": ".. _populationcoding1d-detail-02:\n\n2. PopulationCoding1D in Detail\n--------------------------------\n\n``PopulationCoding1D`` is a simple population coding task: no stimulus → stimulus → no stimulus. This tests the network's ability to form and maintain a memory bump.\n\n2.1 Import and Create Task\n~~~~~~~~~~~~~~~~~~~~~~~~~~"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from canns.task.tracking import PopulationCoding1D\n",
    "from canns.models.basic import CANN1D\n",
    "import brainpy.math as bm  # :cite:p:`wang2023brainpy`\n",
    "\n",
    "# First create model instance\n",
    "bm.set_dt(0.1)\n",
    "model = CANN1D(num=256, tau=1.0, k=8.1, a=0.5, A=10, J0=4.0)\n",
    "\n",
    "# Create task\n",
    "task = PopulationCoding1D(\n",
    "    cann_instance=model,      # CANN model instance\n",
    "    before_duration=10.0,     # Duration before stimulus\n",
    "    after_duration=50.0,      # Duration after stimulus\n",
    "    Iext=1.0,                 # Stimulus position in feature space\n",
    "    duration=10.0,            # Stimulus duration\n",
    "    time_step=0.1,            # Time step\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-5",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": "2.2 Parameter Descriptions\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n.. list-table::\n   :widths: 20 15 65\n   :header-rows: 1\n\n   * - Parameter\n     - Type\n     - Description\n   * - ``cann_instance``\n     - BaseCANN1D\n     - CANN model instance—task calls its ``get_stimulus_by_pos()``\n   * - ``before_duration``\n     - float\n     - Duration before stimulus presentation (no input period)\n   * - ``after_duration``\n     - float\n     - Duration after stimulus ends (observe bump maintenance)\n   * - ``Iext``\n     - float\n     - Stimulus position in feature space, typically in ``[z_min, z_max]``\n   * - ``duration``\n     - float\n     - Duration of stimulus presentation\n   * - ``time_step``\n     - float\n     - Simulation time step—should match ``bm.set_dt(...)``\n\n**Why these parameters matter**:\n\n- ``cann_instance`` is required because the task needs to call the model's ``get_stimulus_by_pos()`` method to generate appropriate stimulus\n- ``before_duration`` and ``after_duration`` allow observing bump formation and maintenance\n- ``Iext`` determines where the bump will form\n- All durations use the same unit as ``time_step``\n\n2.3 Getting Task Data\n~~~~~~~~~~~~~~~~~~~~~\n\nAfter creating a task, call ``get_data()`` to generate and store input data in ``task.data``:"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PopulationCoding1D>Generating Task data(No For Loop)\n",
      "Total time steps: 700\n",
      "Total duration: 70.0\n",
      "Data shape: (700, 256)\n"
     ]
    }
   ],
   "source": [
    "# Generate task data\n",
    "task.get_data()\n",
    "\n",
    "# Access task properties\n",
    "print(f\"Total time steps: {task.total_steps}\")\n",
    "print(f\"Total duration: {task.total_duration}\")\n",
    "print(f\"Data shape: {task.data.shape}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-7",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": ".. important::\n   ``get_data()`` does not return a value—it modifies ``task.data`` in-place. Access the data via ``task.data``.\n\n----"
  },
  {
   "cell_type": "raw",
   "id": "cell-8",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": ".. _running-simulations-forloop-02:\n\n3. Running Simulations with bm.for_loop\n----------------------------------------\n\n3.1 Why use for_loop?\n~~~~~~~~~~~~~~~~~~~~~\n\nBrainPy :cite:p:`wang2023brainpy` provides ``bm.for_loop`` for efficient simulation loops. Compared to Python ``for`` loops, it offers:\n\n- **JIT Compilation**: Entire loop compiled to efficient machine code\n- **GPU Acceleration**: Automatic GPU utilization\n- **Auto-vectorization**: Better memory access patterns\n\n.. seealso::\n   See `BrainPy Loops Tutorial <https://brainpy.readthedocs.io/tutorial_math/control_flows.html#brainpy-math-for-loop>`_ for detailed ``for_loop`` usage.\n\n3.2 Basic Usage\n~~~~~~~~~~~~~~~"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6b642e56224886a56123fea8ab4d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import brainpy.math as bm  # :cite:p:`wang2023brainpy`\n",
    "\n",
    "# Define step function\n",
    "def run_step(t, inp):\n",
    "    \"\"\"\n",
    "    Single simulation step.\n",
    "\n",
    "    Args:\n",
    "        t: Current time step index\n",
    "        inp: Input data at current time step\n",
    "\n",
    "    Returns:\n",
    "        State variables to record\n",
    "    \"\"\"\n",
    "    model(inp)  # Or model.update(inp)\n",
    "    return model.u.value, model.r.value\n",
    "\n",
    "# Run simulation using task.data\n",
    "results = bm.for_loop(\n",
    "    run_step,           # Step function\n",
    "    operands=(task.run_steps, task.data),  # Number of time steps and input data\n",
    "    progress_bar=10  # Optional progress bar (updates every 10 steps)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-10",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": "3.3 Handling Return Values\n~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n``for_loop`` returns values corresponding to step function returns:"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membrane potential history shape: (700, 256)\n",
      "Firing rate history shape: (700, 256)\n"
     ]
    }
   ],
   "source": [
    "# results is a tuple of return values across all time steps\n",
    "u_history, r_history = results\n",
    "\n",
    "print(f\"Membrane potential history shape: {u_history.shape}\")  # (run_steps, num)\n",
    "print(f\"Firing rate history shape: {r_history.shape}\")  # (run_steps, num)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-12",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": "3.4 JIT Compilation Benefits\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nFirst run includes compilation time (few seconds), but subsequent runs are much faster:"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PopulationCoding1D>Generating Task data(No For Loop)\n",
      "First run: 0.75s\n",
      "Second run: 0.24s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = CANN1D(num=256, tau=1.0, k=8.1, a=0.5, A=10, J0=4.0)\n",
    "\n",
    "# Create a new longer task\n",
    "task = PopulationCoding1D(\n",
    "    cann_instance=model,      # CANN model instance\n",
    "    before_duration=10000.0,     # Duration before stimulus\n",
    "    after_duration=10000.0,      # Duration after stimulus\n",
    "    Iext=1.0,                 # Stimulus position in feature space\n",
    "    duration=10000.0,            # Stimulus duration\n",
    "    time_step=0.1,            # Time step\n",
    ")\n",
    "task.get_data()\n",
    "\n",
    "# First run (includes compilation)\n",
    "start = time.time()\n",
    "results = bm.for_loop(run_step, operands=(task.run_steps, task.data))\n",
    "print(f\"First run: {time.time() - start:.2f}s\")\n",
    "\n",
    "# Second run (already compiled)\n",
    "start = time.time()\n",
    "results = bm.for_loop(run_step, operands=(task.run_steps, task.data))\n",
    "print(f\"Second run: {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-14",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-15",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _complete-example-02:\n",
    "\n",
    "4. Complete Example\n",
    "-------------------\n",
    "\n",
    "Here's a complete example from model creation to simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PopulationCoding1D>Generating Task data(No For Loop)\n",
      "Task Information:\n",
      "  Total time steps: 700\n",
      "  Total duration: 70.0\n",
      "  Data shape: (700, 256)\n",
      "\n",
      "Simulation Results:\n",
      "  Membrane potential history shape: (700, 256)\n",
      "  Firing rate history shape: (700, 256)\n",
      "\n",
      "Before stimulus (t=99) max firing rate: 0.000000\n",
      "During stimulus (t=199) max firing rate: 0.002426\n",
      "After stimulus (t=699) max firing rate: 0.002348\n"
     ]
    }
   ],
   "source": [
    "import brainpy.math as bm  # :cite:p:`wang2023brainpy`\n",
    "from canns.models.basic import CANN1D\n",
    "from canns.task.tracking import PopulationCoding1D\n",
    "\n",
    "# ============================================================\n",
    "# Step 1: Setup environment and create model\n",
    "# ============================================================\n",
    "bm.set_dt(0.1)\n",
    "\n",
    "model = CANN1D(num=256, tau=1.0, k=8.1, a=0.5, A=10, J0=4.0)\n",
    "\n",
    "# ============================================================\n",
    "# Step 2: Create task\n",
    "# ============================================================\n",
    "task = PopulationCoding1D(\n",
    "    cann_instance=model,\n",
    "    before_duration=10.0,\n",
    "    after_duration=50.0,\n",
    "    Iext=0.0,\n",
    "    duration=10.0,\n",
    "    time_step=0.1,\n",
    ")\n",
    "\n",
    "# Get task data\n",
    "task.get_data()\n",
    "\n",
    "print(\"Task Information:\")\n",
    "print(f\"  Total time steps: {task.total_steps}\")\n",
    "print(f\"  Total duration: {task.total_duration}\")\n",
    "print(f\"  Data shape: {task.data.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 3: Define simulation step function\n",
    "# ============================================================\n",
    "def run_step(t, inp):\n",
    "    model.update(inp)\n",
    "    return model.u.value, model.r.value\n",
    "\n",
    "# ============================================================\n",
    "# Step 4: Run simulation\n",
    "# ============================================================\n",
    "u_history, r_history = bm.for_loop(\n",
    "    run_step,\n",
    "    operands=(task.run_steps, task.data),\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Step 5: Inspect results\n",
    "# ============================================================\n",
    "print(\"\\nSimulation Results:\")\n",
    "print(f\"  Membrane potential history shape: {u_history.shape}\")\n",
    "print(f\"  Firing rate history shape: {r_history.shape}\")\n",
    "\n",
    "# Check states at different phases\n",
    "before_steps = int(10.0 / 0.1)  # Before stimulus\n",
    "stim_end = int(20.0 / 0.1)      # End of stimulus\n",
    "after_steps = int(70.0 / 0.1)   # End of simulation\n",
    "\n",
    "print(f\"\\nBefore stimulus (t={before_steps-1}) max firing rate: {bm.max(r_history[before_steps-1]):.6f}\")\n",
    "print(f\"During stimulus (t={stim_end-1}) max firing rate: {bm.max(r_history[stim_end-1]):.6f}\")\n",
    "print(f\"After stimulus (t={after_steps-1}) max firing rate: {bm.max(r_history[after_steps-1]):.6f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cell-17",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": "**Expected output**:\n\n- Before stimulus: firing rate ≈0\n- During stimulus: firing rate increases (bump forms)\n- After stimulus: firing rate maintained (memory persists)\n\n----"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": ".. _next-steps-02:\n\n5. Next Steps\n-------------\n\nCongratulations! You now understand how to generate tasks and run CANN simulations. You've learned:\n\n- How to create smooth tracking tasks with ``SmoothTracking1D`` and ``SmoothTracking2D``\n- How to generate navigation tasks with ``OpenLoopNavigationTask``\n- How to run simulations using ``bm.for_loop`` for efficiency\n- How to record and analyze network states over time\n- The difference between open-loop (pre-generated trajectory) and closed-loop (interactive) tasks\n\nWhat You've Learned\n~~~~~~~~~~~~~~~~~~~\n\n**Task Generation**\n   You can create various input patterns for CANN models—from simple tracking to complex navigation trajectories.\n\n**Simulation Workflows**\n   You understand the standard simulation pattern: initialize model → create task → run loop → analyze results.\n\n**Performance Optimization**\n   You know how to use JIT-compiled loops for fast simulation of long time series.\n\n**Data Organization**\n   You can structure simulation outputs for downstream analysis and visualization.\n\nContinue Learning\n~~~~~~~~~~~~~~~~~\n\nNow proceed to visualization and analysis:\n\n- :doc:`Tutorial 3: Analysis and Visualization <03_analysis_visualization>`—Learn how to create energy landscapes, firing field plots, and animations\n\nThen continue with:\n\n- :doc:`Tutorial 4: Parameter Effects <04_parameter_effects>`—Systematic exploration of how parameters affect dynamics\n- :doc:`Tutorial 5: Hierarchical Path Integration <05_hierarchical_network>`—Multi-scale navigation with grid cells\n- :doc:`Tutorial 6: Theta Sweep System <06_theta_sweep_hd_grid>`—Theta-modulated head direction and grid cells\n\nOr explore other workflows:\n\n- **Scenario 2: Data Analysis**—Analyze experimental neural recordings\n- **Scenario 3: Brain-Inspired Learning**—Train networks with Hebbian learning\n- **Scenario 4: Pipeline**—End-to-end research workflows\n\nKey Takeaways\n~~~~~~~~~~~~~\n\n1. **Tasks define inputs**—Task modules generate the external stimuli that drive CANN dynamics\n2. **Separation of concerns**—Models define dynamics, tasks define inputs, analyzers handle visualization\n3. **Flexibility**—The same model can be used with different tasks for various applications\n4. **Efficiency matters**—Use compiled loops (``bm.for_loop``) for production simulations\n\nBest Practices\n~~~~~~~~~~~~~~\n\nWhen running simulations:\n\n1. **Start small**—Test with short durations first, then scale up\n2. **Monitor memory**—Long simulations with many neurons can consume significant memory\n3. **Save intermediate results**—Use ``np.save`` to checkpoint long simulations\n4. **Document parameters**—Keep track of task and model parameters for reproducibility\n\nNext: :doc:`Tutorial 3: Analysis and Visualization <03_analysis_visualization>`",
   "id": "cell-18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}