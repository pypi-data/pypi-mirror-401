# generated by datamodel-codegen:
#   filename:  openapi.yaml
#   timestamp: 2026-01-15T12:02:50+00:00

from __future__ import annotations

from enum import Enum
from typing import Any
from typing import Dict
from typing import List
from typing import Literal
from typing import Optional
from typing import Union

from pydantic import ConfigDict
from pydantic import Field
from pydantic import RootModel
from pydantic import SecretStr

from .base_model import LFBaseModel


class Id(LFBaseModel):
    id: str


class Success(LFBaseModel):
    message: Optional[str] = Field(None, description="A human-readable message")
    """
    A human-readable message
    """


class Pending(LFBaseModel):
    message: Optional[str] = Field(None, description="A human-readable message")
    """
    A human-readable message
    """

    status: Literal["PENDING"] = "PENDING"


class LoginRequest(LFBaseModel):
    email: str

    password: str

    remember: bool = False


class CredentialType(Enum):
    """
    The type of that a user uses.
    """

    password = "password"


class TaskSpecification(LFBaseModel):
    task_id: str = Field(..., description="ID of the task.")
    """
    ID of the task.
    """

    task_config: Dict[str, Any] = Field(
        ..., description="Config (maybe partial) that conforms to the spec in the Task."
    )
    """
    Config (maybe partial) that conforms to the spec in the Task.
    """

    entity_id: str = Field(
        ...,
        description="Either dataset id or model id. The type of the entity is in the Task.",
    )
    """
    Either dataset id or model id. The type of the entity is in the Task.
    """

    display_name: Optional[str] = Field(
        None,
        min_length=1,
        description="The name that will be assigned to the evaluation. If not given, it will be auto-generated.",
    )
    """
    The name that will be assigned to the evaluation. If not given, it will be auto-generated.
    """


class Mode(Enum):
    """
    The mode of evaluation to be performed.
    """

    FULL = "full"
    FAST = "fast"
    DEBUG = "debug"


class EvaluationConfig(LFBaseModel):
    """
    Parameters required when starting an evaluation.
    """

    mode: Mode = Field(..., description="The mode of evaluation to be performed.")
    """
    The mode of evaluation to be performed.
    """


class ModelAdapterProvider(Enum):
    """
    The provider of the model adapter.
    """

    LATTICEFLOW = "latticeflow"
    USER = "user"


class MLTask(Enum):
    """
    The type of machine learning task to be performed.
    """

    CHAT_COMPLETION = "chat_completion"
    GUARDRAIL_INPUT_FILTER = "guardrail_input_filter"
    EMBEDDINGS = "embeddings"
    CUSTOM = "custom"


class ModelAdapterCodeLanguage(Enum):
    """
    The programming language used in the code snippet. Currently, only 'jinja' is supported.
    """

    JINJA = "jinja"


class TrustChainVerification(Enum):
    """
    How to trust the CA trust chain.

    - `verify_trust_chain` (default) will verify the server certificate against the configured CA trust.
    - `accept_untrusted` will not perform server certificate verification. NOTE: This is a
      security hazard and should be avoided.

    """

    VERIFY_TRUST_CHAIN = "verify_trust_chain"
    ACCEPT_UNTRUSTED = "accept_untrusted"


class IntegrationModelProviderId(Enum):
    """
    The internal identifiers for all model providers known by the system.
    """

    ANTHROPIC = "anthropic"
    FIREWORKS = "fireworks"
    GEMINI = "gemini"
    NOVITA = "novita"
    OPENAI = "openai"
    SAMBANOVA = "sambanova"
    TOGETHER = "together"
    ZENGUARD = "zenguard"


class LocalModelProviderId(Enum):
    """
    Private, non integrated model providers
    """

    LOCAL = "local"


class PiiLeakage(LFBaseModel):
    """
    Mitigation capability for PII.
    """

    display_name: str = Field(..., min_length=1)


class PromptInjection(LFBaseModel):
    """
    Mitigation capability for PII.
    """

    display_name: str = Field(..., min_length=1)


class Mitigations(LFBaseModel):
    """
    The mitigation capabilities of the model
    """

    pii_leakage: Optional[PiiLeakage] = Field(
        None, description="Mitigation capability for PII."
    )
    """
    Mitigation capability for PII.
    """

    prompt_injection: Optional[PromptInjection] = Field(
        None, description="Mitigation capability for PII."
    )
    """
    Mitigation capability for PII.
    """


class ModelCapabilities(LFBaseModel):
    """
    The model capabilities.
    """

    mitigations: Optional[Mitigations] = Field(
        None, description="The mitigation capabilities of the model"
    )
    """
    The mitigation capabilities of the model
    """


class DatasetMetadata(LFBaseModel):
    """
    Dataset metadata.
    """

    num_rows: int

    columns: List[str]

    download_url: str = Field(
        ..., description="URL to download the dataset in JSONL format."
    )
    """
    URL to download the dataset in JSONL format.
    """


class Dataset(LFBaseModel):
    """
    All properties required for the creation of a Dataset, except the binary file.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the dataset."
    )
    """
    The display name of the dataset.
    """

    description: Optional[str] = Field(
        None, description="An optional description of the dataset."
    )
    """
    An optional description of the dataset.
    """

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="A unique key for the dataset.",
    )
    """
    A unique key for the dataset.
    """


class DatasetProvider(Enum):
    LATTICEFLOW = "latticeflow"
    USER = "user"


class ExecutionStatus(Enum):
    NOT_STARTED = "not_started"
    PENDING = "pending"
    FINISHED = "finished"


class ResultStatus(Enum):
    SUCCEEDED = "succeeded"
    FAILED = "failed"
    CANCELLED = "cancelled"


class DatasetGenerationRequest(LFBaseModel):
    dataset_generator_config: Dict[str, Any] = Field(
        ..., description="The configuration used by the dataset generator."
    )
    """
    The configuration used by the dataset generator.
    """

    num_samples: int = Field(..., description="The number of samples to generate.")
    """
    The number of samples to generate.
    """


class ExecutionProgress(LFBaseModel):
    progress: float = Field(
        ..., ge=0.0, le=1.0, description="A progress indicator for the evaluation."
    )
    """
    A progress indicator for the evaluation.
    """

    num_total_samples: Optional[int] = Field(
        None,
        description="The total number of samples to be processed for this evaluation.",
    )
    """
    The total number of samples to be processed for this evaluation.
    """

    num_processed_samples: Optional[int] = Field(
        None, description="The number of samples already processed for this evaluation."
    )
    """
    The number of samples already processed for this evaluation.
    """


class EvaluatedEntityType(Enum):
    DATASET = "dataset"
    MODEL = "model"


class FloatParameterSpec(LFBaseModel):
    type: Literal["float"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    min: Optional[float] = Field(
        None, description="The minimum value of the parameter."
    )
    """
    The minimum value of the parameter.
    """

    max: Optional[float] = Field(
        None, description="The maximum value of the parameter."
    )
    """
    The maximum value of the parameter.
    """

    default_value: Optional[float] = Field(None, description="Default value to choose.")
    """
    Default value to choose.
    """


class IntParameterSpec(LFBaseModel):
    type: Literal["int"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    min: Optional[int] = Field(None, description="The minimum value of the parameter.")
    """
    The minimum value of the parameter.
    """

    max: Optional[int] = Field(None, description="The maximum value of the parameter.")
    """
    The maximum value of the parameter.
    """

    default_value: Optional[int] = Field(None, description="Default value to choose.")
    """
    Default value to choose.
    """


class BooleanParameterSpec(LFBaseModel):
    type: Literal["boolean"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    default_value: Optional[bool] = Field(None, description="The default value to use.")
    """
    The default value to use.
    """


class StringKind(Enum):
    """
    Specifies the kind of string parameter. Supported kinds are 'freeform', 'python', and 'jinja'.
    """

    FREEFORM = "freeform"
    PYTHON = "python"
    JINJA = "jinja"


class StringParameterExample(LFBaseModel):
    value: str = Field(..., description="The example value for the string parameter.")
    """
    The example value for the string parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the example."
    )
    """
    The display name of the example.
    """


class ModelParameterSpec(LFBaseModel):
    type: Literal["model"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    default_value: Optional[str] = Field(None, description="The default value to use.")
    """
    The default value to use.
    """

    nullable: bool = Field(False, description="Whether this field is nullable.")
    """
    Whether this field is nullable.
    """


class DatasetParameterSpec(LFBaseModel):
    type: Literal["dataset"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    default_value: Optional[str] = Field(None, description="The default value to use.")
    """
    The default value to use.
    """

    nullable: bool = Field(False, description="Whether this field is nullable.")
    """
    Whether this field is nullable.
    """


class DatasetColumnParameterSpec(LFBaseModel):
    type: Literal["dataset_column"] = Field(
        ..., description="The type of the parameter."
    )
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    default_value: Optional[str] = Field(None, description="The default value to use.")
    """
    The default value to use.
    """

    nullable: bool = Field(False, description="Whether this field is nullable.")
    """
    Whether this field is nullable.
    """


class ScalarDtype(Enum):
    """
    The scalar data type.
    """

    STRING = "string"
    INTEGER = "integer"
    FLOAT = "float"
    BOOLEAN = "boolean"


class CategoricalParameterSpec(LFBaseModel):
    type: Literal["categorical"] = Field(..., description="The type of parameter.")
    """
    The type of parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    allowed_values: List[str]

    multiple: bool = Field(
        False, description="Whether the parameter can have multiple values."
    )
    """
    Whether the parameter can have multiple values.
    """

    default_value: Optional[str] = Field(None, description="Default value to use.")
    """
    Default value to use.
    """


class TaskDatasetTemplate(LFBaseModel):
    """
    The dataset that will be used to evaluate the model.
    """

    id: str

    fast_subset_size: Union[int, str] = Field(
        200,
        description="Size of the fast evaluation subset. This is the subset size of the dataset that runs in a reasonable amount of time (less than 5 minutes) and is a quick and approximate version of the task. Can be a string if this is a configurable field.",
    )
    """
    Size of the fast evaluation subset. This is the subset size of the dataset that runs in a reasonable amount of time (less than 5 minutes) and is a quick and approximate version of the task. Can be a string if this is a configurable field.
    """


class TaskSolverTemplate(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    type: str = Field(..., description="The type of the solver.")
    """
    The type of the solver.
    """


class TaskMetricTemplate(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    key: Optional[str] = Field(None, description="The key of the metric.")
    """
    The key of the metric.
    """

    type: str = Field(..., description="The type of metric.")
    """
    The type of metric.
    """


class PredefinedTaskDefinition(LFBaseModel):
    type: Literal["predefined"] = Field(..., description="The type of task definition.")
    """
    The type of task definition.
    """


class TaskProvider(Enum):
    LATTICEFLOW = "latticeflow"
    USER = "user"


class Tag(LFBaseModel):
    value: str = Field(..., description="The text value of the tag.")
    """
    The text value of the tag.
    """

    color: str = Field(
        ...,
        pattern="^#([0-9a-fA-F]{6}|[0-9a-fA-F]{3})$",
        description="The color (#RRGGBB or #RGB) associated with the tag, used for UI representation.",
    )
    """
    The color (#RRGGBB or #RGB) associated with the tag, used for UI representation.
    """


class Role(Enum):
    """
    A user role in the system.
    Users with the "admin" role can create and disable users and can reset credentials.
    All users are assigned the "member" role by default, unless their role is explicitly set to "viewer". Users can have more than one role.

    """

    MEMBER = "member"
    ADMIN = "admin"
    VIEWER = "viewer"


class TaskResult(LFBaseModel):
    evaluated_entity_type: EvaluatedEntityType = Field(
        ..., description="The type of the evaluated entity"
    )
    """
    The type of the evaluated entity
    """

    evaluated_entity_id: str = Field(..., description="The ID of the evaluated entity")
    """
    The ID of the evaluated entity
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the task result."
    )
    """
    The display name of the task result.
    """

    task_id: str = Field(..., description="The key of the task.")
    """
    The key of the task.
    """

    task_config: Dict[str, Any] = Field(..., description="The task configuration.")
    """
    The task configuration.
    """

    run_config: EvaluationConfig


class TaskResultErrorStage(Enum):
    CONFIGURATION = "configuration"
    DATASET = "dataset"
    SOLVER = "solver"
    SCORE = "score"
    METRIC = "metric"


class Artifact(LFBaseModel):
    id: str

    file_name: str

    file_url: str


class TaskResultFailures(LFBaseModel):
    num_errors: int

    num_total: int


class LifecycleStage(Enum):
    """
    The AI App's lifecycle stage. Supported values are: `development`, `ideation`, `r_and_d`, `testing`, `production`, `retired`.
    """

    DEVELOPMENT = "development"
    IDEATION = "ideation"
    R_AND_D = "r_and_d"
    TESTING = "testing"
    PRODUCTION = "production"
    RETIRED = "retired"


class UserTypes(Enum):
    """
    The target type of the primary user of the AI app. Supported values are: `internal_specialist`, `internal_all`, `external`.
    """

    INTERNAL_SPECIALIST = "internal_specialist"
    INTERNAL_ALL = "internal_all"
    EXTERNAL = "external"


class DataClassification(Enum):
    """
    The classification of the data that the AI app has access to or has been trained on. Supported values are: `public`, `internal`, `confidential`, `restricted`.
    """

    PUBLIC = "public"
    INTERNAL = "internal"
    CONFIDENTIAL = "confidential"
    RESTRICTED = "restricted"


class BuiltBy(Enum):
    """
    Indicates whether the AI app is built by a third party or in-house. Supported values are: `third_party`, `in_house`.
    """

    THIRD_PARTY = "third_party"
    IN_HOUSE = "in_house"


class AIAppKeyInformation(LFBaseModel):
    """
    The key information needed to determine what risks to show and recommend for pre-screening.
    """

    lifecycle_stage: Optional[LifecycleStage] = Field(
        None,
        description="The AI App's lifecycle stage. Supported values are: `development`, `ideation`, `r_and_d`, `testing`, `production`, `retired`.",
    )
    """
    The AI App's lifecycle stage. Supported values are: `development`, `ideation`, `r_and_d`, `testing`, `production`, `retired`.
    """

    user_types: Optional[UserTypes] = Field(
        None,
        description="The target type of the primary user of the AI app. Supported values are: `internal_specialist`, `internal_all`, `external`.",
    )
    """
    The target type of the primary user of the AI app. Supported values are: `internal_specialist`, `internal_all`, `external`.
    """

    data_classification: Optional[DataClassification] = Field(
        None,
        description="The classification of the data that the AI app has access to or has been trained on. Supported values are: `public`, `internal`, `confidential`, `restricted`.",
    )
    """
    The classification of the data that the AI app has access to or has been trained on. Supported values are: `public`, `internal`, `confidential`, `restricted`.
    """

    has_pii_access: Optional[bool] = Field(
        None, description="Boolean flag whether the AI app has PII access."
    )
    """
    Boolean flag whether the AI app has PII access.
    """

    has_client_data_access: Optional[bool] = Field(
        None, description="Boolean flag whether the AI app has client data access."
    )
    """
    Boolean flag whether the AI app has client data access.
    """

    built_by: Optional[BuiltBy] = Field(
        None,
        description="Indicates whether the AI app is built by a third party or in-house. Supported values are: `third_party`, `in_house`.",
    )
    """
    Indicates whether the AI app is built by a third party or in-house. Supported values are: `third_party`, `in_house`.
    """


class NumericalPredicate(Enum):
    LESS_THAN = "lt"
    LESS_THAN_OR_EQUAL = "leq"
    GREATER_THAN = "gt"
    GREATER_THAN_OR_EQUAL = "geq"
    EQUAL = "eq"


class DatasetData(LFBaseModel):
    """
    Encapsulates a collection of dataset samples and the properties they contain.
    """

    column_names: List[str] = Field(
        ..., description="List of the column names in the dataset's csv file."
    )
    """
    List of the column names in the dataset's csv file.
    """

    sample_rows: List[Dict[str, Any]] = Field(
        ..., description="A few of the rows from the dataset's uploaded csv file."
    )
    """
    A few of the rows from the dataset's uploaded csv file.
    """

    num_rows: int = Field(
        ..., description="The total number of rows in the dataset's uploaded csv file."
    )
    """
    The total number of rows in the dataset's uploaded csv file.
    """


class DeploymentMode(Enum):
    """
    The allowed deployment modes for the app.
    """

    MULTI_TENANT = "multi-tenant"
    SINGLE_TENANT = "single-tenant"


class RawModelInput(LFBaseModel):
    """
    A generic raw model input.
    """

    input: str

    content_type: str


class RawModelOutput(LFBaseModel):
    """
    A raw model response.
    """

    output: str

    status_code: int

    response_headers: Dict[str, str]

    request_headers: Dict[str, str]


class IntegrationDatasetProviderId(Enum):
    """
    The internal identifiers for all model providers known by the system.
    """

    HUGGINGFACE = "huggingface"


class Integration(LFBaseModel):
    """
    Basic integration information shared between most integrations.
    """

    api_key: SecretStr


class OpenAIIntegration(Integration):
    """
    The OpenAI integration configuration object.
    """

    org_id: Optional[str] = None


class ZenguardTier(Enum):
    BASE = "base"
    DEDICATED = "dedicated"


class ZenguardIntegration(Integration):
    """
    The Zenguard integration configuration object.
    """

    tier: ZenguardTier


class ResetUserCredentialAction(LFBaseModel):
    credential_type: CredentialType


class SetupState(Enum):
    """
    The setup state of the application
    """

    initial = "initial"
    complete = "complete"


class AnalyticsConfig(LFBaseModel):
    enabled: bool = Field(..., description="Whether analytics is enabled.")
    """
    Whether analytics is enabled.
    """

    user_uuid: str = Field(..., description="The globally-unique user identifier.")
    """
    The globally-unique user identifier.
    """

    tenant_uuid: str = Field(
        ..., description="The globally-unique tenant (organisation) identifier."
    )
    """
    The globally-unique tenant (organisation) identifier.
    """


class Report(LFBaseModel):
    uri: str


class ClientVersionMismatchError(LFBaseModel):
    """
    Error signaling a version mismatch between the API and the client.
    """

    api_version: str = Field(
        ..., description="Version of the API the client should be changed to."
    )
    """
    Version of the API the client should be changed to.
    """

    client_version: str = Field(
        ..., description="Version of the client as specified in the original request."
    )
    """
    Version of the client as specified in the original request.
    """


class Error(LFBaseModel):
    message: str = Field(..., description="A human-readable error message")
    """
    A human-readable error message
    """


class DatasetGeneratorDataSourceTemplate(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    type: str = Field(
        ...,
        description="The type of supported data source. Supported types are: `dataset_samples`, and `empty`. If it's set to `dataset_samples`, the user can use an existing dataset in AI GO! as the data source through specifying another field `dataset_key`. If it's set to `empty`, the data source yields empty elements. The number of empty elements can be set through `num_samples` field.",
    )
    """
    The type of supported data source. Supported types are: `dataset_samples`, and `empty`. If it's set to `dataset_samples`, the user can use an existing dataset in AI GO! as the data source through specifying another field `dataset_key`. If it's set to `empty`, the data source yields empty elements. The number of empty elements can be set through `num_samples` field.
    """


class DatasetGeneratorSynthesizerTemplate(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    type: str = Field(
        ..., description="Supported synthesizer types are: `llm` and `template`."
    )
    """
    Supported synthesizer types are: `llm` and `template`.
    """


class DatasetGeneratorProvider(Enum):
    LATTICEFLOW = "latticeflow"
    USER = "user"


class DeclarativeDatasetGeneratorDefinition(LFBaseModel):
    type: Literal["declarative_dataset_generator"] = Field(
        ..., description="The type of dataset generator definition."
    )
    """
    The type of dataset generator definition.
    """

    data_source: DatasetGeneratorDataSourceTemplate

    synthesizer: DatasetGeneratorSynthesizerTemplate


class DatasetGenerationErrorStage(Enum):
    CONFIGURATION = "configuration"
    DATA_SOURCE = "data_source"
    SYNTHESIZER = "synthesizer"


class ChatCompletionModelInputBuilderConfig(LFBaseModel):
    model_input_builder_type: Literal["chat_completion"] = Field(
        ..., description="The type of the model input builder."
    )
    """
    The type of the model input builder.
    """

    system_prompt: Optional[str] = Field(
        None,
        examples=["You are a helpful assistant."],
        description="System prompts given to the model. This contains the necessary instructions for the model to perform the task.  Use curly braces '{{ sample.attribute }}' to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.",
    )
    """
    System prompts given to the model. This contains the necessary instructions for the model to perform the task.  Use curly braces '{{ sample.attribute }}' to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.
    """

    user_prompt: str = Field(
        ...,
        examples=["What is the capital of {{ sample.country }}?"],
        description="User prompts given to the model. Use curly braces '{{ sample.attribute }}' to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.",
    )
    """
    User prompts given to the model. Use curly braces '{{ sample.attribute }}' to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.
    """


class GenericModelInputBuilderConfig(LFBaseModel):
    model_input_builder_type: Literal["generic"] = Field(
        ..., description="The type of the model input builder."
    )
    """
    The type of the model input builder.
    """

    template: str = Field(
        ...,
        examples=['{"question": "What is the capital of {{ sample.country }}?"}'],
        description="Jinja template that takes the sample as input and produces a JSON. Use curly braces `{{ sample.attribute }}` to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.",
    )
    """
    Jinja template that takes the sample as input and produces a JSON. Use curly braces `{{ sample.attribute }}` to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.
    """


class ModelInputBuilderKey(Enum):
    """
    The key of the model input builder.
    """

    CHAT_COMPLETION = "chat_completion"
    GENERIC = "generic"


class ModelInputBuilderConfig(
    RootModel[
        Union[ChatCompletionModelInputBuilderConfig, GenericModelInputBuilderConfig]
    ]
):
    root: Union[
        ChatCompletionModelInputBuilderConfig, GenericModelInputBuilderConfig
    ] = Field(..., discriminator="model_input_builder_type")


class TaskMetric(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    key: Optional[str] = Field(None, description="The key of the metric.")
    """
    The key of the metric.
    """

    type: str = Field(..., description="The type of metric.")
    """
    The type of metric.
    """


class Meta(LFBaseModel):
    name: str = Field(..., description="Name of the table.")
    """
    Name of the table.
    """


class TableColumn(LFBaseModel):
    id: str = Field(..., description="The ID of the columns.")
    """
    The ID of the columns.
    """

    display_name: str = Field(
        ..., min_length=1, description="Display name of the column."
    )
    """
    Display name of the column.
    """

    description: Optional[str] = Field(None, description="Description of the column.")
    """
    Description of the column.
    """

    is_primary: bool = Field(
        ...,
        description="Whether the column is primary. In the context of a tabular evidence metric evaluation,\nthis is a column relevant to the interpretation result.\n",
    )
    """
    Whether the column is primary. In the context of a tabular evidence metric evaluation,
    this is a column relevant to the interpretation result.

    """

    type: Optional[str] = Field(None, description="The type of the column.")
    """
    The type of the column.
    """


class TaskResultUsage(LFBaseModel):
    """
    An object that contains the model usage summary for the task result.
    """

    num_samples: int

    num_completion_tokens: Optional[int] = None

    num_prompt_tokens: Optional[int] = None


class ConnectionCheckResult(LFBaseModel):
    success: bool = Field(
        ..., description="Whether the connection check was successful."
    )
    """
    Whether the connection check was successful.
    """

    message: str = Field(
        ...,
        description="In case of success: The model response. Otherwise: An error message.",
    )
    """
    In case of success: The model response. Otherwise: An error message.
    """


class ModelAdapterInput(LFBaseModel):
    """
    Model input represented in the LatticeFlow AIGO format.
    """

    input: str


class ModelAdapterOutput(LFBaseModel):
    """
    Model output represented in the LatticeFlow AIGO format.
    """

    output: str


class ModelAdapterTransformationError(Error):
    """
    Describes an error that occured during model adapter transformation.
    """

    transformed: Optional[str] = None


class StoredTaskSpecification(Id, TaskSpecification):
    valid: bool = Field(
        ...,
        description="True when the specification has beed validated and conforms to the evaluator config spec.",
    )
    """
    True when the specification has beed validated and conforms to the evaluator config spec.
    """


class GeneratedDataset(Dataset):
    dataset_generation_request: DatasetGenerationRequest


class Tenant(LFBaseModel):
    name: str = Field(..., description="A unique name for the tenant.")
    """
    A unique name for the tenant.
    """

    alias: str = Field(
        ...,
        pattern="^[a-z0-9-]+",
        description="A unique URL-friendly identifier for the tenant.",
    )
    """
    A unique URL-friendly identifier for the tenant.
    """

    domains: List[str] = Field(
        ..., description="The internet domains that will be associated with the tenant."
    )
    """
    The internet domains that will be associated with the tenant.
    """


class StoredTenant(Id, Tenant):
    pass


class StoredTenants(LFBaseModel):
    tenants: List[StoredTenant]


class TaskDataset(LFBaseModel):
    """
    The dataset that will be used to evaluate the model.
    """

    id: str

    fast_subset_size: int = Field(
        200,
        description="Size of the fast evaluation subset. This is the subset size of the dataset that runs in a reasonable amount of time (less than 5 minutes) and is a quick and approximate version of the task.",
    )
    """
    Size of the fast evaluation subset. This is the subset size of the dataset that runs in a reasonable amount of time (less than 5 minutes) and is a quick and approximate version of the task.
    """


class GeneralInputBuilder(LFBaseModel):
    type: Literal["generic"] = Field(..., description="The type of input builder.")
    """
    The type of input builder.
    """

    template: str = Field(
        ...,
        examples=['{"question": "What is the capital of {{ sample.country }}?"}'],
        description="Jinja template that takes the sample as input and produces the input in JSON form. Use curly braces `{{ sample.attribute }}` to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.",
    )
    """
    Jinja template that takes the sample as input and produces the input in JSON form. Use curly braces `{{ sample.attribute }}` to denote variables that will be dynamically populated for each sample in the dataset. Full Jinja is supported for the prompt.
    """


class ChatCompletionRole(Enum):
    """
    The role of the message sender, can be `system`, `user`, or `assistant`.
    """

    ASSISTANT = "assistant"
    SYSTEM = "system"
    USER = "user"


class GroupedSingleTurnSolver(LFBaseModel):
    type: Literal["grouped_single_turn_solver"]

    input_builder: GeneralInputBuilder = Field(..., discriminator="type")


class ChatMessageBuilder(LFBaseModel):
    type: Literal["chat_message"]

    content: str

    role: ChatCompletionRole


class TerminationCondition(LFBaseModel):
    includes: str = Field(
        ...,
        description="If the messages includes this string, the termination condition is met. ",
    )
    """
    If the messages includes this string, the termination condition is met. 
    """

    keep_iteration: bool = Field(
        True,
        description="Within a loop, determines if all messages in the current iteration are kept or not, if the termination condition is met. Outside of a loop, decides if the message is kept or not if the termination condition is met.",
    )
    """
    Within a loop, determines if all messages in the current iteration are kept or not, if the termination condition is met. Outside of a loop, decides if the message is kept or not if the termination condition is met.
    """


class GenerateMessage(LFBaseModel):
    """
    Generate a message using the specified model (and custom instructions, specified via extra input messages).
    """

    type: Literal["generate_message"]

    model_id: str

    extra_input_messages: List[ChatMessageBuilder] = Field(
        ...,
        min_length=1,
        description="Additional input messages (in addition to the existing messages) given as input to the model.",
    )
    """
    Additional input messages (in addition to the existing messages) given as input to the model.
    """

    output_role: Optional[ChatCompletionRole] = Field(
        None, description="The role of the output message."
    )
    """
    The role of the output message.
    """

    terminate_if: Optional[TerminationCondition] = None


class TaskScorer(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    key: Optional[str] = Field(
        None,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="The key of the scorer.",
    )
    """
    The key of the scorer.
    """

    type: str = Field(..., description="The type of scorer.")
    """
    The type of scorer.
    """

    metrics: Optional[List[TaskMetric]] = Field(
        None,
        description="The metrics associated with this scorer, which will produce per-task metrics.",
    )
    """
    The metrics associated with this scorer, which will produce per-task metrics.
    """


class EvaluationAction(Enum):
    """
    The action to perform on the given evaluation.

    The available actions and their meanings are:
    - start - Starts the given evaluation. If already running or finished, it will be rerun and all existing tasks terminated.
    - cancel - Stops and invalidates all running tasks in the evaluation. Fails if no tasks are running.

    """

    START = "start"
    CANCEL = "cancel"


class TaskTestRequest(LFBaseModel):
    config: Dict[str, Any]

    entity_id: str

    sample_indices: List[int]


class PasswordUserCredential(LFBaseModel):
    credential_type: CredentialType

    value: SecretStr


class Evaluation(LFBaseModel):
    """
    This entity tracks the execution of multiple tasks.
    """

    display_name: str = Field(..., min_length=1)

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -
    """

    task_specifications: List[TaskSpecification] = Field(
        ..., description="The task specifications associated with the evaluation."
    )
    """
    The task specifications associated with the evaluation.
    """

    config: EvaluationConfig


class ModelAdapterCodeSnippet(LFBaseModel):
    language: ModelAdapterCodeLanguage = Field(
        ..., description="The programming language of the code snippet."
    )
    """
    The programming language of the code snippet.
    """

    source_code: str = Field(..., description="The source code of the model adapter.")
    """
    The source code of the model adapter.
    """


class CertificateValidationContext(LFBaseModel):
    """
    Defines how server certificates should be validated.
    """

    trusted_ca: Optional[str] = Field(
        None,
        description="base64 representation of PEM-encoded certificate(s).\n\nFor example: `cat cert.pem | base64 -w 0`\n'\n",
    )
    """
    base64 representation of PEM-encoded certificate(s).

    For example: `cat cert.pem | base64 -w 0`
    '

    """

    trust_chain_verification: Optional[TrustChainVerification] = Field(
        None,
        description="Settings for verifying the trust chain of the server certificate.",
    )
    """
    Settings for verifying the trust chain of the server certificate.
    """


class DatasetGenerationMetadata(LFBaseModel):
    """
    Dataset generation metadata.
    """

    dataset_generator_id: str

    execution_status: ExecutionStatus

    result_status: Optional[ResultStatus] = None

    dataset_generation_id: str = Field(..., description="The dataset generation ID.")
    """
    The dataset generation ID.
    """

    dataset_generation_request: DatasetGenerationRequest = Field(
        ..., description="The dataset generation request."
    )
    """
    The dataset generation request.
    """

    progress: Optional[ExecutionProgress] = None


class StoredDataset(Id, Dataset):
    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-\\$]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ - $",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ - $
    """

    provider: DatasetProvider

    dataset_metadata: Optional[DatasetMetadata] = Field(
        None, description="Dataset metadata."
    )
    """
    Dataset metadata.
    """

    dataset_generation_metadata: Optional[DatasetGenerationMetadata] = Field(
        None, description="Dataset generation metadata."
    )
    """
    Dataset generation metadata.
    """


class StringParameterSpec(LFBaseModel):
    type: Literal["string"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """

    default_value: Optional[str] = Field(
        None, description="The default value of the parameter."
    )
    """
    The default value of the parameter.
    """

    nullable: bool = Field(False, description="Whether this field is nullable.")
    """
    Whether this field is nullable.
    """

    string_kind: StringKind = Field(
        StringKind.FREEFORM,
        description="Specifies the kind of string parameter. Supported kinds are 'freeform', 'python', and 'jinja'.",
    )
    """
    Specifies the kind of string parameter. Supported kinds are 'freeform', 'python', and 'jinja'.
    """

    examples: Optional[List[StringParameterExample]] = Field(
        None, description="Examples for the string parameter."
    )
    """
    Examples for the string parameter.
    """


class ListParameterSpec(LFBaseModel):
    type: Literal["list"] = Field(..., description="The type of the parameter.")
    """
    The type of the parameter.
    """

    dtype: ScalarDtype = Field(
        ...,
        description="The data type of the elements in the list. Supported scalar data types are 'string', 'integer', 'float', and 'boolean'.",
    )
    """
    The data type of the elements in the list. Supported scalar data types are 'string', 'integer', 'float', and 'boolean'.
    """

    key: str = Field(..., description="The key of the parameter.")
    """
    The key of the parameter.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the parameter."
    )
    """
    The display name of the parameter.
    """

    description: Optional[str] = Field(
        None, description="The description of the parameter."
    )
    """
    The description of the parameter.
    """


class TaskScorerTemplate(LFBaseModel):
    model_config = ConfigDict(extra="allow")

    key: Optional[str] = Field(
        None,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="The key of the scorer.",
    )
    """
    The key of the scorer.
    """

    type: str = Field(..., description="The type of scorer.")
    """
    The type of scorer.
    """

    metrics: Optional[List[TaskMetricTemplate]] = Field(
        None,
        description="The metrics associated with this scorer, which will produce per-task metrics.",
    )
    """
    The metrics associated with this scorer, which will produce per-task metrics.
    """


class StoredTag(Tag, Id):
    pass


class User(LFBaseModel):
    email: str

    name: str

    enabled: bool = True

    roles: List[Role] = Field(
        ...,
        description="The roles that will be assigned to the user. A user must have at least one role.",
    )
    """
    The roles that will be assigned to the user. A user must have at least one role.
    """


class MetricData(LFBaseModel):
    """
    An object that contains the metric scores.
    """

    values: Dict[str, Union[float, int]]

    metric_key: str = Field(..., description="The key of the metric.")
    """
    The key of the metric.
    """

    scorer_key: str = Field(
        ..., description="The key of the scorer to which the metric belongs."
    )
    """
    The key of the scorer to which the metric belongs.
    """


class TaskResultError(LFBaseModel):
    error_type: str = Field(..., description="The type of the error.")
    """
    The type of the error.
    """

    message: str = Field(
        ..., description="The specific error message that occurred during evaluation."
    )
    """
    The specific error message that occurred during evaluation.
    """

    hint: Optional[str] = Field(
        None, description="The suggestion to try out to fix the issue."
    )
    """
    The suggestion to try out to fix the issue.
    """

    stage: Optional[TaskResultErrorStage] = None


class AIApp(LFBaseModel):
    """
    An AI app represents a workspace to execute technical assessments of the AI use case.
    """

    display_name: str = Field(
        ..., min_length=1, description="The AI App's name displayed to the user."
    )
    """
    The AI App's name displayed to the user.
    """

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -
    """

    description: Optional[str] = Field(
        None, description="Short text description of the AI app."
    )
    """
    Short text description of the AI app.
    """

    long_description: Optional[str] = Field(
        None, description="Long description of the AI app in Markdown format."
    )
    """
    Long description of the AI app in Markdown format.
    """

    key_info: AIAppKeyInformation


class StoredIntegration(LFBaseModel):
    """
    A stored representation of an integration, with obfuscated credentials data.
    """

    id: Union[IntegrationModelProviderId, IntegrationDatasetProviderId] = Field(
        ..., description="The ids for all integrations the system supports."
    )
    """
    The ids for all integrations the system supports.
    """

    config: Optional[Dict[str, Any]] = Field(
        None,
        description="If configured contains sanitized config properties for the integration.",
    )
    """
    If configured contains sanitized config properties for the integration.
    """


class StoredIntegrations(LFBaseModel):
    integrations: List[StoredIntegration]


class UserCredential(RootModel[PasswordUserCredential]):
    root: PasswordUserCredential


class DeclarativeDatasetGeneratorDefinitionTemplate(LFBaseModel):
    type: Literal["declarative_dataset_generator"] = Field(
        ..., description="The type of dataset generator definition."
    )
    """
    The type of dataset generator definition.
    """

    data_source: DatasetGeneratorDataSourceTemplate

    synthesizer: DatasetGeneratorSynthesizerTemplate


class DatasetGenerationError(LFBaseModel):
    stage: DatasetGenerationErrorStage

    error_type: str = Field(..., description="The type of the error.")
    """
    The type of the error.
    """

    message: str = Field(
        ..., description="The specific error message that occurred during generation."
    )
    """
    The specific error message that occurred during generation.
    """


class TabularEvidence(LFBaseModel):
    """
    The tabular evidence of the task result.
    """

    columns: List[TableColumn] = Field(
        ..., description="List of columns from the table."
    )
    """
    List of columns from the table.
    """

    rows: List[Dict[str, Any]] = Field(
        ...,
        description="List of row objects where each item maps column names to values.",
    )
    """
    List of row objects where each item maps column names to values.
    """

    meta: Meta


class StoredTags(LFBaseModel):
    tags: List[StoredTag]


class ChatCompletionMessage(LFBaseModel):
    role: ChatCompletionRole = Field(
        ...,
        description="The role of the message sender, can be `system`, `user`, or `assistant`.",
    )
    """
    The role of the message sender, can be `system`, `user`, or `assistant`.
    """

    content: str = Field(
        ...,
        examples=[
            'Please answer the following question with "Yes" or "No". {{ sample.question }}',
            "You are a helpful assistant.",
        ],
        description="The prompt content. The prompt can refer to dynamic variables using curly braces (ex. `{{ sample.attribute }}` to refer to an attribute for the current sample in the dataset). Full Jinja is supported for the prompt.",
    )
    """
    The prompt content. The prompt can refer to dynamic variables using curly braces (ex. `{{ sample.attribute }}` to refer to an attribute for the current sample in the dataset). Full Jinja is supported for the prompt.
    """


class Generate(LFBaseModel):
    """
    Generates a message using the evaluated model.
    """

    type: Literal["generate"]

    terminate_if: Optional[TerminationCondition] = None


class GenerateLoop(LFBaseModel):
    """
    Execute a loop, where at each iteration the sequence of message builders is executed. Each message builder can specify when to terminate the loop. There is a maximum number of iterations.
    """

    type: Literal["loop"]

    message_builders: List[Union[ChatMessageBuilder, Generate, GenerateMessage]]

    max_iterations: int = Field(10, ge=0)


class SampleResult(LFBaseModel):
    sample: Optional[Dict[str, Any]] = None

    solver_output: Optional[Dict[str, Any]] = None

    scores: Optional[List[Dict[str, Any]]] = None

    error: Optional[TaskResultError] = None


class TaskTestResult(LFBaseModel):
    sample_results: Optional[List[SampleResult]] = None

    metrics: Optional[Dict[str, Any]] = None

    error: Optional[TaskResultError] = None


class InitialSetupRequest(LFBaseModel):
    name: str

    email: str

    credentials: PasswordUserCredential


class ModelAdapter(LFBaseModel):
    display_name: str = Field(..., min_length=1)

    description: Optional[str] = None

    long_description: Optional[str] = Field(
        None, description="Long rich text description. Supports markdown formatting."
    )
    """
    Long rich text description. Supports markdown formatting.
    """

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -
    """

    provider: ModelAdapterProvider = ModelAdapterProvider.USER

    task: MLTask

    process_input: Optional[ModelAdapterCodeSnippet] = Field(
        None,
        description='Required for POST and PUT. Required for GET if provider is "custom". The function mapping model inputs (given as key value map) to the body of the HTTP request.',
    )
    """
    Required for POST and PUT. Required for GET if provider is "custom". The function mapping model inputs (given as key value map) to the body of the HTTP request.
    """

    process_output: Optional[ModelAdapterCodeSnippet] = Field(
        None,
        description='Required for POST and PUT. Required for GET if provider is "custom". The function mapping the body of the HTTP response (given as text + status code) to a model output.',
    )
    """
    Required for POST and PUT. Required for GET if provider is "custom". The function mapping the body of the HTTP response (given as text + status code) to a model output.
    """


class TLSContext(LFBaseModel):
    """
    Defines the TLS context.
    """

    validation_context: Optional[CertificateValidationContext] = Field(
        None, description="Settings for validating server certificates."
    )
    """
    Settings for validating server certificates.
    """


class ModelProviderConnectionConfig(LFBaseModel):
    """
    Connection configuration for a model, that is retrieved from a well-known provider integrated with the system.
    """

    connection_type: Literal["provider_connection"] = Field(
        ..., description="The type of connection config."
    )
    """
    The type of connection config.
    """

    provider_id: Union[IntegrationModelProviderId, LocalModelProviderId] = Field(
        ...,
        description="The id of the model provider. Supported values are: `anthropic`, `fireworks`, `gemini`, `novita`, `openai`, `sambanova`, `together`, `zenguard`, and `local`.",
    )
    """
    The id of the model provider. Supported values are: `anthropic`, `fireworks`, `gemini`, `novita`, `openai`, `sambanova`, `together`, `zenguard`, and `local`.
    """

    model_key: str = Field(
        ..., description="A key used to identify the model in the external provider."
    )
    """
    A key used to identify the model in the external provider.
    """


class StoredDatasets(LFBaseModel):
    datasets: List[StoredDataset]


class DeclarativeTaskDefinitionTemplate(LFBaseModel):
    type: Literal["declarative_task"] = Field(
        ..., description="The type of task definition."
    )
    """
    The type of task definition.
    """

    dataset: TaskDatasetTemplate = Field(
        ..., description="The dataset that will be used by this task"
    )
    """
    The dataset that will be used by this task
    """

    solver: TaskSolverTemplate = Field(..., description="The solver used by this task")
    """
    The solver used by this task
    """

    scorers: List[TaskScorerTemplate] = Field(
        ..., description="The scorers used for task"
    )
    """
    The scorers used for task
    """


class StoredUser(Id, User):
    pass


class StoredTaskResult(TaskResult, Id):
    execution_status: ExecutionStatus

    result_status: Optional[ResultStatus] = None

    metrics: Optional[List[MetricData]] = Field(
        None, description="The evaluated metric scores."
    )
    """
    The evaluated metric scores.
    """

    errors: Optional[List[TaskResultError]] = Field(
        None, description="List of errors associated with this task result."
    )
    """
    List of errors associated with this task result.
    """

    artifacts: Optional[List[Artifact]] = Field(
        None, description="List of artifacts associated with this task result."
    )
    """
    List of artifacts associated with this task result.
    """

    failures: Optional[TaskResultFailures] = Field(
        None, description="The sample-level failures statistics."
    )
    """
    The sample-level failures statistics.
    """

    is_cached: Optional[bool] = Field(
        None, description="Whether the task result was computed previously and cached."
    )
    """
    Whether the task result was computed previously and cached.
    """

    progress: Optional[ExecutionProgress] = None

    created_at: int = Field(..., description="Unix timestamp (in seconds).")
    """
    Unix timestamp (in seconds).
    """

    created_by: Optional[StoredUser] = None

    started_at: Optional[int] = Field(None, description="Unix timestamp (in seconds).")
    """
    Unix timestamp (in seconds).
    """

    finished_at: Optional[int] = Field(None, description="Unix timestamp (in seconds).")
    """
    Unix timestamp (in seconds).
    """

    tags: List[StoredTag] = Field(
        ...,
        description="The tags associated with the task (at the time of requesting the results).",
    )
    """
    The tags associated with the task (at the time of requesting the results).
    """


class CreatedUpdated(LFBaseModel):
    created_at: int = Field(..., description="Unix timestamp (in seconds).")
    """
    Unix timestamp (in seconds).
    """

    created_by: StoredUser

    updated_at: int = Field(..., description="Unix timestamp (in seconds).")
    """
    Unix timestamp (in seconds).
    """

    updated_by: StoredUser


class Users(LFBaseModel):
    users: List[StoredUser]


class State(LFBaseModel):
    deployment_id: str = Field(
        ..., min_length=1, description="Unique identifier of the deployment."
    )
    """
    Unique identifier of the deployment.
    """

    user: Optional[StoredUser] = None

    api_key: Optional[SecretStr] = Field(
        None, min_length=1, description="The API key of the user."
    )
    """
    The API key of the user.
    """

    app_version: Optional[str] = Field(None, description="Application version.")
    """
    Application version.
    """

    setup_state: SetupState

    analytics_config: Optional[AnalyticsConfig] = None

    deployment_mode: DeploymentMode


class ParameterSpec(LFBaseModel):
    parameters: List[
        Union[
            FloatParameterSpec,
            IntParameterSpec,
            BooleanParameterSpec,
            StringParameterSpec,
            ModelParameterSpec,
            DatasetParameterSpec,
            DatasetColumnParameterSpec,
            ListParameterSpec,
            CategoricalParameterSpec,
        ]
    ]


class DatasetGenerator(LFBaseModel):
    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the dataset generator."
    )
    """
    The display name of the dataset generator.
    """

    description: str = Field(
        ..., description="The description of the dataset generator."
    )
    """
    The description of the dataset generator.
    """

    long_description: Optional[str] = Field(
        None,
        description="Long description of the dataset generator evaluator in Markdown format.",
    )
    """
    Long description of the dataset generator evaluator in Markdown format.
    """

    config_spec: List[
        Union[
            FloatParameterSpec,
            IntParameterSpec,
            BooleanParameterSpec,
            StringParameterSpec,
            ModelParameterSpec,
            DatasetParameterSpec,
            DatasetColumnParameterSpec,
            ListParameterSpec,
            CategoricalParameterSpec,
        ]
    ]

    definition: DeclarativeDatasetGeneratorDefinitionTemplate


class StoredDatasetGenerator(DatasetGenerator, Id):
    provider: DatasetGeneratorProvider = Field(
        DatasetGeneratorProvider.USER,
        description="The provider of the dataset generator.",
    )
    """
    The provider of the dataset generator.
    """

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-\\$]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ - $",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ - $
    """


class StoredDatasetGenerators(LFBaseModel):
    dataset_generators: List[StoredDatasetGenerator]


class DatasetGenerationPreview(LFBaseModel):
    """
    The preview of the generated dataset, including encountered errors.
    """

    data: DatasetData = Field(
        ..., description="The data preview of the generated dataset."
    )
    """
    The data preview of the generated dataset.
    """

    errors: List[DatasetGenerationError] = Field(
        ..., description="The list of errors encountered during dataset generation."
    )
    """
    The list of errors encountered during dataset generation.
    """


class Scorer(LFBaseModel):
    type: str = Field(..., description="The type of scorer.")
    """
    The type of scorer.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the scorer."
    )
    """
    The display name of the scorer.
    """

    description: str = Field(..., description="The description of the scorer.")
    """
    The description of the scorer.
    """

    long_description: Optional[str] = Field(
        None, description="Long description of the scorer in Markdown format."
    )
    """
    Long description of the scorer in Markdown format.
    """

    parameter_spec: ParameterSpec

    default_metrics: List[TaskMetric]


class Metric(LFBaseModel):
    type: str = Field(..., description="The type of the metric. Globally unique.")
    """
    The type of the metric. Globally unique.
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the metric."
    )
    """
    The display name of the metric.
    """

    description: str = Field(..., description="The description of the metric.")
    """
    The description of the metric.
    """

    parameter_spec: ParameterSpec


class TaskResultEvidence(LFBaseModel):
    metrics: List[MetricData]

    freeform_evidence: Dict[str, Any] = Field(
        ...,
        description="An arbitrary JSON object that represents the free form evidence.",
    )
    """
    An arbitrary JSON object that represents the free form evidence.
    """

    tabular_evidence: List[TabularEvidence] = Field(
        ...,
        description="An array where each entry represents a separate tabular evidence object.",
    )
    """
    An array where each entry represents a separate tabular evidence object.
    """

    usage: Optional[TaskResultUsage] = None


class ChatCompletionInputBuilder(LFBaseModel):
    type: Literal["chat_completion"] = Field(
        ..., description="The kind of input builder."
    )
    """
    The kind of input builder.
    """

    input_messages: List[ChatCompletionMessage]


class MultiTurnSolver(LFBaseModel):
    type: Literal["multi_turn_solver"]

    message_builders: List[
        Union[ChatMessageBuilder, Generate, GenerateMessage, GenerateLoop]
    ] = Field(..., min_length=1)


class StoredModelAdapter(ModelAdapter, Id):
    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-\\$]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ - $",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ - $
    """

    model_ids: List[str]


class ModelCustomConnectionConfig(LFBaseModel):
    """
    Connection configuration for a model, that is provided manually by the user.
    """

    connection_type: Literal["custom_connection"] = Field(
        ..., description="The type of connection config."
    )
    """
    The type of connection config.
    """

    url: str = Field(
        ...,
        description='The model endpoint URL. In case the "openai" adapter is used, only the base URL should be provided here, e.g. "api.openai.com/v1".',
    )
    """
    The model endpoint URL. In case the "openai" adapter is used, only the base URL should be provided here, e.g. "api.openai.com/v1".
    """

    api_key: Optional[SecretStr] = Field(
        None,
        description="The key to be passed as the authorization header (Authorization: Bearer API_KEY).\n",
    )
    """
    The key to be passed as the authorization header (Authorization: Bearer API_KEY).

    """

    model_key: Optional[str] = Field(
        None,
        description='This field is used in case the model is not specified in the URL but in the body instead. For the "openai" adapter, this will be passed as the "model" parameter. For custom adapters, this value is available as model_info.model_key.\n',
    )
    """
    This field is used in case the model is not specified in the URL but in the body instead. For the "openai" adapter, this will be passed as the "model" parameter. For custom adapters, this value is available as model_info.model_key.

    """

    tls_context: Optional[TLSContext] = Field(
        None,
        description="TLS configuration for secure connections to the model endpoint.",
    )
    """
    TLS configuration for secure connections to the model endpoint.
    """

    custom_headers: Optional[Dict[str, Any]] = Field(
        None,
        description="Additional headers to include in requests to the model endpoint.",
    )
    """
    Additional headers to include in requests to the model endpoint.
    """


class Task(LFBaseModel):
    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -
    """

    display_name: str = Field(
        ..., min_length=1, description="The display name of the task."
    )
    """
    The display name of the task.
    """

    description: str = Field(..., description="The description of the task.")
    """
    The description of the task.
    """

    long_description: Optional[str] = Field(
        None, description="Long description of the task in Markdown format."
    )
    """
    Long description of the task in Markdown format.
    """

    tasks: List[MLTask] = Field(
        [], description="The ML tasks for which the task is applicable."
    )
    """
    The ML tasks for which the task is applicable.
    """

    evaluated_entity_type: EvaluatedEntityType

    config_spec: List[
        Union[
            FloatParameterSpec,
            IntParameterSpec,
            BooleanParameterSpec,
            StringParameterSpec,
            ModelParameterSpec,
            DatasetParameterSpec,
            DatasetColumnParameterSpec,
            ListParameterSpec,
            CategoricalParameterSpec,
        ]
    ]

    definition: Union[DeclarativeTaskDefinitionTemplate, PredefinedTaskDefinition] = (
        Field(..., discriminator="type")
    )


class StoredEvaluation(Id):
    display_name: str = Field(..., min_length=1)

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -
    """

    created_at: int = Field(..., description="Unix timestamp (in seconds).")
    """
    Unix timestamp (in seconds).
    """

    created_by: StoredUser

    task_results: List[StoredTaskResult]

    config: EvaluationConfig

    execution_status: ExecutionStatus

    tags: List[StoredTag]


class StoredAIApp(AIApp, Id, CreatedUpdated):
    artifacts: List[Artifact] = Field(
        ..., description="List of uploaded artifacts associated with this AI System."
    )
    """
    List of uploaded artifacts associated with this AI System.
    """

    tags: List[StoredTag]


class StoredAIApps(LFBaseModel):
    ai_apps: List[StoredAIApp]


class StoredScorer(Scorer, Id):
    pass


class StoredScorers(LFBaseModel):
    scorers: List[StoredScorer]


class StoredMetric(Metric, Id):
    pass


class StoredMetrics(LFBaseModel):
    metrics: List[StoredMetric]


class StoredEvaluations(LFBaseModel):
    evaluations: List[StoredEvaluation]


class SingleTurnSolver(LFBaseModel):
    type: Literal["single_turn_solver"]

    input_builder: Union[GeneralInputBuilder, ChatCompletionInputBuilder] = Field(
        ..., discriminator="type"
    )


class StoredModelAdapters(LFBaseModel):
    model_adapters: List[StoredModelAdapter]


class StoredTask(Task, Id):
    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^[a-z0-9_\\-\\$]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ - $",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ - $
    """

    provider: TaskProvider = Field(..., description="The provider of the evaluator.")
    """
    The provider of the evaluator.
    """

    tags: List[StoredTag]


class DeclarativeTaskDefinition(LFBaseModel):
    type: Literal["declarative_task"] = Field(
        ..., description="The type of task definition."
    )
    """
    The type of task definition.
    """

    dataset: TaskDataset

    solver: Union[SingleTurnSolver, GroupedSingleTurnSolver, MultiTurnSolver] = Field(
        ..., discriminator="type"
    )

    scorers: List[TaskScorer]


class Model(LFBaseModel):
    """
    Representation of a publicly accessible model.
    """

    display_name: str = Field(..., min_length=1, description="The name of the Model.")
    """
    The name of the Model.
    """

    key: str = Field(
        ...,
        max_length=250,
        min_length=1,
        pattern="^((local|together|zenguard|gemini|openai|fireworks|sambanova|anthropic|novita)\\$)?[a-z0-9_-]+$",
        description="Key: 1-250 chars, allowed: a-z 0-9 _ -. May optionally start with one of the supported prefixes:  ``local$``, ``together$``, ``zenguard$``, ``gemini$``, ``openai$``, ``fireworks$``, ``sambanova$``,  ``anthropic$``, or ``novita$``.\n",
    )
    """
    Key: 1-250 chars, allowed: a-z 0-9 _ -. May optionally start with one of the supported prefixes:  ``local$``, ``together$``, ``zenguard$``, ``gemini$``, ``openai$``, ``fireworks$``, ``sambanova$``,  ``anthropic$``, or ``novita$``.

    """

    description: Optional[str] = None

    rate_limit: Optional[int] = Field(
        None, description="The maximum allowed number of requests per minute."
    )
    """
    The maximum allowed number of requests per minute.
    """

    task: MLTask

    adapter_id: str = Field(
        ..., description="The ID of the model adapter to be used with this model."
    )
    """
    The ID of the model adapter to be used with this model.
    """

    config: Union[ModelCustomConnectionConfig, ModelProviderConnectionConfig] = Field(
        ...,
        discriminator="connection_type",
        description="The configuration for connecting to the model.",
    )
    """
    The configuration for connecting to the model.
    """


class StoredTasks(LFBaseModel):
    tasks: List[StoredTask]


class ModelProvider(LFBaseModel):
    """
    Represents an external company or entity that manages and exposes models.
    """

    id: Union[IntegrationModelProviderId, LocalModelProviderId] = Field(
        ...,
        description="The internal identifiers for all model providers known by the system.",
    )
    """
    The internal identifiers for all model providers known by the system.
    """

    display_name: str = Field(..., min_length=1)

    has_credentials: bool

    models: List[Model]


class ModelProviders(LFBaseModel):
    model_providers: List[ModelProvider]


class StoredModel(Model, Id):
    capabilities: ModelCapabilities


class StoredModels(LFBaseModel):
    models: List[StoredModel]


class EntitiesUsedInEvaluation(LFBaseModel):
    """
    Represents all entities used in an evaluation.
    """

    model_adapters: StoredModelAdapters

    models: StoredModels

    datasets: StoredDatasets

    tasks: StoredTasks

    evaluation: StoredEvaluation
