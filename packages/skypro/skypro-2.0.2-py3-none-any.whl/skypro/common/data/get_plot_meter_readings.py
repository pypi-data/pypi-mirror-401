from datetime import datetime
from typing import Optional, Callable, List, Tuple

import pandas as pd

from skypro.common.config.data_source import PlotMeterReadingDataSource
from skypro.common.config.data_source_csv import CSVPlotMeterReadingsDataSource
from skypro.common.config.data_source_flows import FlowsPlotMeterReadingsDataSource
from skypro.common.data.utility import get_csv_data_source, drop_extra_rows, sanity_checks, convert_cols_to_str_type
from skypro.common.notice.notice import Notice


def get_plot_meter_readings(
        source: PlotMeterReadingDataSource,
        start: Optional[datetime],
        end: Optional[datetime],
        file_path_resolver_func: Optional[Callable],
        db_engine: Optional,
        schema: str = "flows",
        context: Optional[str] = None,
) -> Tuple[pd.DataFrame, List[Notice]]:
    """
    This reads a data source - either CSVs from disk or directly from a database - and returns plot-level meter readings in a dataframe alongside a list of warnings.
    :param source: locates the data in either local files or a remote database
    :param start: inclusive
    :param end: exclusive
    :param file_path_resolver_func: A function that does any env var substitutions necessary for file paths
    :param db_engine: SQLAlchemy DB engine, as required
    :param context: a string that is added to notices to help the user understand what the data is about
    :return:
    """

    if source.flows_plot_meter_readings_data_source:
        df = _get_flows_plot_meter_readings(
            source=source.flows_plot_meter_readings_data_source,
            start=start,
            end=end,
            db_engine=db_engine,
            schema=schema
        )
    elif source.csv_plot_meter_readings_data_source:
        df = _get_csv_plot_meter_readings(
            source=source.csv_plot_meter_readings_data_source,
            start=start,
            end=end,
            file_path_resolver_func=file_path_resolver_func,
        )
    else:
        raise ValueError("Unknown source type")

    return df, sanity_checks(df, start, end, context)


def _get_flows_plot_meter_readings(
        source: FlowsPlotMeterReadingsDataSource,
        start: datetime,
        end: datetime,
        db_engine,
        schema: str = "flows",
) -> pd.DataFrame:
    """
    Reads Emlite plot meter readings from the flows database that are on the given feeders.
    """

    feeder_id_list_str = ', '.join(f"'{str(u)}'::uuid" for u in source.feeder_ids)

    query = (
        "SELECT "
        "rih.timestamp as timestamp, "
        "fr.id as feeder_id, "
        "mr.register_id as register_id, "
        "mr2.nature as nature, "
        "rih.kwh AS kwh "
        f"FROM {schema}.register_interval_hh rih "
        f"JOIN {schema}.meter_registers mr ON mr.register_id = rih.register_id "
        f"JOIN {schema}.meter_registers mr2 on mr.register_id = mr2.register_id "
        f"JOIN {schema}.service_head_meter shm on shm.meter = mr2.meter_id "
        f"JOIN {schema}.service_head_registry shr on shr.id = shm.service_head "
        f"JOIN {schema}.feeder_registry fr on fr.id = shr.feeder "
        f"WHERE rih.timestamp >= '{start.isoformat()}' "
        f"AND rih.timestamp < '{end.isoformat()}' "
        f"AND fr.id = ANY(ARRAY[{feeder_id_list_str}]) "
        f"order by rih.timestamp, fr.id, mr.register_id"
    )
    # TODO: we may want a more rigorous check for meters that are  missing ALL data for the entire month?

    df = pd.read_sql(query, con=db_engine)

    # SQLAlchemy reads UUIDs as the formal UUID type, but we want them as strings for simplicity
    convert_cols_to_str_type(df, ["feeder_id", "register_id"])

    df = df.rename(columns={"timestamp": "time"})
    df["time"] = pd.to_datetime(df["time"], format="ISO8601")

    return df


def _get_csv_plot_meter_readings(
    source: CSVPlotMeterReadingsDataSource,
    start: Optional[datetime],
    end: Optional[datetime],
    file_path_resolver_func: Optional[Callable],
) -> pd.DataFrame:
    """
    Pulls readings about the plot-level meters that are on the specified feeders from the given CSV files.
    """

    df = get_csv_data_source(source, file_path_resolver_func)

    df["time"] = pd.to_datetime(df["utctime"], format="ISO8601")
    df = df.drop(columns=["utctime", "clocktime"])

    # Old CSV files have old naming - bring this up to date with the FlowsDB naming
    df = df.rename(columns={
        "feederID": "feeder_id",
        "registerID": "register_id",
        "nature": "nature",
        "energyImportedActiveDelta": "kwh",
    })

    df = df[df["feeder_id"].isin([str(feeder_id) for feeder_id in source.feeder_ids])]

    # Remove any data that is outside the time range of interest
    # TODO: only read in CSVs for the months that are required in the first place
    df = drop_extra_rows(df, start, end)

    return df

