# coding: utf-8

"""
    ai/h2o/eval_studio/v1/insight.proto

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: version not set
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from eval_studio_client.api.models.v1_batch_create_leaderboards_without_cache_request import V1BatchCreateLeaderboardsWithoutCacheRequest

class TestV1BatchCreateLeaderboardsWithoutCacheRequest(unittest.TestCase):
    """V1BatchCreateLeaderboardsWithoutCacheRequest unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> V1BatchCreateLeaderboardsWithoutCacheRequest:
        """Test V1BatchCreateLeaderboardsWithoutCacheRequest
            include_option is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `V1BatchCreateLeaderboardsWithoutCacheRequest`
        """
        model = V1BatchCreateLeaderboardsWithoutCacheRequest()
        if include_optional:
            return V1BatchCreateLeaderboardsWithoutCacheRequest(
                requests = [
                    eval_studio_client.api.models.v1_create_leaderboard_request.v1CreateLeaderboardRequest(
                        leaderboard = eval_studio_client.api.models.v1_leaderboard.v1Leaderboard(
                            name = '', 
                            create_time = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                            creator = '', 
                            update_time = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                            updater = '', 
                            delete_time = datetime.datetime.strptime('2013-10-20 19:20:30.00', '%Y-%m-%d %H:%M:%S.%f'), 
                            deleter = '', 
                            display_name = '', 
                            description = '', 
                            status = 'LEADERBOARD_STATUS_UNSPECIFIED', 
                            evaluator = '', 
                            tests = [
                                ''
                                ], 
                            model = '', 
                            create_operation = '', 
                            leaderboard_report = '', 
                            leaderboard_table = '', 
                            leaderboard_summary = '', 
                            llm_models = [
                                ''
                                ], 
                            leaderboard_problems = [
                                eval_studio_client.api.models.v1_problem_and_action.v1ProblemAndAction(
                                    description = '', 
                                    severity = '', 
                                    problem_type = '', 
                                    problem_attrs = {
                                        'key' : ''
                                        }, 
                                    actions_description = '', 
                                    explainer_id = '', 
                                    explainer_name = '', 
                                    explanation_type = '', 
                                    explanation_name = '', 
                                    explanation_mime = '', 
                                    resources = [
                                        ''
                                        ], )
                                ], 
                            evaluator_parameters = '', 
                            insights = [
                                eval_studio_client.api.models.v1_insight.v1Insight(
                                    description = '', 
                                    actions_description = '', 
                                    actions_codes = [
                                        ''
                                        ], 
                                    evaluator_id = '', 
                                    evaluator_display_name = '', 
                                    explanation_type = '', 
                                    explanation_name = '', 
                                    explanation_mime = '', 
                                    insight_type = '', 
                                    insight_attrs = {
                                        'key' : ''
                                        }, )
                                ], 
                            model_parameters = '', 
                            h2ogpte_collection = '', 
                            type = 'LEADERBOARD_TYPE_UNSPECIFIED', 
                            demo = True, 
                            test_lab = '', 
                            evaluation_type = 'EVALUATION_TYPE_UNSPECIFIED', ), )
                    ],
                dashboard_display_name = '',
                dashboard_description = ''
            )
        else:
            return V1BatchCreateLeaderboardsWithoutCacheRequest(
        )
        """

    def testV1BatchCreateLeaderboardsWithoutCacheRequest(self):
        """Test V1BatchCreateLeaderboardsWithoutCacheRequest"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
