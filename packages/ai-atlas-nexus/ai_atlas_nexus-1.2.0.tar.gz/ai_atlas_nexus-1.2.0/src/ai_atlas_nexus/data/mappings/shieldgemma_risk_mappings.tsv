# curie_map:
#   shieldgemma-taxonomy: https://ai.google.dev/gemma/shieldgemma#
#   ibm-risk-atlas: https://www.ibm.com/docs/en/watsonx/saas?topic=
#   nist-ai-rmf: https://www.nist.gov/itl/ai-risk-management-framework/
#   semapv: https://w3id.org/semapv/vocab/
#   skos: http://www.w3.org/2004/02/skos/core#
# license: https://www.apache.org/licenses/LICENSE-2.0.html
# mapping_date: '2025-10-15'
# mapping_set_description: Mappings between ShieldGemma safety categories and IBM AI Risk Atlas risks
# mapping_set_id: https://github.com/IBM/ai-atlas-nexus/tree/main/src/data/mappings/shieldgemma-to-risk-atlas.tsv
subject_id	subject_label	predicate_id	object_id	object_label	mapping_justification	confidence	author_id	mapping_date	comment
shieldgemma-taxonomy:shieldgemma-sexually-explicit	Sexually Explicit Content	skos:relatedMatch	ibm-risk-atlas:atlas-harmful-output	Harmful output	semapv:ManualMappingCuration	0.90	elizabeth.daly@ie.ibm.com	2025-01-15	ShieldGemma sexually explicit content is a specific type of harmful output. Atlas harmful-output is broader (includes violence, dangerous statements). Related but not exact match.
shieldgemma-taxonomy:shieldgemma-sexually-explicit	Sexually Explicit Content	skos:relatedMatch	ibm-risk-atlas:atlas-toxic-output	Toxic output	semapv:ManualMappingCuration	0.75	elizabeth.daly@ie.ibm.com	2025-01-15	Sexually explicit content can be considered toxic depending on context. Overlap exists but toxic output includes profanity, hate speech beyond sexual content.
shieldgemma-taxonomy:shieldgemma-sexually-explicit	Sexually Explicit Content	skos:relatedMatch	ibm-risk-atlas:atlas-nonconsensual-use	Nonconsensual use	semapv:ManualMappingCuration	0.65	elizabeth.daly@ie.ibm.com	2025-01-15	ShieldGemma can detect explicit content used in deepfakes or nonconsensual generation contexts.
shieldgemma-taxonomy:shieldgemma-dangerous-content	Dangerous Content	skos:relatedMatch	ibm-risk-atlas:atlas-harmful-output	Harmful output	semapv:LexicalMatching	0.95	elizabeth.daly@ie.ibm.com	2025-01-15	Strong semantic alignment - both address content causing physical harm. Atlas harmful-output explicitly mentions violence and dangerous statements.
shieldgemma-taxonomy:shieldgemma-dangerous-content	Dangerous Content	skos:relatedMatch	ibm-risk-atlas:atlas-harmful-code-generation	Harmful code generation	semapv:ManualMappingCuration	0.80	elizabeth.daly@ie.ibm.com	2025-01-15	Dangerous content includes code that could cause harm to systems or users.
shieldgemma-taxonomy:shieldgemma-dangerous-content	Dangerous Content	skos:relatedMatch	ibm-risk-atlas:atlas-dangerous-use	Dangerous use	semapv:LexicalMatching	0.85	elizabeth.daly@ie.ibm.com	2025-01-15	Both address intentional use of AI to harm people. ShieldGemma detects dangerous content, atlas:dangerous-use covers broader misuse scenarios.
shieldgemma-taxonomy:shieldgemma-hate-speech	Hate Speech	skos:relatedMatch	ibm-risk-atlas:atlas-output-bias	Output bias	semapv:ManualMappingCuration	0.90	elizabeth.daly@ie.ibm.com	2025-01-15	Hate speech targets protected attributes (race, ethnicity, religion, etc.) which aligns with output bias that unfairly represents groups. Strong semantic overlap.
shieldgemma-taxonomy:shieldgemma-hate-speech	Hate Speech	skos:relatedMatch	ibm-risk-atlas:atlas-toxic-output	Toxic output	semapv:LexicalMatching	0.85	elizabeth.daly@ie.ibm.com	2025-01-15	Hate speech is a specific form of toxic output. Atlas toxic-output includes hateful and abusive content.
shieldgemma-taxonomy:shieldgemma-hate-speech	Hate Speech	skos:relatedMatch	ibm-risk-atlas:atlas-spreading-toxicity	Spreading toxicity	semapv:ManualMappingCuration	0.82	elizabeth.daly@ie.ibm.com	2025-01-15	Intentional generation of hateful content for spreading. ShieldGemma detects hate speech that could be used to spread toxicity.
shieldgemma-taxonomy:shieldgemma-hate-speech	Hate Speech	skos:relatedMatch	ibm-risk-atlas:atlas-decision-bias	Decision bias	semapv:ManualMappingCuration	0.70	elizabeth.daly@ie.ibm.com	2025-01-15	Hate speech can lead to biased decisions. Connection exists but decision-bias is more about unfair advantaging in model decisions rather than language content.
shieldgemma-taxonomy:shieldgemma-hate-speech	Hate Speech	skos:relatedMatch	ibm-risk-atlas:atlas-data-bias	Data bias	semapv:ManualMappingCuration	0.60	elizabeth.daly@ie.ibm.com	2025-01-15	Hate speech in training data contributes to data bias. Connection is indirect - ShieldGemma detects output, data-bias is training concern.
shieldgemma-taxonomy:shieldgemma-harassment	Harassment	skos:relatedMatch	ibm-risk-atlas:atlas-harmful-output	Harmful output	semapv:ManualMappingCuration	0.85	elizabeth.daly@ie.ibm.com	2025-01-15	Harassment is a form of harmful content targeting individuals or groups.
shieldgemma-taxonomy:shieldgemma-harassment	Harassment	skos:relatedMatch	ibm-risk-atlas:atlas-toxic-output	Toxic output	semapv:LexicalMatching	0.88	elizabeth.daly@ie.ibm.com	2025-01-15	Harassment includes bullying behaviors explicitly mentioned in atlas toxic-output definition.
shieldgemma-taxonomy:shieldgemma-harassment	Harassment	skos:relatedMatch	ibm-risk-atlas:atlas-spreading-toxicity	Spreading toxicity	semapv:ManualMappingCuration	0.75	elizabeth.daly@ie.ibm.com	2025-01-15	Harassment content used to spread abuse and toxicity to individuals or groups.
shieldgemma-taxonomy:shieldgemma-harassment	Harassment	skos:relatedMatch	ibm-risk-atlas:atlas-over-or-under-reliance	Over- or under-reliance	semapv:ManualMappingCuration	0.40	elizabeth.daly@ie.ibm.com	2025-01-15	Weak connection - harassment detection helps users avoid over-reliance on models that generate abusive content. Indirect relationship.
