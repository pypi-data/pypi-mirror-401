from __future__ import annotations

import datetime
import logging
import time
from contextlib import ContextDecorator
from pathlib import Path
from typing import TYPE_CHECKING
from uuid import UUID, uuid4

import polars_cloud
import polars_cloud.polars_cloud as pcr
from polars_cloud import constants
from polars_cloud.context.compute_connect_select import select_compute_cluster
from polars_cloud.context.compute_specs import (
    ComputeContextSpecs,
    resolve_compute_context_specs,
)
from polars_cloud.context.compute_status import ComputeContextStatus
from polars_cloud.exceptions import ComputeClusterMisspecified
from polars_cloud.polars_cloud import ClientOptions
from polars_cloud.workspace import Workspace, WorkspaceStatus

logger = logging.getLogger(__name__)

if TYPE_CHECKING:
    import io
    import sys
    from types import TracebackType

    from polars_cloud._typing import ConnectionMode, LogLevel
    from polars_cloud.organization import Organization

    if sys.version_info >= (3, 11):
        from typing import Self
    else:
        from typing_extensions import Self

DEFAULT_SCHEDULER_PORT = 5051


class ClientContext:
    """Client context in which queries can be submitted too.

    The client context is an abstraction over a low-level client that can
    submit queries to some compute destination.
    """

    def __init__(self) -> None:
        self._compute_id: UUID | None = None
        self._connection_mode = pcr.DBClusterModeSchema.Direct
        self._direct_client: pcr.SchedulerClient | None = None

    def _get_direct_client(self) -> pcr.SchedulerClient | None:
        return self._direct_client

    def _get_token(self) -> str | None:
        return None


class ClusterContext(ClientContext):
    """Cluster context in which queries are executed.

    The cluster context is an abstraction of some remote cluster that is routable
    from the client. This will bypass any calls to the Polars Cloud control plane
    and talk to the cluster's scheduler directly.
    """

    def __init__(
        self,
        compute_address: str,
        *,
        compute_port: int = DEFAULT_SCHEDULER_PORT,
        insecure: bool = False,
        tls_cert_domain: str | None = None,
        public_server_crt: bytes | None = None,
        tls_certificate: bytes | None = None,
        tls_private_key: bytes | None = None,
    ) -> None:
        self._connection_mode = pcr.DBClusterModeSchema.Direct
        self._compute_id = uuid4()
        client_options = ClientOptions()

        client_options.tls_cert_domain = tls_cert_domain
        client_options.public_server_crt = public_server_crt
        client_options.tls_certificate = tls_certificate
        client_options.tls_private_key = tls_private_key
        client_options.insecure = insecure
        compute_address = f"{compute_address}:{compute_port}"
        self._direct_client = pcr.SchedulerClient(compute_address, client_options)


class ComputeContext(ClientContext, ContextDecorator):
    """Compute context in which queries are executed.

    The compute context is an abstraction of the underlying hardware
    (either a single node or multiple nodes in case of a cluster).

    Parameters
    ----------
    name
        The name of the registered ComputeContext to start, or connect to
        if already running.
    cpus
        The number of CPUs each instance in the compute context
        should have access to. This acts as a lower bound, Polars Cloud
        finds the smallest available machine that satisfies both cpu and
        memory requirements.
    memory
        The amount of RAM (in GB) each instance in the compute context
        should have access to. This acts as a lower bound, see `cpus`.
    instance_type
        The instance type to use.
    storage
        The amount of disk space (in GB) each instance in the compute context
        should have access to.
    cluster_size
        The number of machines to spin up in the cluster. Defaults to `1`.
        Includes the optional big worker instance.
    requirements
        Path to a file or a file-like object [#filelike]_ containing dependencies to
        install in the compute context, in the `requirements.txt format`_.
    connection_mode
        How the context will connect to the compute cluster.
        - direct: connect directly to the compute cluster.
        - proxy: send queries to the compute cluster via the control plane.
        Defaults to `direct`.
    workspace
        The workspace to run this context in.
        You may specify the name (str), the id (UUID) or the Workspace object.
        If you're in multiple organizations that have a workspace with the same name
        then you need to explicitly specify the organization.
    labels
        Labels of the workspace (will be implicitly created)
    log_level : {'info', 'debug', 'trace'}
        Override the log level of the context for debug purposes.
    idle_timeout_mins
        How many minutes a cluster can be idle before it will be automatically killed.
        The minimum is 10 minutes, by default it is set to 1 hour.

    Examples
    --------
    >>> ctx = pc.ComputeContext(
        workspace="workspace-name", cpus=24, memory=24, cluster_size=2, labels="docs"
    )
    >>> ctx
    ComputeContext(
        id=None,
        cpus=24,
        memory=24,
        instance_type=None,
        storage=None,
        cluster_size=2,
        mode="direct",
        workspace_name="workspace-name",
        labels=["docs"],
        log_level=LogLevelSchema.Info,
    )
    >>> ctx.register("compute-name")
    >>> pc.ComputeContext(workspace="workspace-name", name="compute-name")
    ComputeContext(
        name="cluster-name",
        workspace_name="workspace-name",
        id=None,
        cpus=24,
        memory=24,
        instance_type=None,
        storage=None,
        cluster_size=2,
        mode="direct",
        labels=["docs"],
        log_level=LogLevelSchema.Info,
    )

    The ComputeContext can also be used as a decorator or context manager,
    which will set it as the default context within its scope,
    automatically starting and stopping the underlying compute: ::

        @pc.ComputeContext(workspace="workspace-name", cpus=96, memory=256)
        def run_queries():
            ...
            query1.remote().execute()
            query2.remote().execute()


        # or

        with pc.ComputeContext(workspace="workspace-name", cpus=96, memory=256):
            ...
            query1.remote().execute()
            query2.remote().execute()

    Notes
    -----
    .. note::
     If the `cpus`, `memory`, and `instance_type` parameters are not set, the parameters
     are resolved with the default context specs of the workspace.

    .. rubric:: Footnotes
    .. [#filelike] By “file-like object” we refer to objects that have a read() method,
                   such as a file handler like the builtin open function, or a BytesIO
                   instance.
    .. _requirements.txt format: https://pip.pypa.io/en/stable/reference/requirements-file-format/

    """

    def __init__(
        self,
        *,
        name: str | None = None,
        cpus: int | None = None,
        memory: int | None = None,
        instance_type: str | None = None,
        storage: int | None = None,
        cluster_size: int | None = None,
        requirements: str | Path | io.IOBase | bytes | None = None,
        connection_mode: ConnectionMode | None = None,
        workspace: str | UUID | Workspace | None = None,
        labels: list[str] | str | None = None,
        log_level: LogLevel | None = None,
        idle_timeout_mins: int | None = None,
        insecure: bool = False,
    ) -> None:
        self._workspace = Workspace._parse(workspace)
        self._insecure = insecure
        self._direct_client = None
        self._compute_id: UUID | None = None
        self._compute_token: str | None = None
        self._requirements_txt: str | None
        self._name: str | None = None

        if name is not None:
            if (
                cpus is not None
                or memory is not None
                or instance_type is not None
                or storage is not None
                or cluster_size is not None
                or requirements is not None
                or connection_mode is not None
                or labels is not None
                or log_level is not None
                or idle_timeout_mins is not None
            ):
                msg = "cannot specify both `name` and any other specs"
                raise ComputeClusterMisspecified(msg)
            self._name = name
            m = constants.API_CLIENT.get_compute_cluster_manifest(
                self._workspace.id, name
            )
            self._specs = ComputeContextSpecs(
                cpus=m.req_cpu_cores,
                memory=m.req_ram_gb,
                instance_type=m.instance_type,
                storage=m.req_storage,
                big_instance_type=m.big_instance_type,
                big_instance_multiplier=m.req_big_instance_multiplier,
                cluster_size=m.cluster_size,
            )
            # TODO: Get the labels as well
            self._labels = None
            self._connection_mode: pcr.DBClusterModeSchema = m.mode
            self._log_level: pcr.LogLevelSchema = m.log_level
            self._idle_timeout_mins = m.idle_timeout_mins

            self._polars_version = pcr.polars_version()
            if self._polars_version != m.polars_version:
                msg = f"locally installed polars version ({self._polars_version}) does not match polars version specified in manifest ({m.polars_version})"
                raise ComputeClusterMisspecified(msg)

            python_version = pcr.python_version()
            if python_version != m.python_version:
                msg = f"locally installed python version ({python_version}) does not match python version specified in manifest ({m.python_version})"
                raise ComputeClusterMisspecified(msg)

        else:
            self._specs = resolve_compute_context_specs(
                self._workspace,
                cpus=cpus,
                memory=memory,
                instance_type=instance_type,
                storage=storage,
                cluster_size=cluster_size,
            )

            self._labels = [labels] if isinstance(labels, str) else labels
            self._connection_mode = pcr.DBClusterModeSchema.from_str(connection_mode)
            self._log_level = pcr.LogLevelSchema.from_str(log_level)
            self._idle_timeout_mins = idle_timeout_mins
            self._polars_version = pcr.polars_version()

            if requirements is not None:
                if isinstance(requirements, (str, Path)):
                    self._requirements_txt = Path(requirements).read_text()
                else:
                    if isinstance(requirements, bytes):
                        bytes_ = requirements
                    else:
                        bytes_ = requirements.read()
                    if isinstance(bytes_, str):
                        self._requirements_txt = bytes_
                    else:
                        self._requirements_txt = str(bytes_, encoding="utf-8")
            else:
                self._requirements_txt = None

    def __repr__(self) -> str:
        return (
            f"{self.__class__.__name__}("
            f"id={self._compute_id}, "
            f"cpus={self._specs.cpus!r}, "
            f"memory={self._specs.memory!r}, "
            f"instance_type={self._specs.instance_type!r}, "
            f"storage={self._specs.storage!r}, "
            f"cluster_size={self._specs.cluster_size!r}, "
            f"connection_mode={self.connection_mode!r}, "
            f"insecure={self._insecure!r}, "
            f"workspace_name={self.workspace.name!r}, "
            f"labels={self.labels!r}, "
            f"log_level={self._log_level!r}"
        )

    @classmethod
    def _from_api_schema(
        cls, schema: pcr.ComputeSchema
    ) -> tuple[Self, ComputeContextStatus]:
        self = cls(
            cpus=schema.req_cpu_cores,
            memory=schema.req_ram_gb,
            cluster_size=schema.cluster_size,
            instance_type=schema.instance_type,
            storage=schema.req_storage,
            workspace=Workspace(id=schema.workspace_id),
            connection_mode=schema.mode.as_str(),
            # TODO: Get the labels as well
            labels=None,
            log_level=schema.log_level.as_str(),
        )
        self._compute_id = schema.id
        self._polars_version = schema.polars_version
        return self, ComputeContextStatus._from_api_schema(schema.status)

    def get_status(self) -> ComputeContextStatus:
        """Get the status of the compute context.

        Examples
        --------
        >>> ctx = pc.ComputeContext(workspace="workspace-name", cpus=24, memory=24)
        >>> ctx.get_status()
        UNINITIALIZED
        """
        if self._compute_id is None:
            return ComputeContextStatus.UNINITIALIZED
        else:
            status = constants.API_CLIENT.get_compute_cluster(
                self.workspace.id, self._compute_id
            ).status
            return ComputeContextStatus._from_api_schema(status)

    def register(self, name: str) -> None:
        """Register the compute cluster specs under the given name.

        This does not start the compute cluster, instead allows the cluster to be
        started with this name in future.

        Parameters
        ----------
        name
            Name to register the compute cluster under.

        Examples
        --------
        >>> ctx = pc.ComputeContext(workspace="workspace-name", cpus=24, memory=24)
        >>> ctx.register("my-cluster")
        >>> ctx.start()
        >>> ctx = pc.ComputeContext(workspace="workspace-name", name="my-cluster")
        >>> ctx.start()
        """
        self._name = name

        constants.API_CLIENT.register_compute_cluster_manifest(
            workspace_id=self.workspace.id,
            name=self._name,
            cluster_size=self._specs.cluster_size,
            mode=self._connection_mode,
            cpus=self._specs.cpus,
            ram_gb=self._specs.memory,
            instance_type=self._specs.instance_type,
            storage=self._specs.storage,
            big_instance_type=self._specs.big_instance_type,
            big_instance_multiplier=self._specs.big_instance_multiplier,
            big_instance_storage=self._specs.big_instance_storage,
            requirements_txt=self._requirements_txt,
            labels=self._labels,
            log_level=self.log_level,
            idle_timeout_mins=self._idle_timeout_mins,
        )

    def unregister(self) -> None:
        if self._name is None:
            msg = "can't unregister ComputeContext without name"
            raise RuntimeError(msg)

        constants.API_CLIENT.unregister_compute_cluster_manifest(
            workspace_id=self.workspace.id, name=self._name
        )

        self._name = None

    def start(self, *, wait: bool = False) -> None:
        """Start the compute context.

        This boots up the underlying node(s) of the compute context.

        Parameters
        ----------
        wait
            Wait for the compute context to be ready before returning.
            If the `ComputeContext` is in direct connection mode, it will always
            wait until ready.

        Examples
        --------
        >>> ctx = pc.ComputeContext(workspace="workspace-name", cpus=24, memory=24)
        >>> ctx.start()
        """
        status = self.get_status()
        if status.is_failed():
            msg = "can't start compute in a failed state"
            raise RuntimeError(msg)
        elif status.is_available():
            return

        if self._name is not None:
            compute = constants.API_CLIENT.start_compute_cluster_manifest(
                workspace_id=self.workspace.id, name=self._name
            )
            self._compute_id = compute.id
        else:
            compute = constants.API_CLIENT.start_compute(
                workspace_id=self.workspace.id,
                cluster_size=self._specs.cluster_size,
                mode=self._connection_mode,
                cpus=self._specs.cpus,
                ram_gb=self._specs.memory,
                instance_type=self._specs.instance_type,
                storage=self._specs.storage,
                big_instance_type=self._specs.big_instance_type,
                big_instance_multiplier=self._specs.big_instance_multiplier,
                big_instance_storage=self._specs.big_instance_storage,
                requirements_txt=self._requirements_txt,
                labels=self._labels,
                log_level=self.log_level,
                idle_timeout_mins=self._idle_timeout_mins,
            )
            self._compute_id = compute.id

        msg = f"View your compute metrics on: https://cloud.pola.rs/portal/{self.organization.id}/{self.workspace.id}/compute/{self._compute_id}"
        logger.info(msg)

        wait = True if self._connection_mode == pcr.DBClusterModeSchema.Direct else wait
        if wait:
            _poll_compute_status_until(self, ComputeContextStatus.IDLE)

    def stop(self, *, wait: bool = False) -> None:
        """Stop the compute context.

        Parameters
        ----------
        wait
            If True, this will block this thread until context is stopped.

        Examples
        --------
        >>> ctx = pc.ComputeContext(workspace="workspace-name", cpus=24, memory=24)
        >>> ctx.stop()
        """
        if self._compute_id is None:
            msg = "nothing to stop, context is not running"
            raise RuntimeError(msg)

        constants.API_CLIENT.stop_compute_cluster(self.workspace.id, self._compute_id)
        if wait:
            _poll_compute_status_until(self, ComputeContextStatus.STOPPED, 10, 5, 100)

        self._compute_id = None
        self._direct_client = None

    @classmethod
    def list(
        cls, workspace: Workspace | UUID | str
    ) -> list[tuple[Self, ComputeContextStatus]]:
        """List all compute contexts in the workspace and the current status for each.

        Parameters
        ----------
        workspace
            Name or ID of the workspace the compute context lives in

        Examples
        --------
        >>> pc.ComputeContext.list(workspace="YourWorkspace")
        [(ComputeContext(...), ComputeContextStatus)],
        [(ComputeContext(...), ComputeContextStatus)],
        [(ComputeContext(...), ComputeContextStatus)],
        """
        w = Workspace._parse(workspace)
        compute_contexts = constants.API_CLIENT.get_compute_clusters(w.id)
        return [cls._from_api_schema(c) for c in compute_contexts]

    @classmethod
    def connect(
        cls,
        compute_id: str | UUID,
        workspace: str | UUID | Workspace | None = None,
    ) -> Self:
        """Reconnect with an already running compute context by id.

        Parameters
        ----------
        workspace
            The workspace in which the compute context lives
        compute_id
            The unique identifier of the existing compute context.

        Examples
        --------
        >>> ctx = pc.ComputeContext.connect(
        ...     workspace="WorkspaceName",
        ...     compute_id="xxxxxxxx-1860-7521-829d-40444726cbca",
        ... )
        """
        compute_uuid = compute_id if isinstance(compute_id, UUID) else UUID(compute_id)
        workspace = Workspace._parse(workspace)
        details = constants.API_CLIENT.get_compute_cluster(workspace.id, compute_uuid)
        ctx, status = cls._from_api_schema(details)
        if not status.is_available():
            msg = f"Context is in an incorrect state: {status}"
            raise RuntimeError(msg)
        return ctx

    @classmethod
    def select(
        cls,
        workspace: str | UUID | Workspace | None = None,
    ) -> Self | None:
        """Connect to existing compute context interactively.

        Parameters
        ----------
        workspace
            The workspace in which the compute context lives

        Examples
        --------
        >>> ctx = pc.ComputeContext.select(
        ...     workspace="WorkspaceName",
        ... )
        """
        if workspace:
            workspace = Workspace._parse(workspace)
            if workspace.status != WorkspaceStatus.Active:
                msg = "`connect your workspace with your cloud first before connecting to compute contexts.`"
                raise ComputeClusterMisspecified(msg)
            workspaces = [workspace]
        else:
            workspaces = [
                w for w in Workspace.list() if w.status == WorkspaceStatus.Active
            ]
        contexts = [
            (w, context)
            for w in workspaces
            for context in constants.API_CLIENT.get_compute_clusters(
                w.id,
                status=[
                    pcr.ComputeStatusSchema.Starting,
                    pcr.ComputeStatusSchema.Idle,
                    pcr.ComputeStatusSchema.Running,
                ],
            )
        ]
        contexts.sort(key=lambda x: x[1].request_time, reverse=True)
        idx = select_compute_cluster(contexts)
        if idx is not None:
            ctx, _status = cls._from_api_schema(contexts[idx][1])
            return ctx
        return None

    @property
    def cpus(self) -> int | None:
        """The number of CPUs each instance has access to."""
        return self._specs.cpus

    @property
    def memory(self) -> int | None:
        """The amount of RAM (in GB) each instance has access to."""
        return self._specs.memory

    @property
    def instance_type(self) -> str | None:
        """The instance type of the compute context."""
        return self._specs.instance_type

    @property
    def storage(self) -> int | None:
        """The amount of disk space (in GB) each instance has access to."""
        return self._specs.storage

    @property
    def cluster_size(self) -> int:
        """The number of compute nodes in the context."""
        return self._specs.cluster_size

    @property
    def connection_mode(self) -> str:
        """In what way to connect to the compute cluster."""
        return self._connection_mode.as_str()

    @property
    def labels(self) -> list[str] | None:  # type: ignore[valid-type]
        """The labels of the compute context."""
        return self._labels

    @property
    def organization(self) -> Organization:
        """The organization to run the compute context in."""
        return self._workspace.organization

    @property
    def workspace(self) -> Workspace:
        """The workspace to run the compute context in."""
        return self._workspace

    @property
    def log_level(self) -> pcr.LogLevelSchema:
        return self._log_level

    def _get_direct_client(self) -> pcr.SchedulerClient | None:
        if self.connection_mode != "direct":
            return None
        if self._direct_client is not None:
            return self._direct_client

        logger.debug("Getting compute server info")
        assert self._compute_id is not None, (
            "Compute id undefined while getting direct client"
        )
        server_info = constants.API_CLIENT.get_compute_server_info(
            self.workspace.id, self._compute_id
        )
        logger.debug("Successfully obtained compute server info")

        client_options = ClientOptions()
        client_options.public_server_crt = str.encode(server_info.public_server_key)
        client_options.insecure = self._insecure
        compute_address = f"{server_info.public_address}:{DEFAULT_SCHEDULER_PORT}"
        client = pcr.SchedulerClient(compute_address, client_options)
        self._direct_client = client
        return self._direct_client

    def _get_token(self) -> str | None:
        assert self._compute_id is not None, "Compute id undefined while getting token"

        if self.connection_mode != "direct":
            return None

        if self._direct_client is None:
            self._get_direct_client()

        if self._compute_token is None or pcr.py_is_token_expired(
            self._compute_token, datetime.timedelta(minutes=5)
        ):
            response = constants.API_CLIENT.get_compute_cluster_token(
                self.workspace.id, self._compute_id
            )
            self._compute_token = response.token

        return self._compute_token

    @property
    def polars_version(self) -> str:
        return self._polars_version

    def __enter__(self) -> ComputeContext:
        self._cm = polars_cloud.set_compute_context(self)
        self._cm.__enter__()
        return self

    def __exit__(
        self,
        exc_type: type[BaseException],
        exc_value: BaseException,
        traceback: TracebackType,
    ) -> bool | None:
        self.stop()
        return self._cm.__exit__(exc_type, exc_value, traceback)


def _poll_compute_status_until(
    compute: ComputeContext,
    desired_state: ComputeContextStatus,
    start_delay: int = 30,
    interval: int = 3,
    timeout: int = 300,
) -> ComputeContextStatus:
    """Poll the compute status until the compute context is in desired_state."""
    # Poll at least once for fast response
    status = compute.get_status()
    if status == desired_state:
        return status

    max_polls = int((timeout - start_delay) / interval)
    time.sleep(start_delay)
    for i in range(max_polls):
        logger.debug("Polling compute status (try %s)", str(i))
        status = compute.get_status()
        logger.debug("Got compute status %s", status)
        if status == desired_state:
            return status
        elif status == ComputeContextStatus.FAILED:
            msg = "Compute cluster in failed state"
            logger.info(msg)
            raise RuntimeError(msg)
        else:
            time.sleep(interval)
    else:
        msg = f"Compute context failed to reach desired state {desired_state} after polling for {timeout} seconds"
        logger.info(msg)
        raise RuntimeError(msg)
