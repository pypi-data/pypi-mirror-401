from typing import Type
from pydantic import BaseModel
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder


def get_gemini(
    model_name: str,
    pydantic_model: Type[BaseModel],
    temperature: float = 0.1,
    timeout: int = 120,
):

    base_llm = ChatGoogleGenerativeAI(
        model=model_name,
        temperature=temperature,
        timeout=timeout,
        convert_system_message_to_human=True,
    )

    llm_structured = base_llm.with_structured_output(pydantic_model)
    base_prompt = ChatPromptTemplate.from_messages([
        MessagesPlaceholder("messages")
    ])
    chain = base_prompt | llm_structured

    if chain is None:
        raise RuntimeError("LLM not available for the given model_name")

    return chain