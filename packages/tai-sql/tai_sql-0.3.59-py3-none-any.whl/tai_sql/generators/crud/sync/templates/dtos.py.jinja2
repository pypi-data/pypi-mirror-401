# Este archivo ha sido generado automáticamente por tai-sql
# No modifiques este archivo directamente
{% import "macros.jinja2" as macros %}
{{ imports|join('\n') }}

# Logger
logger = Alphi.get_logger_by_name("{{ logger_name }}")

# General Enum class
class EnumModel:

    def __init__(self, name: str, values: List[str]):
        self.name = name
        self.values = values
    
    def find_many(self) -> List[str]:
        """
        Devuelve una lista de los valores del Enum.
        
        Returns:
            List[str]: Lista de valores del Enum
        """
        logger.info(f"Obteniendo valores del Enum '{self.name}' - {len(self.values)} valores disponibles")
        return self.values


class AggregationResult(PrettyModel):
    """
    Resultado estructurado para operaciones de agregación.
    
    Proporciona información detallada sobre el resultado de operaciones
    como sum, mean, max, min, incluyendo metadatos de validación y errores.
    
    Attributes:
        success: Indica si la operación fue exitosa (al menos un campo válido procesado)
        data: Diccionario con los resultados de la agregación
        processed_fields: Lista de campos que se procesaron exitosamente
        warnings: Lista de advertencias sobre campos que se ignoraron
        errors: Lista de errores encontrados durante la validación
        metadata: Información adicional sobre la operación
    
    Examples:
        ```python
        # Operación exitosa
        result = AggregationResult(
            success=True,
            data={"sum_price": 150.50, "sum_quantity": 25},
            processed_fields=["price", "quantity"],
            warnings=[],
            errors=[],
            metadata={"total_requested_fields": 2, "execution_time_ms": 45}
        )
        
        # Operación con advertencias
        result = AggregationResult(
            success=True,
            data={"sum_price": 150.50},
            processed_fields=["price"],
            warnings=["Campo 'description' de tipo 'TEXT' no es numérico"],
            errors=[],
            metadata={"total_requested_fields": 2, "execution_time_ms": 32}
        )
        
        # Operación con errores
        result = AggregationResult(
            success=False,
            data={},
            processed_fields=[],
            warnings=[],
            errors=["Campo 'nonexistent_field' no existe en el modelo"],
            metadata={"total_requested_fields": 1, "execution_time_ms": 12}
        )
        ```
    """
    
    success: bool = Field(
        description="Indica si la operación fue exitosa (al menos un campo válido procesado)"
    )
    
    data: Dict[str, Optional[Union[int, float, str]]] = Field(
        description="Diccionario con los resultados de la agregación. Las claves siguen el patrón '<operacion>_<campo>'"
    )
    
    processed_fields: List[str] = Field(
        description="Lista de campos que se procesaron exitosamente en la agregación"
    )
    
    warnings: List[str] = Field(
        default_factory=list,
        description="Lista de advertencias sobre campos que se ignoraron (ej: tipos no numéricos)"
    )
    
    errors: List[str] = Field(
        default_factory=list,
        description="Lista de errores encontrados durante la validación (ej: campos inexistentes)"
    )
    
    metadata: Dict[str, Any] = Field(
        default_factory=dict,
        description="Información adicional sobre la operación (ej: tiempo de ejecución, estadísticas)"
    )
    
    def has_warnings(self) -> bool:
        """Retorna True si hay advertencias."""
        return len(self.warnings) > 0
    
    def has_errors(self) -> bool:
        """Retorna True si hay errores."""
        return len(self.errors) > 0
    
    def get_summary(self) -> str:
        """
        Retorna un resumen legible de la operación.
        
        Returns:
            str: Resumen de la operación de agregación
        """
        if not self.success:
            return f"Operación fallida: {len(self.errors)} errores encontrados"
        
        summary_parts = [f"Operación exitosa: {len(self.processed_fields)} campos procesados"]
        
        if self.has_warnings():
            summary_parts.append(f"{len(self.warnings)} advertencias")
            
        if self.has_errors():
            summary_parts.append(f"{len(self.errors)} errores no críticos")
        
        return ", ".join(summary_parts)
    
    model_config = {
        "str_strip_whitespace": True,
        "validate_assignment": True,
        "arbitrary_types_allowed": True,
        "json_schema_extra": {
            "examples": [
                {
                    "success": True,
                    "data": {"sum_price": 150.50, "sum_quantity": 25},
                    "processed_fields": ["price", "quantity"],
                    "warnings": [],
                    "errors": [],
                    "metadata": {"total_requested_fields": 2, "execution_time_ms": 45}
                },
                {
                    "success": True,
                    "data": {"mean_score": 8.5},
                    "processed_fields": ["score"],
                    "warnings": ["Campo 'name' de tipo 'VARCHAR' no es numérico"],
                    "errors": [],
                    "metadata": {"total_requested_fields": 2, "execution_time_ms": 32}
                },
                {
                    "success": False,
                    "data": {},
                    "processed_fields": [],
                    "warnings": [],
                    "errors": ["Campo 'invalid_field' no existe en el modelo"],
                    "metadata": {"total_requested_fields": 1, "execution_time_ms": 12}
                }
            ]
        }
    }


{% for model in models %}
{% set all_pk_autoincrement = true %}
{% set pk_path_params = "/{" + (model.columns | selectattr('args.primary_key', 'equalto', True) | map(attribute='name') | join('}/{')) + "}" %}
{% for column in model.columns %}
    {% if column.args.get('primary_key', False) and not column.args.get('autoincrement', False) %}
        {% set all_pk_autoincrement = false %}
    {% endif %}
{% endfor %}
class {{ model.name }}Read(PrettyModel):
    """
    Data Transfer Object de lectura para {{ model.name }}.
    
    {% if model.description %}
    {{ model.description | indent(4) }}
    {% else %}
    Representa un registro de {{ model.name }} en la base de datos.
    {% endif %}
    
    Este modelo se utiliza como respuesta en endpoints de la API que devuelven
    información de {{ model.tablename }} existentes en la base de datos.
    
    Campos de la tabla:
    {% for column in model.columns %}
        - {{ column.name }} ({{ column.type }}{% if column.nullable %}, opcional{% endif %}): {{ column.description }}
    {% endfor %}
    
    {% if model.relations %}
    Relaciones disponibles (usar con parámetro 'includes'):
    {% for relation in model.relations %}
        - {{ relation.name }}: {% if relation.direction == 'one-to-many' %}Lista de {{ relation.target }} relacionados{% else %}{{ relation.target }} relacionado{% endif %} ({{ relation.direction }})
          {% if relation.description %}
            {{ relation.description | indent(10) }}
          {% endif %}
    {% endfor %}
    
    Uso del parámetro 'includes':
        Para cargar relaciones específicas, usa el parámetro 'includes' en la consulta:
        
        Ejemplos básicos:
        ```python
        # Solo datos básicos de {{ model.name }}
        Un registro > GET /{{ model.tablename }}{{ pk_path_params }}
        or
        Varios registros > GET /{{ model.tablename }}
        
        {% for relation in model.relations %}
        # Incluir {{ relation.name }}
        Un registro > GET /{{ model.tablename }}{{ pk_path_params }}?includes={{ relation.name }}
        or
        Varios registros > GET /{{ model.tablename }}?includes={{ relation.name }}
        
        {% endfor %}
        {% if model.relations|length > 1 %}
        # Múltiples relaciones en una sola consulta
        Un registro > GET /{{ model.tablename }}{{ pk_path_params }}?{% for relation in model.relations[:2] %}includes={{ relation.name }}{{ "&" if not loop.last }}{% endfor %}{{''}}
        or
        Varios registros > GET /{{ model.tablename }}?{% for relation in model.relations[:2] %}includes={{ relation.name }}{{ "&" if not loop.last }}{% endfor %}{{''}}
        
        {% endif %}
        # Relaciones anidadas (hasta {{ max_depth }} niveles):
        {% for relation in model.relations %}
        # {{ relation.name }} con sus propias relaciones
        Un registro > GET /{{ model.tablename }}{{ pk_path_params }}?includes={{ relation.name }}.{nested_relation}
        or
        Varios registros > GET /{{ model.tablename }}?includes={{ relation.name }}.{nested_relation}
        {% endfor %}
        ```
    
    Casos de uso típicos:
        {% if model.relations %}
        - Consulta básica: Obtener {{ model.tablename }} sin relaciones (rápido)
        {% for relation in model.relations %}
        - Con {{ relation.name }}: Para mostrar {{ model.tablename }} con {% if relation.direction == 'one-to-many' %}todos sus {{ relation.target | lower }}s{% else %}su {{ relation.target | lower }} relacionado{% endif %}{{''}}
        {% endfor %}
        - Consulta completa: Todas las relaciones para vistas detalladas
        {% else %}
        - Consulta de registros de {{ model.name }} (sin relaciones disponibles)
        {% endif %}
    
    {% if model.examples %}
    Ejemplos de respuesta JSON:
        {% set first_example = model.examples[0] %}
        Respuesta básica (sin includes):
        ```json
        {
            {% for column in model.columns %}
            "{{ column.name }}": {% if first_example[column.name] is defined %}{{ first_example[column.name] | tojson }}{% else %}"valor_ejemplo"{% endif %}{{ "," }}
            {% endfor %}
            {% if model.relations %}
            {% for relation in model.relations %}
            "{{ relation.name }}": null{{ "," if not loop.last }}
            {% endfor %}
            {% endif %}
        }
        ```
        
        {% if model.relations %}
        {% set first_relation = model.relations[0] %}
        Respuesta con includes={{ first_relation.name }}:
        ```json
        {
            {% for column in model.columns %}
            "{{ column.name }}": {% if first_example[column.name] is defined %}{{ first_example[column.name] | tojson }}{% else %}"valor_ejemplo"{% endif %},
            {% endfor %}
            "{{ first_relation.name }}": {% if first_relation.direction == 'one-to-many' %}[
                {
                    "...": "campos de {{ first_relation.target }}"
                }
            ]{% else %}{
                "...": "campos de {{ first_relation.target }}"
            }{% endif %}{% if model.relations|length > 1 %},
            {% for relation in model.relations[1:] %}
            "{{ relation.name }}": null{{ "," if not loop.last }}
            {% endfor %}
            {% endif %}{{''}}
        }
        ```
        {% endif %}
        {% endif %}
    {% endif %}
    
    Rendimiento:
        - Sin includes: Consulta rápida, solo tabla {{ model.name }}
        {% for relation in model.relations %}
        - Con {{ relation.name }}: {% if relation.direction == 'one-to-many' %}Carga múltiples registros de {{ relation.target }}{% else %}Una consulta adicional para {{ relation.target }}{% endif %}{{''}}
        {% endfor %}
        - Máxima profundidad de anidación: {{ max_depth }} niveles
    """
    {% for column in model.columns %}
    {% set example_value = none %}
    {% if model.examples and model.examples|length > 0 %}
    {% set example_value = (model.examples | selectattr(column.name, 'defined') | map(attribute=column.name) | first) %}
    {% endif %}

    {{ column.name }}: {% if column.nullable %}Optional[{{ column.type }}]{% else %}{{ column.type }}{% endif %} = Field(
        description="{{ column.description }}",
        {% if example_value is not none %}
        example={{ example_value | tojson }}
        {% endif %}
    )
    {% endfor %}

    {% for relation in model.relations %}
    {% if relation.direction == 'one-to-many' %}

    {{ relation.name }}: Optional[List[{{ relation.target }}Read]] = Field(
        default=None,
        description="""
        Lista de {{ relation.target }} relacionados con este {{ model.name }}.
        {% if relation.description %}
        
        {{ relation.description | indent(8) }}
        {% endif %}
        
        Para cargar esta relación, incluye '{{ relation.name }}' en el parámetro includes:
        - includes={{ relation.name }} → Carga {{ relation.target }}s básicos
        - includes={{ relation.name }}.{nested} → Carga con relaciones anidadas
        
        Relación: {{ model.name }} 1:N {{ relation.target }} (un {{ model.tablename }} puede tener múltiples {{ relation.target | lower }}s)
        """
    )
    {% elif relation.direction == 'many-to-one' %}

    {{ relation.name }}: Optional[{{ relation.target }}Read] = Field(
        default=None,
        description="""
        {{ relation.target }} relacionado con este {{ model.name }}.
        {% if relation.description %}
        
        {{ relation.description | indent(8) }}
        {% endif %}
        
        Para cargar esta relación, incluye '{{ relation.name }}' en el parámetro includes:
        - includes={{ relation.name }} → Carga {{ relation.target }} básico
        - includes={{ relation.name }}.{nested} → Carga con relaciones anidadas
        
        Relación: {{ model.name }} N:1 {{ relation.target }} (múltiples {{ model.tablename }}s pueden tener el mismo {{ relation.target | lower }})
        """
    )
    {% endif %}
    {% endfor %}

    {{ macros.pydantic_model_config() }}
    {% if model.examples %}
    
    model_config['json_schema_extra'] = {
        "examples": [
            {% for example in model.examples %}
            {
                {% for column in model.columns %}
                "{{ column.name }}": {% if example[column.name] is defined %}{% if example[column.name] is none %}None{% else %}{{ example[column.name] | tojson }}{% endif %}{% else %}"valor_ejemplo"{% endif %},
                {% endfor %}
                {% for relation in model.relations %}
                "{{ relation.name }}": {% if relation.direction == 'one-to-many' %}[
                    {
                        "...": "campos de {{ relation.target }}"
                    }
                ],{{'\n'}}{% else %}{
                    "...": "campos de {{ relation.target }}"
                },{{'\n'}}{% endif %}
                {% endfor %}{{''}}
            },
            {% endfor %}
        ]
    }
    {% endif %}
    
    @classmethod
    def from_instance(
        cls,
        instance: {{ model.name }},
        {% if not model.is_view %}
        includes: Optional[List[str]] = None,
        max_depth: int = {{ max_depth }}
        {% endif %}
    ) -> {{ model.name }}Read:
        """
        Crea un DTO desde una instancia del modelo SQLAlchemy con carga optimizada de relaciones.
        
        Args:
            instance: Instancia del modelo {{ model.name }}
            includes: Lista de relaciones a incluir (formato: 'relation' o 'relation.nested_relation')
            max_depth: Profundidad máxima de anidación para evitar recursión infinita
            
        Returns:
            {{ model.name }}Read: Instancia del DTO
        """

        # Construir DTO base
        dto_data = {
            {% for column in model.columns %}
            '{{ column.name }}': instance.{{ column.name }},
            {% endfor %}
        }

        {% if not model.is_view and model.has_relations  %}
        # Procesar relaciones con control de profundidad
        if includes is not None and max_depth > 0:
            {% for relation in model.relations %}
            {% if relation.direction == 'one-to-many' %}
            # Relación 1:N - {{ relation.name }}
            if should_include_relation('{{ relation.name }}', includes):
                nested_includes = get_nested_includes('{{ relation.name }}', includes)
                # Este check debería cumplirse siempre, es por seguridad
                if hasattr(instance, '{{ relation.name }}') and instance.{{ relation.name }} is not None:
                    dto_data['{{ relation.name }}'] = [
                        {{ relation.target }}Read.from_instance(
                            reg, 
                            nested_includes, 
                            max_depth - 1
                        ) 
                        for reg in instance.{{ relation.name }}
                    ]

            {% elif relation.direction == 'many-to-one' %}
            # Relación N:1 - {{ relation.name }}
            if should_include_relation('{{ relation.name }}', includes):
                nested_includes = get_nested_includes('{{ relation.name }}', includes)
                # Este check debería cumplirse siempre, es por seguridad
                if hasattr(instance, '{{ relation.name }}') and instance.{{ relation.name }} is not None:
                    dto_data['{{ relation.name }}'] = {{ relation.target }}Read.from_instance(
                        instance.{{ relation.name }}, 
                        nested_includes, 
                        max_depth - 1
                    )

            {% endif %}
            {% endfor %}
        {% endif %}
        return cls(**dto_data)

    {% if not model.is_view %}
    @classmethod
    def from_created_instance(cls, instance: {{ model.name }}, included: set[str], excluded: str=None) -> {{ model.name }}Read:
        """
        Crea un DTO desde una instancia del modelo SQLAlchemy
        
        Args:
            instance: Instancia del modelo {{ model.name }}
            included: Set de nombres de relaciones que fueron cargadas con session.refresh()
            excluded: Nombre de relación a excluir para evitar recursión infinita
            
        Returns:
            {{ model.name }}Read: Instancia del DTO
        """

        # Construir DTO base
        dto_data = {
            {% for column in model.columns %}
            '{{ column.name }}': instance.{{ column.name }},
            {% endfor %}
        }

        {% if model.relations %}

        # Solo procesar relaciones que fueron explícitamente cargadas con session.refresh()
        # NO usar hasattr() ni getattr() porque disparan lazy loading
        {% for relation in model.relations %}
        if '{{ relation.name }}' in included and '{{ relation.name }}' != excluded:
        {% if relation.direction == 'one-to-many' %}
            dto_data['{{ relation.name }}'] = [
                {{ relation.target }}Read.from_created_instance(reg, included, '{{ relation.backref }}') 
                for reg in instance.{{ relation.name }}
            ]
        {% elif relation.direction == 'many-to-one' %}
            dto_data['{{ relation.name }}'] = {{ relation.target }}Read.from_created_instance(
                instance.{{ relation.name }}, included, '{{ relation.backref }}'
            )
        {% endif %}
        {% endfor %}

        {% endif %}
        return cls(**dto_data)

    {% endif %}
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> {{ model.name }}Read:
        """
        Crea un DTO desde un diccionario
        
        Args:
            data: Diccionario con los datos del DTO
            
        Returns:
            {{ model.name }}Read: Instancia del DTO
        """
        return cls(**data)
    
    def to_dict(self) -> Dict[str, Any]:
        return self.model_dump()


{% if not model.is_view %}
class {{ model.name }}Create(PrettyModel):
    """Data Transfer Object de escritura para {{ model.name }}. Define objetos para ser creados en la base de datos."""
    {% for column in model.columns -%}
    {% if not column.args.get('autoincrement', False) and column.default is none and not column.nullable and not column.is_foreign_key %}
    {{ column.name }}: {{ column.type }}
    {% endif %}
    {% endfor %}
    {% for column in model.columns -%}
    {% if column.is_foreign_key %}
    {{ column.name }}: Optional[{{ column.type }}] = None
    {% elif column.default is none and column.nullable %}
    {{ column.name }}: Optional[{{ column.type }}] = None
    {% elif column.default is not none %}
        {% if column.default == "datetime.now" %}
    {{ column.name }}: {{ column.type }} = Field(default_factory=datetime.now)
        {% elif column.default == "datetime.today" %}
    {{ column.name }}: {{ column.type }} = Field(default_factory=datetime.today)
        {% elif column.default in [True, False, None] %}
    {{ column.name }}: {{ column.type }} = {{ column.default }}
        {% elif column.default is string %}
            {% if column.default.isdigit() %}
    {{ column.name }}: {{ column.type }} = {{ column.default }}
            {% elif column.default.replace(" ", "").isalnum() %}
    {{ column.name }}: {{ column.type }} = "{{ column.default }}"
            {% else %}
    {{ column.name }}: {{ column.type }} = "{{ column.default | replace('"', '\\"') }}"
            {% endif %}
        {% else %}
    {{ column.name }}: {{ column.type }} = {{ column.default }}
        {% endif %}
    {% endif %}
    {% endfor %}

    {% for relation in model.relations %}
    {% if relation.direction == 'one-to-many' %}
    {{ relation.name }}: Optional[List[{{ relation.target }}Create]] = None
    {% elif relation.direction == 'many-to-one' %}
    {{ relation.name }}: Optional[{{ relation.target }}Create] = None
    {% endif %}
    {% endfor %}

    {{ macros.pydantic_model_config() }}
    
    def to_instance(self) -> {{ model.name }}:
        """
        Crea una instancia del modelo SQLAlchemy desde el DTO
        
        Returns:
            {{ model.name }}: Instancia del modelo SQLAlchemy
        """

        model = {{ model.name }}(
            {% for column in model.columns %}
            {% if not column.args.get('autoincrement', False) %}
            {{ column.name }}=self.{{ column.name }},
            {% endif %}
            {% endfor %}
        )
        
        # Evaluación lazy de relaciones costosas
        {% for relation in model.relations %}
        if self.{{ relation.name }} is not None:
            {% if relation.direction == 'one-to-many' %}
            {{ relation.name }} = [reg.to_instance() for reg in self.{{ relation.name }}]
            {% elif relation.direction == 'many-to-one' %}
            {{ relation.name }} = self.{{ relation.name }}.to_instance()
            {% endif %}
            model.{{ relation.name }} = {{ relation.name }}
        {% endfor %}

        return model
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> {{ model.name }}Create:
        """
        Crea un DTO desde un diccionario
        
        Args:
            data: Diccionario con los datos del DTO
            
        Returns:
            {{ model.name }}Read: Instancia del DTO
        """
        return cls(**data)

    def to_dict(self) -> Dict[str, Any]:
        return self.model_dump()


class {{ model.name }}Filter(PrettyModel):
    """Data Transfer Object de actualización para {{ model.name }}.
    Define los filtros que sirven para buscar registros en la DB."""
    {% for column in model.columns -%}
    {% if not column.args.get('autoincrement', False) %}
    {{ column.name }}: {{ column.type }} = None
    {% endif %}
    {% endfor %}

    {{ macros.pydantic_model_config() }}
    
    def to_dict(self) -> Dict[str, Any]:
        return self.model_dump(exclude_unset=True)


class {{ model.name }}UpdateValues(PrettyModel):
    """Data Transfer Object de actualización para {{ model.name }}.
    Define los valores que se modificarán en los registros correspondientes."""
    {% for column in model.columns -%}
    {% if not column.args.get('autoincrement', False) %}
    {% if not column.nullable %}
    {{ column.name }}: {{ column.type }} = None
    {% else %}
    {{ column.name }}: Optional[{{ column.type }}] = None
    {% endif %}
    {% endif %}
    {% endfor %}

    {{ macros.pydantic_model_config() }}
    
    def to_dict(self) -> Dict[str, Any]:
        return self.model_dump(exclude_unset=True)


class {{ model.name }}Update(PrettyModel):
    """Data Transfer Object de actualización para {{ model.name }}."""
    filter: {{ model.name }}Filter
    values: {{ model.name }}UpdateValues

    {{ macros.pydantic_model_config() }}
{% endif %}

class {{ model.name }}DataFrameValidator:
    """ Validador de DataFrame para el modelo {{ model.name }} """

    def validate_dataframe_schema(
        self, 
        df: DataFrame, 
        ignore_extra_columns: bool, 
        fill_missing_nullable: bool
    ) -> None:
        """
        Valida que el esquema del DataFrame sea compatible con el modelo.
        
        Args:
            df: DataFrame a validar
            ignore_extra_columns: Si ignorar columnas extra
            fill_missing_nullable: Si llenar columnas nullable faltantes
            
        Raises:
            ValueError: Si el esquema no es compatible
        """
        # Definir columnas del modelo
        model_columns = {
            {% for column in model.columns %}
            '{{ column.name }}': {
                'type': '{{ column.type }}',
                'nullable': {{ 'True' if column.nullable else 'False' }},
                'primary_key': {{ column.args.get('primary_key', False) }},
                'autoincrement': {{ column.args.get('autoincrement', False) }}
            }{{ ',' if not loop.last }}
            {% endfor %}
        }
        
        df_columns = set(df.columns)
        required_columns = set(model_columns.keys())
        
        # Verificar columnas extra
        extra_columns = df_columns - required_columns
        if extra_columns and not ignore_extra_columns:
            raise ValueError(
                f"DataFrame contiene columnas no definidas en el modelo: {list(extra_columns)}\n"
                f"Usa ignore_extra_columns=True para ignorarlas o elimínalas del DataFrame"
            )
        
        # Verificar columnas faltantes
        missing_columns = required_columns - df_columns
        
        # Filtrar columnas que pueden faltar
        critical_missing = []
        for col in missing_columns:
            col_info = model_columns[col]
            # Las columnas críticas son las que no son nullable, no son auto-increment y no son PK auto
            if (not col_info['nullable'] and 
                not col_info['autoincrement'] and 
                not (col_info['primary_key'] and col_info['autoincrement'])):
                critical_missing.append(col)
        
        if critical_missing:
            raise ValueError(
                f"DataFrame falta columnas requeridas (NOT NULL): {critical_missing}\n"
                f"Estas columnas son obligatorias y deben estar presentes en el DataFrame"
            )
        
        # Advertir sobre columnas nullable faltantes
        nullable_missing = [col for col in missing_columns if col not in critical_missing]
        if nullable_missing and not fill_missing_nullable:
            import warnings
            warnings.warn(
                f"DataFrame falta columnas nullable: {nullable_missing}\n"
                f"Usa fill_missing_nullable=True para llenarlas automáticamente con None"
            )
    
    def validate_dataframe_types(self, df: "DataFrame") -> None:
        """
        Valida que los tipos de datos del DataFrame sean compatibles.
        
        Args:
            df: DataFrame a validar
            
        Raises:
            TypeError: Si los tipos no son compatibles
        """
        
        # Mapeo de tipos SQLAlchemy a tipos pandas compatibles
        type_compatibility = {
            {% for column in model.columns %}
            '{{ column.name }}': {
                'sqlalchemy_type': '{{ column.type }}',
                'compatible_pandas_types': [
                    {% if 'int' == column.type or 'BigInteger' == column.type %}
                    'int64', 'Int64', 'int32', 'Int32', 'int16', 'Int16', 'int8', 'Int8', 'object'
                    {% elif 'float' == column.type or 'Numeric' == column.type %}
                    'float64', 'float32', 'int64', 'Int64', 'object'
                    {% elif 'bool' == column.type %}
                    'bool', 'boolean', 'object'
                    {% elif 'datetime' == column.type %}
                    'datetime64[ns]', 'object'
                    {% elif 'date' == column.type %}
                    'datetime64[ns]', 'object'
                    {% elif 'str' == column.type or 'Text' == column.type %}
                    'object', 'string', 'category'
                    {% else %}
                    'object'
                    {% endif %}
                ]
            }{{ ',' if not loop.last }}
            {% endfor %}
        }
        
        type_errors = []
        
        for column in df.columns:
            if column in type_compatibility:
                df_dtype = str(df[column].dtype)
                compatible_types = type_compatibility[column]['compatible_pandas_types']
                sqlalchemy_type = type_compatibility[column]['sqlalchemy_type']
                
                if df_dtype not in compatible_types:
                    # Verificar si puede ser convertido
                    if self.can_convert_type(df[column], sqlalchemy_type):
                        continue
                    
                    type_errors.append(
                        f"Columna '{column}': tipo '{df_dtype}' no compatible con '{sqlalchemy_type}'. "
                        f"Tipos aceptados: {compatible_types}"
                    )
        
        if type_errors:
            raise TypeError(
                "Errores de tipo de datos encontrados:\n" + 
                "\n".join(f"  - {error}" for error in type_errors) +
                "\n\nConsidera convertir los tipos antes de la inserción."
            )
    
    def can_convert_type(self, series: "Series", target_sqlalchemy_type: str) -> bool:
        """
        Verifica si una serie puede ser convertida al tipo SQLAlchemy objetivo.
        
        Args:
            series: Serie de pandas a verificar
            target_sqlalchemy_type: Tipo SQLAlchemy objetivo
            
        Returns:
            bool: True si puede ser convertida
        """
        try:
            import pandas as pd
        except ImportError:
            raise ImportError(
                "pandas no está instalado. Para usar from_df(), instala pandas:\n"
                "pip install pandas\n"
                "o si usas poetry:\n"
                "poetry add pandas"
            )
        
        try:
            # Probar conversión en una muestra pequeña
            sample = series.dropna().head(10)
            if sample.empty:
                return True
            
            if 'int' in target_sqlalchemy_type:
                pd.to_numeric(sample, errors='raise')
            elif 'float' in target_sqlalchemy_type or 'Numeric' in target_sqlalchemy_type:
                pd.to_numeric(sample, errors='raise')
            elif 'bool' in target_sqlalchemy_type:
                # Verificar valores booleanos válidos
                valid_bool_values = {True, False, 1, 0, '1', '0', 'true', 'false', 'True', 'False'}
                if not all(val in valid_bool_values for val in sample.unique()):
                    return False
            elif 'datetime' in target_sqlalchemy_type or 'date' in target_sqlalchemy_type:
                pd.to_datetime(sample, errors='raise')
            
            return True
        except:
            return False
    
    def prepare_dataframe_for_insertion(
        self, 
        df: "DataFrame", 
        ignore_extra_columns: bool, 
        fill_missing_nullable: bool
    ) -> "DataFrame":
        """
        Prepara el DataFrame para inserción en la base de datos.
        
        Args:
            df: DataFrame original
            ignore_extra_columns: Si ignorar columnas extra
            fill_missing_nullable: Si llenar columnas faltantes nullable
            
        Returns:
            DataFrame preparado para inserción
        """
        try:
            import pandas as pd
            import numpy as np
        except ImportError:
            return df
        
        # Crear copia para no modificar el original
        cleaned_df = df.copy()
        
        # Definir columnas del modelo
        model_columns = {
            {% for column in model.columns %}
            '{{ column.name }}': {
                'nullable': {{ 'True' if column.nullable else 'False' }},
                'autoincrement': {{ column.args.get('autoincrement', False) }}
            }{{ ',' if not loop.last }}
            {% endfor %}
        }
        
        # Eliminar columnas extra si se solicita
        if ignore_extra_columns:
            extra_columns = set(cleaned_df.columns) - set(model_columns.keys())
            if extra_columns:
                cleaned_df = cleaned_df.drop(columns=list(extra_columns))
        
        # Agregar columnas nullable faltantes si se solicita
        if fill_missing_nullable:
            for col_name, col_info in model_columns.items():
                if (col_name not in cleaned_df.columns and 
                    col_info['nullable'] and 
                    not col_info['autoincrement']):
                    cleaned_df[col_name] = None
        
        # Eliminar columnas autoincrement (la BD las manejará)
        autoincrement_columns = [
            col for col, info in model_columns.items() 
            if info['autoincrement'] and col in cleaned_df.columns
        ]
        if autoincrement_columns:
            cleaned_df = cleaned_df.drop(columns=autoincrement_columns)
        
        # Reordenar columnas según el modelo (las que existan)
        model_column_order = [col for col in model_columns.keys() if col in cleaned_df.columns]
        cleaned_df = cleaned_df[model_column_order]
        
        return cleaned_df
    
    def clean_records_data(self, records_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Limpia los datos de registros para inserción en BD.
        
        Args:
            records_data: Lista de diccionarios con datos de registros
            
        Returns:
            Lista de diccionarios limpiados
        """
        try:
            import pandas as pd
        except ImportError:
            return records_data
        
        cleaned_records = []
        
        for record in records_data:
            cleaned_record = {}
            for key, value in record.items():
                # Manejar valores NaN y NaT de pandas
                if pd.isna(value):
                    cleaned_record[key] = None
                # Manejar tipos numpy
                elif hasattr(value, 'item'):  # numpy scalars
                    cleaned_record[key] = value.item()
                else:
                    cleaned_record[key] = value
            
            cleaned_records.append(cleaned_record)
        
        return cleaned_records

        
{% endfor %}