"""Schemaç”Ÿæˆå™¨

åŸºäºæ–‡æ¡£å†…å®¹åˆ†æï¼Œç”Ÿæˆå®šåˆ¶åŒ–çš„çŸ¥è¯†å›¾è°±Schema
"""

import json
import os
from typing import Any, Dict, List, Optional
from loguru import logger


class SchemaGenerator:
    """Schemaç”Ÿæˆå™¨ï¼Œåˆ†ææ–‡æ¡£ç”Ÿæˆå®šåˆ¶schema"""
    
    def __init__(self, llm_client=None, strong_llm_client=None, prompt_manager=None, base_schema_path: Optional[str] = None):
        self.llm_client = llm_client  # é»˜è®¤LLMå®¢æˆ·ç«¯
        self.strong_llm_client = strong_llm_client or llm_client  # å¼ºæ¨¡å‹å®¢æˆ·ç«¯ï¼Œç”¨äºå¤æ‚åˆ†æ
        self.prompt_manager = prompt_manager
        
        # åŠ è½½åŸºç¡€schema
        if base_schema_path and os.path.exists(base_schema_path):
            with open(base_schema_path, 'r', encoding='utf-8') as f:
                self.base_schema = json.load(f)
        else:
            # é»˜è®¤åŸºç¡€schema
            self.base_schema = {
                "Nodes": ["person", "organization", "location", "event", "concept"],
                "Relations": ["related_to", "part_of", "located_in", "works_for", "created_by"],
                "Attributes": ["name", "description", "type", "date", "status"]
            }
        
        logger.info("Schemaç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_documents(self, documents: List[str]) -> Dict[str, Any]:
        """åˆ†ææ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆæ–‡æ¡£åˆ†ææŠ¥å‘Š
        
        Args:
            documents: æ–‡æ¡£å†…å®¹åˆ—è¡¨
            
        Returns:
            æ–‡æ¡£åˆ†æç»“æœ
        """
        logger.info(f"å¼€å§‹åˆ†æ {len(documents)} ä¸ªæ–‡æ¡£")
        
        if not self.strong_llm_client or not self.prompt_manager:
            logger.error("âŒ ç¼ºå°‘LLMå®¢æˆ·ç«¯æˆ–æç¤ºè¯ç®¡ç†å™¨")
            return {}
        
        # æ™ºèƒ½æ–‡æ¡£å†…å®¹å¤„ç†
        combined_content = self._prepare_documents_for_analysis(documents)
        
        try:
            # ä½¿ç”¨æ–‡æ¡£åˆ†ææç¤ºè¯
            prompt = self.prompt_manager.format_prompt(
                "document_analysis",
                document_content=combined_content
            )
            
            logger.debug("è°ƒç”¨å¼ºæ¨¡å‹è¿›è¡Œæ–‡æ¡£åˆ†æ")
            logger.info(f"åˆ†æå†…å®¹é•¿åº¦: {len(combined_content)} å­—ç¬¦")
            response = self.strong_llm_client.call(prompt)
            
            # è§£æå“åº”
            analysis_result = self._parse_analysis_response(response)
            
            logger.success(f"âœ… æ–‡æ¡£åˆ†æå®Œæˆ: {analysis_result.get('category', 'æœªçŸ¥ç±»åˆ«')}")
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _prepare_documents_for_analysis(self, documents: List[str]) -> str:
        """æ™ºèƒ½å‡†å¤‡æ–‡æ¡£å†…å®¹ç”¨äºåˆ†æï¼Œå……åˆ†åˆ©ç”¨128kä¸Šä¸‹æ–‡"""
        logger.info(f"å‡†å¤‡æ–‡æ¡£å†…å®¹ï¼Œå……åˆ†åˆ©ç”¨128kä¸Šä¸‹æ–‡èƒ½åŠ›")
        
        # ä¼°ç®—tokenæ•°é‡ (ç²—ç•¥ä¼°ç®—ï¼š1 token â‰ˆ 0.75ä¸ªè‹±æ–‡å•è¯ â‰ˆ 1.5ä¸ªä¸­æ–‡å­—ç¬¦)
        max_chars = 120000  # é¢„ç•™8k tokensç»™æç¤ºè¯å’Œå“åº”
        
        # ç­–ç•¥1ï¼šå¦‚æœæ–‡æ¡£æ€»é‡ä¸å¤§ï¼Œå…¨éƒ¨ä½¿ç”¨
        total_length = sum(len(doc) for doc in documents)
        if total_length <= max_chars:
            logger.info(f"æ–‡æ¡£æ€»é•¿åº¦ {total_length} å­—ç¬¦ï¼Œå…¨éƒ¨ç”¨äºåˆ†æ")
            return "\n\n".join(documents)
        
        # ç­–ç•¥2ï¼šæ™ºèƒ½é‡‡æ · - ç¡®ä¿è¦†ç›–æ‰€æœ‰æ–‡æ¡£
        logger.info(f"æ–‡æ¡£æ€»é•¿åº¦ {total_length} å­—ç¬¦ï¼Œä½¿ç”¨æ™ºèƒ½é‡‡æ ·ç­–ç•¥")
        
        # ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ†é…ç©ºé—´
        doc_count = len(documents)
        chars_per_doc = max_chars // doc_count
        
        sampled_docs = []
        for i, doc in enumerate(documents):
            if len(doc) <= chars_per_doc:
                # çŸ­æ–‡æ¡£å…¨éƒ¨ä½¿ç”¨
                sampled_docs.append(doc)
                logger.debug(f"æ–‡æ¡£ {i+1}: å®Œæ•´ä½¿ç”¨ ({len(doc)} å­—ç¬¦)")
            else:
                # é•¿æ–‡æ¡£é‡‡æ ·ï¼šå¼€å¤´ + ä¸­é—´ + ç»“å°¾
                start_size = chars_per_doc // 3
                middle_size = chars_per_doc // 3
                end_size = chars_per_doc - start_size - middle_size
                
                start_part = doc[:start_size]
                middle_start = len(doc) // 2 - middle_size // 2
                middle_part = doc[middle_start:middle_start + middle_size]
                end_part = doc[-end_size:]
                
                sampled_doc = f"{start_part}\n...[ä¸­é—´å†…å®¹]...\n{middle_part}\n...[åç»­å†…å®¹]...\n{end_part}"
                sampled_docs.append(sampled_doc)
                logger.debug(f"æ–‡æ¡£ {i+1}: æ™ºèƒ½é‡‡æ · ({len(sampled_doc)} å­—ç¬¦ï¼ŒåŸé•¿åº¦ {len(doc)})")
        
        combined_content = "\n\n=== æ–‡æ¡£åˆ†éš” ===\n\n".join(sampled_docs)
        logger.info(f"âœ… æ–‡æ¡£å‡†å¤‡å®Œæˆ: {len(combined_content)} å­—ç¬¦ï¼Œè¦†ç›– {len(documents)} ä¸ªæ–‡æ¡£")
        
        return combined_content
    
    def generate_custom_schema_from_documents(self, documents: List[str]) -> Dict[str, Any]:
        """ç›´æ¥åŸºäºå®Œæ•´æ–‡æ¡£å†…å®¹ç”Ÿæˆå®šåˆ¶schemaï¼ˆæ¨èæ–¹æ³•ï¼‰
        
        Args:
            documents: å®Œæ•´æ–‡æ¡£å†…å®¹åˆ—è¡¨
            
        Returns:
            å®šåˆ¶åŒ–çš„schema
        """
        logger.info("å¼€å§‹åŸºäºå®Œæ•´æ–‡æ¡£ç”Ÿæˆå®šåˆ¶Schema")
        
        if not self.strong_llm_client or not self.prompt_manager:
            logger.error("âŒ ç¼ºå°‘LLMå®¢æˆ·ç«¯æˆ–æç¤ºè¯ç®¡ç†å™¨")
            return self.base_schema
        
        try:
            # æ™ºèƒ½æ–‡æ¡£å†…å®¹å¤„ç†ï¼Œå……åˆ†åˆ©ç”¨128kä¸Šä¸‹æ–‡
            combined_content = self._prepare_documents_for_analysis(documents)
            
            # ä½¿ç”¨å®Œæ•´æ–‡æ¡£å†…å®¹ç”Ÿæˆschema
            prompt = self.prompt_manager.format_prompt(
                "schema_generation",
                base_schema=json.dumps(self.base_schema, ensure_ascii=False, indent=2),
                document_content=combined_content,
                document_category="å­¦æœ¯è®ºæ–‡",  # å¯ä»¥ä»æ–‡æ¡£åˆ†æä¸­è·å–
                document_tags="AI, åŸºå‡†æµ‹è¯•, æœªæ¥é¢„æµ‹"  # å¯ä»¥ä»æ–‡æ¡£åˆ†æä¸­è·å–
            )
            
            logger.debug("è°ƒç”¨å¼ºæ¨¡å‹åŸºäºå®Œæ•´æ–‡æ¡£ç”Ÿæˆå®šåˆ¶Schema")
            response = self.strong_llm_client.call(prompt)
            
            # è§£æå“åº”
            custom_schema = self._parse_schema_response(response)
            
            # éªŒè¯å’Œä¼˜åŒ–schema
            validated_schema = self._validate_schema(custom_schema)
            
            logger.success(f"âœ… åŸºäºå®Œæ•´æ–‡æ¡£çš„å®šåˆ¶Schemaç”Ÿæˆå®Œæˆ")
            logger.debug(f"ğŸ“‹ å®ä½“ç±»å‹: {len(validated_schema.get('Nodes', []))}")
            logger.debug(f"ğŸ“‹ å…³ç³»ç±»å‹: {len(validated_schema.get('Relations', []))}")
            logger.debug(f"ğŸ“‹ å±æ€§ç±»å‹: {len(validated_schema.get('Attributes', []))}")
            
            # æ‰“å°ç”Ÿæˆçš„Schemaè¯¦æƒ…
            logger.info("ç”Ÿæˆçš„å®šåˆ¶Schema:")
            logger.info(f"ğŸ“‹ å®ä½“ç±»å‹ ({len(validated_schema.get('Nodes', []))}): {validated_schema.get('Nodes', [])}")
            logger.info(f"ğŸ”— å…³ç³»ç±»å‹ ({len(validated_schema.get('Relations', []))}): {validated_schema.get('Relations', [])}")
            logger.info(f"å±æ€§ç±»å‹ ({len(validated_schema.get('Attributes', []))}): {validated_schema.get('Attributes', [])}")
            
            if 'domain_info' in validated_schema:
                domain_info = validated_schema['domain_info']
                logger.info(f"é¢†åŸŸä¿¡æ¯: {domain_info.get('primary_domain', 'æœªçŸ¥')}")
                logger.info(f"æ ¸å¿ƒæ¦‚å¿µ: {domain_info.get('key_concepts', [])}")
            
            return validated_schema
            
        except Exception as e:
            logger.error(f"âŒ Schemaç”Ÿæˆå¤±è´¥: {e}")
            logger.warning("ğŸ”„ å›é€€åˆ°åŸºç¡€Schema")
            return self.base_schema

    def generate_custom_schema(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºæ–‡æ¡£åˆ†æç»“æœç”Ÿæˆå®šåˆ¶schemaï¼ˆå…¼å®¹æ—§æ–¹æ³•ï¼‰
        
        Args:
            analysis_result: æ–‡æ¡£åˆ†æç»“æœ
            
        Returns:
            å®šåˆ¶åŒ–çš„schema
        """
        logger.warning("âš ï¸ ä½¿ç”¨åŸºäºæ‘˜è¦çš„Schemaç”Ÿæˆæ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨generate_custom_schema_from_documents")
        
        if not self.strong_llm_client or not self.prompt_manager:
            logger.error("âŒ ç¼ºå°‘LLMå®¢æˆ·ç«¯æˆ–æç¤ºè¯ç®¡ç†å™¨")
            return self.base_schema
        
        try:
            # å‡†å¤‡schemaç”Ÿæˆçš„è¾“å…¥
            document_summary = analysis_result.get('summary', '')
            document_category = analysis_result.get('category', 'é€šç”¨æ–‡æ¡£')
            document_tags = ', '.join(analysis_result.get('tags', []))
            
            # ä½¿ç”¨schemaç”Ÿæˆæç¤ºè¯
            prompt = self.prompt_manager.format_prompt(
                "schema_generation",
                base_schema=json.dumps(self.base_schema, ensure_ascii=False, indent=2),
                document_content=document_summary,  # æ”¹ä¸ºä½¿ç”¨document_contentå‚æ•°
                document_category=document_category,
                document_tags=document_tags
            )
            
            logger.debug("è°ƒç”¨å¼ºæ¨¡å‹ç”Ÿæˆå®šåˆ¶Schema")
            response = self.strong_llm_client.call(prompt)
            
            # è§£æå“åº”
            custom_schema = self._parse_schema_response(response)
            
            # éªŒè¯å’Œä¼˜åŒ–schema
            validated_schema = self._validate_schema(custom_schema)
            
            logger.success(f"âœ… å®šåˆ¶Schemaç”Ÿæˆå®Œæˆ")
            logger.debug(f"ğŸ“‹ å®ä½“ç±»å‹: {len(validated_schema.get('Nodes', []))}")
            logger.debug(f"ğŸ“‹ å…³ç³»ç±»å‹: {len(validated_schema.get('Relations', []))}")
            logger.debug(f"ğŸ“‹ å±æ€§ç±»å‹: {len(validated_schema.get('Attributes', []))}")
            
            # æ‰“å°ç”Ÿæˆçš„Schemaè¯¦æƒ…
            logger.info("ç”Ÿæˆçš„å®šåˆ¶Schema:")
            logger.info(f"ğŸ“‹ å®ä½“ç±»å‹ ({len(validated_schema.get('Nodes', []))}): {validated_schema.get('Nodes', [])}")
            logger.info(f"ğŸ”— å…³ç³»ç±»å‹ ({len(validated_schema.get('Relations', []))}): {validated_schema.get('Relations', [])}")
            logger.info(f"å±æ€§ç±»å‹ ({len(validated_schema.get('Attributes', []))}): {validated_schema.get('Attributes', [])}")
            
            if 'domain_info' in validated_schema:
                domain_info = validated_schema['domain_info']
                logger.info(f"é¢†åŸŸä¿¡æ¯: {domain_info.get('primary_domain', 'æœªçŸ¥')}")
                logger.info(f"æ ¸å¿ƒæ¦‚å¿µ: {domain_info.get('key_concepts', [])}")
            
            return validated_schema
            
        except Exception as e:
            logger.error(f"âŒ Schemaç”Ÿæˆå¤±è´¥: {e}")
            logger.warning("ğŸ”„ å›é€€åˆ°åŸºç¡€Schema")
            return self.base_schema
    
    def _parse_analysis_response(self, response: str) -> Dict[str, Any]:
        """è§£ææ–‡æ¡£åˆ†æå“åº”"""
        try:
            cleaned_response = self._clean_llm_response(response)
            analysis_data = json.loads(cleaned_response)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ['summary', 'category', 'domain']
            for field in required_fields:
                if field not in analysis_data:
                    logger.warning(f"âš ï¸ ç¼ºå°‘åˆ†æå­—æ®µ: {field}")
                    analysis_data[field] = "æœªçŸ¥"
            
            return analysis_data
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ æ–‡æ¡£åˆ†æJSONè§£æå¤±è´¥: {e}")
            return {
                "summary": "æ–‡æ¡£åˆ†æå¤±è´¥",
                "category": "é€šç”¨æ–‡æ¡£",
                "domain": "é€šç”¨",
                "tags": [],
                "key_concepts": []
            }
    
    def _parse_schema_response(self, response: str) -> Dict[str, Any]:
        """è§£æschemaç”Ÿæˆå“åº”"""
        try:
            cleaned_response = self._clean_llm_response(response)
            schema_data = json.loads(cleaned_response)
            
            # éªŒè¯å¿…è¦å­—æ®µ
            required_fields = ['Nodes', 'Relations', 'Attributes']
            for field in required_fields:
                if field not in schema_data:
                    logger.warning(f"âš ï¸ ç¼ºå°‘Schemaå­—æ®µ: {field}")
                    schema_data[field] = self.base_schema.get(field, [])
            
            return schema_data
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Schema JSONè§£æå¤±è´¥: {e}")
            return self.base_schema
    
    def _clean_llm_response(self, response: str) -> str:
        """æ¸…ç†LLMå“åº”ï¼Œæå–JSONå†…å®¹"""
        response = response.strip()
        
        # ç§»é™¤markdownä»£ç å—
        if response.startswith('```json'):
            response = response[7:]
        elif response.startswith('```'):
            response = response[3:]
        if response.endswith('```'):
            response = response[:-3]
        
        # æŸ¥æ‰¾JSONå†…å®¹
        start_idx = response.find('{')
        end_idx = response.rfind('}')
        
        if start_idx != -1 and end_idx != -1:
            response = response[start_idx:end_idx+1]
        
        return response.strip()
    
    def _validate_schema(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å’Œä¼˜åŒ–schema"""
        validated_schema = {
            "Nodes": [],
            "Relations": [],
            "Attributes": []
        }
        
        # éªŒè¯å¹¶åˆå¹¶å®ä½“ç±»å‹
        base_nodes = set(self.base_schema.get('Nodes', []))
        custom_nodes = set(schema.get('Nodes', []))
        validated_schema['Nodes'] = list(base_nodes | custom_nodes)
        
        # éªŒè¯å¹¶åˆå¹¶å…³ç³»ç±»å‹
        base_relations = set(self.base_schema.get('Relations', []))
        custom_relations = set(schema.get('Relations', []))
        validated_schema['Relations'] = list(base_relations | custom_relations)
        
        # éªŒè¯å¹¶åˆå¹¶å±æ€§ç±»å‹
        base_attributes = set(self.base_schema.get('Attributes', []))
        custom_attributes = set(schema.get('Attributes', []))
        validated_schema['Attributes'] = list(base_attributes | custom_attributes)
        
        # ä¿ç•™é¢†åŸŸä¿¡æ¯
        if 'domain_info' in schema:
            validated_schema['domain_info'] = schema['domain_info']
        
        logger.debug(f"SchemaéªŒè¯å®Œæˆ: {len(validated_schema['Nodes'])} å®ä½“ç±»å‹, {len(validated_schema['Relations'])} å…³ç³»ç±»å‹")
        
        return validated_schema
    
    def save_custom_schema(self, schema: Dict[str, Any], file_path: str) -> bool:
        """ä¿å­˜å®šåˆ¶schemaåˆ°æ–‡ä»¶
        
        Args:
            schema: å®šåˆ¶schema
            file_path: ä¿å­˜è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(schema, f, ensure_ascii=False, indent=2)
            
            logger.info(f"å®šåˆ¶Schemaå·²ä¿å­˜: {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜Schemaå¤±è´¥: {e}")
            return False