"""
EvalSet: æ ‡å‡†åŒ–è¯„æµ‹é›†æ ¼å¼

å€Ÿé‰´ ADK çš„ evalset.json æ ¼å¼ï¼Œæä¾›ç»Ÿä¸€çš„è¯„æµ‹é›†å®šä¹‰ã€‚
"""

from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union
from datetime import datetime, timezone
from pathlib import Path
import json
import uuid


class ExpectedToolUse(BaseModel):
    """
    é¢„æœŸçš„å·¥å…·è°ƒç”¨
    
    å®šä¹‰ä¸€ä¸ªé¢„æœŸçš„å·¥å…·è°ƒç”¨ï¼ŒåŒ…æ‹¬å·¥å…·åç§°ã€è¾“å…¥å‚æ•°å’ŒåŒ¹é…æ¨¡å¼ã€‚
    """
    tool_name: str = Field(description="é¢„æœŸè°ƒç”¨çš„å·¥å…·åç§°")
    tool_input: Optional[Dict[str, Any]] = Field(
        default=None, 
        description="é¢„æœŸçš„å·¥å…·è¾“å…¥å‚æ•°ï¼ˆå¯é€‰ï¼Œç”¨äºç²¾ç¡®åŒ¹é…ï¼‰"
    )
    match_mode: str = Field(
        default="name_only",
        description="åŒ¹é…æ¨¡å¼: name_only(ä»…åŒ¹é…åç§°), partial(éƒ¨åˆ†åŒ¹é…å‚æ•°), exact(å®Œå…¨åŒ¹é…)"
    )
    
    def matches(self, actual_tool_name: str, actual_input: Optional[Dict[str, Any]] = None) -> bool:
        """
        æ£€æŸ¥å®é™…è°ƒç”¨æ˜¯å¦åŒ¹é…é¢„æœŸ
        
        Args:
            actual_tool_name: å®é™…è°ƒç”¨çš„å·¥å…·åç§°
            actual_input: å®é™…çš„å·¥å…·è¾“å…¥å‚æ•°
            
        Returns:
            æ˜¯å¦åŒ¹é…
        """
        # åç§°å¿…é¡»åŒ¹é…
        if self.tool_name != actual_tool_name:
            return False
        
        # ä»…åŒ¹é…åç§°
        if self.match_mode == "name_only" or self.tool_input is None:
            return True
        
        # éƒ¨åˆ†åŒ¹é…ï¼šé¢„æœŸçš„å‚æ•°éƒ½å­˜åœ¨äºå®é™…å‚æ•°ä¸­
        if self.match_mode == "partial":
            if actual_input is None:
                return False
            for key, value in self.tool_input.items():
                if key not in actual_input or actual_input[key] != value:
                    return False
            return True
        
        # å®Œå…¨åŒ¹é…
        if self.match_mode == "exact":
            return self.tool_input == actual_input
        
        return False


class EvalCase(BaseModel):
    """
    å•ä¸ªè¯„æµ‹ç”¨ä¾‹
    
    å®šä¹‰ä¸€ä¸ªå®Œæ•´çš„è¯„æµ‹ç”¨ä¾‹ï¼ŒåŒ…æ‹¬è¾“å…¥ã€é¢„æœŸè¾“å‡ºå’Œå…ƒæ•°æ®ã€‚
    """
    id: str = Field(
        default_factory=lambda: str(uuid.uuid4())[:8],
        description="ç”¨ä¾‹å”¯ä¸€æ ‡è¯†ç¬¦"
    )
    name: Optional[str] = Field(default=None, description="ç”¨ä¾‹åç§°ï¼ˆå¯é€‰ï¼‰")
    query: str = Field(description="ç”¨æˆ·è¾“å…¥/æŸ¥è¯¢")
    
    # é¢„æœŸçš„å·¥å…·è°ƒç”¨åºåˆ—
    expected_tool_use: Optional[List[ExpectedToolUse]] = Field(
        default=None,
        description="é¢„æœŸçš„å·¥å…·è°ƒç”¨åºåˆ—"
    )
    
    # é¢„æœŸçš„æœ€ç»ˆå“åº”
    reference: Optional[str] = Field(
        default=None,
        description="é¢„æœŸçš„æœ€ç»ˆå“åº”ï¼ˆç”¨äºå“åº”è´¨é‡è¯„ä¼°ï¼‰"
    )
    
    # è¯„ä¼°é…ç½®
    trajectory_match_mode: str = Field(
        default="in_order",
        description="è½¨è¿¹åŒ¹é…æ¨¡å¼: exact(å®Œå…¨åŒ¹é…), in_order(é¡ºåºåŒ¹é…), any_order(ä»»æ„é¡ºåº)"
    )
    
    # å…ƒæ•°æ®
    tags: List[str] = Field(default_factory=list, description="ç”¨ä¾‹æ ‡ç­¾")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="é¢å¤–å…ƒæ•°æ®")
    
    # åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
    initial_context: Optional[Dict[str, Any]] = Field(
        default=None,
        description="åˆå§‹ä¸Šä¸‹æ–‡å˜é‡"
    )


class EvalResult(BaseModel):
    """
    å•ä¸ªç”¨ä¾‹çš„è¯„æµ‹ç»“æœ
    """
    case_id: str = Field(description="ç”¨ä¾‹ ID")
    case_name: Optional[str] = Field(default=None, description="ç”¨ä¾‹åç§°")
    
    # æ‰§è¡Œä¿¡æ¯
    success: bool = Field(description="æ˜¯å¦æ‰§è¡ŒæˆåŠŸ")
    error: Optional[str] = Field(default=None, description="é”™è¯¯ä¿¡æ¯")
    
    # è½¨è¿¹åŒ¹é…ç»“æœ
    trajectory_score: float = Field(
        default=0.0,
        description="è½¨è¿¹åŒ¹é…åˆ†æ•° (0.0-1.0)"
    )
    trajectory_matched: bool = Field(
        default=False,
        description="è½¨è¿¹æ˜¯å¦åŒ¹é…é¢„æœŸ"
    )
    
    # å“åº”è¯„ä¼°ç»“æœ
    response_score: Optional[float] = Field(
        default=None,
        description="å“åº”è´¨é‡åˆ†æ•° (0.0-1.0)"
    )
    
    # å®é™…æ‰§è¡Œæ•°æ®
    actual_tool_calls: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="å®é™…çš„å·¥å…·è°ƒç”¨åºåˆ—"
    )
    actual_response: Optional[str] = Field(
        default=None,
        description="å®é™…çš„æœ€ç»ˆå“åº”"
    )
    
    # æ€§èƒ½æŒ‡æ ‡
    execution_time_ms: Optional[float] = Field(
        default=None,
        description="æ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"
    )
    token_usage: Optional[Dict[str, int]] = Field(
        default=None,
        description="Token ä½¿ç”¨é‡"
    )
    cost: Optional[float] = Field(
        default=None,
        description="æ‰§è¡Œæˆæœ¬"
    )
    
    # æ—¶é—´æˆ³
    evaluated_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc),
        description="è¯„æµ‹æ—¶é—´"
    )


class EvalSummary(BaseModel):
    """
    è¯„æµ‹æ±‡æ€»ç»“æœ
    """
    total_cases: int = Field(description="æ€»ç”¨ä¾‹æ•°")
    passed_cases: int = Field(description="é€šè¿‡çš„ç”¨ä¾‹æ•°")
    failed_cases: int = Field(description="å¤±è´¥çš„ç”¨ä¾‹æ•°")
    error_cases: int = Field(description="æ‰§è¡Œé”™è¯¯çš„ç”¨ä¾‹æ•°")
    
    # åˆ†æ•°
    overall_score: float = Field(description="æ€»ä½“åˆ†æ•° (0.0-1.0)")
    trajectory_accuracy: float = Field(description="è½¨è¿¹åŒ¹é…å‡†ç¡®ç‡")
    response_accuracy: Optional[float] = Field(
        default=None,
        description="å“åº”å‡†ç¡®ç‡ï¼ˆå¦‚æœæœ‰ referenceï¼‰"
    )
    
    # æ€§èƒ½
    avg_execution_time_ms: Optional[float] = Field(
        default=None,
        description="å¹³å‡æ‰§è¡Œæ—¶é—´"
    )
    total_tokens: Optional[int] = Field(default=None, description="æ€» Token ä½¿ç”¨é‡")
    total_cost: Optional[float] = Field(default=None, description="æ€»æˆæœ¬")
    
    # å…ƒæ•°æ®
    evalset_name: str = Field(description="è¯„æµ‹é›†åç§°")
    evalset_version: str = Field(description="è¯„æµ‹é›†ç‰ˆæœ¬")
    evaluated_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc),
        description="è¯„æµ‹æ—¶é—´"
    )
    
    def to_report(self) -> str:
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        lines = [
            f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"è¯„æµ‹æŠ¥å‘Š: {self.evalset_name} v{self.evalset_version}",
            f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"",
            f"ğŸ“Š ç”¨ä¾‹ç»Ÿè®¡:",
            f"  - æ€»ç”¨ä¾‹æ•°: {self.total_cases}",
            f"  - é€šè¿‡: {self.passed_cases} ({self.passed_cases/self.total_cases*100:.1f}%)",
            f"  - å¤±è´¥: {self.failed_cases}",
            f"  - é”™è¯¯: {self.error_cases}",
            f"",
            f"ğŸ“ˆ è¯„åˆ†:",
            f"  - æ€»ä½“åˆ†æ•°: {self.overall_score:.2%}",
            f"  - è½¨è¿¹å‡†ç¡®ç‡: {self.trajectory_accuracy:.2%}",
        ]
        
        if self.response_accuracy is not None:
            lines.append(f"  - å“åº”å‡†ç¡®ç‡: {self.response_accuracy:.2%}")
        
        if self.avg_execution_time_ms is not None:
            lines.append(f"")
            lines.append(f"âš¡ æ€§èƒ½:")
            lines.append(f"  - å¹³å‡æ‰§è¡Œæ—¶é—´: {self.avg_execution_time_ms:.0f}ms")
        
        if self.total_tokens is not None:
            lines.append(f"  - æ€» Token: {self.total_tokens:,}")
        
        if self.total_cost is not None:
            lines.append(f"  - æ€»æˆæœ¬: ${self.total_cost:.4f}")
        
        lines.append(f"")
        lines.append(f"ğŸ• è¯„æµ‹æ—¶é—´: {self.evaluated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append(f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        return "\n".join(lines)


class EvalSet(BaseModel):
    """
    è¯„æµ‹é›†
    
    åŒ…å«å¤šä¸ªè¯„æµ‹ç”¨ä¾‹çš„é›†åˆï¼Œæ”¯æŒä» JSON æ–‡ä»¶åŠ è½½å’Œä¿å­˜ã€‚
    æ ¼å¼å€Ÿé‰´ ADK çš„ evalset.jsonã€‚
    """
    name: str = Field(description="è¯„æµ‹é›†åç§°")
    version: str = Field(default="1.0.0", description="è¯„æµ‹é›†ç‰ˆæœ¬")
    description: Optional[str] = Field(default=None, description="è¯„æµ‹é›†æè¿°")
    
    # ç”¨ä¾‹åˆ—è¡¨
    cases: List[EvalCase] = Field(default_factory=list, description="è¯„æµ‹ç”¨ä¾‹åˆ—è¡¨")
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = Field(default_factory=dict, description="é¢å¤–å…ƒæ•°æ®")
    created_at: datetime = Field(
        default_factory=lambda: datetime.now(timezone.utc),
        description="åˆ›å»ºæ—¶é—´"
    )
    
    @classmethod
    def from_file(cls, path: Union[str, Path]) -> "EvalSet":
        """
        ä» JSON æ–‡ä»¶åŠ è½½è¯„æµ‹é›†
        
        Args:
            path: JSON æ–‡ä»¶è·¯å¾„
            
        Returns:
            EvalSet å®ä¾‹
        """
        path = Path(path)
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # å…¼å®¹ ADK æ ¼å¼ï¼ˆç›´æ¥æ˜¯ç”¨ä¾‹æ•°ç»„ï¼‰
        if isinstance(data, list):
            # ADK æ ¼å¼ï¼šç›´æ¥æ˜¯ç”¨ä¾‹æ•°ç»„
            cases = []
            for i, case_data in enumerate(data):
                # è½¬æ¢ expected_tool_use æ ¼å¼
                if "expected_tool_use" in case_data:
                    tool_uses = []
                    for tu in case_data["expected_tool_use"]:
                        tool_uses.append(ExpectedToolUse(
                            tool_name=tu.get("tool_name", tu.get("name", "")),
                            tool_input=tu.get("tool_input", tu.get("input")),
                            match_mode=tu.get("match_mode", "name_only")
                        ))
                    case_data["expected_tool_use"] = tool_uses
                
                cases.append(EvalCase(
                    id=case_data.get("id", str(i)),
                    **{k: v for k, v in case_data.items() if k != "id"}
                ))
            
            return cls(
                name=path.stem,
                cases=cases
            )
        
        # AgenticX æ ¼å¼
        return cls(**data)
    
    def to_file(self, path: Union[str, Path]) -> None:
        """
        ä¿å­˜è¯„æµ‹é›†åˆ° JSON æ–‡ä»¶
        
        Args:
            path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        path = Path(path)
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(self.model_dump(mode='json'), f, indent=2, ensure_ascii=False, default=str)
    
    def add_case(self, case: EvalCase) -> None:
        """æ·»åŠ è¯„æµ‹ç”¨ä¾‹"""
        self.cases.append(case)
    
    def get_case(self, case_id: str) -> Optional[EvalCase]:
        """æ ¹æ® ID è·å–ç”¨ä¾‹"""
        for case in self.cases:
            if case.id == case_id:
                return case
        return None
    
    def filter_by_tags(self, tags: List[str]) -> List[EvalCase]:
        """æ ¹æ®æ ‡ç­¾ç­›é€‰ç”¨ä¾‹"""
        return [case for case in self.cases if any(tag in case.tags for tag in tags)]
    
    def __len__(self) -> int:
        return len(self.cases)
    
    def __iter__(self):
        return iter(self.cases)

