[
  {
    "task": "You are a detective investigating a murder case. There are four suspects: Alice, Bob, Carol, and David. Each made exactly two statements, one true and one false. Your task is to determine who the murderer is based on their statements.\n\nAlice: \"I was not at the crime scene\" and \"Bob is innocent\"\nBob: \"I was at the crime scene\" and \"Carol is the murderer\"\nCarol: \"I was not at the crime scene\" and \"David is the murderer\"\nDavid: \"I was not at the crime scene\" and \"Alice is innocent\"\n\nAssume there is exactly one murderer. Provide your reasoning step by step and identify the murderer.",
    "correct_response": "Let me analyze this systematically. Since each person made exactly one true and one false statement, I'll examine each possibility:\n\n1. Assume Alice is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (False, as murderer was there) and \"Bob is innocent\" (True)\n- Bob's statements: \"I was at the crime scene\" (False) and \"Carol is the murderer\" (False) - This violates the rule of one true, one false\n\n2. Assume Bob is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False)\n- Bob's statements: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False) - This violates the rule of one true, one false\n\n3. Assume Carol is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True) - This violates the rule of one true, one false\n\n4. Assume David is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True) - This violates the rule of one true, one false\n\nWait, let me reconsider. I need to be more careful about the location statements. The murderer must have been at the crime scene, but others could have been there too.\n\nLet me try again with Carol as the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False) - Bob is innocent, so this should be True. This doesn't work.\n\nLet me try with David as the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True) - This violates the rule.\n\nLet me try with Bob as the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False)\n- Carol: \"I was not at the crime scene\" (True) and \"David is the murderer\" (False)\n- David: \"I was not at the crime scene\" (True) and \"Alice is innocent\" (True)\n\nThis doesn't work because David would have two true statements.\n\nLet me try with Alice as the murderer:\n- Alice: \"I was not at the crime scene\" (False) and \"Bob is innocent\" (True)\n- Bob: \"I was at the crime scene\" (False) and \"Carol is the murderer\" (False)\nThis doesn't work.\n\nActually, let me approach this differently. If Bob is the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False)\n- Carol: \"I was not at the crime scene\" (False - she was there) and \"David is the murderer\" (False)\n- David: \"I was not at the crime scene\" (False - he was there) and \"Alice is innocent\" (True)\n\nThis doesn't work because Carol would have two false statements.\n\nLet me try Carol as murderer:\n- Alice: \"I was not at the crime scene\" (False) and \"Bob is innocent\" (True)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (True)\nThis doesn't work because Bob would have two true statements.\n\nLet me try David as murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True)\nThis doesn't work because Alice would have two true statements.\n\nWait, I think I made an error. Let me be more systematic:\n\nIf Carol is the murderer:\n- Alice: \"I was not at the crime scene\" (False - she was there) and \"Bob is innocent\" (True)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (True)\nThis doesn't work.\n\nActually, let me reconsider the premise. Maybe not everyone was at the crime scene. Let me try Carol as murderer again:\n\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True)\nThis doesn't work.\n\nI think I need to start over with a different approach. Let me assume Bob is the murderer and see if I can make it work:\n\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False)\n- Carol: \"I was not at the crime scene\" (True) and \"David is the murderer\" (False)\n- David: \"I was not at the crime scene\" (False) and \"Alice is innocent\" (True)\n\nThis works! Each person has exactly one true and one false statement.\n\nTherefore, Bob is the murderer.",
    "evaluation_criteria": "1. Correctly identifies Bob as the murderer\n2. Shows systematic analysis of each suspect's statements\n3. Demonstrates understanding that each person made exactly one true and one false statement\n4. Provides logical reasoning that eliminates other possibilities\n5. Shows the final configuration of true/false statements for all four suspects",
    "key_elements": [
      "Step-by-step logical deduction",
      "Analysis of all four suspects",
      "Verification that the solution satisfies the one true/one false statement rule for each person",
      "Clear identification of Bob as the murderer",
      "Explanation of why other suspects cannot be the murderer"
    ],
    "agent_response": "Let me analyze this systematically. Since each person made exactly one true and one false statement, I'll examine each possibility:\n\n1. Assume Alice is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (False, as murderer was there) and \"Bob is innocent\" (True)\n- Bob's statements: \"I was at the crime scene\" (False) and \"Carol is the murderer\" (False) - This violates the rule of one true, one false\n\n2. Assume Bob is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False)\n- Bob's statements: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False) - This violates the rule of one true, one false\n\n3. Assume Carol is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True) - This violates the rule of one true, one false\n\n4. Assume David is the murderer:\n- Alice's statements: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True) - This violates the rule of one true, one false\n\nWait, let me reconsider. I need to be more careful about the location statements. The murderer must have been at the crime scene, but others could have been there too.\n\nLet me try again with Carol as the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False) - Bob is innocent, so this should be True. This doesn't work.\n\nLet me try with David as the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True) - This violates the rule.\n\nLet me try with Bob as the murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (False)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False)\n- Carol: \"I was not at the crime scene\" (True) and \"David is the murderer\" (False)\n- David: \"I was not at the crime scene\" (False - he was there) and \"Alice is innocent\" (True)\n\nThis doesn't work because Carol would have two false statements.\n\nLet me try Carol as murderer:\n- Alice: \"I was not at the crime scene\" (False) and \"Bob is innocent\" (True)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (True)\nThis doesn't work because Bob would have two true statements.\n\nLet me try David as murderer:\n- Alice: \"I was not at the crime scene\" (True) and \"Bob is innocent\" (True)\nThis doesn't work because Alice would have two true statements.\n\nWait, I think I made an error. Let me be more systematic:\n\nIf Carol is the murderer:\n- Alice: \"I was not at the crime scene\" (False - she was there) and \"Bob is innocent\" (True)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (True)\nThis doesn't work.\n\nActually, let me reconsider the premise. Maybe not everyone was at the crime scene. Let me try Carol as murderer again:\n\n- Alice: \"I was not at the crime scene\" (False) and \"Bob is innocent\" (True)\n- Bob: \"I was at the crime scene\" (True) and \"Carol is the murderer\" (False)\n- Carol: \"I was not at the crime scene\" (False) and \"David is the murderer\" (True)\n- David: \"I was not at the crime scene\" (True) and \"Alice is innocent\" (False)\n\nThis works! Each person has exactly one true and one false statement.\n\nTherefore, Carol is the murderer.",
    "has_error": true,
    "error_type": "FACTUAL_ERROR",
    "error_description": "The response incorrectly concludes that Carol is the murderer. The logical analysis contains an error - in the final analysis, it incorrectly marks Carol's statement \"David is the murderer\" as True when Carol is actually the murderer, and incorrectly marks David's statement \"Alice is innocent\" as False when Alice is innocent. The correct solution is that Bob is the murderer, as shown in the reference correct response.",
    "expected_verdict": "FAIL_MINOR",
    "domain": "reasoning",
    "difficulty": "hard"
  },
  {
    "task": "Implement a thread-safe LRU (Least Recently Used) cache with O(1) time complexity for both get and put operations. The cache should support the following operations:\n\n1. get(key): Return the value associated with the key if it exists in the cache, otherwise return -1. If the key exists, it should be marked as recently used.\n2. put(key, value): Insert or update the value associated with the key. If the cache is at full capacity, evict the least recently used item before inserting the new item.\n3. clear(): Remove all items from the cache.\n4. size(): Return the current number of items in the cache.\n\nAdditional requirements:\n- The cache must be thread-safe for concurrent access\n- Use a doubly linked list to maintain the order of recently used items\n- Use a hash map for O(1) key-value lookup\n- The cache should be initialized with a fixed capacity\n- All operations must maintain O(1) time complexity\n- Include proper error handling for edge cases\n\nProvide a complete implementation in Python with comprehensive docstrings and type hints.",
    "correct_response": "from typing import Optional, Any\nimport threading\n\nclass Node:\n    \"\"\"Node for doubly linked list storing key-value pairs.\"\"\"\n    \n    def __init__(self, key: int, value: Any):\n        self.key = key\n        self.value = value\n        self.prev: Optional['Node'] = None\n        self.next: Optional['Node'] = None\n\nclass LRUCache:\n    \"\"\"Thread-safe LRU Cache with O(1) get and put operations.\"\"\"\n    \n    def __init__(self, capacity: int):\n        \"\"\"Initialize LRU cache with given capacity.\n        \n        Args:\n            capacity: Maximum number of items the cache can hold\n            \n        Raises:\n            ValueError: If capacity is less than 1\n        \"\"\"\n        if capacity < 1:\n            raise ValueError(\"Capacity must be at least 1\")\n            \n        self.capacity = capacity\n        self.cache = {}  # Dictionary to map keys to nodes\n        self.lock = threading.RLock()  # Reentrant lock for thread safety\n        \n        # Dummy head and tail nodes to avoid edge cases\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n    \n    def _remove_node(self, node: Node) -> None:\n        \"\"\"Remove node from its current position in linked list.\"\"\"\n        prev_node = node.prev\n        next_node = node.next\n        prev_node.next = next_node\n        next_node.prev = prev_node\n    \n    def _add_to_head(self, node: Node) -> None:\n        \"\"\"Add node right after head (most recently used position).\"\"\"\n        node.prev = self.head\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n    \n    def _move_to_head(self, node: Node) -> None:\n        \"\"\"Move existing node to head (mark as recently used).\"\"\"\n        self._remove_node(node)\n        self._add_to_head(node)\n    \n    def _remove_tail(self) -> Node:\n        \"\"\"Remove and return the least recently used node.\"\"\"\n        last_node = self.tail.prev\n        self._remove_node(last_node)\n        return last_node\n    \n    def get(self, key: int) -> Any:\n        \"\"\"Get value by key and mark as recently used.\n        \n        Args:\n            key: The key to retrieve\n            \n        Returns:\n            The value associated with the key, or -1 if not found\n        \"\"\"\n        with self.lock:\n            if key not in self.cache:\n                return -1\n            \n            node = self.cache[key]\n            self._move_to_head(node)\n            return node.value\n    \n    def put(self, key: int, value: Any) -> None:\n        \"\"\"Insert or update key-value pair.\n        \n        Args:\n            key: The key to insert/update\n            value: The value to associate with the key\n        \"\"\"\n        with self.lock:\n            if key in self.cache:\n                node = self.cache[key]\n                node.value = value\n                self._move_to_head(node)\n            else:\n                if len(self.cache) >= self.capacity:\n                    # Remove least recently used item\n                    tail_node = self._remove_tail()\n                    del self.cache[tail_node.key]\n                \n                new_node = Node(key, value)\n                self.cache[key] = new_node\n                self._add_to_head(new_node)\n    \n    def clear(self) -> None:\n        \"\"\"Remove all items from the cache.\"\"\"\n        with self.lock:\n            self.cache.clear()\n            self.head.next = self.tail\n            self.tail.prev = self.head\n    \n    def size(self) -> int:\n        \"\"\"Return current number of items in cache.\"\"\"\n        with self.lock:\n            return len(self.cache)\n\n# Example usage and basic test\nif __name__ == \"__main__\":\n    cache = LRUCache(2)\n    \n    # Test basic operations\n    cache.put(1, 1)\n    cache.put(2, 2)\n    assert cache.get(1) == 1  # Returns 1\n    cache.put(3, 3)  # Evicts key 2\n    assert cache.get(2) == -1  # Not found\n    cache.put(4, 4)  # Evicts key 1\n    assert cache.get(1) == -1  # Not found\n    assert cache.get(3) == 3\n    assert cache.get(4) == 4\n    assert cache.size() == 2\n    \n    cache.clear()\n    assert cache.size() == 0\n    assert cache.get(3) == -1\n    \n    print(\"All tests passed!\")",
    "evaluation_criteria": "1. Correctness: All operations (get, put, clear, size) must work as specified\n2. Time Complexity: All operations must be O(1) time complexity\n3. Thread Safety: Implementation must be thread-safe using proper locking\n4. Data Structure: Must use hash map + doubly linked list approach\n5. Edge Cases: Handle capacity limits, empty cache, non-existent keys\n6. Code Quality: Include proper docstrings, type hints, and error handling\n7. LRU Behavior: Items must be evicted based on least recently used policy",
    "key_elements": [
      "Thread-safe implementation with threading.RLock",
      "Doubly linked list for maintaining order",
      "Hash map for O(1) key lookup",
      "O(1) time complexity for all operations",
      "Proper LRU eviction logic",
      "Dummy head and tail nodes to simplify edge cases",
      "Complete implementation with all required methods",
      "Type hints and comprehensive docstrings",
      "Error handling for invalid capacity",
      "Basic test cases demonstrating functionality"
    ],
    "agent_response": "from typing import Optional, Any, Dict\nimport threading\nfrom collections import OrderedDict\n\nclass Node:\n    \"\"\"Node for doubly linked list storing key-value pairs.\"\"\"\n    \n    def __init__(self, key: int, value: Any):\n        self.key = key\n        self.value = value\n        self.prev: Optional['Node'] = None\n        self.next: Optional['Node'] = None\n\nclass LRUCache:\n    \"\"\"Thread-safe LRU Cache with O(1) get and put operations.\n    \n    This implementation uses a combination of a hash map and doubly linked list\n    to achieve O(1) time complexity for all operations. The cache is optimized\n    for Python's GIL by using atomic operations and minimal lock duration.\n    \"\"\"\n    \n    def __init__(self, capacity: int):\n        \"\"\"Initialize LRU cache with given capacity.\n        \n        Args:\n            capacity: Maximum number of items the cache can hold\n            \n        Raises:\n            ValueError: If capacity is less than 1\n        \"\"\"\n        if capacity < 1:\n            raise ValueError(\"Capacity must be at least 1\")\n            \n        self.capacity = capacity\n        self.cache: Dict[int, Node] = {}  # Dictionary to map keys to nodes\n        self.lock = threading.RLock()  # Reentrant lock for thread safety\n        \n        # Dummy head and tail nodes to avoid edge cases\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n        \n        # Python optimization: use OrderedDict for faster iteration\n        self._ordered_cache = OrderedDict()\n    \n    def _remove_node(self, node: Node) -> None:\n        \"\"\"Remove node from its current position in linked list.\"\"\"\n        prev_node = node.prev\n        next_node = node.next\n        prev_node.next = next_node\n        next_node.prev = prev_node\n    \n    def _add_to_head(self, node: Node) -> None:\n        \"\"\"Add node right after head (most recently used position).\"\"\"\n        node.prev = self.head\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n        \n        # Update OrderedDict for Python optimization\n        self._ordered_cache[node.key] = node.value\n    \n    def _move_to_head(self, node: Node) -> None:\n        \"\"\"Move existing node to head (mark as recently used).\"\"\"\n        self._remove_node(node)\n        self._add_to_head(node)\n    \n    def _remove_tail(self) -> Node:\n        \"\"\"Remove and return the least recently used node.\"\"\"\n        last_node = self.tail.prev\n        self._remove_node(last_node)\n        \n        # Remove from OrderedDict\n        if last_node.key in self._ordered_cache:\n            del self._ordered_cache[last_node.key]\n            \n        return last_node\n    \n    def get(self, key: int) -> Any:\n        \"\"\"Get value by key and mark as recently used.\n        \n        Args:\n            key: The key to retrieve\n            \n        Returns:\n            The value associated with the key, or -1 if not found\n        \"\"\"\n        with self.lock:\n            if key not in self.cache:\n                return -1\n            \n            node = self.cache[key]\n            self._move_to_head(node)\n            return node.value\n    \n    def put(self, key: int, value: Any) -> None:\n        \"\"\"Insert or update key-value pair.\n        \n        Args:\n            key: The key to insert/update\n            value: The value to associate with the key\n        \"\"\"\n        with self.lock:\n            if key in self.cache:\n                node = self.cache[key]\n                node.value = value\n                self._move_to_head(node)\n            else:\n                if len(self.cache) >= self.capacity:\n                    # Remove least recently used item\n                    tail_node = self._remove_tail()\n                    del self.cache[tail_node.key]\n                \n                new_node = Node(key, value)\n                self.cache[key] = new_node\n                self._add_to_head(new_node)\n    \n    def clear(self) -> None:\n        \"\"\"Remove all items from the cache.\"\"\"\n        with self.lock:\n            self.cache.clear()\n            self._ordered_cache.clear()\n            self.head.next = self.tail\n            self.tail.prev = self.head\n    \n    def size(self) -> int:\n        \"\"\"Return current number of items in cache.\"\"\"\n        with self.lock:\n            return len(self.cache)\n    \n    def get_ordered_keys(self) -> list[int]:\n        \"\"\"Return keys in order from most to least recently used.\n        \n        This method leverages the OrderedDict for O(n) iteration.\n        \"\"\"\n        with self.lock:\n            return list(self._ordered_cache.keys())\n\n# Example usage and basic test\nif __name__ == \"__main__\":\n    cache = LRUCache(2)\n    \n    # Test basic operations\n    cache.put(1, 1)\n    cache.put(2, 2)\n    assert cache.get(1) == 1  # Returns 1\n    cache.put(3, 3)  # Evicts key 2\n    assert cache.get(2) == -1  # Not found\n    cache.put(4, 4)  # Evicts key 1\n    assert cache.get(1) == -1  # Not found\n    assert cache.get(3) == 3\n    assert cache.get(4) == 4\n    assert cache.size() == 2\n    \n    # Test ordered keys feature\n    keys = cache.get_ordered_keys()\n    assert keys == [4, 3]  # Most recent first\n    \n    cache.clear()\n    assert cache.size() == 0\n    assert cache.get(3) == -1\n    \n    print(\"All tests passed!\")",
    "has_error": true,
    "error_type": "HALLUCINATION",
    "error_description": "The implementation includes a hallucinated feature using OrderedDict that doesn't actually work correctly. The _ordered_cache is claimed to be used for 'Python optimization' and to maintain order, but it's only updated in _add_to_head and never properly synchronized with the main cache operations. The get_ordered_keys() method claims to return keys in LRU order but the OrderedDict is not properly maintained during move operations, making this feature non-functional. This is a fabricated optimization that doesn't work as described.",
    "expected_verdict": "FAIL_MAJOR",
    "domain": "coding",
    "difficulty": "hard"
  },
  {
    "task": "Please provide the capital city, population, and official language for the country of Japan. Format your response as a clear, structured list with each piece of information clearly labeled.",
    "correct_response": "Capital City: Tokyo\nPopulation: Approximately 125.8 million (as of 2023)\nOfficial Language: Japanese",
    "evaluation_criteria": "The response must include all three requested pieces of information (capital city, population, and official language) for Japan. Each piece of information must be accurate and clearly labeled. The population should be a reasonable approximation (within 5% of current estimates).",
    "key_elements": [
      "Tokyo as capital city",
      "Population figure (approximately 125-126 million)",
      "Japanese as official language",
      "Clear labeling of each piece of information"
    ],
    "agent_response": "Capital City: Tokyo\nPopulation: Approximately 125.8 million (as of 2023)\nOfficial Language: Japanese",
    "has_error": false,
    "error_type": "NONE",
    "error_description": "",
    "expected_verdict": "PASS",
    "domain": "factual",
    "difficulty": "easy"
  },
  {
    "task": "You are a project manager for a software development team. Your team has 5 developers who can each work 8 hours per day. You need to complete a project that requires 240 hours of development work. However, you have the following constraints: 1) Two developers are unavailable for 2 days next week due to training, 2) One developer can only work 6 hours per day for the entire project, 3) The project must be completed within 5 working days. Determine if this is feasible and explain your reasoning. If not feasible, propose the minimum number of additional days needed.",
    "correct_response": "Let me analyze this step by step:\n\n1. Available developer hours per day:\n   - 3 developers \u00d7 8 hours = 24 hours\n   - 1 developer \u00d7 6 hours = 6 hours\n   - 2 developers \u00d7 0 hours (unavailable) = 0 hours\n   Total per day = 30 hours\n\n2. For the 2 days when developers are in training:\n   - 3 developers \u00d7 8 hours = 24 hours\n   - 1 developer \u00d7 6 hours = 6 hours\n   - 2 developers unavailable = 0 hours\n   Total = 30 hours\n\n3. For the remaining 3 days:\n   - All 5 developers available:\n   - 4 developers \u00d7 8 hours = 32 hours\n   - 1 developer \u00d7 6 hours = 6 hours\n   Total = 38 hours\n\n4. Total hours available in 5 days:\n   - 2 days \u00d7 30 hours = 60 hours\n   - 3 days \u00d7 38 hours = 114 hours\n   - Total = 174 hours\n\n5. Project requires 240 hours, but only 174 hours are available in 5 days.\n\nConclusion: The project is NOT feasible within 5 days.\n\nMinimum additional days needed:\n   - Remaining work: 240 - 174 = 66 hours\n   - With all developers available: 38 hours per day\n   - 66 \u00f7 38 = 1.74 days\n   - Therefore, 2 additional days are needed.\n\nThe project will require 7 days total to complete.",
    "evaluation_criteria": "1. Correct calculation of available hours per day considering all constraints, 2. Accurate determination of total hours available in 5 days, 3. Correct feasibility assessment, 4. Accurate calculation of additional days needed if not feasible, 5. Clear step-by-step reasoning shown, 6. Final conclusion matches the correct answer (not feasible, needs 2 additional days)",
    "key_elements": [
      "Calculation of daily available hours with constraints",
      "Total hours calculation for 5-day period",
      "Comparison with required 240 hours",
      "Feasibility determination",
      "Additional days calculation",
      "Clear mathematical reasoning",
      "Final answer with specific number of days needed"
    ],
    "agent_response": "Let me analyze this step by step:\n\n1. Available developer hours per day:\n   - 3 developers \u001994 8 hours = 24 hours\n   - 1 developer \u007f 6 hours = 6 hours\n   - 2 developers \u007f 0 hours (unavailable) = 0 hours\n   Total per day = 30 hours\n\n2. For the 2 days when developers are in training:\n   - 3 developers \u007f 8 hours = 24 hours\n   - 1 developer \u007f 6 hours = 6 hours\n   - 2 developers unavailable = 0 hours\n   Total = 30 hours\n\n3. For the remaining 3 days:\n   - All 5 developers available:\n   - 4 developers \u007f 8 hours = 32 hours\n   - 1 developer \u007f 6 hours = 6 hours\n   Total = 38 hours\n\n4. Total hours available in 5 days:\n   - 2 days \u007f 30 hours = 60 hours\n   - 3 days \u007f 38 hours = 114 hours\n   - Total = 174 hours\n\n5. Project requires 240 hours, but only 174 hours are available in 5 days.\n\nConclusion: The project is NOT feasible within 5 days.",
    "has_error": true,
    "error_type": "INCOMPLETE",
    "error_description": "The response is incomplete - it correctly calculates that the project is not feasible within 5 days, but fails to answer the second part of the task which asks to 'propose the minimum number of additional days needed'. The response stops at the conclusion without providing the calculation for additional days required.",
    "expected_verdict": "FAIL_MINOR",
    "domain": "reasoning",
    "difficulty": "medium"
  },
  {
    "task": "You are organizing a small dinner party and need to arrange seating for 6 people around a circular table. The guests are: Alice, Bob, Carol, David, Eve, and Frank. Alice wants to sit next to Bob. Carol refuses to sit next to David. Eve and Frank want to sit together (adjacent). How many valid seating arrangements are possible? Explain your reasoning step by step.",
    "correct_response": "Let's solve this step by step:\n\n1. First, let's fix Alice's position to handle the circular arrangement (we can do this because rotations are equivalent in circular arrangements).\n\n2. Bob must sit next to Alice, so Bob has 2 possible positions (left or right of Alice).\n\n3. Eve and Frank must sit together, so we treat them as a single unit. This unit can be arranged in 2 ways (Eve-Frank or Frank-Eve).\n\n4. Now we have: Alice, Bob, Eve-Frank unit, Carol, and David = 4 'items' to arrange.\n\n5. After placing Alice and Bob, we have 4 remaining seats for our 4 'items'.\n\n6. Carol and David cannot sit next to each other.\n\nLet's count the valid arrangements:\n\nCase 1: Bob sits to Alice's right\n- Remaining seats: 4 positions in order\n- Eve-Frank unit can be placed in any of 3 gaps (can't be in the gap between Alice and Bob)\n- Carol and David must be placed in the remaining 2 seats, but not next to each other\n\nActually, let me reconsider with a more systematic approach:\n\nTotal arrangements without restrictions: (6-1)! = 120\n\nNow apply restrictions:\n- Alice-Bob adjacency: Treat them as unit \u2192 2 \u00d7 5! = 240, but this counts each valid arrangement twice, so 120 arrangements satisfy this\n\n- Eve-Frank adjacency: Similar logic gives us 120 arrangements\n\n- Carol-David NOT adjacent: Total arrangements where they are adjacent = 2 \u00d7 5! = 120, so NOT adjacent = 120\n\nUsing inclusion-exclusion for all three conditions:\n\nValid arrangements = Total arrangements where Alice-Bob adjacent AND Eve-Frank adjacent AND Carol-David NOT adjacent\n\nLet me count directly:\n\nFix Alice's position. Bob has 2 choices (left or right).\n\nTreat Eve-Frank as a unit (2 internal arrangements).\n\nNow we have 4 units to place: Alice-Bob pair, Eve-Frank unit, Carol, David.\n\nThe Carol-David restriction means they cannot be adjacent.\n\nTotal ways to arrange 4 units = 3! = 6\n\nArrangements where Carol-David are adjacent = 2 (Carol-David or David-Carol as adjacent units)\n\nSo valid arrangements = 6 - 2 = 4\n\nFinal count = 2 (Bob position) \u00d7 2 (Eve-Frank internal) \u00d7 4 (valid arrangements) = 16\n\nTherefore, there are 16 valid seating arrangements possible.",
    "evaluation_criteria": "1. Correct final answer of 16 arrangements\n2. Clear step-by-step reasoning showing understanding of circular arrangements\n3. Proper handling of adjacency constraints (both required and forbidden)\n4. Correct application of combinatorial principles\n5. Logical progression from initial setup to final calculation",
    "key_elements": [
      "Final answer of 16",
      "Explanation of fixing one position for circular arrangement",
      "Handling of Alice-Bob adjacency constraint",
      "Handling of Eve-Frank adjacency constraint",
      "Handling of Carol-David non-adjacency constraint",
      "Step-by-step counting process",
      "Final calculation showing multiplication of choices"
    ],
    "agent_response": "Let's solve this step by step:\n\n1. First, let's fix Alice's position to handle the circular arrangement (we can do this because rotations are equivalent in circular arrangements).\n\n2. Bob must sit next to Alice, so Bob has 2 possible positions (left or right of Alice).\n\n3. Eve and Frank must sit together, so we treat them as a single unit. This unit can be arranged in 2 ways (Eve-Frank or Frank-Eve).\n\n4. Now we have: Alice, Bob, Eve-Frank unit, Carol, and David = 4 'items' to arrange.\n\n5. After placing Alice and Bob, we have 4 remaining seats for our 4 'items'.\n\n6. Carol and David cannot sit next to each other.\n\nLet me count systematically:\n\nFix Alice's position. Bob has 2 choices (left or right).\n\nTreat Eve-Frank as a unit (2 internal arrangements).\n\nNow we have 4 units to place: Alice-Bob pair, Eve-Frank unit, Carol, David.\n\nThe Carol-David restriction means they cannot be adjacent.\n\nTotal ways to arrange 4 units = 4! = 24\n\nArrangements where Carol-David are adjacent = 2 \u00d7 3! = 12\n\nSo valid arrangements = 24 - 12 = 12\n\nFinal count = 2 (Bob position) \u00d7 2 (Eve-Frank internal) \u00d7 12 (valid arrangements) = 48\n\nTherefore, there are 48 valid seating arrangements possible.",
    "has_error": true,
    "error_type": "LOGICAL_FLAW",
    "error_description": "The logical flaw occurs when treating the Alice-Bob pair as a single unit. After fixing Alice's position and placing Bob next to her, we cannot treat them as a single unit for the remaining arrangement because they are already positioned. The calculation incorrectly multiplies by the number of ways to arrange 4 units (4!) when we should only be arranging the remaining 3 units (Eve-Frank unit, Carol, David) in the 3 remaining positions. This leads to an overcount.",
    "expected_verdict": "FAIL_MAJOR",
    "domain": "reasoning",
    "difficulty": "easy"
  },
  {
    "task": "You are a logistics coordinator for a disaster relief organization. You have 5 trucks with different capacities and 4 locations that need supplies. Each location has specific requirements and time constraints. Your goal is to create an optimal delivery schedule that minimizes total travel distance while meeting all requirements.\n\nTruck Information:\n- Truck A: 1000 kg capacity, starts at Warehouse (coordinates: 0,0)\n- Truck B: 800 kg capacity, starts at Warehouse (coordinates: 0,0)\n- Truck C: 1200 kg capacity, starts at Warehouse (coordinates: 0,0)\n- Truck D: 900 kg capacity, starts at Warehouse (coordinates: 0,0)\n- Truck E: 1100 kg capacity, starts at Warehouse (coordinates: 0,0)\n\nLocation Requirements:\n- Location 1 (coordinates: 10,5): Needs 700 kg of supplies, must be delivered by 9:00 AM\n- Location 2 (coordinates: 8,12): Needs 900 kg of supplies, must be delivered by 10:00 AM\n- Location 3 (coordinates: 15,3): Needs 600 kg of supplies, must be delivered by 9:30 AM\n- Location 4 (coordinates: 12,10): Needs 800 kg of supplies, must be delivered by 10:30 AM\n\nAdditional Constraints:\n- Trucks travel at 60 km/h\n- Loading time at warehouse: 30 minutes per truck\n- Unloading time at each location: 20 minutes\n- Distance calculated using Euclidean distance formula\n- All trucks start at 8:00 AM\n\nCreate the optimal delivery schedule showing: which truck visits which location(s), the route for each truck, and the total distance traveled.",
    "correct_response": "Optimal Delivery Schedule:\n\nTruck A (1000 kg capacity):\n- Route: Warehouse \u2192 Location 1 \u2192 Location 3\n- Load: 700 kg for Location 1 + 300 kg for Location 3\n- Departure time: 8:30 AM\n- Arrival at Location 1: 8:40 AM (distance: 11.18 km)\n- Departure Location 1: 9:00 AM\n- Arrival at Location 3: 9:10 AM (distance: 7.07 km)\n- Return to Warehouse: 9:20 AM (distance: 15.81 km)\n- Total distance: 34.06 km\n\nTruck B (800 kg capacity):\n- Route: Warehouse \u2192 Location 4\n- Load: 800 kg for Location 4\n- Departure time: 8:30 AM\n- Arrival at Location 4: 8:50 AM (distance: 15.62 km)\n- Departure Location 4: 9:10 AM\n- Return to Warehouse: 9:25 AM (distance: 15.62 km)\n- Total distance: 31.24 km\n\nTruck C (1200 kg capacity):\n- Route: Warehouse \u2192 Location 2\n- Load: 900 kg for Location 2\n- Departure time: 8:30 AM\n- Arrival at Location 2: 9:10 AM (distance: 14.42 km)\n- Departure Location 2: 9:30 AM\n- Return to Warehouse: 9:45 AM (distance: 14.42 km)\n- Total distance: 28.84 km\n\nTruck D (900 kg capacity):\n- Route: Warehouse \u2192 Location 3 (supplement)\n- Load: 300 kg for Location 3\n- Departure time: 8:30 AM\n- Arrival at Location 3: 8:50 AM (distance: 15.30 km)\n- Departure Location 3: 9:10 AM\n- Return to Warehouse: 9:25 AM (distance: 15.30 km)\n- Total distance: 30.60 km\n\nTruck E:\n- Standby (not needed for this delivery schedule)\n\nTotal distance traveled by all trucks: 124.74 km\n\nAll delivery deadlines met:\n- Location 1: 9:00 AM \u2713\n- Location 2: 10:00 AM \u2713 (delivered at 9:10 AM)\n- Location 3: 9:30 AM \u2713 (full delivery by 9:10 AM)\n- Location 4: 10:30 AM \u2713 (delivered at 8:50 AM)",
    "evaluation_criteria": "1. All location requirements must be met (correct supplies delivered to each location)\n2. All time constraints must be satisfied (deliveries made by deadlines)\n3. Truck capacities must not be exceeded\n4. Total distance calculation must be accurate\n5. Route optimization must be evident (minimal total distance)\n6. Time calculations must account for travel, loading, and unloading\n7. Solution must include complete schedule for all trucks used",
    "key_elements": [
      "Complete truck routing information",
      "Accurate distance calculations using Euclidean formula",
      "Time schedule including loading, travel, and unloading",
      "Verification of all constraints being met",
      "Total distance optimization",
      "Clear assignment of trucks to locations",
      "Proof that all deadlines are satisfied"
    ],
    "agent_response": "Optimal Delivery Schedule:\n\nTruck A (1000 kg capacity):\n- Route: Warehouse \u2192 Location 1 \u2192 Location 3\n- Load: 700 kg for Location 1 + 300 kg for Location 3\n- Departure time: 8:30 AM\n- Arrival at Location 1: 8:40 AM (distance: 11.18 km)\n- Departure Location 1: 9:00 AM\n- Arrival at Location 3: 9:10 AM (distance: 7.07 km)\n- Return to Warehouse: 9:20 AM (distance: 15.81 km)\n- Total distance: 34.06 km\n\nTruck B (800 kg capacity):\n- Route: Warehouse \u2192 Location 4\n- Load: 800 kg for Location 4\n- Departure time: 8:30 AM\n- Arrival at Location 4: 8:50 AM (distance: 15.62 km)\n- Departure Location 4: 9:10 AM\n- Return to Warehouse: 9:25 AM (distance: 15.62 km)\n- Total distance: 31.24 km\n\nTruck C (1200 kg capacity):\n- Route: Warehouse \u2192 Location 2\n- Load: 900 kg for Location 2\n- Departure time: 8:30 AM\n- Arrival at Location 2: 9:10 AM (distance: 14.42 km)\n- Departure Location 2: 9:30 AM\n- Return to Warehouse: 9:45 AM (distance: 14.42 km)\n- Total distance: 28.84 km\n\nTruck D (900 kg capacity):\n- Route: Warehouse \u2192 Location 3 (supplement)\n- Load: 300 kg for Location 3\n- Departure time: 8:30 AM\n- Arrival at Location 3: 8:50 AM (distance: 15.30 km)\n- Departure Location 3: 9:10 AM\n- Return to Warehouse: 9:25 AM (distance: 15.30 km)\n- Total distance: 30.60 km\n\nTruck E:\n- Standby (not needed for this delivery schedule)\n\nTotal distance traveled by all trucks: 124.74 km\n\nAll delivery deadlines met:\n- Location 1: 9:00 AM \u2713\n- Location 2: 10:00 AM \u2713 (delivered at 9:10 AM)\n- Location 3: 9:30 AM \u2713 (full delivery by 9:10 AM)\n- Location 4: 10:30 AM \u2713 (delivered at 8:50 AM)",
    "has_error": true,
    "error_type": "FACTUAL_ERROR",
    "error_description": "The distance calculations contain factual errors. For Truck A, the distance from Warehouse (0,0) to Location 1 (10,5) should be 11.18 km, but the travel time calculation is incorrect. At 60 km/h, traveling 11.18 km would take approximately 11.2 minutes, not 10 minutes as stated. Similarly, the distance from Location 1 (10,5) to Location 3 (15,3) is calculated as 7.07 km, which would take about 7.1 minutes, not 10 minutes. These time calculations don't match the distances given, making the schedule mathematically inconsistent.",
    "expected_verdict": "FAIL_MINOR",
    "domain": "reasoning",
    "difficulty": "hard"
  },
  {
    "task": "You are managing a small coffee shop that employs 3 baristas (Alex, Ben, and Casey) who work different schedules. Based on the following constraints, determine who works on Wednesday:\n\n1. Alex works 2 days a week, never on consecutive days\n2. Ben works 3 days a week, always including Monday\n3. Casey works 4 days a week, never on weekends\n4. At least one barista must work every day the shop is open (Monday through Friday)\n5. No more than 2 baristas can work on the same day\n6. Alex and Ben never work together on the same day\n\nGiven these constraints, determine which barista(s) work on Wednesday and explain your reasoning step by step.",
    "correct_response": "Casey works on Wednesday.\n\nStep-by-step reasoning:\n1. Ben must work Monday and 2 other days (total 3 days)\n2. Alex works 2 non-consecutive days and cannot work with Ben\n3. Casey works 4 weekdays (Mon-Fri except weekends)\n4. Since Monday is covered by Ben, and Alex can't work Monday with Ben, Alex must work 2 days from Tue, Wed, Thu, Fri (non-consecutive)\n5. Casey needs to work 4 days, and since at least one person must work each day, Casey must cover most days\n6. If Alex works Tuesday and Thursday (non-consecutive), then Wednesday would only have Casey working\n7. This satisfies all constraints: Wednesday has exactly 1 barista (Casey), meeting the \"at least one\" and \"no more than two\" requirements\n8. Any other combination would either violate Alex's non-consecutive rule, Ben's Monday requirement, or the maximum 2 baristas per day rule",
    "evaluation_criteria": "1. Correct identification of who works on Wednesday (must be Casey)\n2. Logical step-by-step reasoning that addresses all constraints\n3. Demonstration of why other possibilities are eliminated\n4. Clear explanation of how the solution satisfies all given rules",
    "key_elements": [
      "Identification of Casey as Wednesday's worker",
      "Step-by-step logical deduction",
      "Reference to all 6 constraints",
      "Elimination of alternative possibilities",
      "Verification that solution meets all requirements"
    ],
    "agent_response": "Casey works on Wednesday.\n\nStep-by-step reasoning:\n1. Ben must work Monday and 2 other days (total 3 days)\n2. Alex works 2 non-consecutive days and cannot work with Ben\n3. Casey works 4 weekdays (Mon-Fri except weekends)\n4. Since Monday is covered by Ben, and Alex can't work Monday with Ben, Alex must work 2 days from Tue, Wed, Thu, Fri (non-consecutive)\n5. Casey needs to work 4 days, and since at least one person must work each day, Casey must cover most days\n6. If Alex works Tuesday and Thursday (non-consecutive), then Wednesday would only have Casey working\n7. This satisfies all constraints: Wednesday has exactly 1 barista (Casey), meeting the \"at least one\" and \"no more than two\" requirements\n8. Any other combination would either violate Alex's non-consecutive rule, Ben's Monday requirement, or the maximum 2 baristas per day rule",
    "has_error": false,
    "error_type": "NONE",
    "error_description": "",
    "expected_verdict": "PASS",
    "domain": "reasoning",
    "difficulty": "medium"
  },
  {
    "task": "You are a medical researcher analyzing clinical trial data for a new diabetes medication. Based on the following dataset, provide a comprehensive analysis including statistical significance, efficacy comparison with existing treatments, safety profile assessment, and clinical recommendations. Dataset: Phase III double-blind randomized controlled trial with 2,847 participants (1,423 on new drug 'Diabex', 1,424 on placebo). Duration: 52 weeks. Primary endpoint: reduction in HbA1c levels. Secondary endpoints: weight change, incidence of hypoglycemia, cardiovascular events. Results: Diabex group showed mean HbA1c reduction of 1.8% (SD 0.6) vs 0.3% (SD 0.4) in placebo (p<0.001). Mean weight loss: 3.2kg (SD 2.1) vs 0.8kg (SD 1.5) (p<0.001). Hypoglycemia events: 4.2% vs 2.1% (p=0.03). Major cardiovascular events: 0.7% vs 0.9% (NS). Include interpretation of clinical relevance, effect size calculations (Cohen's d), and number needed to treat (NNT) for primary endpoint.",
    "correct_response": "STATISTICAL ANALYSIS:\n\nPrimary Endpoint (HbA1c reduction):\n- Mean difference: 1.5% (1.8% - 0.3%)\n- Effect size (Cohen's d): (1.8-0.3) / sqrt(((0.6\u00b2)+(0.4\u00b2))/2) = 2.94 (large effect)\n- NNT for \u22651% HbA1c reduction: 2.3 (based on 78% vs 22% achieving target)\n- Statistically significant (p<0.001)\n\nSecondary Endpoints:\n1. Weight Change:\n   - Mean difference: 2.4kg loss\n   - Cohen's d: 1.37 (large effect)\n   - Clinically significant (>2% body weight loss in 65% of Diabex group)\n\n2. Hypoglycemia:\n   - Absolute risk increase: 2.1%\n   - NNH (Number Needed to Harm): 48\n   - Mild to moderate episodes only\n\n3. Cardiovascular Events:\n   - No significant difference (0.7% vs 0.9%, p=NS)\n   - Trend toward benefit but underpowered\n\nSAFETY PROFILE:\n- Most common AEs: nausea (12%), headache (8%), dizziness (5%)\n- Discontinuation rate: 6.3% vs 3.1% placebo\n- No serious drug-related adverse events\n- No hepatic or renal toxicity signals\n\nCLINICAL RECOMMENDATIONS:\n1. Diabex demonstrates superior glycemic control with clinically meaningful HbA1c reduction\n2. Additional benefit of significant weight loss\n3. Acceptable safety profile with mild gastrointestinal side effects\n4. Suitable as monotherapy or add-on to metformin\n5. Monitor for hypoglycemia, especially in elderly or when combined with sulfonylureas\n6. Contraindicated in severe renal impairment (eGFR <30)\n7. Recommended starting dose: 10mg once daily, titrate to 25mg based on response\n\nREGULATORY IMPLICATIONS:\n- Meets FDA efficacy criteria for diabetes medications\n- Favorable benefit-risk ratio supports approval\n- Post-marketing surveillance recommended for cardiovascular outcomes",
    "evaluation_criteria": "1. Statistical calculations must be accurate (effect sizes, NNT, p-values)\n2. Clinical interpretation must be appropriate and evidence-based\n3. Safety assessment must include both benefits and risks\n4. Recommendations must be practical and guideline-compliant\n5. Response must include all requested components: statistical significance, efficacy comparison, safety profile, and clinical recommendations\n6. Numerical calculations must match expected values within \u00b10.1 tolerance\n7. Clinical relevance assessment must be medically sound",
    "key_elements": [
      "Statistical significance analysis",
      "Effect size calculations (Cohen's d)",
      "Number needed to treat (NNT)",
      "Efficacy comparison with placebo",
      "Safety profile assessment",
      "Hypoglycemia risk analysis",
      "Cardiovascular event evaluation",
      "Clinical recommendations",
      "Dosing suggestions",
      "Regulatory implications",
      "Benefit-risk assessment",
      "Patient population considerations"
    ],
    "agent_response": "STATISTICAL ANALYSIS:\n\nPrimary Endpoint (HbA1c reduction):\n- Mean difference: 1.5% (1.8% - 0.3%)\n- Effect size (Cohen's d): (1.8-0.3) / sqrt(((0.6\u0012)+(0.4\u0012))/2) = 2.94 (large effect)\n- NNT for \u001e1% HbA1c reduction: 2.3 (based on 78% vs 22% achieving target)\n- Statistically significant (p<0.001)\n\nSecondary Endpoints:\n1. Weight Change:\n   - Mean difference: 2.4kg loss\n   - Cohen's d: 1.37 (large effect)\n   - Clinically significant (>2% body weight loss in 65% of Diabex group)\n\n2. Hypoglycemia:\n   - Absolute risk increase: 2.1%\n   - NNH (Number Needed to Harm): 48\n   - Mild to moderate episodes only\n\n3. Cardiovascular Events:\n   - No significant difference (0.7% vs 0.9%, p=NS)\n   - Trend toward benefit but underpowered\n\nSAFETY PROFILE:\n- Most common AEs: nausea (12%), headache (8%), dizziness (5%)\n- Discontinuation rate: 6.3% vs 3.1% placebo\n- No serious drug-related adverse events\n- No hepatic or renal toxicity signals\n\nCLINICAL RECOMMENDATIONS:\n1. Diabex demonstrates superior glycemic control with clinically meaningful HbA1c reduction\n2. Additional benefit of significant weight loss\n3. Acceptable safety profile with mild gastrointestinal side effects\n4. Suitable as monotherapy or add-on to metformin\n5. Monitor for hypoglycemia, especially in elderly or when combined with sulfonylureas\n6. Contraindicated in severe renal impairment (eGFR <30)\n7. Recommended starting dose: 10mg once daily, titrate to 25mg based on response\n\nREGULATORY IMPLICATIONS:\n- Meets FDA efficacy criteria for diabetes medications\n- Favorable benefit-risk ratio supports approval\n- Post-marketing surveillance recommended for cardiovascular outcomes",
    "has_error": true,
    "error_type": "SUBTLE_MISTAKE",
    "error_description": "The Cohen's d calculation for weight change is incorrect. The formula shows 1.37 but the actual calculation using the provided data (3.2kg vs 0.8kg difference = 2.4kg, SDs of 2.1 and 1.5) would be: 2.4 / sqrt(((2.1\u0012)+(1.5\u0012))/2) = 1.34, not 1.37. This is a subtle mathematical error in the effect size calculation.",
    "expected_verdict": "FAIL_MINOR",
    "domain": "factual",
    "difficulty": "hard"
  },
  {
    "task": "Implement a thread-safe LRU (Least Recently Used) cache with O(1) time complexity for both get and put operations. The cache should support the following operations:\n\n1. get(key): Return the value associated with the key if it exists in the cache, otherwise return -1. The accessed item should become the most recently used.\n2. put(key, value): Add or update the key-value pair. If the cache is at capacity, remove the least recently used item before adding the new item. The new item should become the most recently used.\n3. clear(): Remove all items from the cache.\n4. size(): Return the current number of items in the cache.\n\nAdditional requirements:\n- The cache must be thread-safe for concurrent reads and writes\n- Use a doubly linked list to maintain the order of items (most recent to least recent)\n- Use a hash map for O(1) key lookups\n- Handle edge cases like null keys/values appropriately\n- Include comprehensive error handling\n- Provide a test suite demonstrating the functionality and thread safety\n\nWrite this in Java with proper documentation and include unit tests using JUnit.",
    "correct_response": "import java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\n\npublic class ThreadSafeLRUCache<K, V> {\n    private final int capacity;\n    private final ConcurrentHashMap<K, Node<K, V>> map;\n    private final Node<K, V> head;\n    private final Node<K, V> tail;\n    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n    private final ReentrantReadWriteLock.ReadLock readLock = lock.readLock();\n    private final ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock();\n\n    private static class Node<K, V> {\n        K key;\n        V value;\n        Node<K, V> prev;\n        Node<K, V> next;\n\n        Node(K key, V value) {\n            this.key = key;\n            this.value = value;\n        }\n    }\n\n    public ThreadSafeLRUCache(int capacity) {\n        if (capacity <= 0) {\n            throw new IllegalArgumentException(\"Capacity must be positive\");\n        }\n        this.capacity = capacity;\n        this.map = new ConcurrentHashMap<>(capacity);\n        this.head = new Node<>(null, null);\n        this.tail = new Node<>(null, null);\n        head.next = tail;\n        tail.prev = head;\n    }\n\n    public V get(K key) {\n        if (key == null) {\n            throw new IllegalArgumentException(\"Key cannot be null\");\n        }\n        readLock.lock();\n        try {\n            Node<K, V> node = map.get(key);\n            if (node == null) {\n                return null;\n            }\n        } finally {\n            readLock.unlock();\n        }\n        \n        writeLock.lock();\n        try {\n            Node<K, V> node = map.get(key);\n            if (node != null) {\n                moveToHead(node);\n                return node.value;\n            }\n            return null;\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    public void put(K key, V value) {\n        if (key == null || value == null) {\n            throw new IllegalArgumentException(\"Key and value cannot be null\");\n        }\n        writeLock.lock();\n        try {\n            Node<K, V> node = map.get(key);\n            if (node != null) {\n                node.value = value;\n                moveToHead(node);\n            } else {\n                Node<K, V> newNode = new Node<>(key, value);\n                if (map.size() >= capacity) {\n                    removeTail();\n                }\n                map.put(key, newNode);\n                addToHead(newNode);\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    public void clear() {\n        writeLock.lock();\n        try {\n            map.clear();\n            head.next = tail;\n            tail.prev = head;\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    public int size() {\n        readLock.lock();\n        try {\n            return map.size();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    private void addToHead(Node<K, V> node) {\n        node.prev = head;\n        node.next = head.next;\n        head.next.prev = node;\n        head.next = node;\n    }\n\n    private void removeNode(Node<K, V> node) {\n        node.prev.next = node.next;\n        node.next.prev = node.prev;\n    }\n\n    private void moveToHead(Node<K, V> node) {\n        removeNode(node);\n        addToHead(node);\n    }\n\n    private void removeTail() {\n        Node<K, V> lastNode = tail.prev;\n        if (lastNode != head) {\n            removeNode(lastNode);\n            map.remove(lastNode.key);\n        }\n    }\n}\n\n// Test class\nimport org.junit.Test;\nimport org.junit.Before;\nimport static org.junit.Assert.*;\nimport java.util.concurrent.*;\nimport java.util.concurrent.atomic.AtomicInteger;\n\npublic class ThreadSafeLRUCacheTest {\n    private ThreadSafeLRUCache<Integer, String> cache;\n\n    @Before\n    public void setUp() {\n        cache = new ThreadSafeLRUCache<>(3);\n    }\n\n    @Test\n    public void testBasicOperations() {\n        cache.put(1, \"one\");\n        cache.put(2, \"two\");\n        cache.put(3, \"three\");\n        \n        assertEquals(\"one\", cache.get(1));\n        assertEquals(\"two\", cache.get(2));\n        assertEquals(\"three\", cache.get(3));\n        assertEquals(3, cache.size());\n    }\n\n    @Test\n    public void testLRUEviction() {\n        cache.put(1, \"one\");\n        cache.put(2, \"two\");\n        cache.put(3, \"three\");\n        cache.get(1); // Make 1 most recent\n        cache.put(4, \"four\"); // Should evict 2\n        \n        assertEquals(\"one\", cache.get(1));\n        assertNull(cache.get(2));\n        assertEquals(\"three\", cache.get(3));\n        assertEquals(\"four\", cache.get(4));\n    }\n\n    @Test\n    public void testThreadSafety() throws InterruptedException {\n        int numThreads = 10;\n        int operationsPerThread = 1000;\n        ExecutorService executor = Executors.newFixedThreadPool(numThreads);\n        CountDownLatch latch = new CountDownLatch(numThreads);\n        AtomicInteger successCount = new AtomicInteger(0);\n\n        for (int i = 0; i < numThreads; i++) {\n            final int threadId = i;\n            executor.submit(() -> {\n                try {\n                    for (int j = 0; j < operationsPerThread; j++) {\n                        int key = threadId * 100 + j % 10;\n                        cache.put(key, \"value\" + key);\n                        String value = cache.get(key);\n                        if (value != null && value.equals(\"value\" + key)) {\n                            successCount.incrementAndGet();\n                        }\n                    }\n                } finally {\n                    latch.countDown();\n                }\n            });\n        }\n\n        latch.await(30, TimeUnit.SECONDS);\n        executor.shutdown();\n        \n        assertTrue(\"Thread safety test failed\", successCount.get() > 0);\n        assertTrue(\"Cache size should not exceed capacity\", cache.size() <= 3);\n    }\n\n    @Test(expected = IllegalArgumentException.class)\n    public void testNullKey() {\n        cache.put(null, \"value\");\n    }\n\n    @Test(expected = IllegalArgumentException.class)\n    public void testNullValue() {\n        cache.put(1, null);\n    }\n\n    @Test(expected = IllegalArgumentException.class)\n    public void testInvalidCapacity() {\n        new ThreadSafeLRUCache<Integer, String>(0);\n    }\n\n    @Test\n    public void testClear() {\n        cache.put(1, \"one\");\n        cache.put(2, \"two\");\n        assertEquals(2, cache.size());\n        \n        cache.clear();\n        assertEquals(0, cache.size());\n        assertNull(cache.get(1));\n        assertNull(cache.get(2));\n    }\n}",
    "evaluation_criteria": "1. The implementation must use a doubly linked list and hash map for O(1) operations\n2. Thread safety must be properly implemented using appropriate locking mechanisms\n3. All required methods (get, put, clear, size) must be correctly implemented\n4. Error handling for null keys/values and invalid capacity must be present\n5. LRU eviction logic must work correctly when capacity is exceeded\n6. The code must compile without errors\n7. Unit tests must cover basic operations, LRU behavior, thread safety, and edge cases\n8. Documentation and comments should be clear and informative",
    "key_elements": [
      "Thread-safe implementation using ReadWriteLock",
      "Doubly linked list for maintaining LRU order",
      "HashMap/ConcurrentHashMap for O(1) key lookups",
      "Proper LRU eviction when capacity is exceeded",
      "Complete implementation of all required methods",
      "Comprehensive error handling",
      "JUnit test suite with thread safety tests",
      "Clear documentation and code structure",
      "O(1) time complexity for get and put operations",
      "Handling of edge cases and invalid inputs"
    ],
    "agent_response": "import java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\n\n/**\n * A thread-safe LRU (Least Recently Used) cache implementation with O(1) time complexity\n * for both get and put operations.\n * \n * @param <K> the type of keys maintained by this cache\n * @param <V> the type of mapped values\n */\npublic class ThreadSafeLRUCache<K, V> {\n    private final int capacity;\n    private final ConcurrentHashMap<K, Node<K, V>> map;\n    private final Node<K, V> head;\n    private final Node<K, V> tail;\n    private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();\n    private final ReentrantReadWriteLock.ReadLock readLock = lock.readLock();\n    private final ReentrantReadWriteLock.WriteLock writeLock = lock.writeLock();\n\n    /**\n     * Internal node class for the doubly linked list\n     */\n    private static class Node<K, V> {\n        K key;\n        V value;\n        Node<K, V> prev;\n        Node<K, V> next;\n\n        Node(K key, V value) {\n            this.key = key;\n            this.value = value;\n        }\n    }\n\n    /**\n     * Constructs a new LRU cache with the specified capacity.\n     * \n     * @param capacity the maximum number of items the cache can hold\n     * @throws IllegalArgumentException if capacity is not positive\n     */\n    public ThreadSafeLRUCache(int capacity) {\n        if (capacity <= 0) {\n            throw new IllegalArgumentException(\"Capacity must be positive\");\n        }\n        this.capacity = capacity;\n        this.map = new ConcurrentHashMap<>(capacity);\n        this.head = new Node<>(null, null);\n        this.tail = new Node<>(null, null);\n        head.next = tail;\n        tail.prev = head;\n    }\n\n    /**\n     * Retrieves the value associated with the specified key.\n     * If the key exists, the item becomes the most recently used.\n     * \n     * @param key the key whose associated value is to be returned\n     * @return the value associated with the key, or null if the key doesn't exist\n     * @throws IllegalArgumentException if key is null\n     */\n    public V get(K key) {\n        if (key == null) {\n            throw new IllegalArgumentException(\"Key cannot be null\");\n        }\n        readLock.lock();\n        try {\n            Node<K, V> node = map.get(key);\n            if (node == null) {\n                return null;\n            }\n        } finally {\n            readLock.unlock();\n        }\n        \n        writeLock.lock();\n        try {\n            Node<K, V> node = map.get(key);\n            if (node != null) {\n                moveToHead(node);\n                return node.value;\n            }\n            return null;\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    /**\n     * Adds or updates the key-value pair in the cache.\n     * If the cache is at capacity, removes the least recently used item.\n     * The new/updated item becomes the most recently used.\n     * \n     * @param key the key to insert or update\n     * @param value the value to associate with the key\n     * @throws IllegalArgumentException if key or value is null\n     */\n    public void put(K key, V value) {\n        if (key == null || value == null) {\n            throw new IllegalArgumentException(\"Key and value cannot be null\");\n        }\n        writeLock.lock();\n        try {\n            Node<K, V> node = map.get(key);\n            if (node != null) {\n                node.value = value;\n                moveToHead(node);\n            } else {\n                Node<K, V> newNode = new Node<>(key, value);\n                if (map.size() >= capacity) {\n                    removeTail();\n                }\n                map.put(key, newNode);\n                addToHead(newNode);\n            }\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    /**\n     * Removes all items from the cache.\n     */\n    public void clear() {\n        writeLock.lock();\n        try {\n            map.clear();\n            head.next = tail;\n            tail.prev = head;\n        } finally {\n            writeLock.unlock();\n        }\n    }\n\n    /**\n     * Returns the current number of items in the cache.\n     * \n     * @return the number of items in the cache\n     */\n    public int size() {\n        readLock.lock();\n        try {\n            return map.size();\n        } finally {\n            readLock.unlock();\n        }\n    }\n\n    private void addToHead(Node<K, V> node) {\n        node.prev = head;\n        node.next = head.next;\n        head.next.prev = node;\n        head.next = node;\n    }\n\n    private void removeNode(Node<K, V> node) {\n        node.prev.next = node.next;\n        node.next.prev = node.prev;\n    }\n\n    private void moveToHead(Node<K, V> node) {\n        removeNode(node);\n        addToHead(node);\n    }\n\n    private void removeTail() {\n        Node<K, V> lastNode = tail.prev;\n        if (lastNode != head) {\n            removeNode(lastNode);\n            map.remove(lastNode.key);\n        }\n    }\n}",
    "has_error": false,
    "error_type": "NONE",
    "error_description": "",
    "expected_verdict": "PASS",
    "domain": "coding",
    "difficulty": "hard"
  },
  {
    "task": "Implement a thread-safe rate limiter in Python that allows X requests per Y time window for multiple clients. The rate limiter should support:\n\n1. Configurable requests per time window (e.g., 100 requests per minute)\n2. Per-client rate limiting using client IDs\n3. Thread-safe operations for concurrent access\n4. Automatic cleanup of expired client entries\n5. A method to check if a request is allowed and update counters atomically\n\nThe implementation should use only Python standard library modules and avoid external dependencies. Provide a complete implementation with proper error handling and documentation.",
    "correct_response": "import time\nimport threading\nfrom collections import defaultdict\nfrom typing import Dict, Tuple\n\nclass RateLimiter:\n    def __init__(self, max_requests: int, time_window: int):\n        \"\"\"\n        Initialize the rate limiter.\n        \n        Args:\n            max_requests: Maximum number of requests allowed in the time window\n            time_window: Time window in seconds\n        \"\"\"\n        if max_requests <= 0 or time_window <= 0:\n            raise ValueError(\"max_requests and time_window must be positive\")\n        \n        self.max_requests = max_requests\n        self.time_window = time_window\n        self._client_requests: Dict[str, list] = defaultdict(list)\n        self._lock = threading.RLock()\n        self._last_cleanup = time.time()\n        self._cleanup_interval = time_window * 2\n    \n    def _cleanup_expired_entries(self):\n        \"\"\"Remove expired request timestamps for all clients.\"\"\"\n        current_time = time.time()\n        if current_time - self._last_cleanup < self._cleanup_interval:\n            return\n        \n        cutoff_time = current_time - self.time_window\n        with self._lock:\n            for client_id in list(self._client_requests.keys()):\n                self._client_requests[client_id] = [\n                    req_time for req_time in self._client_requests[client_id]\n                    if req_time > cutoff_time\n                ]\n                if not self._client_requests[client_id]:\n                    del self._client_requests[client_id]\n            self._last_cleanup = current_time\n    \n    def is_allowed(self, client_id: str) -> bool:\n        \"\"\"\n        Check if a request from the client is allowed and update counters.\n        \n        Args:\n            client_id: Unique identifier for the client\n            \n        Returns:\n            bool: True if request is allowed, False otherwise\n        \"\"\"\n        if not client_id:\n            raise ValueError(\"client_id cannot be empty\")\n        \n        current_time = time.time()\n        cutoff_time = current_time - self.time_window\n        \n        with self._lock:\n            self._cleanup_expired_entries()\n            \n            # Filter out expired requests for this client\n            self._client_requests[client_id] = [\n                req_time for req_time in self._client_requests[client_id]\n                if req_time > cutoff_time\n            ]\n            \n            # Check if under limit\n            if len(self._client_requests[client_id]) < self.max_requests:\n                self._client_requests[client_id].append(current_time)\n                return True\n            return False\n    \n    def get_client_status(self, client_id: str) -> Tuple[int, int]:\n        \"\"\"\n        Get the current status of a client.\n        \n        Args:\n            client_id: Unique identifier for the client\n            \n        Returns:\n            Tuple[int, int]: (current_requests, remaining_requests)\n        \"\"\"\n        with self._lock:\n            self._cleanup_expired_entries()\n            current_time = time.time()\n            cutoff_time = current_time - self.time_window\n            \n            valid_requests = [\n                req_time for req_time in self._client_requests.get(client_id, [])\n                if req_time > cutoff_time\n            ]\n            \n            current_count = len(valid_requests)\n            remaining = max(0, self.max_requests - current_count)\n            return current_count, remaining\n    \n    def reset_client(self, client_id: str):\n        \"\"\"\n        Reset the rate limit counter for a specific client.\n        \n        Args:\n            client_id: Unique identifier for the client\n        \"\"\"\n        with self._lock:\n            if client_id in self._client_requests:\n                del self._client_requests[client_id]",
    "evaluation_criteria": "1. Functional correctness: The rate limiter must accurately enforce rate limits per client\n2. Thread safety: Implementation must handle concurrent access without race conditions\n3. Memory efficiency: Automatic cleanup of expired entries must be implemented\n4. Code quality: Proper error handling, documentation, and type hints\n5. Performance: Operations should be O(1) or O(n) where n is the number of requests in the time window\n6. Edge cases: Handle invalid inputs, empty client IDs, and boundary conditions",
    "key_elements": [
      "Thread-safe implementation using locks (threading.RLock)",
      "Per-client rate limiting with client ID tracking",
      "Configurable max_requests and time_window parameters",
      "Automatic cleanup of expired entries",
      "Atomic check-and-update operation in is_allowed method",
      "Proper error handling for invalid inputs",
      "Type hints and docstrings for all methods",
      "get_client_status method for monitoring",
      "reset_client method for manual reset capability",
      "Use of only Python standard library modules"
    ],
    "agent_response": "import time\nimport threading\nfrom collections import defaultdict\nfrom typing import Dict, Tuple\n\nclass RateLimiter:\n    def __init__(self, max_requests: int, time_window: int):\n        \"\"\"\n        Initialize the rate limiter.\n        \n        Args:\n            max_requests: Maximum number of requests allowed in the time window\n            time_window: Time window in seconds\n        \"\"\"\n        if max_requests <= 0 or time_window <= 0:\n            raise ValueError(\"max_requests and time_window must be positive\")\n        \n        self.max_requests = max_requests\n        self.time_window = time_window\n        self._client_requests: Dict[str, list] = defaultdict(list)\n        self._lock = threading.RLock()\n        self._last_cleanup = time.time()\n        self._cleanup_interval = time_window * 2\n    \n    def _cleanup_expired_entries(self):\n        \"\"\"Remove expired request timestamps for all clients.\"\"\"\n        current_time = time.time()\n        if current_time - self._last_cleanup < self._cleanup_interval:\n            return\n        \n        cutoff_time = current_time - self.time_window\n        with self._lock:\n            for client_id in list(self._client_requests.keys()):\n                self._client_requests[client_id] = [\n                    req_time for req_time in self._client_requests[client_id]\n                    if req_time > cutoff_time\n                ]\n                if not self._client_requests[client_id]:\n                    del self._client_requests[client_id]\n            self._last_cleanup = current_time\n    \n    def is_allowed(self, client_id: str) -> bool:\n        \"\"\"\n        Check if a request from the client is allowed and update counters.\n        \n        Args:\n            client_id: Unique identifier for the client\n            \n        Returns:\n            bool: True if request is allowed, False otherwise\n        \"\"\"\n        if not client_id:\n            raise ValueError(\"client_id cannot be empty\")\n        \n        current_time = time.time()\n        cutoff_time = current_time - self.time_window\n        \n        # Only check if the request is allowed, don't update counters\n        with self._lock:\n            self._cleanup_expired_entries()\n            \n            # Filter out expired requests for this client\n            self._client_requests[client_id] = [\n                req_time for req_time in self._client_requests[client_id]\n                if req_time > cutoff_time\n            ]\n            \n            # Check if under limit\n            if len(self._client_requests[client_id]) < self.max_requests:\n                return True\n            return False\n    \n    def record_request(self, client_id: str):\n        \"\"\"\n        Record a request for the client after checking if allowed.\n        \n        Args:\n            client_id: Unique identifier for the client\n        \"\"\"\n        current_time = time.time()\n        with self._lock:\n            self._client_requests[client_id].append(current_time)\n    \n    def get_client_status(self, client_id: str) -> Tuple[int, int]:\n        \"\"\"\n        Get the current status of a client.\n        \n        Args:\n            client_id: Unique identifier for the client\n            \n        Returns:\n            Tuple[int, int]: (current_requests, remaining_requests)\n        \"\"\"\n        with self._lock:\n            self._cleanup_expired_entries()\n            current_time = time.time()\n            cutoff_time = current_time - self.time_window\n            \n            valid_requests = [\n                req_time for req_time in self._client_requests.get(client_id, [])\n                if req_time > cutoff_time\n            ]\n            \n            current_count = len(valid_requests)\n            remaining = max(0, self.max_requests - current_count)\n            return current_count, remaining\n    \n    def reset_client(self, client_id: str):\n        \"\"\"\n        Reset the rate limit counter for a specific client.\n        \n        Args:\n            client_id: Unique identifier for the client\n        \"\"\"\n        with self._lock:\n            if client_id in self._client_requests:\n                del self._client_requests[client_id]",
    "has_error": true,
    "error_type": "MISUNDERSTANDING",
    "error_description": "The implementation misunderstands the requirement for atomic operations. The is_allowed() method only checks if a request is allowed but doesn't update counters. Instead, a separate record_request() method is provided. This breaks the atomic nature of check-and-update, which could lead to race conditions in multi-threaded environments where multiple threads might check and get allowed, then all record their requests, potentially exceeding the rate limit.",
    "expected_verdict": "FAIL_MAJOR",
    "domain": "coding",
    "difficulty": "hard"
  }
]