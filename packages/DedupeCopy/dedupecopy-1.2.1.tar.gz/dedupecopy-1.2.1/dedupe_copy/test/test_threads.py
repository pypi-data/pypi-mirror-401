"""
Test module for dedupe_copy.threads module.

This module contains comprehensive tests for all thread classes and utility functions
in the dedupe_copy.threads module, including error handling, thread synchronization,
and various threading scenarios.
"""

import unittest
import queue
import threading
import re
import fnmatch
import os
from unittest.mock import MagicMock, patch
from dedupe_copy.threads import (
    DeleteThread,
    ProgressThread,
    ReadThread,
    ResultProcessor,
    WalkThread,
    _is_file_processing_required,
    distribute_work,
    DistributeWorkConfig,
)
from dedupe_copy.config import WalkConfig
from dedupe_copy.manifest import Manifest


class TestIsFileProcessingRequired(unittest.TestCase):
    """Test cases for the _is_file_processing_required utility function."""

    def test_ignored_with_progress_queue(self):
        """Test that ignored files are properly handled and reported to progress queue."""
        filepath = "/tmp/some/file.txt"
        already_processed = set()
        ignore = ["*.txt"]
        extensions = None
        progress_queue = queue.PriorityQueue()

        # Test with fallback loop (no regex)
        result = _is_file_processing_required(
            filepath, already_processed, ignore, extensions, progress_queue
        )

        self.assertFalse(result)
        self.assertFalse(progress_queue.empty())
        item = progress_queue.get()
        self.assertEqual(item[1], "ignored")

    def test_ignored_with_regex(self):
        """Test that ignored files are properly handled using regex optimization."""
        filepath = "/tmp/some/file.txt"
        already_processed = set()
        ignore = ["*.txt"]
        extensions = None
        progress_queue = queue.PriorityQueue()

        # Pre-compile regex as WalkConfig would

        p = fnmatch.translate(os.path.normcase("*.txt"))
        regex = re.compile(p)

        result = _is_file_processing_required(
            filepath,
            already_processed,
            ignore,
            extensions,
            progress_queue,
            ignore_regex=regex,
        )

        self.assertFalse(result)
        self.assertFalse(progress_queue.empty())
        item = progress_queue.get()
        self.assertEqual(item[1], "ignored")
        self.assertEqual(item[3], "*.txt")  # Should identify the specific pattern


class TestDistributeWork(unittest.TestCase):
    """Test cases for the distribute_work function."""

    def setUp(self):
        """Set up test environment."""
        self.src = "/tmp/test"
        self.progress_queue = queue.PriorityQueue()
        self.work_queue = queue.Queue()
        self.walk_queue = queue.Queue()
        self.already_processed = set()

    @patch("dedupe_copy.threads.os.listdir")
    @patch("dedupe_copy.threads._check_is_ignored")
    def test_distribute_work_ignored_directory(self, mock_check_ignored, mock_listdir):
        """Test distribute_work returns early if directory is ignored (line 129 coverage)."""
        mock_check_ignored.return_value = True

        # Create a mock config
        walk_config = MagicMock()
        walk_config.ignore = ["/tmp/test"]
        walk_config.ignore_regex = None

        config = DistributeWorkConfig(
            already_processed=self.already_processed,
            walk_config=walk_config,
            progress_queue=self.progress_queue,
            work_queue=self.work_queue,
            walk_queue=self.walk_queue,
        )

        distribute_work(self.src, config)

        # Verify os.listdir was NOT called
        mock_listdir.assert_not_called()

    @patch("dedupe_copy.threads.os.listdir")
    @patch("dedupe_copy.threads._check_is_ignored")
    def test_distribute_work_listdir_oserror(self, mock_check_ignored, mock_listdir):
        """Test distribute_work handles OSError from listdir (lines 133-136 coverage)."""
        mock_check_ignored.return_value = False
        mock_listdir.side_effect = OSError("Access denied")

        # Create a mock config
        walk_config = MagicMock()
        config = DistributeWorkConfig(
            already_processed=self.already_processed,
            walk_config=walk_config,
            progress_queue=self.progress_queue,
            work_queue=self.work_queue,
            walk_queue=self.walk_queue,
        )

        distribute_work(self.src, config)

        # Verify error reported to progress queue
        self.assertFalse(self.progress_queue.empty())
        _, type_, path, error = self.progress_queue.get()
        self.assertEqual(type_, "error")
        self.assertEqual(path, self.src)
        self.assertIsInstance(error, OSError)


class TestResultProcessor(unittest.TestCase):
    """Test cases for the ResultProcessor thread class."""

    def setUp(self):
        """Set up test environment with reduced incremental save size for faster tests."""
        # Monkey patch the incremental save size to speed up tests
        self.original_save_size = ResultProcessor.INCREMENTAL_SAVE_SIZE
        ResultProcessor.INCREMENTAL_SAVE_SIZE = 2

    def tearDown(self):
        # Restore original value
        ResultProcessor.INCREMENTAL_SAVE_SIZE = self.original_save_size

    def test_result_processor_handles_processing_error(self):
        """Test that ResultProcessor properly handles and logs processing errors."""
        stop_event = threading.Event()
        result_queue = queue.Queue()
        progress_queue = queue.PriorityQueue()
        collisions = MagicMock()
        manifest = MagicMock()

        # This will cause a TypeError when the manifest is accessed
        manifest.__getitem__.side_effect = TypeError("mocked type error")

        # Put a validly structured item in the queue
        result_queue.put(("some_md5", 100, 123.45, "a/file/path"))

        processor = ResultProcessor(
            stop_event,
            result_queue,
            collisions,
            manifest,
            progress_queue=progress_queue,
        )
        processor.start()

        # Give the thread time to process the item and wait for it to finish
        result_queue.join()
        stop_event.set()
        processor.join(timeout=2)

        self.assertFalse(
            processor.is_alive(), "Processor thread should have terminated"
        )

        # Check that an error was logged to the progress queue
        self.assertFalse(progress_queue.empty())

        # Drain the queue to find the error message, as other messages may be present
        error_item = None
        all_items = []
        while not progress_queue.empty():
            item = progress_queue.get()
            all_items.append(item)
            # Error messages have 4 items: priority, type, path, message
            if len(item) == 4 and item[1] == "error":
                error_item = item
                break  # Found the error message

        self.assertIsNotNone(
            error_item, f"Error message not found in progress queue. Found: {all_items}"
        )

        # Now we can safely unpack and assert
        _priority, msg_type, path, error_msg = error_item
        self.assertEqual(msg_type, "error")
        self.assertEqual(path, "a/file/path")
        self.assertIn("ERROR in result processing", error_msg)
        self.assertIn("mocked type error", error_msg)

    def test_result_processor_incremental_save(self):
        """Test that ResultProcessor performs incremental saves at configured intervals."""
        stop_event = threading.Event()
        result_queue = queue.Queue()
        progress_queue = queue.PriorityQueue()
        collisions = MagicMock()
        manifest = MagicMock()
        manifest.md5_data = {}  # Mock the underlying data store

        processor = ResultProcessor(
            stop_event,
            result_queue,
            collisions,
            manifest,
            progress_queue=progress_queue,
        )

        result_queue.put(("md5_1", 100, 123.45, "a/file/1"))
        result_queue.put(("md5_2", 200, 123.46, "a/file/2"))
        result_queue.put(("md5_3", 300, 123.47, "a/file/3"))

        processor.start()
        result_queue.join()
        stop_event.set()
        processor.join(timeout=2)

        # save should be called once after processing the third item
        manifest.save.assert_called_once()
        self.assertFalse(progress_queue.empty())

    def test_result_processor_incremental_save_error(self):
        """Test that ResultProcessor handles and logs errors during incremental saves."""
        stop_event = threading.Event()
        result_queue = queue.Queue()
        progress_queue = queue.PriorityQueue()
        collisions = MagicMock()
        manifest = MagicMock()
        manifest.md5_data = {}
        manifest.save.side_effect = OSError("mocked save error")
        manifest.db_file_path.return_value = "test.db"

        processor = ResultProcessor(
            stop_event,
            result_queue,
            collisions,
            manifest,
            progress_queue=progress_queue,
        )

        result_queue.put(("md5_1", 100, 123.45, "a/file/1"))
        result_queue.put(("md5_2", 200, 123.46, "a/file/2"))
        result_queue.put(("md5_3", 300, 123.47, "a/file/3"))

        processor.start()
        result_queue.join()
        stop_event.set()
        processor.join(timeout=2)

        manifest.save.assert_called_once()
        self.assertFalse(progress_queue.empty())

        # Drain the queue to find the error message
        error_item = None
        all_items = []
        while not progress_queue.empty():
            item = progress_queue.get()
            all_items.append(item)
            if len(item) == 4 and item[1] == "error":
                error_item = item
                break

        self.assertIsNotNone(
            error_item, f"Error message not found in progress queue. Found: {all_items}"
        )

        _priority, msg_type, _, error_msg = error_item
        self.assertEqual(msg_type, "error")
        self.assertIn("ERROR Saving incremental", error_msg)
        self.assertIn("mocked save error", error_msg)

    def test_commit_batch_with_manifest(self):
        """Test _commit_batch updates manifest.read_sources correctly."""
        stop_event = threading.Event()
        result_queue = queue.Queue()
        collisions = MagicMock()
        manifest = MagicMock(spec=Manifest)  # Use spec to pass isinstance check
        manifest.md5_data = MagicMock()
        manifest.read_sources = MagicMock()
        progress_queue = queue.PriorityQueue()

        processor = ResultProcessor(
            stop_event,
            result_queue,
            collisions,
            manifest,
            progress_queue=progress_queue,
        )

        # pylint: disable=protected-access
        processor._local_cache = {
            "md5_1": [("file1.txt", 100, 123.45)],
            "md5_2": [("file2.txt", 200, 123.46)],
        }
        manifest.md5_data.__contains__.return_value = False
        manifest.md5_data.__getitem__.return_value = []

        # pylint: disable=protected-access
        processor._commit_batch()

        # Verify that manifest.read_sources was updated
        manifest.read_sources.__setitem__.assert_any_call("file1.txt", None)
        manifest.read_sources.__setitem__.assert_any_call("file2.txt", None)


class TestReadThread(unittest.TestCase):
    """Test cases for the ReadThread class."""

    @patch("dedupe_copy.threads.read_file", side_effect=OSError("mocked os error"))
    def test_read_thread_handles_os_error(self, mock_read_file):
        """Test that ReadThread properly handles and logs OS errors during file reading."""
        # pylint: disable=unused-argument
        stop_event = threading.Event()
        work_queue = queue.Queue()
        result_queue = queue.Queue()
        progress_queue = queue.PriorityQueue()
        walk_config = WalkConfig()

        work_queue.put("a/file/path")

        reader = ReadThread(
            work_queue,
            result_queue,
            stop_event,
            walk_config=walk_config,
            progress_queue=progress_queue,
        )
        reader.start()

        work_queue.join()
        stop_event.set()
        reader.join(timeout=2)

        self.assertFalse(reader.is_alive(), "Reader thread should have terminated")
        self.assertTrue(result_queue.empty())
        self.assertFalse(progress_queue.empty())

        _priority, msg_type, path, error = progress_queue.get()
        self.assertEqual(msg_type, "error")
        self.assertEqual(path, "a/file/path")
        self.assertIsInstance(error, OSError)
        self.assertIn("mocked os error", str(error))

    @patch("dedupe_copy.threads.time.sleep")
    @patch("dedupe_copy.threads.read_file")
    def test_read_thread_pauses_on_save_event(self, mock_read_file, mock_sleep):
        """Test that ReadThread pauses execution when save event is set."""
        stop_event = threading.Event()
        save_event = threading.Event()
        work_queue = queue.Queue()
        result_queue = queue.Queue()
        walk_config = WalkConfig()
        sleep_called_event = threading.Event()

        def sleep_side_effect(duration):
            if duration == 1:
                sleep_called_event.set()

        mock_sleep.side_effect = sleep_side_effect
        work_queue.put("a/file/path")

        reader = ReadThread(
            work_queue,
            result_queue,
            stop_event,
            walk_config=walk_config,
            save_event=save_event,
        )

        save_event.set()
        reader.start()

        called = sleep_called_event.wait(timeout=2)
        self.assertTrue(called, "Thread did not call sleep(1)")

        self.assertFalse(mock_read_file.called)

        save_event.clear()
        work_queue.join()
        stop_event.set()
        reader.join(timeout=2)

        mock_read_file.assert_called_once_with("a/file/path", hash_algo="md5")
        self.assertFalse(reader.is_alive())


class TestDeleteThread(unittest.TestCase):
    """Test cases for the DeleteThread class."""

    def test_delete_thread_dry_run(self):
        """Test that DeleteThread in dry-run mode logs actions without performing
        actual deletions."""
        stop_event = threading.Event()
        work_queue = queue.Queue()
        progress_queue = queue.PriorityQueue()

        work_queue.put("a/file/path")

        deleter = DeleteThread(
            work_queue,
            stop_event,
            progress_queue=progress_queue,
            dry_run=True,
        )
        deleter.start()

        work_queue.join()
        stop_event.set()
        deleter.join(timeout=2)

        self.assertFalse(deleter.is_alive())
        self.assertFalse(progress_queue.empty())

        _priority, msg_type, message = progress_queue.get()
        self.assertEqual(msg_type, "message")
        self.assertIn("[DRY RUN] Would delete a/file/path", message)


class TestWalkThread(unittest.TestCase):
    """Test cases for the WalkThread class."""

    @patch("dedupe_copy.threads.time.sleep")
    @patch("dedupe_copy.threads.distribute_work")
    def test_walk_thread_pauses_on_save_event(self, mock_distribute_work, mock_sleep):
        """Test that WalkThread pauses execution when save event is set."""
        stop_event = threading.Event()
        save_event = threading.Event()
        walk_queue = queue.Queue()
        work_queue = queue.Queue()
        walk_config = WalkConfig()
        already_processed = set()
        sleep_called_event = threading.Event()

        def sleep_side_effect(duration):
            if duration == 1:
                sleep_called_event.set()

        mock_sleep.side_effect = sleep_side_effect
        walk_queue.put("a/dir/path")

        walker = WalkThread(
            walk_queue,
            stop_event,
            walk_config=walk_config,
            work_queue=work_queue,
            already_processed=already_processed,
            save_event=save_event,
        )

        save_event.set()
        walker.start()

        called = sleep_called_event.wait(timeout=2)
        self.assertTrue(called, "Thread did not call sleep(1)")

        self.assertFalse(mock_distribute_work.called)

        save_event.clear()
        walk_queue.join()
        stop_event.set()
        walker.join(timeout=2)

        self.assertFalse(walker.is_alive())


class TestProgressThread(unittest.TestCase):
    """Test cases for the ProgressThread class."""

    @patch("dedupe_copy.threads.time.sleep")
    def test_progress_thread_pauses_on_save_event(self, mock_sleep):
        """Test that ProgressThread pauses execution when save event is set."""
        stop_event = threading.Event()
        save_event = threading.Event()
        work_queue = queue.Queue()
        result_queue = queue.Queue()
        progress_queue = queue.PriorityQueue()
        walk_queue = queue.Queue()
        sleep_called_event = threading.Event()

        def sleep_side_effect(duration):
            if duration == 1:
                sleep_called_event.set()

        mock_sleep.side_effect = sleep_side_effect

        progresser = ProgressThread(
            work_queue,
            result_queue,
            progress_queue,
            walk_queue=walk_queue,
            stop_event=stop_event,
            save_event=save_event,
        )

        save_event.set()
        progresser.start()

        called = sleep_called_event.wait(timeout=2)
        self.assertTrue(called, "Thread did not call sleep(1)")

        save_event.clear()
        stop_event.set()
        progresser.join(timeout=2)

        self.assertFalse(progresser.is_alive())
