from dataclasses import dataclass
from typing import Any, Callable, Dict, Generic, List, Type, TypeVar, Union

import pytest
from typing_extensions import ParamSpec

# Required for detailed assertion introspection in failures
pytest.register_assert_rewrite(__name__)

P = ParamSpec("P")
T = TypeVar("T")


@dataclass
class TestCase(Generic[P]):
    """Represents a single scenario generated by an agent or user."""

    __test__ = False
    name: str
    input: Dict[str, Any]
    expected: Union[Any, Type[Exception]]
    test_failure_message: str


@dataclass
class TestSuite(Generic[P, T]):
    """A collection of scenarios for a specific target class or function."""

    __test__ = False
    target: Callable[P, T]
    scenarios: List[TestCase[P]]


# --- Custom Collection ---


def pytest_pycollect_makeitem(collector: pytest.Collector, name: str, obj: Any):
    """
    Discovers TestSuite instances and turns them into pytest collectors.
    """
    if isinstance(obj, TestSuite):
        return TestSuiteCollector.from_parent(collector, name=name, suite=obj)


class TestSuiteCollector(pytest.Collector):
    """Groups ScenarioItems under a single Suite heading."""

    def __init__(self, name: str, parent: pytest.Collector, suite: TestSuite, **kwargs):
        super().__init__(name, parent, **kwargs)
        self.suite = suite

    def collect(self):
        for scenario in self.suite.scenarios:
            yield ScenarioItem.from_parent(
                self, name=scenario.name, scenario=scenario, target=self.suite.target
            )


class ScenarioItem(pytest.Item):
    """The actual executable test unit."""

    def __init__(
        self,
        name: str,
        parent: "TestSuiteCollector",
        scenario: TestCase,
        target: Callable,
        **kwargs,
    ):
        super().__init__(name, parent, **kwargs)
        self.scenario = scenario
        self.target = target

    def runtest(self):
        scenario = self.scenario
        target = self.target

        if isinstance(scenario.expected, type) and issubclass(
            scenario.expected, Exception
        ):
            with pytest.raises(scenario.expected):
                target(**scenario.input)
        else:
            instance = target(**scenario.input)
            # Support .render() pattern or direct return
            result = instance.render() if hasattr(instance, "render") else instance

            assert result == scenario.expected, scenario.test_failure_message

    def reportinfo(self):
        return self.path, 0, f"kedge: {self.parent.name} -> {self.name}"

    def repr_failure(self, excinfo, style=None):
        """Simplifies the traceback for Neovim/Console output."""
        if isinstance(excinfo.value, AssertionError):
            return f"Kedge Scenario Failed: {self.scenario.test_failure_message}\n{excinfo.value}"
        return super().repr_failure(excinfo, style=style)


def pytest_addoption(parser):
    """Register the --kedge-summary flag."""
    group = parser.getgroup("kedge")
    group.addoption(
        "--kedge-summary",
        action="store_true",
        dest="kedge_summary",
        default=False,
        help="Print a clean, agent-readable summary of Kedge test results.",
    )


def pytest_terminal_summary(terminalreporter, exitstatus, config):
    """Hooks into the end of the test session to print a custom report."""
    if not config.getoption("kedge_summary"):
        return

    terminalreporter.section("Kedge Agentic Summary")

    passed = terminalreporter.stats.get("passed", [])
    failed = terminalreporter.stats.get("failed", [])

    if failed:
        terminalreporter.write_line("FAILURES DETECTED:", red=True)
        for rep in failed:
            # We extract the scenario name from the nodeid
            scenario_name = rep.nodeid.split("::")[-1]
            terminalreporter.write_line(f"  - ❌ {scenario_name}")
            # Optional: Print the exact error message
            terminalreporter.write_line(
                f"    Reason: {rep.longreprtext.splitlines()[0]}", yellow=True
            )

    if passed:
        terminalreporter.write_line("\nSUCCESSES:", green=True)
        for rep in passed:
            scenario_name = rep.nodeid.split("::")[-1]
            terminalreporter.write_line(f"  - ✅ {scenario_name}")

    terminalreporter.write_line(f"\nFinal Exit Status: {exitstatus}", bold=True)
