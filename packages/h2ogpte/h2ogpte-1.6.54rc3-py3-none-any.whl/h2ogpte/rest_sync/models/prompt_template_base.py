# coding: utf-8

"""
    h2oGPTe REST API

     # Overview   Users can easily interact with the h2oGPTe API through its REST API, allowing HTTP requests from any programming language.  ## Authorization: Getting an API key  Sign up/in at Enterprise h2oGPTe and generate one of the following two types of API keys:   - **Global API key**: If a Collection is not specified when creating a new API Key, that key is considered to be a global API Key. Use global API Keys to grant full user impersonation and system-wide access to all of your work. Anyone with access to one of your global API Keys can create, delete, or interact with any of your past, current, and future Collections, Documents, Chats, and settings.  - **Collection-specific API key**: Use Collection-specific API Keys to grant external access to only Chat with a specified Collection and make related API calls to it. Collection-specific API keys do not allow other API calls, such as creation, deletion, or access to other Collections or Chats.   Access Enterprise h2oGPTe through your [H2O Generative AI](https://genai.h2o.ai/appstore) app store account, available with a freemium tier.  ## Authorization: Using an API key   All h2oGPTe REST API requests must include an API Key in the \"Authorization\" HTTP header, formatted as follows:  ``` Authorization: Bearer sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX ```  ```sh curl -X 'POST' \\   'https://h2ogpte.genai.h2o.ai/api/v1/collections' \\   -H 'accept: application/json' \\   -H 'Content-Type: application/json' \\   -H 'Authorization: Bearer sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' \\   -d '{     \"name\": \"The name of my Collection\",     \"description\": \"The description of my Collection\",     \"embedding_model\": \"BAAI/bge-large-en-v1.5\"   }' ```      ## Interactive h2oGPTe API testing  This page only showcases the h2oGPTe REST API; you can test it directly in the [Swagger UI](https://h2ogpte.genai.h2o.ai/swagger-ui/). Ensure that you are logged into your Enterprise h2oGPTe account. 

    The version of the OpenAPI document: v1.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class PromptTemplateBase(BaseModel):
    """
    PromptTemplateBase
    """ # noqa: E501
    name: Optional[StrictStr] = Field(default=None, description="A name of the prompt template.")
    description: Optional[StrictStr] = Field(default=None, description="A description of the prompt template.")
    lang: Optional[StrictStr] = Field(default=None, description="A language code.")
    system_prompt: Optional[StrictStr] = Field(default=None, description="A system prompt.")
    pre_prompt_query: Optional[StrictStr] = Field(default=None, description="A text that is prepended before the contextual document chunks.")
    prompt_query: Optional[StrictStr] = Field(default=None, description="A text that is appended to the beginning of the user's message.")
    hyde_no_rag_llm_prompt_extension: Optional[StrictStr] = Field(default=None, description="An LLM prompt extension.")
    pre_prompt_summary: Optional[StrictStr] = Field(default=None, description="A prompt that goes before each large piece of text to summarize.")
    prompt_summary: Optional[StrictStr] = Field(default=None, description="A prompt that goes after each large piece of text to summarize.")
    system_prompt_reflection: Optional[StrictStr] = Field(default=None, description="A system prompt for self-reflection.")
    prompt_reflection: Optional[StrictStr] = Field(default=None, description="A template for self-reflection, must contain two occurrences of %s for full previous prompt (including system prompt, document related context and prompts if applicable, and user prompts) and answer")
    auto_gen_description_prompt: Optional[StrictStr] = Field(default=None, description="A prompt to create a description of the collection.")
    auto_gen_document_summary_pre_prompt_summary: Optional[StrictStr] = Field(default=None, description="A `pre_prompt_summary` for summary of a freshly imported document (if enabled).")
    auto_gen_document_summary_prompt_summary: Optional[StrictStr] = Field(default=None, description="A `prompt_summary` for summary of a freshly imported document (if enabled).`")
    auto_gen_document_sample_questions_prompt: Optional[StrictStr] = Field(default=None, description="A prompt to create sample questions for a freshly imported document (if enabled).")
    default_sample_questions: Optional[List[StrictStr]] = Field(default=None, description="Default sample questions in case there are no auto-generated sample questions.")
    image_batch_image_prompt: Optional[StrictStr] = Field(default=None, description="A prompt for each image batch for vision models.")
    image_batch_final_prompt: Optional[StrictStr] = Field(default=None, description="A prompt for each image batch for vision models.")
    __properties: ClassVar[List[str]] = ["name", "description", "lang", "system_prompt", "pre_prompt_query", "prompt_query", "hyde_no_rag_llm_prompt_extension", "pre_prompt_summary", "prompt_summary", "system_prompt_reflection", "prompt_reflection", "auto_gen_description_prompt", "auto_gen_document_summary_pre_prompt_summary", "auto_gen_document_summary_prompt_summary", "auto_gen_document_sample_questions_prompt", "default_sample_questions", "image_batch_image_prompt", "image_batch_final_prompt"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PromptTemplateBase from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PromptTemplateBase from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "name": obj.get("name"),
            "description": obj.get("description"),
            "lang": obj.get("lang"),
            "system_prompt": obj.get("system_prompt"),
            "pre_prompt_query": obj.get("pre_prompt_query"),
            "prompt_query": obj.get("prompt_query"),
            "hyde_no_rag_llm_prompt_extension": obj.get("hyde_no_rag_llm_prompt_extension"),
            "pre_prompt_summary": obj.get("pre_prompt_summary"),
            "prompt_summary": obj.get("prompt_summary"),
            "system_prompt_reflection": obj.get("system_prompt_reflection"),
            "prompt_reflection": obj.get("prompt_reflection"),
            "auto_gen_description_prompt": obj.get("auto_gen_description_prompt"),
            "auto_gen_document_summary_pre_prompt_summary": obj.get("auto_gen_document_summary_pre_prompt_summary"),
            "auto_gen_document_summary_prompt_summary": obj.get("auto_gen_document_summary_prompt_summary"),
            "auto_gen_document_sample_questions_prompt": obj.get("auto_gen_document_sample_questions_prompt"),
            "default_sample_questions": obj.get("default_sample_questions"),
            "image_batch_image_prompt": obj.get("image_batch_image_prompt"),
            "image_batch_final_prompt": obj.get("image_batch_final_prompt")
        })
        return _obj


