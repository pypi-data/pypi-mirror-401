> 本文檔由 AI 生成。如果您發現任何錯誤或有改進建議，歡迎貢獻！ [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/MakeTrainingDataset/zh-TW.md)

此節點透過編碼圖像和文字來準備訓練資料。它接收一個圖像列表和對應的文字描述列表，然後使用 VAE 模型將圖像轉換為潛在表示，並使用 CLIP 模型將文字轉換為條件資料。最終產生的配對潛在表示和條件資料會以列表形式輸出，可供訓練工作流程使用。

## 輸入參數

| 參數名稱 | 資料類型 | 必填 | 數值範圍 | 描述 |
|-----------|-----------|----------|-------|-------------|
| `images` | IMAGE | 是 | N/A | 要編碼的圖像列表。 |
| `vae` | VAE | 是 | N/A | 用於將圖像編碼為潛在表示的 VAE 模型。 |
| `clip` | CLIP | 是 | N/A | 用於將文字編碼為條件資料的 CLIP 模型。 |
| `texts` | STRING | 否 | N/A | 文字描述列表。長度可以是 n（與圖像數量匹配）、1（重複用於所有圖像）或省略（使用空字串）。 |

**參數限制：**
*   `texts` 列表中的項目數量必須為 0、1，或與 `images` 列表中的項目數量完全一致。如果為 0，則所有圖像都使用空字串。如果為 1，則該單一文字將重複用於所有圖像。

## 輸出結果

| 輸出名稱 | 資料類型 | 描述 |
|-------------|-----------|-------------|
| `latents` | LATENT | 潛在字典列表。 |
| `conditioning` | CONDITIONING | 條件資料列表。 |