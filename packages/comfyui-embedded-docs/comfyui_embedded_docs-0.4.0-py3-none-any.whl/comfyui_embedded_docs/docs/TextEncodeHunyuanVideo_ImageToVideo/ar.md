> تم إنشاء هذه الوثيقة بواسطة الذكاء الاصطناعي. إذا وجدت أي أخطاء أو لديك اقتراحات للتحسين، فلا تتردد في المساهمة! [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/TextEncodeHunyuanVideo_ImageToVideo/ar.md)

يقوم عُقدة TextEncodeHunyuanVideo_ImageToVideo بإنشاء بيانات تكييف لتوليد الفيديو من خلال دمج نصوص التوجيه مع تضمينات الصورة. يستخدم العُقدة نموذج CLIP لمعالجة كل من الإدخال النصي والمعلومات البصرية من ناتج رؤية CLIP، ثم يُنشئ رموزًا تمزج بين هذين المصدرين وفقًا للإعداد المحدد لتناوب الصورة.

## المدخلات

| المعامل | نوع البيانات | مطلوب | النطاق | الوصف |
|-----------|-----------|----------|-------|-------------|
| `كليب` | CLIP | نعم | - | نموذج CLIP المستخدم للتقسيم إلى رموز والتشفير |
| `ناتج رؤية الكليب` | CLIP_VISION_OUTPUT | نعم | - | التضمينات البصرية من نموذج رؤية CLIP التي توفر سياق الصورة |
| `الموجه` | STRING | نعم | - | الوصف النصي لتوجيه عملية توليد الفيديو، يدعم الإدخال متعدد الأسطر ونصوص التوجيه الديناميكية |
| `تداخل الصورة` | INT | نعم | 1-512 | مدى تأثير الصورة مقابل نص التوجيه. الرقم الأعلى يعني تأثيرًا أكبر من نص التوجيه. (القيمة الافتراضية: 2) |

## المخرجات

| اسم المُخرج | نوع البيانات | الوصف |
|-------------|-----------|-------------|
| `CONDITIONING` | CONDITIONING | بيانات التكييف التي تجمع بين المعلومات النصية والبصرية لتوليد الفيديو |