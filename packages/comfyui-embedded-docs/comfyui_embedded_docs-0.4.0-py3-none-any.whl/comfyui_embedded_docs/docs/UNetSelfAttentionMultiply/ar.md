> تم إنشاء هذه الوثيقة بواسطة الذكاء الاصطناعي. إذا وجدت أي أخطاء أو لديك اقتراحات للتحسين، فلا تتردد في المساهمة! [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/UNetSelfAttentionMultiply/ar.md)

تُطبق عقدة UNetSelfAttentionMultiply عوامل ضرب على مكونات الاستعلام والمفتاح والقيمة والإخراج في آلية الانتباه الذاتي بنموذج UNet. تتيح لك تحجيم أجزاء مختلفة من عملية حساب الانتباه لتجريب كيفية تأثير أوزان الانتباه على سلوك النموذج.

## المدخلات

| المعامل | نوع البيانات | مطلوب | النطاق | الوصف |
|-----------|-----------|----------|-------|-------------|
| `النموذج` | MODEL | نعم | - | نموذج UNet المراد تعديله بعوامل تحجيم الانتباه |
| `q` | FLOAT | لا | 0.0 - 10.0 | عامل الضرب لمكون الاستعلام (القيمة الافتراضية: 1.0) |
| `k` | FLOAT | لا | 0.0 - 10.0 | عامل الضرب لمكون المفتاح (القيمة الافتراضية: 1.0) |
| `v` | FLOAT | لا | 0.0 - 10.0 | عامل الضرب لمكون القيمة (القيمة الافتراضية: 1.0) |
| `الناتج` | FLOAT | لا | 0.0 - 10.0 | عامل الضرب لمكون الإخراج (القيمة الافتراضية: 1.0) |

## المخرجات

| اسم المُخرج | نوع البيانات | الوصف |
|-------------|-----------|-------------|
| `MODEL` | MODEL | نموذج UNet المعدل مع مكونات انتباه مُحجّمة |