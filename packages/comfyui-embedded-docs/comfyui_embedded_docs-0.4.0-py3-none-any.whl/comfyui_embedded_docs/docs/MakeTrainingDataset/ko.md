> 이 문서는 AI에 의해 생성되었습니다. 오류를 발견하거나 개선 제안이 있으시면 기여해 주세요! [GitHub에서 편집](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/MakeTrainingDataset/ko.md)

이 노드는 이미지와 텍스트를 인코딩하여 학습 데이터를 준비합니다. 이미지 목록과 해당 텍스트 캡션 목록을 받아 VAE 모델을 사용하여 이미지를 잠재 표현으로 변환하고, CLIP 모델을 사용하여 텍스트를 조건화 데이터로 변환합니다. 결과로 생성된 쌍을 이루는 잠재 표현과 조건화 데이터는 목록 형태로 출력되어 학습 워크플로우에서 바로 사용할 수 있습니다.

## 입력

| 매개변수 | 데이터 타입 | 필수 | 범위 | 설명 |
|-----------|-----------|----------|-------|-------------|
| `images` | IMAGE | 예 | 해당 없음 | 인코딩할 이미지 목록입니다. |
| `vae` | VAE | 예 | 해당 없음 | 이미지를 잠재 표현으로 인코딩하는 VAE 모델입니다. |
| `clip` | CLIP | 예 | 해당 없음 | 텍스트를 조건화 데이터로 인코딩하는 CLIP 모델입니다. |
| `texts` | STRING | 아니요 | 해당 없음 | 텍스트 캡션 목록입니다. 길이가 n(이미지 수와 일치), 1(모든 이미지에 반복 적용), 또는 생략(빈 문자열 사용)일 수 있습니다. |

**매개변수 제약 조건:**
*   `texts` 목록의 항목 수는 0, 1이거나 `images` 목록의 항목 수와 정확히 일치해야 합니다. 0인 경우 모든 이미지에 빈 문자열이 사용됩니다. 1인 경우 해당 단일 텍스트가 모든 이미지에 반복 적용됩니다.

## 출력

| 출력 이름 | 데이터 타입 | 설명 |
|-------------|-----------|-------------|
| `latents` | LATENT | 잠재 딕셔너리 목록입니다. |
| `conditioning` | CONDITIONING | 조건화 목록의 목록입니다. |