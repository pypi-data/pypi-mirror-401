> تم إنشاء هذه الوثيقة بواسطة الذكاء الاصطناعي. إذا وجدت أي أخطاء أو لديك اقتراحات للتحسين، فلا تتردد في المساهمة! [Edit on GitHub](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/TrainLoraNode/ar.md)

ينشئ عقدة TrainLoraNode (تدريب نموذج LoRA) ويقوم بتدريب نموذج LoRA (التكيف ذو الرتبة المنخفضة) على نموذج انتشار باستخدام البيانات الكامنة وبيانات التكييف المقدمة. تتيح لك هذه العقدة ضبط النموذج بدقة باستخدام معاملات تدريب ومحسنات ودوال خسارة مخصصة. يخرج العقد النموذج المدرب مع تطبيق LoRA، وأوزان LoRA، ومقاييس خسارة التدريب، وعدد خطوات التدريب الإجمالية المكتملة.

## المدخلات

| المعامل      | نوع البيانات | مطلوب | النطاق | الوصف |
|--------------|--------------|--------|--------|--------|
| `model`      | MODEL        | نعم    | -      | النموذج الذي سيتم تدريب LoRA عليه. |
| `latents`    | LATENT       | نعم    | -      | البيانات الكامنة المستخدمة في التدريب، وتعمل كمجموعة بيانات/مدخل للنموذج. |
| `positive`   | CONDITIONING | نعم    | -      | التكييف الإيجابي المستخدم في التدريب. |
| `batch_size` | INT          | نعم    | 1-10000 | حجم الدفعة المستخدم في التدريب (الافتراضي: 1). |
| `grad_accumulation_steps` | INT | نعم | 1-1024 | عدد خطوات تراكم التدرج المستخدمة في التدريب (الافتراضي: 1). |
| `steps`      | INT          | نعم    | 1-100000 | عدد الخطوات لتدريب LoRA (الافتراضي: 16). |
| `learning_rate` | FLOAT     | نعم    | 0.0000001-1.0 | معدل التعلم المستخدم في التدريب (الافتراضي: 0.0005). |
| `rank`       | INT          | نعم    | 1-128  | رتبة طبقات LoRA (الافتراضي: 8). |
| `optimizer`  | COMBO        | نعم    | "AdamW"<br>"Adam"<br>"SGD"<br>"RMSprop" | المحسن المستخدم في التدريب (الافتراضي: "AdamW"). |
| `loss_function` | COMBO     | نعم    | "MSE"<br>"L1"<br>"Huber"<br>"SmoothL1" | دالة الخسارة المستخدمة في التدريب (الافتراضي: "MSE"). |
| `seed`       | INT          | نعم    | 0-18446744073709551615 | البذرة المستخدمة في التدريب (تُستخدم في المولد لتهيئة أوزان LoRA وأخذ عينات الضوضاء) (الافتراضي: 0). |
| `training_dtype` | COMBO    | نعم    | "bf16"<br>"fp32" | نوع البيانات المستخدم في التدريب (الافتراضي: "bf16"). |
| `lora_dtype` | COMBO        | نعم    | "bf16"<br>"fp32" | نوع البيانات المستخدم لـ LoRA (الافتراضي: "bf16"). |
| `algorithm`  | COMBO        | نعم    | خيارات متعددة متاحة | الخوارزمية المستخدمة في التدريب. |
| `gradient_checkpointing` | BOOLEAN | نعم | - | استخدام التحقق من التدرج للتدريب (الافتراضي: True). |
| `existing_lora` | COMBO    | نعم    | خيارات متعددة متاحة | نموذج LoRA الحالي للإلحاق به. اضبط على None لإنشاء LoRA جديد (الافتراضي: "[None]"). |

**ملاحظة:** يجب أن يتطابق عدد مدخلات التكييف الإيجابي مع عدد الصور الكامنة. إذا تم تقديم تكييف إيجابي واحد فقط مع صور متعددة، فسيتم تكراره تلقائيًا لجميع الصور.

## المخرجات

| اسم المخرج     | نوع البيانات | الوصف |
|----------------|--------------|--------|
| `model_with_lora` | MODEL    | النموذج الأصلي مع تطبيق LoRA المدرب. |
| `lora`         | LORA_MODEL   | أوزان LoRA المدربة التي يمكن حفظها أو تطبيقها على نماذج أخرى. |
| `loss`         | LOSS_MAP     | قاموس يحتوي على قيم خسارة التدريب عبر الزمن. |
| `steps`        | INT          | العدد الإجمالي لخطوات التدريب المكتملة (بما في ذلك أي خطوات سابقة من LoRA موجود). |