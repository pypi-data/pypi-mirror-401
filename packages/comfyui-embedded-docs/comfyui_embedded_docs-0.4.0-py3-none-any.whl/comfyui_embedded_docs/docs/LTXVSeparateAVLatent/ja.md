> このドキュメントは AI によって生成されました。エラーを見つけた場合や改善のご提案がある場合は、ぜひ貢献してください！ [GitHub で編集](https://github.com/Comfy-Org/embedded-docs/blob/main/comfyui_embedded_docs/docs/LTXVSeparateAVLatent/ja.md)

LTXVSeparateAVLatentノードは、結合された視聴覚潜在表現を受け取り、ビデオ用とオーディオ用の2つの異なる部分に分割します。入力潜在表現からサンプルと、存在する場合はノイズマスクを分離し、2つの新しい潜在オブジェクトを生成します。

## 入力

| パラメータ | データ型 | 必須 | 範囲 | 説明 |
|-----------|-----------|----------|-------|-------------|
| `av_latent` | LATENT | はい | N/A | 分離する結合された視聴覚潜在表現。 |

**注記:** 入力潜在表現の`samples`テンソルは、最初の次元（バッチ次元）に沿って少なくとも2つの要素を持つことが期待されます。最初の要素はビデオ潜在表現に、2番目の要素はオーディオ潜在表現に使用されます。`noise_mask`が存在する場合、同様の方法で分割されます。

## 出力

| 出力名 | データ型 | 説明 |
|-------------|-----------|-------------|
| `video_latent` | LATENT | 分離されたビデオデータを含む潜在表現。 |
| `audio_latent` | LATENT | 分離されたオーディオデータを含む潜在表現。 |