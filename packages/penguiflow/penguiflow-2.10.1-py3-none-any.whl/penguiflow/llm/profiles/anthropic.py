"""Anthropic model profiles.

Defines capabilities and configuration for Claude models.
"""

from __future__ import annotations

from . import ModelProfile

PROFILES: dict[str, ModelProfile] = {
    # Claude 4.5 family (latest)
    "claude-opus-4-5": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,  # Anthropic uses tool_use for structured output
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,  # Lossy transformation
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    "claude-opus-4-5-20251101": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    "claude-sonnet-4-5": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,  # 1M available with beta header
        max_output_tokens=64000,
    ),
    "claude-sonnet-4-5-20250929": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    "claude-haiku-4-5": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    "claude-haiku-4-5-20251001": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    # Claude 4.1 family
    "claude-opus-4-1": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=32000,
    ),
    "claude-opus-4-1-20250805": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=32000,
    ),
    # Claude 4.0 family
    "claude-opus-4": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=32000,
    ),
    "claude-opus-4-20250514": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=32000,
    ),
    "claude-sonnet-4": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,  # 1M available with beta header
        max_output_tokens=64000,
    ),
    "claude-sonnet-4-20250514": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    # Claude 3.7 family
    "claude-3-7-sonnet": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,  # Supports extended thinking
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,  # 128K with beta header
    ),
    "claude-3-7-sonnet-20250219": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=64000,
    ),
    # Claude 3.5 family (legacy)
    "claude-3-5-sonnet": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=8192,
    ),
    "claude-3-5-sonnet-20241022": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=8192,
    ),
    "claude-3-5-haiku": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=8192,
    ),
    "claude-3-5-haiku-20241022": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=8192,
    ),
    # Claude 3 family (legacy)
    "claude-3-opus": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=4096,
    ),
    "claude-3-opus-20240229": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=4096,
    ),
    "claude-3-sonnet": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=4096,
    ),
    "claude-3-sonnet-20240229": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=4096,
    ),
    "claude-3-haiku": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=4096,
    ),
    "claude-3-haiku-20240307": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=False,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="anthropic_tool_use",
        schema_transformer_name="AnthropicJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=200000,
        max_output_tokens=4096,
    ),
}
