"""Unit tests for parallel fetch tools."""

from __future__ import annotations

import pytest

from {{ package_name }}.models import ShardRequest, ShardResult
from {{ package_name }}.tools.fetch import fetch_primary, fetch_secondary


class DummyCtx:
    def __init__(self) -> None:
        self.llm_context = {}
        self.tool_context = {}
        self.meta = {}
{% if with_streaming %}
        self.chunks: list[tuple[str, int, str]] = []
{% endif %}

    async def pause(self, *args, **kwargs):  # pragma: no cover - not used in tests
        del args, kwargs
        raise RuntimeError("pause not supported")

    async def emit_chunk(self, *args, **kwargs):  # pragma: no cover - not used in tests
        {% if with_streaming %}stream_id, seq, text = args[:3]
        self.chunks.append((stream_id, seq, text))
        return None
        {% else %}del args, kwargs
        return None{% endif %}


@pytest.mark.asyncio
async def test_fetch_primary_returns_shard() -> None:
    ctx = DummyCtx()
    result = await fetch_primary(ShardRequest(topic="penguins", shard=0), ctx)
    assert isinstance(result, ShardResult)
    assert result.shard == 0
    assert "penguins" in result.text
{% if with_streaming %}
    assert ctx.chunks
{% endif %}


@pytest.mark.asyncio
async def test_fetch_secondary_returns_shard() -> None:
    ctx = DummyCtx()
    result = await fetch_secondary(ShardRequest(topic="ice", shard=1), ctx)
    assert result.shard == 1
    assert "ice" in result.text
