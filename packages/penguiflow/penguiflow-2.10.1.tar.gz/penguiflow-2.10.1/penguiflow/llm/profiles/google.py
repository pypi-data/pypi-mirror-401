"""Google/Gemini model profiles.

Defines capabilities and configuration for Gemini models.
Updated January 2026 with Gemini 3.0, 2.5, and 2.0 model families.

Reference: https://ai.google.dev/gemini-api/docs/models
"""

from __future__ import annotations

from . import ModelProfile

PROFILES: dict[str, ModelProfile] = {
    # Gemini 3.0 family (latest)
    "gemini-3-pro-preview": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=True,  # Supports thinking mode
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=65536,
    ),
    "gemini-3-flash-preview": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=True,  # Supports thinking mode
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=65536,
    ),
    "gemini-3-pro-image-preview": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=65536,
        max_output_tokens=32768,
    ),
    # Gemini 2.5 family
    "gemini-2.5-pro": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=True,  # State-of-the-art thinking model
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=65536,
    ),
    "gemini-2.5-flash": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=True,  # Supports thinking mode
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=65536,
    ),
    "gemini-2.5-flash-lite": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=True,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=65536,
    ),
    # Gemini 2.0 family
    "gemini-2.0-flash": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=8192,
    ),
    "gemini-2.0-flash-lite": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=8192,
    ),
    # Gemini 1.5 family (legacy)
    "gemini-1.5-pro": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=2000000,
        max_output_tokens=8192,
    ),
    "gemini-1.5-pro-latest": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=2000000,
        max_output_tokens=8192,
    ),
    "gemini-1.5-flash": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=8192,
    ),
    "gemini-1.5-flash-latest": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=8192,
    ),
    "gemini-1.5-flash-8b": ModelProfile(
        supports_schema_guided_output=True,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="native",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=True,
        max_context_tokens=1048576,
        max_output_tokens=8192,
    ),
    # Gemini 1.0 family (legacy)
    "gemini-1.0-pro": ModelProfile(
        supports_schema_guided_output=False,
        supports_json_only_output=True,
        supports_tools=True,
        supports_reasoning=False,
        supports_streaming=True,
        default_output_mode="tools",
        native_structured_kind="google_response_schema",
        schema_transformer_name="GoogleJsonSchemaTransformer",
        strict_mode_default=False,
        max_context_tokens=30720,
        max_output_tokens=2048,
    ),
}
