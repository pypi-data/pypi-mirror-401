# EvalVault 환경 설정
# 이 파일을 .env로 복사하고 실제 값을 입력하세요
#
# ┌─────────────────────────────────────────────────────────────┐
# │ 설정 파일 역할 분리                                          │
# ├─────────────────────────────────────────────────────────────┤
# │ .env              → 시크릿, 인프라 설정 (이 파일)             │
# │ config/models.yaml → 모델 프로필 정의 (git 포함)             │
# └─────────────────────────────────────────────────────────────┘

# ================================================
# 프로필 선택
# ================================================
# 사용할 모델 프로필 (config/models.yaml에서 정의)
# - dev: 개발용 경량 모델 (gemma3:1b, qwen3-embedding:0.6b)
# - prod: 운영용 고성능 모델 (gpt-oss-safeguard:20b, qwen3-embedding:8b)
# - openai: OpenAI API 사용 (gpt-5-mini, text-embedding-3-small)
EVALVAULT_PROFILE=dev
# SQLite DB 경로 (API/CLI 공통)
# EVALVAULT_DB_PATH=data/db/evalvault.db
# 도메인 메모리 DB 경로
# EVALVAULT_MEMORY_DB_PATH=data/db/evalvault_memory.db

# ================================================
# Ollama 서버 설정 (폐쇄망)
# ================================================
# 프로필이 dev 또는 prod일 때 사용
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120
# Tool/function calling 지원 모델 (콤마로 구분)
# - 지원 여부 확인: `ollama show <model>` -> Capabilities에 tools 표시
# - 예시: OLLAMA_TOOL_MODELS=gpt-oss:120b,gpt-oss-safeguard:120b,gpt-oss-safeguard:20b
# OLLAMA_TOOL_MODELS=

# ================================================
# OpenAI 설정 (외부망)
# ================================================
# 프로필이 openai일 때 필요
OPENAI_API_KEY=sk-your-api-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1  # 커스텀 엔드포인트 (선택)

# ================================================
# vLLM 설정 (OpenAI-compatible)
# ================================================
# 프로필이 vllm일 때 필요
# VLLM_BASE_URL=http://localhost:8001/v1
# VLLM_API_KEY=local
# VLLM_MODEL=gpt-oss-120b
# VLLM_EMBEDDING_MODEL=qwen3-embedding:0.6b
# VLLM_EMBEDDING_BASE_URL=http://localhost:8002/v1

# ================================================
# Faithfulness fallback 설정 (선택)
# ================================================
# Ragas faithfulness 실패 시, faithfulness만 더 큰 모델로 재평가합니다.
# FAITHFULNESS_FALLBACK_PROVIDER=ollama
# FAITHFULNESS_FALLBACK_MODEL=gpt-oss-safeguard:20b
# vLLM 예시:
# FAITHFULNESS_FALLBACK_PROVIDER=vllm
# FAITHFULNESS_FALLBACK_MODEL=gpt-oss-120b

# ================================================
# Azure OpenAI 설정 (선택 - 엔터프라이즈)
# ================================================
# AZURE_API_KEY=your-azure-api-key
# AZURE_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_DEPLOYMENT=gpt-4
# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
# AZURE_API_VERSION=2024-02-15-preview

# ================================================
# Langfuse 설정 (셀프호스팅)
# ================================================
# LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
# LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
# LANGFUSE_HOST=http://localhost:3000

# ================================================
# MLflow 설정 (선택)
# ================================================
# MLFLOW_TRACKING_URI=http://localhost:5000
# MLFLOW_EXPERIMENT_NAME=evalvault

# ================================================
# PostgreSQL 설정 (선택 - 프로덕션 스토리지)
# ================================================
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DATABASE=evalvault
# POSTGRES_USER=postgres
# POSTGRES_PASSWORD=your-password

# ================================================
# CORS / Frontend 설정 (React dev)
# ================================================
# React 프론트에서 API를 직접 호출할 때만 필요
# CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# Vite 프론트 환경 변수는 frontend/.env에 설정하세요 (둘 중 하나)
# VITE_API_PROXY_TARGET=http://localhost:8000
# VITE_API_BASE_URL=http://localhost:8000/api/v1

# ================================================
# 참고: 모델 설정
# ================================================
# 모델명과 옵션은 config/models.yaml에서 관리합니다.
# 환경변수가 아닌 YAML 파일로 관리하여:
# - 버전 관리 가능 (git)
# - 팀 간 일관된 설정 공유
# - 모델 변경 이력 추적
