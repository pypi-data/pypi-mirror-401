# RAG 평가 분석 보고서
### run_id: **8f825b22-87f1-4d9b-b3a0-8ff65dbec2c5**

---

## 1. 요약
모델 **ollama/gpt-oss-safeguard:20b** 가 **e2e-auto-insurance-qa-korean** 데이터셋에서 18개의 테스트를 수행했지만 전체 **pass rate** 는 0%로, 가장 낮은 지표인 **answer_relevancy**(평균 0.566) 가 기준 0.7을 크게 하회했습니다.

- **지표**: Faithfulness는 평균 0.833(통과) / Answer Relevancy는 평균 0.566(위험)
- **원인**: 답변과 문맥이 불일치하여 관련성 저하 → “컨텍스트‑답변 정합성”에 대한 품질 저하 (E1, E2, E3)
- **사용자 영향**: 실질적으로 요구되는 정보를 반영하지 못해 사용자에게 신뢰도 손실과 인지부하가 증가

---

## 2. 지표 스코어카드

| Metric | 평균 | Threshold | Pass Rate | 상태 |
|--------|-------|-----------|------------|------|
| Faithfulness | 0.833 | 0.700 | 0.833 | ✅ Pass |
| Answer Relevancy | 0.566 | 0.700 | 0.055 | ⚠️ Risk |

> **주요 사항**
> - Faithfulness 0.833 > 0.7 → 대부분의 경우 참고 문맥이 충분히 반영됨.
> - Answer Relevancy 0.566 < 0.7 → 단 1개의 테스트(“auto‑015”) 를 제외하면 대부분 < 0.7 (특히 *E1*, *E2*, *E3*).

---

## 3. 데이터 품질 / 신뢰도
| 항목 | 결론 |
|------|------|
| 샘플 수 | **18**(표본 수가 적음). 분석 결과를 일반화하기 어려움. |
| 커버리지 | 1.0(모든 문서에 대해 테스트)   |
| 경고 | “추가 데이터 필요” 및 “실행 이력 부족”으로 인해 추세 분석 불가. |
| 결함 | None (미리 정의된 품질 체크는 전혀 실패하지 않음). |

> **결론**: 샘플이 제한적이며, 추세/장기 개선을 위한 과거 실행 기록이 없으므로, **추가 데이터와 반복 실행**이 필요합니다.

---

## 4. 증거 기반 인사이트

| Priority Highlight | Test Case | Metric(s) | 분석 힌트 | 증거 |
|---------------------|-----------|-----------|-----------|------|
| **high‑impact** | *auto‑007* | Faithfulness 0.0, Relevancy 0.495 | “컨텍스트‑답변 정합성 체크 필요” | [E1] |
| **high‑impact** | *auto‑010* | Faithfulness 0.0, Relevancy 0.632 | “컨텍스트‑답변 정합성 체크 필요” | [E2] |
| **high‑impact** | *auto‑003* | Faithfulness 0.0, Relevancy 0.715 | “보장 내용을 과장” | [E3] |
| **가중치 위기** | *auto‑015* | Faithfulness 1.0, Relevancy 0.440 | “정답이 올바르지만 문맥이 부정확” | [E4] |
| **가중치 위기** | *auto‑005* | Faithfulness 1.0, Relevancy 0.442 | “정답은 1억 원이지만 문맥이 과도한 상세 설명에 시맨틱 가려짐” | [E5] |
| **가중치 위기** | *auto‑017* | Faithfulness 1.0, Relevancy 0.446 | “전화 번호가 정정리된 정답이지만 문맥이 불명확” | [E6] |

> **내비게이션**: 가장 불량한 사례를 모두 “사실형” 질문으로 식별했으며, 각 응답이 주어진 문맥에서 핵심정보를 정확히 반영하거나 문맥과 일치하는지 확인이 필수적입니다.

---

## 5. 원인 가설

1. **컨텍스트‑답변 정합성 부족**
   - *E1* 및 *E2*에서 모델이 문맥 일부를 잘못 해석해 정답을 제공하였지만 **Faithfulness 0.0** 으로 실제 문장을 인용할 수 없었다.
2. **Prompt‑Alignment 이슈**
   - “보험료 할증/할인”에 대한 질문(예: *auto‑015*)에서는 정답이 문맥에 존재하지만 **Answer Relevancy** 가 0.44 아래로 낮아, Prompt에 문맥 활용이 미흡한 것으로 추정.
3. **Embedding 모델 성능**
   - **qwen3‑embedding:8b** 를 사용했으나, 한 문장 정도의 문맥을 제대로 연계하지 못해 중요 정보를 끌어오지 못했을 가능성이 있음.

> **근거**: Root cause 데이터에서 “answer_relevancy” 가 기준 이하라는 명시가 있으며, 상세 사례 E1–E6 가 이를 뒷받침합니다.

---

## 6. 개선 제안

| 개선 방향 | 구체적 조치 | 기대 효과 |
|-----------|------------|-----------|
| **Context enrichment** | 문맥 제공 시, 가장 관련성 높은 문장 우선 선택 및 길이 제한 → *E1*, *E2* 오류 방지 | Relevancy 0.7 이상 달성 |
| **Prompt re‑engineering** | “정답이 무엇인가요?” 등 사실형 질문에 대한 명확 지시어 삽입 | Faithfulness 1.0 유지, 불필요 정보 배제 |
| **Dataset augmentation** | “자기신체사고 보상액”, “결제 옵션 할증” 같은 예시를 확대 | 다양성 증가, 높은 스코어일수 확장 |
| **Evaluation‑feedback loop** | 각 테스트 케이스에 대한 상세 정규화 및 재평가 자동 트리거 | 지속적 개선 추적 |
| **Model fine‑tuning** | qwen‑3‑embedding 모델 파인튜닝 → 문맥-정답 매핑 향상 | Relevancy 개선 가능 |

> **유의**: 초기 개선 단계에서 10~20% 비용(≈$0.25) 내부에서 재실행해 피드백 루프를 검증합니다.

---

## 7. 다음 단계

1. **추가 테스트 케이스 도입** – 50+ 질문으로 샘플 확장.
2. **과거 실행 기록 수집** – 트렌드·성능 변화를 분석하기 위한 메타데이터 확보.
3. **문맥 추출 알고리즘 재설계** – 문서 수동으로 선별된 핵심 문장과 비슷한 임베딩 우선순위 적용.
4. **품질 체크 도입** – 각 테스트 케이스에 대해 “정확성”, “불일치 스코어”등 추가 검증.
5. **사용자 피드백 수집** – 실제 사용자 시나리오에서 인지부하 및 신뢰 지표를 평가.

---

## 8. 부록 (산출물 목록)

| 파일 | 용도 |
|------|------|
| `causal_analysis.json` | 원인 분석 결과 |
| `load_data.json` | 데이터 로드 로그 |
| `nlp_analysis.json` | 토큰/어휘 통계 |
| `pattern_detection.json` | 패턴/루트 원인 목록 |
| `priority_summary.json` | 높은 영향 케이스 요약 |
| `ragas_eval.json` | 전반적 평가 |
| `root_cause.json` | 근본 원인 리포트 |
| `statistics.json` | 통계 수치 |
| `trend_detection.json` | 추세 분석 |
| `statistics.json` | 기타 통계 |
| `trend_detection.json` | 트렌드 분석 |

> **Note**: 현재 테스트 시나리오는 짧고 표본 수가 18개에 불과하므로, 추후 **추가 데이터** 확보와 장기 실행 경로 설계가 필수입니다.

---
