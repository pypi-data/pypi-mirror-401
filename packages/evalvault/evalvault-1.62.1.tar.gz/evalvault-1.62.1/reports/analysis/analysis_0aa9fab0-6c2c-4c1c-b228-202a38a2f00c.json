{
  "intent": "generate_detailed",
  "pipeline_id": "92c29866-b73b-4ce9-b738-148f49d393f7",
  "is_complete": true,
  "duration_ms": 85759,
  "started_at": "2026-01-09T09:30:50.021401",
  "finished_at": "2026-01-09T09:32:15.781013",
  "final_output": {
    "report": {
      "report": "# RAG 평가 분석 보고서\n\n## 요약  \n- **실행 ID**: `0aa9fab0-6c2c-4c1c-b228-202a38a2f00c`  \n- **데이터셋**: `test_dataset v1.0.0`  \n- **모델**: `ollama/gpt-oss-safeguard:20b`  \n- **전체 테스트 케이스**: 4  \n- **총 통과율**: **50 %**  \n- **평균 스코어**: **0.692**  \n- **주요 KPI**  \n  - `faithfulness`: **0.50** (목표 0.70 미달) → 실패  \n  - `answer_relevancy`: **0.884** (목표 0.70 초과) → 성공  \n\n세 명의 고충량 테스트 케이스는 `faithfulness` 지표가 0 %로 가장 낮은 점수를 기록했습니다. 이는 `What is Python?` 와 `What is RAG?` 라는 사실 기반 질문에 대한 답변이 문맥과 불일치하거나 불완전하게 제공되었기 때문입니다.\n\n## 문제 진단  \n\n| 테스트 케이스 | 실패 지표 | 평균 스코어 | 부족한 점 | 비고 |\n|------|----------|------------|----------|------|\n| **test_001** | faithfulness | 0.418 | “Python은 고수준 프로그래밍 언어”만 제시; 핵심 ‘해석형’ 정보 누락 | [E1] |\n| **test_003** | faithfulness | 0.454 | “RAG는 Retrieval‑Augmented Generation이란 약자”만 언급; 실제 정의와 차이점 간과 | [E2] |\n| **test_002** | ― | 0.936 | 정확하고 핵심 문장 포함 | [E3] |\n| **test_004** | ― | 0.959 | 상세한 용어와 프로세스 포함 | [E4] |\n\n*문제 핵심*: **faithfulness** 점수가 0.70 이하인 사안이 두 번 발생 → “컨텍스트-답변 정합성”이 충분히 확인되지 않음.  \n*추정 원인*  \n1. 검색 컨텍스트(핵심 정보)를 모델이 완전하게 활용하지 못함.  \n2. 답변 생성 시 “정확한 인용” 없이 압축적인 설명을 제공함.\n\n## 증거 기반 분석  \n\n- **test_001**  \n  - 질문: *What is Python?*  \n  - 정답: *Python은 고수준 해석형 프로그래밍 언어*  \n  - 모델 답변: *Python은 고수준 프로그래밍 언어* → **해석형**이 빠져 신뢰성 저하.  \n  - 컨텍스트: “Python is a programming language” / “Python was created by Guido van Rossum”.  \n  - **faithfulness**: 0.0 → [E1]\n\n- **test_003**  \n  - 질문: *What is RAG?*  \n  - 정답: *RAG는 검색과 생성이 결합되어 LLM 결과를 향상시키는 기술*  \n  - 모델 답변: *RAG stands for Retrieval‑Augmented Generation* → **정의만 전달**, 실제 기능 설명 부족.  \n  - 컨텍스트: “RAG combines retrieval and generation”, “RAG improves LLM responses”.  \n  - **faithfulness**: 0.0 → [E2]\n\n- **test_002** / **test_004**는 모두 **faithfulness** 1.0을 기록하여, 모델이 사실 기반 질문에 대해 잘 처리할 수 있음을 보여준다. 이 두 사례에서는 문맥과 답변이 일치하고, 답변이 충분히 종합적이다.\n\n- **전반적 패턴**:  \n  - `Top keyword: \"is\"`, `question_type: \"factual\"`이 높은 비중을 차지함.  \n  - `answer_relevancy`는 대부분 높은 편(0.84‑0.92)이며, 주된 문제는 정합성에 한정되어 있음.\n\n## 개선 제안  \n\n| 영역 | 제안 | 근거 |\n|------|------|------|\n| **컨텍스트 활용** | 1. 검색 결과를 답변 생성 시 **강제 인용** 구조로 삽입(예: “출처: …”) <br> 2. **컨텍스트 스코어링**을 선행하여 가장 핵심 정보를 보강하여 답변에 포함 | - 테스트 사례[E1, E2]에서 컨텍스트가 활용되지 않은 점, <br> - `faithfulness` 개선을 위한 정합성 강화 |\n| **프롬프트 설계** | 1. “정확한 설명과 함께 출처를 명시하라”는 명시적 지시 <br> 2. 질문이 `factual`인 경우 **정확도 점검** 프롬프트 삽입 | - `analysis_hints`(문맥-답변 정합성 점검 필요)가 이미 제시됨 |\n| **품질 체크** | 1. **자동 정합성 검사**(컨텍스트‑답변 차이점 비교) <br> 2. `faithfulness`가 0.7 미달 시 **재검색** 또는 **다른 문서** 시도 | - `metrics_evaluated`에 `faithfulness`가 포함되어 있으므로, 자동화 가능 |\n| **데이터 확장** | 1. 추가적인 `factual` 유형 질문과 그에 대한 다수의 컨텍스트 사례를 수집 <br> 2. `analysis_hints`를 더 세분화 (예: “코드 예시를 포함하라”) | - 향후 변동 추세(“pass_rate down” )를 보완하려면 더 많은 데이터를 사용해 기계 학습을 재훈련 가능 |\n\n## 다음 단계  \n\n1. **리포트 기반 리펙터링**  \n   - 모델 프롬프트 및 검색 파이프라인에 “출처 기반 인용”을 요구하도록 수정.  \n   - 정합성 점검 로직을 추가하고, `faithfulness`가 0.7 미만일 경우 자동 재검색을 트리거.\n\n2. **추가 테스트 실행**  \n   - `factual` 유형의 다수 샘플을 도입하여 `faithfulness` 개선 여부를 실험.  \n   - `threshold` 기준 재검토(현재 0.7)와 실제 사용자 시나리오에 맞는 목표 재정립.\n\n3. **모델/연산 리소스 검토**  \n   - 실행 비용(0.051 USD) 및 토큰량(18,642)을 고려하여, 모델 크기와 API 호출 수를 조정.\n\n4. **다음 평가 주기**  \n   - 개선 후 `faithfulness` 목표 0.75 이상, `answer_relevancy` 0.90 이상을 목표로 재평가.  \n   - `pass_rate` 상승 동향을 모니터링하면서, **bottom_percentile** 케이스를 20 % 이하로 감소.\n\n---\n\n*필요 시 추가 데이터(문맥이 풍부한 사례, 모델의 내부 로깅 등)를 수집해 분석을 보완할 수 있습니다.*",
      "format": "markdown",
      "llm_used": true,
      "llm_model": "ollama/gpt-oss-safeguard:20b",
      "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
      "summary": {
        "report_type": "analysis",
        "total_evidence": 4,
        "has_run": true
      },
      "evidence": [
        {
          "test_case_id": "test_001",
          "avg_score": 0.4183,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is Python?",
          "answer": "Python is a high-level programming language.",
          "contexts": [
            "Python is a programming language",
            "Python was created by Guido van Rossum"
          ],
          "ground_truth": "Python is a high-level interpreted programming language.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.8366828943604284
          },
          "evidence_id": "E1"
        },
        {
          "test_case_id": "test_003",
          "avg_score": 0.4544,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is RAG?",
          "answer": "RAG stands for Retrieval-Augmented Generation.",
          "contexts": [
            "RAG combines retrieval and generation",
            "RAG improves LLM responses"
          ],
          "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.9087545725582776
          },
          "evidence_id": "E2"
        },
        {
          "test_case_id": "test_002",
          "avg_score": 0.9362,
          "failed_metrics": [],
          "question": "What is machine learning?",
          "answer": "Machine learning is a subset of AI.",
          "contexts": [
            "ML is part of AI",
            "ML uses algorithms to learn from data"
          ],
          "ground_truth": "Machine learning is a method of data analysis that automates analytical model building.",
          "metrics": {
            "faithfulness": 1.0,
            "answer_relevancy": 0.8724614057329397
          },
          "evidence_id": "E3"
        },
        {
          "test_case_id": "test_004",
          "avg_score": 0.9591,
          "failed_metrics": [],
          "question": "What is TDD?",
          "answer": "TDD means Test-Driven Development.",
          "contexts": [
            "Test-Driven Development",
            "Write tests first",
            "Red-Green-Refactor cycle"
          ],
          "ground_truth": "TDD is a software development approach where tests are written before code.",
          "metrics": {
            "faithfulness": 1.0,
            "answer_relevancy": 0.9181316279283243
          },
          "evidence_id": "E4"
        }
      ]
    }
  },
  "node_results": {
    "load_data": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "loaded": true,
        "query": "generate_detailed",
        "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
        "additional_params": {
          "evaluation_run": {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:27:38.337182",
            "finished_at": "2026-01-09T09:30:49.992680",
            "results": [
              {
                "test_case_id": "test_001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8366828943604284,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4550,
                "latency_ms": 55617,
                "cost_usd": 0.0125825,
                "trace_id": null,
                "started_at": "2026-01-09T09:27:38.337382",
                "finished_at": "2026-01-09T09:28:33.954776",
                "question": "What is Python?",
                "answer": "Python is a high-level programming language.",
                "contexts": [
                  "Python is a programming language",
                  "Python was created by Guido van Rossum"
                ],
                "ground_truth": "Python is a high-level interpreted programming language."
              },
              {
                "test_case_id": "test_002",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8724614057329397,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4524,
                "latency_ms": 43321,
                "cost_usd": 0.012547500000000001,
                "trace_id": null,
                "started_at": "2026-01-09T09:28:33.954978",
                "finished_at": "2026-01-09T09:29:17.276445",
                "question": "What is machine learning?",
                "answer": "Machine learning is a subset of AI.",
                "contexts": [
                  "ML is part of AI",
                  "ML uses algorithms to learn from data"
                ],
                "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
              },
              {
                "test_case_id": "test_003",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9087545725582776,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4660,
                "latency_ms": 41342,
                "cost_usd": 0.012925,
                "trace_id": null,
                "started_at": "2026-01-09T09:29:17.276532",
                "finished_at": "2026-01-09T09:29:58.619119",
                "question": "What is RAG?",
                "answer": "RAG stands for Retrieval-Augmented Generation.",
                "contexts": [
                  "RAG combines retrieval and generation",
                  "RAG improves LLM responses"
                ],
                "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
              },
              {
                "test_case_id": "test_004",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9181316279283243,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4908,
                "latency_ms": 51373,
                "cost_usd": 0.01353,
                "trace_id": null,
                "started_at": "2026-01-09T09:29:58.619185",
                "finished_at": "2026-01-09T09:30:49.992357",
                "question": "What is TDD?",
                "answer": "TDD means Test-Driven Development.",
                "contexts": [
                  "Test-Driven Development",
                  "Write tests first",
                  "Red-Green-Refactor cycle"
                ],
                "ground_truth": "TDD is a software development approach where tests are written before code."
              }
            ],
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          "report_type": "analysis",
          "use_llm_report": true
        },
        "run": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "dataset_name": "test_dataset",
          "dataset_version": "1.0.0",
          "model_name": "ollama/gpt-oss-safeguard:20b",
          "started_at": "2026-01-09T09:27:38.337182",
          "finished_at": "2026-01-09T09:30:49.992680",
          "results": [
            {
              "test_case_id": "test_001",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 0.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.8366828943604284,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4550,
              "latency_ms": 55617,
              "cost_usd": 0.0125825,
              "trace_id": null,
              "started_at": "2026-01-09T09:27:38.337382",
              "finished_at": "2026-01-09T09:28:33.954776",
              "question": "What is Python?",
              "answer": "Python is a high-level programming language.",
              "contexts": [
                "Python is a programming language",
                "Python was created by Guido van Rossum"
              ],
              "ground_truth": "Python is a high-level interpreted programming language."
            },
            {
              "test_case_id": "test_002",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 1.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.8724614057329397,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4524,
              "latency_ms": 43321,
              "cost_usd": 0.012547500000000001,
              "trace_id": null,
              "started_at": "2026-01-09T09:28:33.954978",
              "finished_at": "2026-01-09T09:29:17.276445",
              "question": "What is machine learning?",
              "answer": "Machine learning is a subset of AI.",
              "contexts": [
                "ML is part of AI",
                "ML uses algorithms to learn from data"
              ],
              "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
            },
            {
              "test_case_id": "test_003",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 0.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.9087545725582776,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4660,
              "latency_ms": 41342,
              "cost_usd": 0.012925,
              "trace_id": null,
              "started_at": "2026-01-09T09:29:17.276532",
              "finished_at": "2026-01-09T09:29:58.619119",
              "question": "What is RAG?",
              "answer": "RAG stands for Retrieval-Augmented Generation.",
              "contexts": [
                "RAG combines retrieval and generation",
                "RAG improves LLM responses"
              ],
              "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
            },
            {
              "test_case_id": "test_004",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 1.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.9181316279283243,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4908,
              "latency_ms": 51373,
              "cost_usd": 0.01353,
              "trace_id": null,
              "started_at": "2026-01-09T09:29:58.619185",
              "finished_at": "2026-01-09T09:30:49.992357",
              "question": "What is TDD?",
              "answer": "TDD means Test-Driven Development.",
              "contexts": [
                "Test-Driven Development",
                "Write tests first",
                "Red-Green-Refactor cycle"
              ],
              "ground_truth": "TDD is a software development approach where tests are written before code."
            }
          ],
          "metrics_evaluated": [
            "faithfulness",
            "answer_relevancy"
          ],
          "thresholds": {
            "faithfulness": 0.7,
            "answer_relevancy": 0.7
          },
          "total_tokens": 18642,
          "total_cost_usd": 0.051585,
          "langfuse_trace_id": null,
          "tracker_metadata": {
            "run_mode": "full"
          },
          "retrieval_metadata": {}
        },
        "metrics": {
          "faithfulness": [
            0.0,
            1.0,
            0.0,
            1.0
          ],
          "answer_relevancy": [
            0.8366828943604284,
            0.8724614057329397,
            0.9087545725582776,
            0.9181316279283243
          ]
        },
        "summary": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "dataset_name": "test_dataset",
          "dataset_version": "1.0.0",
          "model_name": "ollama/gpt-oss-safeguard:20b",
          "started_at": "2026-01-09T09:27:38.337182",
          "finished_at": "2026-01-09T09:30:49.992680",
          "total_test_cases": 4,
          "passed_test_cases": 2,
          "pass_rate": 0.5,
          "total_tokens": 18642,
          "total_cost_usd": 0.051585,
          "duration_seconds": 191.655498,
          "tracker_metadata": {
            "run_mode": "full"
          },
          "metrics_evaluated": [
            "faithfulness",
            "answer_relevancy"
          ],
          "run_mode": "full",
          "thresholds": {
            "faithfulness": 0.7,
            "answer_relevancy": 0.7
          },
          "avg_faithfulness": 0.5,
          "avg_answer_relevancy": 0.8840076251449925
        }
      }
    },
    "load_runs": {
      "status": "completed",
      "error": null,
      "duration_ms": 4,
      "output": {
        "runs": [
          {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:27:38.337182",
            "finished_at": "2026-01-09T09:30:49.992680",
            "results": [
              {
                "test_case_id": "test_001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8366828943604284,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4550,
                "latency_ms": 55617,
                "cost_usd": 0.0125825,
                "trace_id": null,
                "started_at": "2026-01-09T09:27:38.337382",
                "finished_at": "2026-01-09T09:28:33.954776",
                "question": "What is Python?",
                "answer": "Python is a high-level programming language.",
                "contexts": [
                  "Python is a programming language",
                  "Python was created by Guido van Rossum"
                ],
                "ground_truth": "Python is a high-level interpreted programming language."
              },
              {
                "test_case_id": "test_002",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8724614057329397,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4524,
                "latency_ms": 43321,
                "cost_usd": 0.012547500000000001,
                "trace_id": null,
                "started_at": "2026-01-09T09:28:33.954978",
                "finished_at": "2026-01-09T09:29:17.276445",
                "question": "What is machine learning?",
                "answer": "Machine learning is a subset of AI.",
                "contexts": [
                  "ML is part of AI",
                  "ML uses algorithms to learn from data"
                ],
                "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
              },
              {
                "test_case_id": "test_003",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9087545725582776,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4660,
                "latency_ms": 41342,
                "cost_usd": 0.012925,
                "trace_id": null,
                "started_at": "2026-01-09T09:29:17.276532",
                "finished_at": "2026-01-09T09:29:58.619119",
                "question": "What is RAG?",
                "answer": "RAG stands for Retrieval-Augmented Generation.",
                "contexts": [
                  "RAG combines retrieval and generation",
                  "RAG improves LLM responses"
                ],
                "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
              },
              {
                "test_case_id": "test_004",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9181316279283243,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4908,
                "latency_ms": 51373,
                "cost_usd": 0.01353,
                "trace_id": null,
                "started_at": "2026-01-09T09:29:58.619185",
                "finished_at": "2026-01-09T09:30:49.992357",
                "question": "What is TDD?",
                "answer": "TDD means Test-Driven Development.",
                "contexts": [
                  "Test-Driven Development",
                  "Write tests first",
                  "Red-Green-Refactor cycle"
                ],
                "ground_truth": "TDD is a software development approach where tests are written before code."
              }
            ],
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "9fbf4776-9f5b-4c4b-ba08-c556032cee86",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:24:21.002694",
            "finished_at": "2026-01-09T09:24:56.964326",
            "results": [
              {
                "test_case_id": "test_001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 12137,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:21.002915",
                "finished_at": "2026-01-09T09:24:33.140065",
                "question": "What is Python?",
                "answer": "Python is a high-level programming language.",
                "contexts": [
                  "Python is a programming language",
                  "Python was created by Guido van Rossum"
                ],
                "ground_truth": "Python is a high-level interpreted programming language."
              },
              {
                "test_case_id": "test_002",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 7959,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:33.140190",
                "finished_at": "2026-01-09T09:24:41.100049",
                "question": "What is machine learning?",
                "answer": "Machine learning is a subset of AI.",
                "contexts": [
                  "ML is part of AI",
                  "ML uses algorithms to learn from data"
                ],
                "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
              },
              {
                "test_case_id": "test_003",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 7968,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:41.100115",
                "finished_at": "2026-01-09T09:24:49.068845",
                "question": "What is RAG?",
                "answer": "RAG stands for Retrieval-Augmented Generation.",
                "contexts": [
                  "RAG combines retrieval and generation",
                  "RAG improves LLM responses"
                ],
                "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
              },
              {
                "test_case_id": "test_004",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 7895,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:49.068887",
                "finished_at": "2026-01-09T09:24:56.964077",
                "question": "What is TDD?",
                "answer": "TDD means Test-Driven Development.",
                "contexts": [
                  "Test-Driven Development",
                  "Write tests first",
                  "Red-Green-Refactor cycle"
                ],
                "ground_truth": "TDD is a software development approach where tests are written before code."
              }
            ],
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "a491fa0e-208d-4a34-acc6-2aba629dd0c3",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:14.026053",
            "finished_at": "2026-01-09T08:14:15.026053",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "f042196b-1c77-463c-b695-3a5b938e349f",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.938368",
            "finished_at": "2026-01-09T08:14:14.938368",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "702cb7d4-6b3d-4ec8-9f02-19465c377e52",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.875276",
            "finished_at": "2026-01-09T08:14:14.875276",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "1d968863-7d66-4327-8a62-a885bab741d4",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.840518",
            "finished_at": "2026-01-09T08:14:14.840518",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          }
        ],
        "summaries": [
          {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:27:38.337182",
            "finished_at": "2026-01-09T09:30:49.992680",
            "total_test_cases": 4,
            "passed_test_cases": 2,
            "pass_rate": 0.5,
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "duration_seconds": 191.655498,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "avg_faithfulness": 0.5,
            "avg_answer_relevancy": 0.8840076251449925
          },
          {
            "run_id": "9fbf4776-9f5b-4c4b-ba08-c556032cee86",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:24:21.002694",
            "finished_at": "2026-01-09T09:24:56.964326",
            "total_test_cases": 4,
            "passed_test_cases": 0,
            "pass_rate": 0.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 35.961632,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "avg_faithfulness": 0.0,
            "avg_answer_relevancy": 0.0
          },
          {
            "run_id": "a491fa0e-208d-4a34-acc6-2aba629dd0c3",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:14.026053",
            "finished_at": "2026-01-09T08:14:15.026053",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          },
          {
            "run_id": "f042196b-1c77-463c-b695-3a5b938e349f",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.938368",
            "finished_at": "2026-01-09T08:14:14.938368",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          },
          {
            "run_id": "702cb7d4-6b3d-4ec8-9f02-19465c377e52",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.875276",
            "finished_at": "2026-01-09T08:14:14.875276",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          },
          {
            "run_id": "1d968863-7d66-4327-8a62-a885bab741d4",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.840518",
            "finished_at": "2026-01-09T08:14:14.840518",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          }
        ],
        "count": 6,
        "missing_run_ids": []
      }
    },
    "statistics": {
      "status": "completed",
      "error": null,
      "duration_ms": 8,
      "output": {
        "analysis": {
          "analysis_id": "33eea616-6a40-4343-828e-8ecaebad90e3",
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "analysis_type": "statistical",
          "created_at": "2026-01-09T09:30:50.034681",
          "metadata": {},
          "metrics_summary": {
            "faithfulness": {
              "mean": 0.5,
              "std": 0.5,
              "min": 0.0,
              "max": 1.0,
              "median": 0.5,
              "percentile_25": 0.0,
              "percentile_75": 1.0,
              "count": 4
            },
            "answer_relevancy": {
              "mean": 0.8840076251449925,
              "std": 0.03220948733981754,
              "min": 0.8366828943604284,
              "max": 0.9181316279283243,
              "median": 0.8906079891456087,
              "percentile_25": 0.8635167778898118,
              "percentile_75": 0.9110988364007893,
              "count": 4
            }
          },
          "correlation_matrix": [
            [
              1.0,
              0.3504834326153369
            ],
            [
              0.3504834326153369,
              1.0
            ]
          ],
          "correlation_metrics": [
            "faithfulness",
            "answer_relevancy"
          ],
          "significant_correlations": [],
          "low_performers": [
            {
              "test_case_id": "test_001",
              "metric_name": "faithfulness",
              "score": 0.0,
              "threshold": 0.7,
              "question_preview": "What is Python?",
              "potential_causes": [
                "Answer contains information not in context",
                "Possible hallucination"
              ]
            },
            {
              "test_case_id": "test_003",
              "metric_name": "faithfulness",
              "score": 0.0,
              "threshold": 0.7,
              "question_preview": "What is RAG?",
              "potential_causes": [
                "Answer contains information not in context",
                "Possible hallucination"
              ]
            }
          ],
          "insights": [
            "Moderate pass rate needs improvement: 50.0%",
            "Best performing metric: answer_relevancy (mean: 0.884)",
            "Worst performing metric: faithfulness (mean: 0.500)",
            "High variance metrics (std > 0.2): faithfulness",
            "Found 2 low-performing test cases (score < threshold)",
            "Most problematic metric: faithfulness (2 low performers)"
          ],
          "overall_pass_rate": 0.5,
          "metric_pass_rates": {
            "faithfulness": 0.5,
            "answer_relevancy": 1.0
          }
        },
        "summary": {
          "total_metrics": 2,
          "average_score": 0.692,
          "overall_pass_rate": 0.5
        },
        "statistics": {
          "faithfulness": {
            "mean": 0.5,
            "std": 0.5,
            "min": 0.0,
            "max": 1.0,
            "median": 0.5,
            "percentile_25": 0.0,
            "percentile_75": 1.0,
            "count": 4
          },
          "answer_relevancy": {
            "mean": 0.8840076251449925,
            "std": 0.03220948733981754,
            "min": 0.8366828943604284,
            "max": 0.9181316279283243,
            "median": 0.8906079891456087,
            "percentile_25": 0.8635167778898118,
            "percentile_75": 0.9110988364007893,
            "count": 4
          }
        },
        "insights": [
          "Moderate pass rate needs improvement: 50.0%",
          "Best performing metric: answer_relevancy (mean: 0.884)",
          "Worst performing metric: faithfulness (mean: 0.500)",
          "High variance metrics (std > 0.2): faithfulness",
          "Found 2 low-performing test cases (score < threshold)",
          "Most problematic metric: faithfulness (2 low performers)"
        ],
        "analysis_id": "33eea616-6a40-4343-828e-8ecaebad90e3",
        "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
        "correlation_metrics": [
          "faithfulness",
          "answer_relevancy"
        ],
        "correlation_matrix": [
          [
            1.0,
            0.3504834326153369
          ],
          [
            0.3504834326153369,
            1.0
          ]
        ],
        "significant_correlations": [],
        "low_performers": [
          {
            "test_case_id": "test_001",
            "metric_name": "faithfulness",
            "score": 0.0,
            "threshold": 0.7,
            "question_preview": "What is Python?",
            "potential_causes": [
              "Answer contains information not in context",
              "Possible hallucination"
            ]
          },
          {
            "test_case_id": "test_003",
            "metric_name": "faithfulness",
            "score": 0.0,
            "threshold": 0.7,
            "question_preview": "What is RAG?",
            "potential_causes": [
              "Answer contains information not in context",
              "Possible hallucination"
            ]
          }
        ],
        "metric_pass_rates": {
          "faithfulness": 0.5,
          "answer_relevancy": 1.0
        }
      }
    },
    "ragas_eval": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "summary": {
          "metric_count": 2,
          "sample_count": 4,
          "overall_score": 0.692,
          "recomputed": false
        },
        "metrics": {
          "faithfulness": 0.5,
          "answer_relevancy": 0.8840076251449925
        },
        "per_case": [
          {
            "test_case_id": "test_001",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.8366828943604284
            },
            "avg_score": 0.4183,
            "question_preview": "What is Python?"
          },
          {
            "test_case_id": "test_002",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.8724614057329397
            },
            "avg_score": 0.9362,
            "question_preview": "What is machine learning?"
          },
          {
            "test_case_id": "test_003",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.9087545725582776
            },
            "avg_score": 0.4544,
            "question_preview": "What is RAG?"
          },
          {
            "test_case_id": "test_004",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.9181316279283243
            },
            "avg_score": 0.9591,
            "question_preview": "What is TDD?"
          }
        ]
      }
    },
    "nlp_analysis": {
      "status": "completed",
      "error": null,
      "duration_ms": 218,
      "output": {
        "analysis": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "question_stats": {
            "char_count": 67,
            "word_count": 13,
            "sentence_count": 4,
            "avg_word_length": 3.923076923076923,
            "unique_word_ratio": 0.5384615384615384
          },
          "answer_stats": {
            "char_count": 162,
            "word_count": 25,
            "sentence_count": 4,
            "avg_word_length": 5.36,
            "unique_word_ratio": 0.92
          },
          "context_stats": {
            "char_count": 258,
            "word_count": 43,
            "sentence_count": 1,
            "avg_word_length": 5.023255813953488,
            "unique_word_ratio": 0.9069767441860465
          },
          "question_types": [
            {
              "question_type": "factual",
              "count": 4,
              "percentage": 1.0,
              "avg_scores": {
                "answer_relevancy": 0.8840076251449925,
                "faithfulness": 0.5
              }
            }
          ],
          "top_keywords": [
            {
              "keyword": "is",
              "frequency": 6,
              "tfidf_score": 0.24634723644073758,
              "avg_metric_scores": null
            },
            {
              "keyword": "tdd",
              "frequency": 2,
              "tfidf_score": 0.17105004542815092,
              "avg_metric_scores": null
            },
            {
              "keyword": "what",
              "frequency": 4,
              "tfidf_score": 0.1666027922057938,
              "avg_metric_scores": null
            },
            {
              "keyword": "python",
              "frequency": 2,
              "tfidf_score": 0.16341620996113213,
              "avg_metric_scores": null
            },
            {
              "keyword": "rag",
              "frequency": 2,
              "tfidf_score": 0.1618416489767295,
              "avg_metric_scores": null
            },
            {
              "keyword": "learning",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "machine",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "development",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "driven",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "means",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "test",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "high",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "language",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "level",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "programming",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "augmented",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "for",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "generation",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "retrieval",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "stands",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            }
          ],
          "topic_clusters": [],
          "insights": [
            "Questions are short and concise",
            "Dominant question type: factual (100%)",
            "Top keywords: is, tdd, what"
          ]
        },
        "summary": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "has_text_stats": true,
          "has_question_type_analysis": true,
          "has_keyword_analysis": true,
          "question_stats_preview": 3.25,
          "answer_stats_preview": 6.25,
          "context_count": 1,
          "dominant_question_type": "factual",
          "top_keywords_preview": [
            "is",
            "tdd",
            "what",
            "python",
            "rag"
          ]
        },
        "statistics": {
          "text_stats": {
            "questions": {
              "char_count": 67,
              "word_count": 13,
              "sentence_count": 4,
              "avg_word_length": 3.923076923076923,
              "unique_word_ratio": 0.5384615384615384
            },
            "answers": {
              "char_count": 162,
              "word_count": 25,
              "sentence_count": 4,
              "avg_word_length": 5.36,
              "unique_word_ratio": 0.92
            },
            "contexts": {
              "char_count": 258,
              "word_count": 43,
              "sentence_count": 1,
              "avg_word_length": 5.023255813953488,
              "unique_word_ratio": 0.9069767441860465
            }
          },
          "question_type_distribution": [
            {
              "question_type": "factual",
              "count": 4,
              "percentage": 1.0,
              "avg_scores": {
                "answer_relevancy": 0.8840076251449925,
                "faithfulness": 0.5
              }
            }
          ],
          "keywords": [
            {
              "keyword": "is",
              "frequency": 6,
              "tfidf_score": 0.24634723644073758,
              "avg_metric_scores": null
            },
            {
              "keyword": "tdd",
              "frequency": 2,
              "tfidf_score": 0.17105004542815092,
              "avg_metric_scores": null
            },
            {
              "keyword": "what",
              "frequency": 4,
              "tfidf_score": 0.1666027922057938,
              "avg_metric_scores": null
            },
            {
              "keyword": "python",
              "frequency": 2,
              "tfidf_score": 0.16341620996113213,
              "avg_metric_scores": null
            },
            {
              "keyword": "rag",
              "frequency": 2,
              "tfidf_score": 0.1618416489767295,
              "avg_metric_scores": null
            },
            {
              "keyword": "learning",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "machine",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "development",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "driven",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "means",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "test",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "high",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "language",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "level",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "programming",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "augmented",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "for",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "generation",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "retrieval",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "stands",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            }
          ]
        },
        "insights": [
          "Questions are short and concise",
          "Dominant question type: factual (100%)",
          "Top keywords: is, tdd, what"
        ],
        "analysis_id": null,
        "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
        "question_types": [
          {
            "question_type": "factual",
            "count": 4,
            "percentage": 1.0,
            "avg_scores": {
              "answer_relevancy": 0.8840076251449925,
              "faithfulness": 0.5
            }
          }
        ],
        "top_keywords": [
          {
            "keyword": "is",
            "frequency": 6,
            "tfidf_score": 0.24634723644073758,
            "avg_metric_scores": null
          },
          {
            "keyword": "tdd",
            "frequency": 2,
            "tfidf_score": 0.17105004542815092,
            "avg_metric_scores": null
          },
          {
            "keyword": "what",
            "frequency": 4,
            "tfidf_score": 0.1666027922057938,
            "avg_metric_scores": null
          },
          {
            "keyword": "python",
            "frequency": 2,
            "tfidf_score": 0.16341620996113213,
            "avg_metric_scores": null
          },
          {
            "keyword": "rag",
            "frequency": 2,
            "tfidf_score": 0.1618416489767295,
            "avg_metric_scores": null
          },
          {
            "keyword": "learning",
            "frequency": 2,
            "tfidf_score": 0.14221086885062423,
            "avg_metric_scores": null
          },
          {
            "keyword": "machine",
            "frequency": 2,
            "tfidf_score": 0.14221086885062423,
            "avg_metric_scores": null
          },
          {
            "keyword": "development",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "driven",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "means",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "test",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "high",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "language",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "level",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "programming",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "augmented",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "for",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "generation",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "retrieval",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "stands",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          }
        ],
        "topic_clusters": []
      }
    },
    "time_series": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "series": [
          {
            "run_id": "1d968863-7d66-4327-8a62-a885bab741d4",
            "timestamp": "2026-01-09T08:14:13.840518",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "702cb7d4-6b3d-4ec8-9f02-19465c377e52",
            "timestamp": "2026-01-09T08:14:13.875276",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "f042196b-1c77-463c-b695-3a5b938e349f",
            "timestamp": "2026-01-09T08:14:13.938368",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "a491fa0e-208d-4a34-acc6-2aba629dd0c3",
            "timestamp": "2026-01-09T08:14:14.026053",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "9fbf4776-9f5b-4c4b-ba08-c556032cee86",
            "timestamp": "2026-01-09T09:24:21.002694",
            "pass_rate": 0.0,
            "model_name": "gpt-oss-safeguard:20b"
          },
          {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "timestamp": "2026-01-09T09:27:38.337182",
            "pass_rate": 0.5,
            "model_name": "ollama/gpt-oss-safeguard:20b"
          }
        ],
        "summary": {
          "run_count": 6,
          "avg_pass_rate": 0.75,
          "start": "2026-01-09T08:14:13.840518",
          "end": "2026-01-09T09:27:38.337182"
        }
      }
    },
    "causal_analysis": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "analysis": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "analysis_id": "608ad604-7a86-4d3e-a53f-163bab69e988",
          "created_at": "2026-01-09T09:30:50.254070",
          "factor_stats": {},
          "factor_impacts": [],
          "causal_relationships": [],
          "root_causes": [],
          "interventions": [],
          "insights": [
            "Insufficient samples for causal analysis (4 < 10)"
          ]
        },
        "summary": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "factor_count": 0,
          "significant_impact_count": 0,
          "root_cause_count": 0
        },
        "statistics": {},
        "insights": [
          "Insufficient samples for causal analysis (4 < 10)"
        ],
        "analysis_id": "608ad604-7a86-4d3e-a53f-163bab69e988",
        "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
        "factor_stats": {},
        "significant_impacts": [],
        "root_causes": [],
        "interventions": []
      }
    },
    "low_samples": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "threshold": 0.5,
        "low_performers": [
          {
            "test_case_id": "test_001",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.8366828943604284
            },
            "avg_score": 0.4183,
            "question_preview": "What is Python?"
          },
          {
            "test_case_id": "test_003",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.9087545725582776
            },
            "avg_score": 0.4544,
            "question_preview": "What is RAG?"
          }
        ],
        "count": 2
      }
    },
    "diagnostic": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "threshold": 0.6,
        "diagnostics": [
          {
            "metric": "faithfulness",
            "issue": "faithfulness 점수가 기준치 미달입니다 (0.50 < 0.70).",
            "score": 0.5,
            "threshold": 0.7,
            "gap": 0.2
          }
        ],
        "recommendations": [
          "답변을 검색 컨텍스트에 더 강하게 고정하고 근거 인용을 강화하세요."
        ]
      }
    },
    "priority_summary": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "bottom_percentile": 10.0,
        "impact_count": 3,
        "total_cases": 4,
        "bottom_count": 1,
        "bottom_cases": [
          {
            "test_case_id": "test_001",
            "avg_score": 0.4183,
            "failed_metrics": [
              "faithfulness"
            ],
            "failed_metric_count": 1,
            "gap_by_metric": {
              "faithfulness": 0.7
            },
            "shortfall": 0.7,
            "impact_score": 0.616,
            "worst_metric": "faithfulness",
            "worst_score": 0.0,
            "worst_gap": 0.7,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is Python?",
            "analysis_hints": [
              "컨텍스트-답변 정합성 점검 필요",
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "bottom_percentile",
              "high_impact"
            ]
          }
        ],
        "impact_cases": [
          {
            "test_case_id": "test_001",
            "avg_score": 0.4183,
            "failed_metrics": [
              "faithfulness"
            ],
            "failed_metric_count": 1,
            "gap_by_metric": {
              "faithfulness": 0.7
            },
            "shortfall": 0.7,
            "impact_score": 0.616,
            "worst_metric": "faithfulness",
            "worst_score": 0.0,
            "worst_gap": 0.7,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is Python?",
            "analysis_hints": [
              "컨텍스트-답변 정합성 점검 필요",
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "bottom_percentile",
              "high_impact"
            ]
          },
          {
            "test_case_id": "test_003",
            "avg_score": 0.4544,
            "failed_metrics": [
              "faithfulness"
            ],
            "failed_metric_count": 1,
            "gap_by_metric": {
              "faithfulness": 0.7
            },
            "shortfall": 0.7,
            "impact_score": 0.616,
            "worst_metric": "faithfulness",
            "worst_score": 0.0,
            "worst_gap": 0.7,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is RAG?",
            "analysis_hints": [
              "컨텍스트-답변 정합성 점검 필요",
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "high_impact"
            ]
          },
          {
            "test_case_id": "test_002",
            "avg_score": 0.9362,
            "failed_metrics": [],
            "failed_metric_count": 0,
            "gap_by_metric": {},
            "shortfall": 0.0,
            "impact_score": 0.1,
            "worst_metric": null,
            "worst_score": null,
            "worst_gap": null,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is machine learning?",
            "analysis_hints": [
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "high_impact"
            ]
          }
        ],
        "run_metadata": {
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "dataset_name": "test_dataset",
          "dataset_version": "1.0.0",
          "model_name": "ollama/gpt-oss-safeguard:20b",
          "started_at": "2026-01-09T09:27:38.337182",
          "finished_at": "2026-01-09T09:30:49.992680",
          "total_test_cases": 4,
          "passed_test_cases": 2,
          "pass_rate": 0.5,
          "total_tokens": 18642,
          "total_cost_usd": 0.051585,
          "duration_seconds": 191.655498,
          "tracker_metadata": {
            "run_mode": "full"
          },
          "metrics_evaluated": [
            "faithfulness",
            "answer_relevancy"
          ],
          "run_mode": "full",
          "thresholds": {
            "faithfulness": 0.7,
            "answer_relevancy": 0.7
          },
          "avg_faithfulness": 0.5,
          "avg_answer_relevancy": 0.8840076251449925
        }
      }
    },
    "pattern_detection": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "patterns": [
          {
            "label": "Top keyword",
            "detail": "is (freq 6)"
          },
          {
            "label": "Top keyword",
            "detail": "tdd (freq 2)"
          },
          {
            "label": "Top keyword",
            "detail": "what (freq 4)"
          },
          {
            "label": "Top keyword",
            "detail": "python (freq 2)"
          },
          {
            "label": "Top keyword",
            "detail": "rag (freq 2)"
          },
          {
            "label": "Question type",
            "detail": "factual (1.0%)"
          }
        ],
        "summary": {
          "keyword_count": 20,
          "question_type_count": 1
        }
      }
    },
    "trend_detection": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "trends": [
          {
            "metric": "pass_rate",
            "direction": "down",
            "delta": -0.5
          }
        ],
        "summary": {
          "start": 1.0,
          "end": 0.5,
          "delta": -0.5
        },
        "recommendations": [
          "Performance is trending down; investigate changes."
        ]
      }
    },
    "root_cause": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "causes": [
          {
            "metric": "faithfulness",
            "reason": "faithfulness 점수가 기준치 미달입니다 (0.50 < 0.70)."
          }
        ],
        "recommendations": [
          "답변을 검색 컨텍스트에 더 강하게 고정하고 근거 인용을 강화하세요."
        ],
        "low_performer_count": 2
      }
    },
    "report": {
      "status": "completed",
      "error": null,
      "duration_ms": 85526,
      "output": {
        "report": "# RAG 평가 분석 보고서\n\n## 요약  \n- **실행 ID**: `0aa9fab0-6c2c-4c1c-b228-202a38a2f00c`  \n- **데이터셋**: `test_dataset v1.0.0`  \n- **모델**: `ollama/gpt-oss-safeguard:20b`  \n- **전체 테스트 케이스**: 4  \n- **총 통과율**: **50 %**  \n- **평균 스코어**: **0.692**  \n- **주요 KPI**  \n  - `faithfulness`: **0.50** (목표 0.70 미달) → 실패  \n  - `answer_relevancy`: **0.884** (목표 0.70 초과) → 성공  \n\n세 명의 고충량 테스트 케이스는 `faithfulness` 지표가 0 %로 가장 낮은 점수를 기록했습니다. 이는 `What is Python?` 와 `What is RAG?` 라는 사실 기반 질문에 대한 답변이 문맥과 불일치하거나 불완전하게 제공되었기 때문입니다.\n\n## 문제 진단  \n\n| 테스트 케이스 | 실패 지표 | 평균 스코어 | 부족한 점 | 비고 |\n|------|----------|------------|----------|------|\n| **test_001** | faithfulness | 0.418 | “Python은 고수준 프로그래밍 언어”만 제시; 핵심 ‘해석형’ 정보 누락 | [E1] |\n| **test_003** | faithfulness | 0.454 | “RAG는 Retrieval‑Augmented Generation이란 약자”만 언급; 실제 정의와 차이점 간과 | [E2] |\n| **test_002** | ― | 0.936 | 정확하고 핵심 문장 포함 | [E3] |\n| **test_004** | ― | 0.959 | 상세한 용어와 프로세스 포함 | [E4] |\n\n*문제 핵심*: **faithfulness** 점수가 0.70 이하인 사안이 두 번 발생 → “컨텍스트-답변 정합성”이 충분히 확인되지 않음.  \n*추정 원인*  \n1. 검색 컨텍스트(핵심 정보)를 모델이 완전하게 활용하지 못함.  \n2. 답변 생성 시 “정확한 인용” 없이 압축적인 설명을 제공함.\n\n## 증거 기반 분석  \n\n- **test_001**  \n  - 질문: *What is Python?*  \n  - 정답: *Python은 고수준 해석형 프로그래밍 언어*  \n  - 모델 답변: *Python은 고수준 프로그래밍 언어* → **해석형**이 빠져 신뢰성 저하.  \n  - 컨텍스트: “Python is a programming language” / “Python was created by Guido van Rossum”.  \n  - **faithfulness**: 0.0 → [E1]\n\n- **test_003**  \n  - 질문: *What is RAG?*  \n  - 정답: *RAG는 검색과 생성이 결합되어 LLM 결과를 향상시키는 기술*  \n  - 모델 답변: *RAG stands for Retrieval‑Augmented Generation* → **정의만 전달**, 실제 기능 설명 부족.  \n  - 컨텍스트: “RAG combines retrieval and generation”, “RAG improves LLM responses”.  \n  - **faithfulness**: 0.0 → [E2]\n\n- **test_002** / **test_004**는 모두 **faithfulness** 1.0을 기록하여, 모델이 사실 기반 질문에 대해 잘 처리할 수 있음을 보여준다. 이 두 사례에서는 문맥과 답변이 일치하고, 답변이 충분히 종합적이다.\n\n- **전반적 패턴**:  \n  - `Top keyword: \"is\"`, `question_type: \"factual\"`이 높은 비중을 차지함.  \n  - `answer_relevancy`는 대부분 높은 편(0.84‑0.92)이며, 주된 문제는 정합성에 한정되어 있음.\n\n## 개선 제안  \n\n| 영역 | 제안 | 근거 |\n|------|------|------|\n| **컨텍스트 활용** | 1. 검색 결과를 답변 생성 시 **강제 인용** 구조로 삽입(예: “출처: …”) <br> 2. **컨텍스트 스코어링**을 선행하여 가장 핵심 정보를 보강하여 답변에 포함 | - 테스트 사례[E1, E2]에서 컨텍스트가 활용되지 않은 점, <br> - `faithfulness` 개선을 위한 정합성 강화 |\n| **프롬프트 설계** | 1. “정확한 설명과 함께 출처를 명시하라”는 명시적 지시 <br> 2. 질문이 `factual`인 경우 **정확도 점검** 프롬프트 삽입 | - `analysis_hints`(문맥-답변 정합성 점검 필요)가 이미 제시됨 |\n| **품질 체크** | 1. **자동 정합성 검사**(컨텍스트‑답변 차이점 비교) <br> 2. `faithfulness`가 0.7 미달 시 **재검색** 또는 **다른 문서** 시도 | - `metrics_evaluated`에 `faithfulness`가 포함되어 있으므로, 자동화 가능 |\n| **데이터 확장** | 1. 추가적인 `factual` 유형 질문과 그에 대한 다수의 컨텍스트 사례를 수집 <br> 2. `analysis_hints`를 더 세분화 (예: “코드 예시를 포함하라”) | - 향후 변동 추세(“pass_rate down” )를 보완하려면 더 많은 데이터를 사용해 기계 학습을 재훈련 가능 |\n\n## 다음 단계  \n\n1. **리포트 기반 리펙터링**  \n   - 모델 프롬프트 및 검색 파이프라인에 “출처 기반 인용”을 요구하도록 수정.  \n   - 정합성 점검 로직을 추가하고, `faithfulness`가 0.7 미만일 경우 자동 재검색을 트리거.\n\n2. **추가 테스트 실행**  \n   - `factual` 유형의 다수 샘플을 도입하여 `faithfulness` 개선 여부를 실험.  \n   - `threshold` 기준 재검토(현재 0.7)와 실제 사용자 시나리오에 맞는 목표 재정립.\n\n3. **모델/연산 리소스 검토**  \n   - 실행 비용(0.051 USD) 및 토큰량(18,642)을 고려하여, 모델 크기와 API 호출 수를 조정.\n\n4. **다음 평가 주기**  \n   - 개선 후 `faithfulness` 목표 0.75 이상, `answer_relevancy` 0.90 이상을 목표로 재평가.  \n   - `pass_rate` 상승 동향을 모니터링하면서, **bottom_percentile** 케이스를 20 % 이하로 감소.\n\n---\n\n*필요 시 추가 데이터(문맥이 풍부한 사례, 모델의 내부 로깅 등)를 수집해 분석을 보완할 수 있습니다.*",
        "format": "markdown",
        "llm_used": true,
        "llm_model": "ollama/gpt-oss-safeguard:20b",
        "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
        "summary": {
          "report_type": "analysis",
          "total_evidence": 4,
          "has_run": true
        },
        "evidence": [
          {
            "test_case_id": "test_001",
            "avg_score": 0.4183,
            "failed_metrics": [
              "faithfulness"
            ],
            "question": "What is Python?",
            "answer": "Python is a high-level programming language.",
            "contexts": [
              "Python is a programming language",
              "Python was created by Guido van Rossum"
            ],
            "ground_truth": "Python is a high-level interpreted programming language.",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.8366828943604284
            },
            "evidence_id": "E1"
          },
          {
            "test_case_id": "test_003",
            "avg_score": 0.4544,
            "failed_metrics": [
              "faithfulness"
            ],
            "question": "What is RAG?",
            "answer": "RAG stands for Retrieval-Augmented Generation.",
            "contexts": [
              "RAG combines retrieval and generation",
              "RAG improves LLM responses"
            ],
            "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information.",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.9087545725582776
            },
            "evidence_id": "E2"
          },
          {
            "test_case_id": "test_002",
            "avg_score": 0.9362,
            "failed_metrics": [],
            "question": "What is machine learning?",
            "answer": "Machine learning is a subset of AI.",
            "contexts": [
              "ML is part of AI",
              "ML uses algorithms to learn from data"
            ],
            "ground_truth": "Machine learning is a method of data analysis that automates analytical model building.",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.8724614057329397
            },
            "evidence_id": "E3"
          },
          {
            "test_case_id": "test_004",
            "avg_score": 0.9591,
            "failed_metrics": [],
            "question": "What is TDD?",
            "answer": "TDD means Test-Driven Development.",
            "contexts": [
              "Test-Driven Development",
              "Write tests first",
              "Red-Green-Refactor cycle"
            ],
            "ground_truth": "TDD is a software development approach where tests are written before code.",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.9181316279283243
            },
            "evidence_id": "E4"
          }
        ]
      }
    }
  },
  "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c"
}
