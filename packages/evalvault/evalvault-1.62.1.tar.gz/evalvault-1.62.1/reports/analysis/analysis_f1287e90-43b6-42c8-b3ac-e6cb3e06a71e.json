{
  "intent": "generate_detailed",
  "pipeline_id": "976be9d3-ba55-4704-b9ff-eab0d0640152",
  "is_complete": true,
  "duration_ms": 86201,
  "started_at": "2026-01-09T11:22:53.429285",
  "finished_at": "2026-01-09T11:24:19.630352",
  "final_output": {
    "report": {
      "report": "# RAG 평가 분석 보고서  \n**Run ID**: f1287e90-43b6-42c8-b3ac-e6cb3e06a71e | **Dataset**: test_dataset v1.0.0 | **모델**: ollama/gpt‑oss‑safeguard:20b  \n\n---\n\n## 1. 요약  \n**주요 결론**: 전체 합계 0.692의 과반자(50 %)가 기준치를 초과하지 않으며, 신뢰성(faithfulness) 부족이 가장 큰 문제입니다.  \n\n- **지표**: 대다수 테스트에서 answer_relevancy는 0.884 이상인 반면 faithfulness는 평균 0.5(위험 수준)입니다.  \n- **원인**: 답변이 컨텍스트와 충분히 정합되지 않아 근거 인용이 미흡한 점이 크게 영향을 끼칩니다.  \n- **사용자 영향**: 신뢰가 낮아 사용자는 정보의 정확성에 의문을 가질 수 있고, 이해와 인지부하가 증가합니다.  \n\n---\n\n## 2. 지표 스코어카드  \n\n| metric | 평균 | threshold | pass_rate | 상태 |\n|--------|------|-----------|-----------|------|\n| answer_relevancy | 0.884 | 0.7 | 1.00 | Pass |\n| faithfulness | 0.500 | 0.7 | 0.50 | Risk |\n\n> **전체 pass_rate**: 0.50 (4개 테스트 중 2개만 성공)  \n\n---\n\n## 3. 데이터 품질/신뢰도\n\n| 항목 | 상태 |\n|------|------|\n| 샘플 수 | 4(표본 수가 소수) |\n| coverage | 1.0 (모든 테스트에 필수 메트릭 적용) |\n| 추세 분석 | 부족 (데이터가 한 번에 한 실행) |\n\n> *표시된 경고*: `표본 수가 적음`, `추세 분석을 위한 실행 이력 부족`. 작은 샘플로 인해 통계 해석에 주의 필요.  \n\n---\n\n## 4. 증거 기반 인사이트  \n\n| 테스트 ID | 질문 | answer_relevancy | faithfulness | 주요 문제 포인트 | evidence_id |\n|-----------|------|------------------|--------------|------------------|-------------|\n| test_001 | What is Python? | 0.837 | 0.0 | 컨텍스트와 불일치 | [E1] |\n| test_003 | What is RAG? | 0.909 | 0.0 | 근거 없이 정리된 정의 | [E2] |\n| test_002 | What is machine learning? | 0.872 | 1.0 | 컨텍스트와 일치 | [E3] |\n| test_004 | What is TDD? | 0.918 | 1.0 | 정확히 정정 | [E4] |\n\n- **패턴**: 핵심 키워드 `is`, `tdd`, `what`, `python`, `rag` 순위 하위.  \n- **대부분의 사례**(test_001, test_003)에서 faithfulness가 0으로 떨어져 **위험 요인**이 두 번 발생.  \n\n**사용자 인식**  \n- *신뢰성* 낮은 답변은 사용자에게 부정확한 정보를 제공함으로써 **신뢰 저하**를 초래.  \n- 사실 질문에서 신뢰성이 보장되지 않을 경우 **인지부하**가 증가해 추론이 필요.\n\n---\n\n## 5. 원인 가설  \n\n1. **컨텍스트 정합성 부재**  \n   - 테스트 E1, E2에서 답변이 제공된 컨텍스트와 크게 차이나며 핵심 사실이 누락.  \n2. **근거 인용 미흡**  \n   - 모델이 답변을 생성할 때 외부 정보(컨텍스트) 참조를 불충분히 활용.  \n3. **지문 길이 및 복잡성**  \n   - 질문이 짧고 단순(`factual`)이어서 모델이 외부 정보에 대한 의존도를 낮춤.  \n\n> **root_cause**: faithfulness 징후가 0.5 미달 → **비판적 근거 부재**.\n\n---\n\n## 6. 개선 제안  \n\n| 영역 | 제안 | 근거 |\n|------|------|------|\n| **컨텍스트 활용** | 문맥 매칭 알고리즘(예: BM25 또는 DPR)으로 가장 관련 있는 문장을 선택 후 강조 표시 | E1, E2 에서 낮은 faithfulness |\n| **근거 기반 인용** | 답변에 인용 부호 또는 링크 삽입 → 사용자가 직접 컨텍스트 확인 가능 | *제안* 메트릭 |\n| **데이터 보강** | 테스트 샘플 증가 및 다양한 질문 유형 추가 | “표본 수가 적음” 경고 |\n| **모델 튜닝** | `faithfulness` 목표치를 0.7 이상으로 강제하도록 파인튜닝 또는 후처리 기준 적용 | `thresholds.fai­l­ty­ness = 0.7` |\n| **평가 프레임워크 보강** | 실시간 추세 및 시계열 분석 추가 | “추세 분석 부족” |\n\n---\n\n## 7. 다음 단계  \n\n1. **샘플 확장** – 10~20개 추가 테스트 수행, 다양한 질문 유형(문법, 개념, 인용 등).  \n2. **컨텍스트 매핑 재설계** – 더 정밀한 맥락 연관성 스코어링 도입.  \n3. **사후 검증** – 자동화된 근거 인용 검증 스크립트 개발.  \n4. **A/B 테스트** – 두 버전(현재 vs. 개선) 비교하여 `faithfulness` 향상 여부 확인.  \n\n---\n\n## 8. 부록(산출물)\n\n| 파일 | 내용 |\n|------|------|\n| causal_analysis.json | 원인 분석 결과 |\n| load_data.json | 데이터 로딩 스크립트 |\n| nlp_analysis.json | 키워드, 문장 통계 |\n| pattern_detection.json | Top keyword, question type 패턴 |\n| priority_summary.json | 위험 및 우선순위 평가 |\n| ragas_eval.json | 평가 메트릭 결과 |\n| root_cause.json | root_cause 및 추천 |\n| statistics.json | 전체 통계 |\n| trend_detection.json | 추세 및 변화 |\n\n---\n\n> **추가 데이터 필요**: 현 시점에서 샘플 수가 적어 추세 파악이 어려우며, 다른 모델 간 비교 분석이 필요하면 추가 run data 수집을 권장합니다.",
      "format": "markdown",
      "llm_used": true,
      "llm_model": "ollama/gpt-oss-safeguard:20b",
      "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
      "summary": {
        "report_type": "analysis",
        "total_evidence": 4,
        "has_run": true
      },
      "evidence": [
        {
          "test_case_id": "test_001",
          "avg_score": 0.4183,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is Python?",
          "answer": "Python is a high-level programming language.",
          "contexts": [
            "Python is a programming language",
            "Python was created by Guido van Rossum"
          ],
          "ground_truth": "Python is a high-level interpreted programming language.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.8366828943604284
          },
          "evidence_id": "E1"
        },
        {
          "test_case_id": "test_003",
          "avg_score": 0.4544,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is RAG?",
          "answer": "RAG stands for Retrieval-Augmented Generation.",
          "contexts": [
            "RAG combines retrieval and generation",
            "RAG improves LLM responses"
          ],
          "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.9087545725582776
          },
          "evidence_id": "E2"
        },
        {
          "test_case_id": "test_002",
          "avg_score": 0.9362,
          "failed_metrics": [],
          "question": "What is machine learning?",
          "answer": "Machine learning is a subset of AI.",
          "contexts": [
            "ML is part of AI",
            "ML uses algorithms to learn from data"
          ],
          "ground_truth": "Machine learning is a method of data analysis that automates analytical model building.",
          "metrics": {
            "faithfulness": 1.0,
            "answer_relevancy": 0.8724614057329397
          },
          "evidence_id": "E3"
        },
        {
          "test_case_id": "test_004",
          "avg_score": 0.9591,
          "failed_metrics": [],
          "question": "What is TDD?",
          "answer": "TDD means Test-Driven Development.",
          "contexts": [
            "Test-Driven Development",
            "Write tests first",
            "Red-Green-Refactor cycle"
          ],
          "ground_truth": "TDD is a software development approach where tests are written before code.",
          "metrics": {
            "faithfulness": 1.0,
            "answer_relevancy": 0.9181316279283243
          },
          "evidence_id": "E4"
        }
      ]
    }
  },
  "node_results": {
    "load_data": {
      "status": "completed",
      "error": null,
      "duration_ms": 2,
      "output": {
        "loaded": true,
        "query": "generate_detailed",
        "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
        "additional_params": {
          "report_type": "analysis",
          "use_llm_report": true
        },
        "run": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "dataset_name": "test_dataset",
          "dataset_version": "1.0.0",
          "model_name": "ollama/gpt-oss-safeguard:20b",
          "started_at": "2026-01-09T09:47:43.429178",
          "finished_at": "2026-01-09T09:51:00.132606",
          "results": [
            {
              "test_case_id": "test_001",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 0.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.8366828943604284,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4550,
              "latency_ms": 54079,
              "cost_usd": 0.0125825,
              "trace_id": null,
              "started_at": "2026-01-09T09:47:43.429338",
              "finished_at": "2026-01-09T09:48:37.509082",
              "question": "What is Python?",
              "answer": "Python is a high-level programming language.",
              "contexts": [
                "Python is a programming language",
                "Python was created by Guido van Rossum"
              ],
              "ground_truth": "Python is a high-level interpreted programming language."
            },
            {
              "test_case_id": "test_002",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 1.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.8724614057329397,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4524,
              "latency_ms": 43633,
              "cost_usd": 0.012547500000000001,
              "trace_id": null,
              "started_at": "2026-01-09T09:48:37.509919",
              "finished_at": "2026-01-09T09:49:21.143545",
              "question": "What is machine learning?",
              "answer": "Machine learning is a subset of AI.",
              "contexts": [
                "ML is part of AI",
                "ML uses algorithms to learn from data"
              ],
              "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
            },
            {
              "test_case_id": "test_003",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 0.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.9087545725582776,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4660,
              "latency_ms": 44261,
              "cost_usd": 0.012925,
              "trace_id": null,
              "started_at": "2026-01-09T09:49:21.143707",
              "finished_at": "2026-01-09T09:50:05.405462",
              "question": "What is RAG?",
              "answer": "RAG stands for Retrieval-Augmented Generation.",
              "contexts": [
                "RAG combines retrieval and generation",
                "RAG improves LLM responses"
              ],
              "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
            },
            {
              "test_case_id": "test_004",
              "metrics": [
                {
                  "name": "faithfulness",
                  "score": 1.0,
                  "threshold": 0.7,
                  "reason": null
                },
                {
                  "name": "answer_relevancy",
                  "score": 0.9181316279283243,
                  "threshold": 0.7,
                  "reason": null
                }
              ],
              "tokens_used": 4908,
              "latency_ms": 54726,
              "cost_usd": 0.01353,
              "trace_id": null,
              "started_at": "2026-01-09T09:50:05.405693",
              "finished_at": "2026-01-09T09:51:00.132125",
              "question": "What is TDD?",
              "answer": "TDD means Test-Driven Development.",
              "contexts": [
                "Test-Driven Development",
                "Write tests first",
                "Red-Green-Refactor cycle"
              ],
              "ground_truth": "TDD is a software development approach where tests are written before code."
            }
          ],
          "metrics_evaluated": [
            "faithfulness",
            "answer_relevancy"
          ],
          "thresholds": {
            "faithfulness": 0.7,
            "answer_relevancy": 0.7
          },
          "total_tokens": 18642,
          "total_cost_usd": 0.051585,
          "langfuse_trace_id": null,
          "tracker_metadata": {
            "run_mode": "full"
          },
          "retrieval_metadata": {}
        },
        "metrics": {
          "faithfulness": [
            0.0,
            1.0,
            0.0,
            1.0
          ],
          "answer_relevancy": [
            0.8366828943604284,
            0.8724614057329397,
            0.9087545725582776,
            0.9181316279283243
          ]
        },
        "summary": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "dataset_name": "test_dataset",
          "dataset_version": "1.0.0",
          "model_name": "ollama/gpt-oss-safeguard:20b",
          "started_at": "2026-01-09T09:47:43.429178",
          "finished_at": "2026-01-09T09:51:00.132606",
          "total_test_cases": 4,
          "passed_test_cases": 2,
          "pass_rate": 0.5,
          "total_tokens": 18642,
          "total_cost_usd": 0.051585,
          "duration_seconds": 196.703428,
          "tracker_metadata": {
            "run_mode": "full"
          },
          "metrics_evaluated": [
            "faithfulness",
            "answer_relevancy"
          ],
          "run_mode": "full",
          "thresholds": {
            "faithfulness": 0.7,
            "answer_relevancy": 0.7
          },
          "avg_faithfulness": 0.5,
          "avg_answer_relevancy": 0.8840076251449925
        }
      }
    },
    "load_runs": {
      "status": "completed",
      "error": null,
      "duration_ms": 4,
      "output": {
        "runs": [
          {
            "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:47:43.429178",
            "finished_at": "2026-01-09T09:51:00.132606",
            "results": [
              {
                "test_case_id": "test_001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8366828943604284,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4550,
                "latency_ms": 54079,
                "cost_usd": 0.0125825,
                "trace_id": null,
                "started_at": "2026-01-09T09:47:43.429338",
                "finished_at": "2026-01-09T09:48:37.509082",
                "question": "What is Python?",
                "answer": "Python is a high-level programming language.",
                "contexts": [
                  "Python is a programming language",
                  "Python was created by Guido van Rossum"
                ],
                "ground_truth": "Python is a high-level interpreted programming language."
              },
              {
                "test_case_id": "test_002",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8724614057329397,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4524,
                "latency_ms": 43633,
                "cost_usd": 0.012547500000000001,
                "trace_id": null,
                "started_at": "2026-01-09T09:48:37.509919",
                "finished_at": "2026-01-09T09:49:21.143545",
                "question": "What is machine learning?",
                "answer": "Machine learning is a subset of AI.",
                "contexts": [
                  "ML is part of AI",
                  "ML uses algorithms to learn from data"
                ],
                "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
              },
              {
                "test_case_id": "test_003",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9087545725582776,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4660,
                "latency_ms": 44261,
                "cost_usd": 0.012925,
                "trace_id": null,
                "started_at": "2026-01-09T09:49:21.143707",
                "finished_at": "2026-01-09T09:50:05.405462",
                "question": "What is RAG?",
                "answer": "RAG stands for Retrieval-Augmented Generation.",
                "contexts": [
                  "RAG combines retrieval and generation",
                  "RAG improves LLM responses"
                ],
                "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
              },
              {
                "test_case_id": "test_004",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9181316279283243,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4908,
                "latency_ms": 54726,
                "cost_usd": 0.01353,
                "trace_id": null,
                "started_at": "2026-01-09T09:50:05.405693",
                "finished_at": "2026-01-09T09:51:00.132125",
                "question": "What is TDD?",
                "answer": "TDD means Test-Driven Development.",
                "contexts": [
                  "Test-Driven Development",
                  "Write tests first",
                  "Red-Green-Refactor cycle"
                ],
                "ground_truth": "TDD is a software development approach where tests are written before code."
              }
            ],
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:27:38.337182",
            "finished_at": "2026-01-09T09:30:49.992680",
            "results": [
              {
                "test_case_id": "test_001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8366828943604284,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4550,
                "latency_ms": 55617,
                "cost_usd": 0.0125825,
                "trace_id": null,
                "started_at": "2026-01-09T09:27:38.337382",
                "finished_at": "2026-01-09T09:28:33.954776",
                "question": "What is Python?",
                "answer": "Python is a high-level programming language.",
                "contexts": [
                  "Python is a programming language",
                  "Python was created by Guido van Rossum"
                ],
                "ground_truth": "Python is a high-level interpreted programming language."
              },
              {
                "test_case_id": "test_002",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.8724614057329397,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4524,
                "latency_ms": 43321,
                "cost_usd": 0.012547500000000001,
                "trace_id": null,
                "started_at": "2026-01-09T09:28:33.954978",
                "finished_at": "2026-01-09T09:29:17.276445",
                "question": "What is machine learning?",
                "answer": "Machine learning is a subset of AI.",
                "contexts": [
                  "ML is part of AI",
                  "ML uses algorithms to learn from data"
                ],
                "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
              },
              {
                "test_case_id": "test_003",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9087545725582776,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4660,
                "latency_ms": 41342,
                "cost_usd": 0.012925,
                "trace_id": null,
                "started_at": "2026-01-09T09:29:17.276532",
                "finished_at": "2026-01-09T09:29:58.619119",
                "question": "What is RAG?",
                "answer": "RAG stands for Retrieval-Augmented Generation.",
                "contexts": [
                  "RAG combines retrieval and generation",
                  "RAG improves LLM responses"
                ],
                "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
              },
              {
                "test_case_id": "test_004",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 1.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.9181316279283243,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 4908,
                "latency_ms": 51373,
                "cost_usd": 0.01353,
                "trace_id": null,
                "started_at": "2026-01-09T09:29:58.619185",
                "finished_at": "2026-01-09T09:30:49.992357",
                "question": "What is TDD?",
                "answer": "TDD means Test-Driven Development.",
                "contexts": [
                  "Test-Driven Development",
                  "Write tests first",
                  "Red-Green-Refactor cycle"
                ],
                "ground_truth": "TDD is a software development approach where tests are written before code."
              }
            ],
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "9fbf4776-9f5b-4c4b-ba08-c556032cee86",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:24:21.002694",
            "finished_at": "2026-01-09T09:24:56.964326",
            "results": [
              {
                "test_case_id": "test_001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 12137,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:21.002915",
                "finished_at": "2026-01-09T09:24:33.140065",
                "question": "What is Python?",
                "answer": "Python is a high-level programming language.",
                "contexts": [
                  "Python is a programming language",
                  "Python was created by Guido van Rossum"
                ],
                "ground_truth": "Python is a high-level interpreted programming language."
              },
              {
                "test_case_id": "test_002",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 7959,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:33.140190",
                "finished_at": "2026-01-09T09:24:41.100049",
                "question": "What is machine learning?",
                "answer": "Machine learning is a subset of AI.",
                "contexts": [
                  "ML is part of AI",
                  "ML uses algorithms to learn from data"
                ],
                "ground_truth": "Machine learning is a method of data analysis that automates analytical model building."
              },
              {
                "test_case_id": "test_003",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 7968,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:41.100115",
                "finished_at": "2026-01-09T09:24:49.068845",
                "question": "What is RAG?",
                "answer": "RAG stands for Retrieval-Augmented Generation.",
                "contexts": [
                  "RAG combines retrieval and generation",
                  "RAG improves LLM responses"
                ],
                "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information."
              },
              {
                "test_case_id": "test_004",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  },
                  {
                    "name": "answer_relevancy",
                    "score": 0.0,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 7895,
                "cost_usd": null,
                "trace_id": null,
                "started_at": "2026-01-09T09:24:49.068887",
                "finished_at": "2026-01-09T09:24:56.964077",
                "question": "What is TDD?",
                "answer": "TDD means Test-Driven Development.",
                "contexts": [
                  "Test-Driven Development",
                  "Write tests first",
                  "Red-Green-Refactor cycle"
                ],
                "ground_truth": "TDD is a software development approach where tests are written before code."
              }
            ],
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "a491fa0e-208d-4a34-acc6-2aba629dd0c3",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:14.026053",
            "finished_at": "2026-01-09T08:14:15.026053",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "f042196b-1c77-463c-b695-3a5b938e349f",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.938368",
            "finished_at": "2026-01-09T08:14:14.938368",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          },
          {
            "run_id": "702cb7d4-6b3d-4ec8-9f02-19465c377e52",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.875276",
            "finished_at": "2026-01-09T08:14:14.875276",
            "results": [
              {
                "test_case_id": "tc-001",
                "metrics": [
                  {
                    "name": "faithfulness",
                    "score": 0.9,
                    "threshold": 0.7,
                    "reason": null
                  }
                ],
                "tokens_used": 0,
                "latency_ms": 0,
                "cost_usd": null,
                "trace_id": null,
                "started_at": null,
                "finished_at": null,
                "question": null,
                "answer": null,
                "contexts": null,
                "ground_truth": null
              }
            ],
            "metrics_evaluated": [
              "faithfulness"
            ],
            "thresholds": {
              "faithfulness": 0.7
            },
            "total_tokens": 0,
            "total_cost_usd": null,
            "langfuse_trace_id": null,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "retrieval_metadata": {}
          }
        ],
        "summaries": [
          {
            "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:47:43.429178",
            "finished_at": "2026-01-09T09:51:00.132606",
            "total_test_cases": 4,
            "passed_test_cases": 2,
            "pass_rate": 0.5,
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "duration_seconds": 196.703428,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "avg_faithfulness": 0.5,
            "avg_answer_relevancy": 0.8840076251449925
          },
          {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "ollama/gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:27:38.337182",
            "finished_at": "2026-01-09T09:30:49.992680",
            "total_test_cases": 4,
            "passed_test_cases": 2,
            "pass_rate": 0.5,
            "total_tokens": 18642,
            "total_cost_usd": 0.051585,
            "duration_seconds": 191.655498,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "avg_faithfulness": 0.5,
            "avg_answer_relevancy": 0.8840076251449925
          },
          {
            "run_id": "9fbf4776-9f5b-4c4b-ba08-c556032cee86",
            "dataset_name": "test_dataset",
            "dataset_version": "1.0.0",
            "model_name": "gpt-oss-safeguard:20b",
            "started_at": "2026-01-09T09:24:21.002694",
            "finished_at": "2026-01-09T09:24:56.964326",
            "total_test_cases": 4,
            "passed_test_cases": 0,
            "pass_rate": 0.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 35.961632,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness",
              "answer_relevancy"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7,
              "answer_relevancy": 0.7
            },
            "avg_faithfulness": 0.0,
            "avg_answer_relevancy": 0.0
          },
          {
            "run_id": "a491fa0e-208d-4a34-acc6-2aba629dd0c3",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:14.026053",
            "finished_at": "2026-01-09T08:14:15.026053",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          },
          {
            "run_id": "f042196b-1c77-463c-b695-3a5b938e349f",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.938368",
            "finished_at": "2026-01-09T08:14:14.938368",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          },
          {
            "run_id": "702cb7d4-6b3d-4ec8-9f02-19465c377e52",
            "dataset_name": "test",
            "dataset_version": "1.0.0",
            "model_name": "gpt-5-nano",
            "started_at": "2026-01-09T08:14:13.875276",
            "finished_at": "2026-01-09T08:14:14.875276",
            "total_test_cases": 1,
            "passed_test_cases": 1,
            "pass_rate": 1.0,
            "total_tokens": 0,
            "total_cost_usd": null,
            "duration_seconds": 1.0,
            "tracker_metadata": {
              "run_mode": "full"
            },
            "metrics_evaluated": [
              "faithfulness"
            ],
            "run_mode": "full",
            "thresholds": {
              "faithfulness": 0.7
            },
            "avg_faithfulness": 0.9
          }
        ],
        "count": 6,
        "missing_run_ids": []
      }
    },
    "statistics": {
      "status": "completed",
      "error": null,
      "duration_ms": 1,
      "output": {
        "analysis": {
          "analysis_id": "9bf2bdc5-8190-477c-bd20-d39d054fad9b",
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "analysis_type": "statistical",
          "created_at": "2026-01-09T11:22:53.437195",
          "metadata": {},
          "metrics_summary": {
            "faithfulness": {
              "mean": 0.5,
              "std": 0.5,
              "min": 0.0,
              "max": 1.0,
              "median": 0.5,
              "percentile_25": 0.0,
              "percentile_75": 1.0,
              "count": 4
            },
            "answer_relevancy": {
              "mean": 0.8840076251449925,
              "std": 0.03220948733981754,
              "min": 0.8366828943604284,
              "max": 0.9181316279283243,
              "median": 0.8906079891456087,
              "percentile_25": 0.8635167778898118,
              "percentile_75": 0.9110988364007893,
              "count": 4
            }
          },
          "correlation_matrix": [
            [
              1.0,
              0.3504834326153369
            ],
            [
              0.3504834326153369,
              1.0
            ]
          ],
          "correlation_metrics": [
            "faithfulness",
            "answer_relevancy"
          ],
          "significant_correlations": [],
          "low_performers": [
            {
              "test_case_id": "test_001",
              "metric_name": "faithfulness",
              "score": 0.0,
              "threshold": 0.7,
              "question_preview": "What is Python?",
              "potential_causes": [
                "Answer contains information not in context",
                "Possible hallucination"
              ]
            },
            {
              "test_case_id": "test_003",
              "metric_name": "faithfulness",
              "score": 0.0,
              "threshold": 0.7,
              "question_preview": "What is RAG?",
              "potential_causes": [
                "Answer contains information not in context",
                "Possible hallucination"
              ]
            }
          ],
          "insights": [
            "Moderate pass rate needs improvement: 50.0%",
            "Best performing metric: answer_relevancy (mean: 0.884)",
            "Worst performing metric: faithfulness (mean: 0.500)",
            "High variance metrics (std > 0.2): faithfulness",
            "Found 2 low-performing test cases (score < threshold)",
            "Most problematic metric: faithfulness (2 low performers)"
          ],
          "overall_pass_rate": 0.5,
          "metric_pass_rates": {
            "faithfulness": 0.5,
            "answer_relevancy": 1.0
          }
        },
        "summary": {
          "total_metrics": 2,
          "average_score": 0.692,
          "overall_pass_rate": 0.5
        },
        "statistics": {
          "faithfulness": {
            "mean": 0.5,
            "std": 0.5,
            "min": 0.0,
            "max": 1.0,
            "median": 0.5,
            "percentile_25": 0.0,
            "percentile_75": 1.0,
            "count": 4
          },
          "answer_relevancy": {
            "mean": 0.8840076251449925,
            "std": 0.03220948733981754,
            "min": 0.8366828943604284,
            "max": 0.9181316279283243,
            "median": 0.8906079891456087,
            "percentile_25": 0.8635167778898118,
            "percentile_75": 0.9110988364007893,
            "count": 4
          }
        },
        "insights": [
          "Moderate pass rate needs improvement: 50.0%",
          "Best performing metric: answer_relevancy (mean: 0.884)",
          "Worst performing metric: faithfulness (mean: 0.500)",
          "High variance metrics (std > 0.2): faithfulness",
          "Found 2 low-performing test cases (score < threshold)",
          "Most problematic metric: faithfulness (2 low performers)"
        ],
        "analysis_id": "9bf2bdc5-8190-477c-bd20-d39d054fad9b",
        "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
        "correlation_metrics": [
          "faithfulness",
          "answer_relevancy"
        ],
        "correlation_matrix": [
          [
            1.0,
            0.3504834326153369
          ],
          [
            0.3504834326153369,
            1.0
          ]
        ],
        "significant_correlations": [],
        "low_performers": [
          {
            "test_case_id": "test_001",
            "metric_name": "faithfulness",
            "score": 0.0,
            "threshold": 0.7,
            "question_preview": "What is Python?",
            "potential_causes": [
              "Answer contains information not in context",
              "Possible hallucination"
            ]
          },
          {
            "test_case_id": "test_003",
            "metric_name": "faithfulness",
            "score": 0.0,
            "threshold": 0.7,
            "question_preview": "What is RAG?",
            "potential_causes": [
              "Answer contains information not in context",
              "Possible hallucination"
            ]
          }
        ],
        "metric_pass_rates": {
          "faithfulness": 0.5,
          "answer_relevancy": 1.0
        }
      }
    },
    "ragas_eval": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "summary": {
          "metric_count": 2,
          "sample_count": 4,
          "overall_score": 0.692,
          "recomputed": false
        },
        "metrics": {
          "faithfulness": 0.5,
          "answer_relevancy": 0.8840076251449925
        },
        "per_case": [
          {
            "test_case_id": "test_001",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.8366828943604284
            },
            "avg_score": 0.4183,
            "question_preview": "What is Python?"
          },
          {
            "test_case_id": "test_002",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.8724614057329397
            },
            "avg_score": 0.9362,
            "question_preview": "What is machine learning?"
          },
          {
            "test_case_id": "test_003",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.9087545725582776
            },
            "avg_score": 0.4544,
            "question_preview": "What is RAG?"
          },
          {
            "test_case_id": "test_004",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.9181316279283243
            },
            "avg_score": 0.9591,
            "question_preview": "What is TDD?"
          }
        ]
      }
    },
    "nlp_analysis": {
      "status": "completed",
      "error": null,
      "duration_ms": 155,
      "output": {
        "analysis": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "question_stats": {
            "char_count": 67,
            "word_count": 13,
            "sentence_count": 4,
            "avg_word_length": 3.923076923076923,
            "unique_word_ratio": 0.5384615384615384
          },
          "answer_stats": {
            "char_count": 162,
            "word_count": 25,
            "sentence_count": 4,
            "avg_word_length": 5.36,
            "unique_word_ratio": 0.92
          },
          "context_stats": {
            "char_count": 258,
            "word_count": 43,
            "sentence_count": 1,
            "avg_word_length": 5.023255813953488,
            "unique_word_ratio": 0.9069767441860465
          },
          "question_types": [
            {
              "question_type": "factual",
              "count": 4,
              "percentage": 1.0,
              "avg_scores": {
                "answer_relevancy": 0.8840076251449925,
                "faithfulness": 0.5
              }
            }
          ],
          "top_keywords": [
            {
              "keyword": "is",
              "frequency": 6,
              "tfidf_score": 0.24634723644073758,
              "avg_metric_scores": null
            },
            {
              "keyword": "tdd",
              "frequency": 2,
              "tfidf_score": 0.17105004542815092,
              "avg_metric_scores": null
            },
            {
              "keyword": "what",
              "frequency": 4,
              "tfidf_score": 0.1666027922057938,
              "avg_metric_scores": null
            },
            {
              "keyword": "python",
              "frequency": 2,
              "tfidf_score": 0.16341620996113213,
              "avg_metric_scores": null
            },
            {
              "keyword": "rag",
              "frequency": 2,
              "tfidf_score": 0.1618416489767295,
              "avg_metric_scores": null
            },
            {
              "keyword": "learning",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "machine",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "development",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "driven",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "means",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "test",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "high",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "language",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "level",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "programming",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "augmented",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "for",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "generation",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "retrieval",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "stands",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            }
          ],
          "topic_clusters": [],
          "insights": [
            "Questions are short and concise",
            "Dominant question type: factual (100%)",
            "Top keywords: is, tdd, what"
          ]
        },
        "summary": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "has_text_stats": true,
          "has_question_type_analysis": true,
          "has_keyword_analysis": true,
          "question_stats_preview": 3.25,
          "answer_stats_preview": 6.25,
          "context_count": 1,
          "dominant_question_type": "factual",
          "top_keywords_preview": [
            "is",
            "tdd",
            "what",
            "python",
            "rag"
          ]
        },
        "statistics": {
          "text_stats": {
            "questions": {
              "char_count": 67,
              "word_count": 13,
              "sentence_count": 4,
              "avg_word_length": 3.923076923076923,
              "unique_word_ratio": 0.5384615384615384
            },
            "answers": {
              "char_count": 162,
              "word_count": 25,
              "sentence_count": 4,
              "avg_word_length": 5.36,
              "unique_word_ratio": 0.92
            },
            "contexts": {
              "char_count": 258,
              "word_count": 43,
              "sentence_count": 1,
              "avg_word_length": 5.023255813953488,
              "unique_word_ratio": 0.9069767441860465
            }
          },
          "question_type_distribution": [
            {
              "question_type": "factual",
              "count": 4,
              "percentage": 1.0,
              "avg_scores": {
                "answer_relevancy": 0.8840076251449925,
                "faithfulness": 0.5
              }
            }
          ],
          "keywords": [
            {
              "keyword": "is",
              "frequency": 6,
              "tfidf_score": 0.24634723644073758,
              "avg_metric_scores": null
            },
            {
              "keyword": "tdd",
              "frequency": 2,
              "tfidf_score": 0.17105004542815092,
              "avg_metric_scores": null
            },
            {
              "keyword": "what",
              "frequency": 4,
              "tfidf_score": 0.1666027922057938,
              "avg_metric_scores": null
            },
            {
              "keyword": "python",
              "frequency": 2,
              "tfidf_score": 0.16341620996113213,
              "avg_metric_scores": null
            },
            {
              "keyword": "rag",
              "frequency": 2,
              "tfidf_score": 0.1618416489767295,
              "avg_metric_scores": null
            },
            {
              "keyword": "learning",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "machine",
              "frequency": 2,
              "tfidf_score": 0.14221086885062423,
              "avg_metric_scores": null
            },
            {
              "keyword": "development",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "driven",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "means",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "test",
              "frequency": 1,
              "tfidf_score": 0.08552502271407546,
              "avg_metric_scores": null
            },
            {
              "keyword": "high",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "language",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "level",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "programming",
              "frequency": 1,
              "tfidf_score": 0.08170810498056606,
              "avg_metric_scores": null
            },
            {
              "keyword": "augmented",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "for",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "generation",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "retrieval",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            },
            {
              "keyword": "stands",
              "frequency": 1,
              "tfidf_score": 0.08092082448836475,
              "avg_metric_scores": null
            }
          ]
        },
        "insights": [
          "Questions are short and concise",
          "Dominant question type: factual (100%)",
          "Top keywords: is, tdd, what"
        ],
        "analysis_id": null,
        "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
        "question_types": [
          {
            "question_type": "factual",
            "count": 4,
            "percentage": 1.0,
            "avg_scores": {
              "answer_relevancy": 0.8840076251449925,
              "faithfulness": 0.5
            }
          }
        ],
        "top_keywords": [
          {
            "keyword": "is",
            "frequency": 6,
            "tfidf_score": 0.24634723644073758,
            "avg_metric_scores": null
          },
          {
            "keyword": "tdd",
            "frequency": 2,
            "tfidf_score": 0.17105004542815092,
            "avg_metric_scores": null
          },
          {
            "keyword": "what",
            "frequency": 4,
            "tfidf_score": 0.1666027922057938,
            "avg_metric_scores": null
          },
          {
            "keyword": "python",
            "frequency": 2,
            "tfidf_score": 0.16341620996113213,
            "avg_metric_scores": null
          },
          {
            "keyword": "rag",
            "frequency": 2,
            "tfidf_score": 0.1618416489767295,
            "avg_metric_scores": null
          },
          {
            "keyword": "learning",
            "frequency": 2,
            "tfidf_score": 0.14221086885062423,
            "avg_metric_scores": null
          },
          {
            "keyword": "machine",
            "frequency": 2,
            "tfidf_score": 0.14221086885062423,
            "avg_metric_scores": null
          },
          {
            "keyword": "development",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "driven",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "means",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "test",
            "frequency": 1,
            "tfidf_score": 0.08552502271407546,
            "avg_metric_scores": null
          },
          {
            "keyword": "high",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "language",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "level",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "programming",
            "frequency": 1,
            "tfidf_score": 0.08170810498056606,
            "avg_metric_scores": null
          },
          {
            "keyword": "augmented",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "for",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "generation",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "retrieval",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          },
          {
            "keyword": "stands",
            "frequency": 1,
            "tfidf_score": 0.08092082448836475,
            "avg_metric_scores": null
          }
        ],
        "topic_clusters": []
      }
    },
    "time_series": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "series": [
          {
            "run_id": "702cb7d4-6b3d-4ec8-9f02-19465c377e52",
            "timestamp": "2026-01-09T08:14:13.875276",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "f042196b-1c77-463c-b695-3a5b938e349f",
            "timestamp": "2026-01-09T08:14:13.938368",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "a491fa0e-208d-4a34-acc6-2aba629dd0c3",
            "timestamp": "2026-01-09T08:14:14.026053",
            "pass_rate": 1.0,
            "model_name": "gpt-5-nano"
          },
          {
            "run_id": "9fbf4776-9f5b-4c4b-ba08-c556032cee86",
            "timestamp": "2026-01-09T09:24:21.002694",
            "pass_rate": 0.0,
            "model_name": "gpt-oss-safeguard:20b"
          },
          {
            "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
            "timestamp": "2026-01-09T09:27:38.337182",
            "pass_rate": 0.5,
            "model_name": "ollama/gpt-oss-safeguard:20b"
          },
          {
            "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
            "timestamp": "2026-01-09T09:47:43.429178",
            "pass_rate": 0.5,
            "model_name": "ollama/gpt-oss-safeguard:20b"
          }
        ],
        "summary": {
          "run_count": 6,
          "avg_pass_rate": 0.6667,
          "start": "2026-01-09T08:14:13.875276",
          "end": "2026-01-09T09:47:43.429178"
        }
      }
    },
    "causal_analysis": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "analysis": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "analysis_id": "9398c0e2-2774-4bdf-84d9-ef12d55c3a01",
          "created_at": "2026-01-09T11:22:53.592717",
          "factor_stats": {},
          "factor_impacts": [],
          "causal_relationships": [],
          "root_causes": [],
          "interventions": [],
          "insights": [
            "Insufficient samples for causal analysis (4 < 10)"
          ]
        },
        "summary": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "factor_count": 0,
          "significant_impact_count": 0,
          "root_cause_count": 0
        },
        "statistics": {},
        "insights": [
          "Insufficient samples for causal analysis (4 < 10)"
        ],
        "analysis_id": "9398c0e2-2774-4bdf-84d9-ef12d55c3a01",
        "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
        "factor_stats": {},
        "significant_impacts": [],
        "root_causes": [],
        "interventions": []
      }
    },
    "low_samples": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "threshold": 0.5,
        "low_performers": [
          {
            "test_case_id": "test_001",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.8366828943604284
            },
            "avg_score": 0.4183,
            "question_preview": "What is Python?"
          },
          {
            "test_case_id": "test_003",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.9087545725582776
            },
            "avg_score": 0.4544,
            "question_preview": "What is RAG?"
          }
        ],
        "count": 2
      }
    },
    "diagnostic": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "threshold": 0.6,
        "diagnostics": [
          {
            "metric": "faithfulness",
            "issue": "faithfulness 점수가 기준치 미달입니다 (0.50 < 0.70).",
            "score": 0.5,
            "threshold": 0.7,
            "gap": 0.2
          }
        ],
        "recommendations": [
          "답변을 검색 컨텍스트에 더 강하게 고정하고 근거 인용을 강화하세요."
        ]
      }
    },
    "priority_summary": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "bottom_percentile": 10.0,
        "impact_count": 3,
        "total_cases": 4,
        "bottom_count": 1,
        "bottom_cases": [
          {
            "test_case_id": "test_001",
            "avg_score": 0.4183,
            "failed_metrics": [
              "faithfulness"
            ],
            "failed_metric_count": 1,
            "gap_by_metric": {
              "faithfulness": 0.7
            },
            "shortfall": 0.7,
            "impact_score": 0.616,
            "worst_metric": "faithfulness",
            "worst_score": 0.0,
            "worst_gap": 0.7,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is Python?",
            "analysis_hints": [
              "컨텍스트-답변 정합성 점검 필요",
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "bottom_percentile",
              "high_impact"
            ]
          }
        ],
        "impact_cases": [
          {
            "test_case_id": "test_001",
            "avg_score": 0.4183,
            "failed_metrics": [
              "faithfulness"
            ],
            "failed_metric_count": 1,
            "gap_by_metric": {
              "faithfulness": 0.7
            },
            "shortfall": 0.7,
            "impact_score": 0.616,
            "worst_metric": "faithfulness",
            "worst_score": 0.0,
            "worst_gap": 0.7,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is Python?",
            "analysis_hints": [
              "컨텍스트-답변 정합성 점검 필요",
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "bottom_percentile",
              "high_impact"
            ]
          },
          {
            "test_case_id": "test_003",
            "avg_score": 0.4544,
            "failed_metrics": [
              "faithfulness"
            ],
            "failed_metric_count": 1,
            "gap_by_metric": {
              "faithfulness": 0.7
            },
            "shortfall": 0.7,
            "impact_score": 0.616,
            "worst_metric": "faithfulness",
            "worst_score": 0.0,
            "worst_gap": 0.7,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is RAG?",
            "analysis_hints": [
              "컨텍스트-답변 정합성 점검 필요",
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "high_impact"
            ]
          },
          {
            "test_case_id": "test_002",
            "avg_score": 0.9362,
            "failed_metrics": [],
            "failed_metric_count": 0,
            "gap_by_metric": {},
            "shortfall": 0.0,
            "impact_score": 0.1,
            "worst_metric": null,
            "worst_score": null,
            "worst_gap": null,
            "question_type": "factual",
            "question_type_label": "사실",
            "question_preview": "What is machine learning?",
            "analysis_hints": [
              "질문 유형: 사실"
            ],
            "metadata": null,
            "tags": [
              "high_impact"
            ]
          }
        ],
        "run_metadata": {
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "dataset_name": "test_dataset",
          "dataset_version": "1.0.0",
          "model_name": "ollama/gpt-oss-safeguard:20b",
          "started_at": "2026-01-09T09:47:43.429178",
          "finished_at": "2026-01-09T09:51:00.132606",
          "total_test_cases": 4,
          "passed_test_cases": 2,
          "pass_rate": 0.5,
          "total_tokens": 18642,
          "total_cost_usd": 0.051585,
          "duration_seconds": 196.703428,
          "tracker_metadata": {
            "run_mode": "full"
          },
          "metrics_evaluated": [
            "faithfulness",
            "answer_relevancy"
          ],
          "run_mode": "full",
          "thresholds": {
            "faithfulness": 0.7,
            "answer_relevancy": 0.7
          },
          "avg_faithfulness": 0.5,
          "avg_answer_relevancy": 0.8840076251449925
        }
      }
    },
    "pattern_detection": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "patterns": [
          {
            "label": "Top keyword",
            "detail": "is (freq 6)"
          },
          {
            "label": "Top keyword",
            "detail": "tdd (freq 2)"
          },
          {
            "label": "Top keyword",
            "detail": "what (freq 4)"
          },
          {
            "label": "Top keyword",
            "detail": "python (freq 2)"
          },
          {
            "label": "Top keyword",
            "detail": "rag (freq 2)"
          },
          {
            "label": "Question type",
            "detail": "factual (1.0%)"
          }
        ],
        "summary": {
          "keyword_count": 20,
          "question_type_count": 1
        }
      }
    },
    "trend_detection": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "trends": [
          {
            "metric": "pass_rate",
            "direction": "down",
            "delta": -0.5
          }
        ],
        "summary": {
          "start": 1.0,
          "end": 0.5,
          "delta": -0.5
        },
        "recommendations": [
          "Performance is trending down; investigate changes."
        ]
      }
    },
    "root_cause": {
      "status": "completed",
      "error": null,
      "duration_ms": 0,
      "output": {
        "causes": [
          {
            "metric": "faithfulness",
            "reason": "faithfulness 점수가 기준치 미달입니다 (0.50 < 0.70)."
          }
        ],
        "recommendations": [
          "답변을 검색 컨텍스트에 더 강하게 고정하고 근거 인용을 강화하세요."
        ],
        "low_performer_count": 2
      }
    },
    "report": {
      "status": "completed",
      "error": null,
      "duration_ms": 86037,
      "output": {
        "report": "# RAG 평가 분석 보고서  \n**Run ID**: f1287e90-43b6-42c8-b3ac-e6cb3e06a71e | **Dataset**: test_dataset v1.0.0 | **모델**: ollama/gpt‑oss‑safeguard:20b  \n\n---\n\n## 1. 요약  \n**주요 결론**: 전체 합계 0.692의 과반자(50 %)가 기준치를 초과하지 않으며, 신뢰성(faithfulness) 부족이 가장 큰 문제입니다.  \n\n- **지표**: 대다수 테스트에서 answer_relevancy는 0.884 이상인 반면 faithfulness는 평균 0.5(위험 수준)입니다.  \n- **원인**: 답변이 컨텍스트와 충분히 정합되지 않아 근거 인용이 미흡한 점이 크게 영향을 끼칩니다.  \n- **사용자 영향**: 신뢰가 낮아 사용자는 정보의 정확성에 의문을 가질 수 있고, 이해와 인지부하가 증가합니다.  \n\n---\n\n## 2. 지표 스코어카드  \n\n| metric | 평균 | threshold | pass_rate | 상태 |\n|--------|------|-----------|-----------|------|\n| answer_relevancy | 0.884 | 0.7 | 1.00 | Pass |\n| faithfulness | 0.500 | 0.7 | 0.50 | Risk |\n\n> **전체 pass_rate**: 0.50 (4개 테스트 중 2개만 성공)  \n\n---\n\n## 3. 데이터 품질/신뢰도\n\n| 항목 | 상태 |\n|------|------|\n| 샘플 수 | 4(표본 수가 소수) |\n| coverage | 1.0 (모든 테스트에 필수 메트릭 적용) |\n| 추세 분석 | 부족 (데이터가 한 번에 한 실행) |\n\n> *표시된 경고*: `표본 수가 적음`, `추세 분석을 위한 실행 이력 부족`. 작은 샘플로 인해 통계 해석에 주의 필요.  \n\n---\n\n## 4. 증거 기반 인사이트  \n\n| 테스트 ID | 질문 | answer_relevancy | faithfulness | 주요 문제 포인트 | evidence_id |\n|-----------|------|------------------|--------------|------------------|-------------|\n| test_001 | What is Python? | 0.837 | 0.0 | 컨텍스트와 불일치 | [E1] |\n| test_003 | What is RAG? | 0.909 | 0.0 | 근거 없이 정리된 정의 | [E2] |\n| test_002 | What is machine learning? | 0.872 | 1.0 | 컨텍스트와 일치 | [E3] |\n| test_004 | What is TDD? | 0.918 | 1.0 | 정확히 정정 | [E4] |\n\n- **패턴**: 핵심 키워드 `is`, `tdd`, `what`, `python`, `rag` 순위 하위.  \n- **대부분의 사례**(test_001, test_003)에서 faithfulness가 0으로 떨어져 **위험 요인**이 두 번 발생.  \n\n**사용자 인식**  \n- *신뢰성* 낮은 답변은 사용자에게 부정확한 정보를 제공함으로써 **신뢰 저하**를 초래.  \n- 사실 질문에서 신뢰성이 보장되지 않을 경우 **인지부하**가 증가해 추론이 필요.\n\n---\n\n## 5. 원인 가설  \n\n1. **컨텍스트 정합성 부재**  \n   - 테스트 E1, E2에서 답변이 제공된 컨텍스트와 크게 차이나며 핵심 사실이 누락.  \n2. **근거 인용 미흡**  \n   - 모델이 답변을 생성할 때 외부 정보(컨텍스트) 참조를 불충분히 활용.  \n3. **지문 길이 및 복잡성**  \n   - 질문이 짧고 단순(`factual`)이어서 모델이 외부 정보에 대한 의존도를 낮춤.  \n\n> **root_cause**: faithfulness 징후가 0.5 미달 → **비판적 근거 부재**.\n\n---\n\n## 6. 개선 제안  \n\n| 영역 | 제안 | 근거 |\n|------|------|------|\n| **컨텍스트 활용** | 문맥 매칭 알고리즘(예: BM25 또는 DPR)으로 가장 관련 있는 문장을 선택 후 강조 표시 | E1, E2 에서 낮은 faithfulness |\n| **근거 기반 인용** | 답변에 인용 부호 또는 링크 삽입 → 사용자가 직접 컨텍스트 확인 가능 | *제안* 메트릭 |\n| **데이터 보강** | 테스트 샘플 증가 및 다양한 질문 유형 추가 | “표본 수가 적음” 경고 |\n| **모델 튜닝** | `faithfulness` 목표치를 0.7 이상으로 강제하도록 파인튜닝 또는 후처리 기준 적용 | `thresholds.fai­l­ty­ness = 0.7` |\n| **평가 프레임워크 보강** | 실시간 추세 및 시계열 분석 추가 | “추세 분석 부족” |\n\n---\n\n## 7. 다음 단계  \n\n1. **샘플 확장** – 10~20개 추가 테스트 수행, 다양한 질문 유형(문법, 개념, 인용 등).  \n2. **컨텍스트 매핑 재설계** – 더 정밀한 맥락 연관성 스코어링 도입.  \n3. **사후 검증** – 자동화된 근거 인용 검증 스크립트 개발.  \n4. **A/B 테스트** – 두 버전(현재 vs. 개선) 비교하여 `faithfulness` 향상 여부 확인.  \n\n---\n\n## 8. 부록(산출물)\n\n| 파일 | 내용 |\n|------|------|\n| causal_analysis.json | 원인 분석 결과 |\n| load_data.json | 데이터 로딩 스크립트 |\n| nlp_analysis.json | 키워드, 문장 통계 |\n| pattern_detection.json | Top keyword, question type 패턴 |\n| priority_summary.json | 위험 및 우선순위 평가 |\n| ragas_eval.json | 평가 메트릭 결과 |\n| root_cause.json | root_cause 및 추천 |\n| statistics.json | 전체 통계 |\n| trend_detection.json | 추세 및 변화 |\n\n---\n\n> **추가 데이터 필요**: 현 시점에서 샘플 수가 적어 추세 파악이 어려우며, 다른 모델 간 비교 분석이 필요하면 추가 run data 수집을 권장합니다.",
        "format": "markdown",
        "llm_used": true,
        "llm_model": "ollama/gpt-oss-safeguard:20b",
        "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
        "summary": {
          "report_type": "analysis",
          "total_evidence": 4,
          "has_run": true
        },
        "evidence": [
          {
            "test_case_id": "test_001",
            "avg_score": 0.4183,
            "failed_metrics": [
              "faithfulness"
            ],
            "question": "What is Python?",
            "answer": "Python is a high-level programming language.",
            "contexts": [
              "Python is a programming language",
              "Python was created by Guido van Rossum"
            ],
            "ground_truth": "Python is a high-level interpreted programming language.",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.8366828943604284
            },
            "evidence_id": "E1"
          },
          {
            "test_case_id": "test_003",
            "avg_score": 0.4544,
            "failed_metrics": [
              "faithfulness"
            ],
            "question": "What is RAG?",
            "answer": "RAG stands for Retrieval-Augmented Generation.",
            "contexts": [
              "RAG combines retrieval and generation",
              "RAG improves LLM responses"
            ],
            "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information.",
            "metrics": {
              "faithfulness": 0.0,
              "answer_relevancy": 0.9087545725582776
            },
            "evidence_id": "E2"
          },
          {
            "test_case_id": "test_002",
            "avg_score": 0.9362,
            "failed_metrics": [],
            "question": "What is machine learning?",
            "answer": "Machine learning is a subset of AI.",
            "contexts": [
              "ML is part of AI",
              "ML uses algorithms to learn from data"
            ],
            "ground_truth": "Machine learning is a method of data analysis that automates analytical model building.",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.8724614057329397
            },
            "evidence_id": "E3"
          },
          {
            "test_case_id": "test_004",
            "avg_score": 0.9591,
            "failed_metrics": [],
            "question": "What is TDD?",
            "answer": "TDD means Test-Driven Development.",
            "contexts": [
              "Test-Driven Development",
              "Write tests first",
              "Red-Green-Refactor cycle"
            ],
            "ground_truth": "TDD is a software development approach where tests are written before code.",
            "metrics": {
              "faithfulness": 1.0,
              "answer_relevancy": 0.9181316279283243
            },
            "evidence_id": "E4"
          }
        ]
      }
    }
  },
  "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
  "artifacts": {
    "dir": "reports/analysis/artifacts/analysis_f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
    "index": "reports/analysis/artifacts/analysis_f1287e90-43b6-42c8-b3ac-e6cb3e06a71e/index.json"
  }
}
