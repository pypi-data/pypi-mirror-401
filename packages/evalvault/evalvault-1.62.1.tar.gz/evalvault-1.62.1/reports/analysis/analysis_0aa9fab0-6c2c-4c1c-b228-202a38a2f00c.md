# RAG 평가 분석 보고서

## 요약
- **실행 ID**: `0aa9fab0-6c2c-4c1c-b228-202a38a2f00c`
- **데이터셋**: `test_dataset v1.0.0`
- **모델**: `ollama/gpt-oss-safeguard:20b`
- **전체 테스트 케이스**: 4
- **총 통과율**: **50 %**
- **평균 스코어**: **0.692**
- **주요 KPI**
  - `faithfulness`: **0.50** (목표 0.70 미달) → 실패
  - `answer_relevancy`: **0.884** (목표 0.70 초과) → 성공

세 명의 고충량 테스트 케이스는 `faithfulness` 지표가 0 %로 가장 낮은 점수를 기록했습니다. 이는 `What is Python?` 와 `What is RAG?` 라는 사실 기반 질문에 대한 답변이 문맥과 불일치하거나 불완전하게 제공되었기 때문입니다.

## 문제 진단

| 테스트 케이스 | 실패 지표 | 평균 스코어 | 부족한 점 | 비고 |
|------|----------|------------|----------|------|
| **test_001** | faithfulness | 0.418 | “Python은 고수준 프로그래밍 언어”만 제시; 핵심 ‘해석형’ 정보 누락 | [E1] |
| **test_003** | faithfulness | 0.454 | “RAG는 Retrieval‑Augmented Generation이란 약자”만 언급; 실제 정의와 차이점 간과 | [E2] |
| **test_002** | ― | 0.936 | 정확하고 핵심 문장 포함 | [E3] |
| **test_004** | ― | 0.959 | 상세한 용어와 프로세스 포함 | [E4] |

*문제 핵심*: **faithfulness** 점수가 0.70 이하인 사안이 두 번 발생 → “컨텍스트-답변 정합성”이 충분히 확인되지 않음.
*추정 원인*
1. 검색 컨텍스트(핵심 정보)를 모델이 완전하게 활용하지 못함.
2. 답변 생성 시 “정확한 인용” 없이 압축적인 설명을 제공함.

## 증거 기반 분석

- **test_001**
  - 질문: *What is Python?*
  - 정답: *Python은 고수준 해석형 프로그래밍 언어*
  - 모델 답변: *Python은 고수준 프로그래밍 언어* → **해석형**이 빠져 신뢰성 저하.
  - 컨텍스트: “Python is a programming language” / “Python was created by Guido van Rossum”.
  - **faithfulness**: 0.0 → [E1]

- **test_003**
  - 질문: *What is RAG?*
  - 정답: *RAG는 검색과 생성이 결합되어 LLM 결과를 향상시키는 기술*
  - 모델 답변: *RAG stands for Retrieval‑Augmented Generation* → **정의만 전달**, 실제 기능 설명 부족.
  - 컨텍스트: “RAG combines retrieval and generation”, “RAG improves LLM responses”.
  - **faithfulness**: 0.0 → [E2]

- **test_002** / **test_004**는 모두 **faithfulness** 1.0을 기록하여, 모델이 사실 기반 질문에 대해 잘 처리할 수 있음을 보여준다. 이 두 사례에서는 문맥과 답변이 일치하고, 답변이 충분히 종합적이다.

- **전반적 패턴**:
  - `Top keyword: "is"`, `question_type: "factual"`이 높은 비중을 차지함.
  - `answer_relevancy`는 대부분 높은 편(0.84‑0.92)이며, 주된 문제는 정합성에 한정되어 있음.

## 개선 제안

| 영역 | 제안 | 근거 |
|------|------|------|
| **컨텍스트 활용** | 1. 검색 결과를 답변 생성 시 **강제 인용** 구조로 삽입(예: “출처: …”) <br> 2. **컨텍스트 스코어링**을 선행하여 가장 핵심 정보를 보강하여 답변에 포함 | - 테스트 사례[E1, E2]에서 컨텍스트가 활용되지 않은 점, <br> - `faithfulness` 개선을 위한 정합성 강화 |
| **프롬프트 설계** | 1. “정확한 설명과 함께 출처를 명시하라”는 명시적 지시 <br> 2. 질문이 `factual`인 경우 **정확도 점검** 프롬프트 삽입 | - `analysis_hints`(문맥-답변 정합성 점검 필요)가 이미 제시됨 |
| **품질 체크** | 1. **자동 정합성 검사**(컨텍스트‑답변 차이점 비교) <br> 2. `faithfulness`가 0.7 미달 시 **재검색** 또는 **다른 문서** 시도 | - `metrics_evaluated`에 `faithfulness`가 포함되어 있으므로, 자동화 가능 |
| **데이터 확장** | 1. 추가적인 `factual` 유형 질문과 그에 대한 다수의 컨텍스트 사례를 수집 <br> 2. `analysis_hints`를 더 세분화 (예: “코드 예시를 포함하라”) | - 향후 변동 추세(“pass_rate down” )를 보완하려면 더 많은 데이터를 사용해 기계 학습을 재훈련 가능 |

## 다음 단계

1. **리포트 기반 리펙터링**
   - 모델 프롬프트 및 검색 파이프라인에 “출처 기반 인용”을 요구하도록 수정.
   - 정합성 점검 로직을 추가하고, `faithfulness`가 0.7 미만일 경우 자동 재검색을 트리거.

2. **추가 테스트 실행**
   - `factual` 유형의 다수 샘플을 도입하여 `faithfulness` 개선 여부를 실험.
   - `threshold` 기준 재검토(현재 0.7)와 실제 사용자 시나리오에 맞는 목표 재정립.

3. **모델/연산 리소스 검토**
   - 실행 비용(0.051 USD) 및 토큰량(18,642)을 고려하여, 모델 크기와 API 호출 수를 조정.

4. **다음 평가 주기**
   - 개선 후 `faithfulness` 목표 0.75 이상, `answer_relevancy` 0.90 이상을 목표로 재평가.
   - `pass_rate` 상승 동향을 모니터링하면서, **bottom_percentile** 케이스를 20 % 이하로 감소.

---

*필요 시 추가 데이터(문맥이 풍부한 사례, 모델의 내부 로깅 등)를 수집해 분석을 보완할 수 있습니다.*
