{
  "output": {
    "report": {
      "report": "# RAG í‰ê°€ ë¶„ì„ ë³´ê³ ì„œ  \n**ë¹„êµ ëŒ€ìƒ**: `run_a (0aa9fab0â€‘6c2câ€‘4c1câ€‘b228â€‘202a38a2f00c)` vs `run_b (f1287e90â€‘43b6â€‘42c8â€‘b3acâ€‘e6cb3e06a71e)`  \n**ë°ì´í„°ì…‹**: `test_dataset v1.0.0` (ë³€ê²½ ì—†ìŒ)  \n**ëª¨ë¸**: `ollama/gptâ€‘ossâ€‘safeguard:20b`  \n**í‰ê°€ ê¸°ê°„**: 2026â€‘01â€‘09\n\n---\n\n## ğŸ“Œ ìš”ì•½  \në‘ ì‹¤í–‰ì€ ë™ì¼í•œ ëª¨ë¸Â·ë°ì´í„°ì…‹Â·êµ¬ì„±ì„ ì‚¬ìš©í•´ ì‹¤í–‰ëœ ê²°ê³¼, **Faithfulness** ë° **Answer Relevancy** ì§€í‘œì—ì„œ ì°¨ì´ê°€ ì—†ìœ¼ë©°(í‰ê·  0.5 / 0.884)â€¯**ì§€í‘œ ë³€í™”ê°€ ê±°ì˜ ë¬´ì‹œ ê°€ëŠ¥**í–ˆë‹¤.  \n- **ì§€í‘œ**: Faithfulness 0.5, Relevancy 0.884, ë‘ ì‹¤í–‰ ëª¨ë‘ Pass Rate 0.5  \n- **ë³€ê²½ ì‚¬í•­**: ë°ì´í„°ì…‹/êµ¬ì„±/í”„ë¡¬í”„íŠ¸ ë³€í™” ì—†ìŒ â†’ ëª¨ë¸ ì„±ê³¼ì˜ ì°¨ì´ ì—†ìŒ  \n- **ì‚¬ìš©ì ì˜í–¥**: í˜„ ì‹œì ì—ì„œëŠ” ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ benefitì´ë‚˜ ë¦¬ìŠ¤í¬ê°€ ê´€ì¸¡ë˜ì§€ ì•ŠìŒ(ë‹¨, í‘œë³¸ ìˆ˜ê°€ ì ì–´ í†µê³„ì  ì‹ ë¢°ë„ ë‚®ìŒ)\n\n---\n\n## ğŸ” ë³€ê²½ ì‚¬í•­ ìš”ì•½  \n| í•­ëª© | Runâ€¯A | Runâ€¯B | ë³€í™” ì—¬ë¶€ |\n|------|-------|-------|-----------|\n| ë°ì´í„°ì…‹ ë²„ì „ | 1.0.0 | 1.0.0 | **ì—†ìŒ** |\n| ì„¤ì •(ì˜µì…˜) | ë™ì¼ | ë™ì¼ | **ì—†ìŒ** |\n| í”„ë¡¬í”„íŠ¸ | ê¸°ë¡ ë¯¸ì¡´ì¬ | ê¸°ë¡ ë¯¸ì¡´ì¬ | **ë¯¸ê²€ì¦** |\n\n> **â€» ì£¼ì˜**: í”„ë¡¬í”„íŠ¸ ìŠ¤ëƒ…ìƒ·ì´ ì—†ìœ¼ë¯€ë¡œ í”„ë¡¬í”„íŠ¸ ì°¨ì´ í•´ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n---\n\n## ğŸ“Š ì§€í‘œ ë¹„êµ ìŠ¤ì½”ì–´ì¹´ë“œ  \n\n| metric | mean_A | mean_B | diff | diff_percent | pâ€‘value | effect_size | effect_level | status |\n|--------|--------|--------|------|--------------|---------|-------------|--------------|--------|\n| faithfulness | 0.50 | 0.50 | 0.00 | 0.00% | 1.00 | 0.0 | negligible | flat |\n| answer_relevancy | 0.884 | 0.884 | 0.00 | 0.00% | 1.00 | 0.0 | negligible | flat |\n\n> **ì„¤ëª…**: ë‘ ì‹¤í–‰ ëª¨ë‘ `faithfulness`ì™€ `answer_relevancy`ê°€ ë™ì¼í•œ í‰ê· ì„ ë³´ì˜€ìœ¼ë©°, í†µê³„ì  ì°¨ì´(`p_value = 1.00`)ê°€ ì—†ì–´ **ìœ ì˜ë¯¸í•œ ê°œì„ Â·í•˜ë½**ì´ ê´€ì¸¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\n---\n\n## ğŸ“ˆ í†µê³„ì  ì‹ ë¢°ë„  \n- **í‘œë³¸ ìˆ˜**: 4ê°œ(ë˜ëŠ” 3ê°œ) í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë§Œ ì‚¬ìš© â†’ í†µê³„ì  power ë¶€ì¡±  \n- **pâ€‘value**: ëª¨ë“  ì§€í‘œì—ì„œ 1.00 â†’ ì°¨ì´ê°€ ì—†ìŒì„ ì˜ë¯¸í•˜ì§€ë§Œ ì‘ì€ í‘œë³¸ ë•Œë¬¸ì— ê²°ê³¼ì˜ ì¼ë°˜ì„±ì€ ë¶ˆíˆ¬ëª…  \n- **íš¨ê³¼í¬ê¸°**: 0.0 â†’ ì‹¤ì§ˆì  ì°¨ì´ëŠ” ì—†ì§€ë§Œ ì‹ ë¢° êµ¬ê°„ì€ ê³„ì‚° ë¶ˆê°€  \n\n> **ì¶”ê°€ ë°ì´í„° í•„ìš”**: ë” ë§ì€ ì¼€ì´ìŠ¤(â‰¥30)ì™€ ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜•ì„ í†µí•´ ì‹ ë¢°ì„± í™•ë³´ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.\n\n---\n\n## âš ï¸ ì›ì¸ ë¶„ì„  \n| ì›ì¸ | ì¦ê±° | ì˜í–¥ |\n|------|------|------|\n| í”„ë¡¬í”„íŠ¸ ë¶ˆí™•ì • | `prompt_changes.status` = \"missing\" | ì‹¤ì œ LLM í–‰ë™ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŒ â†’ ê²°ê³¼ í•´ì„ì— í•œê³„ |\n| í‘œë³¸ ìˆ˜ ë¶€ì¡± | `quality_summary.flags`: â€œí‘œë³¸ ìˆ˜ê°€ ì ìŒâ€ | í†µê³„ì  ê²€ì •ì´ í˜ë“¦ |\n| ì§€í‘œ ì„¤ì • | `thresholds.faitfulness = 0.7 > í‰ê· ` | `faithfulness`ê°€ ë‚®ì€ ì¼€ì´ìŠ¤(ì˜ˆ: A1, A2, B1, B2) |  \n> **ì˜ˆì‹œ**: `test_001`(Faithfulness 0.0)[A1]Â·`test_003`(Faithfulness 0.0)[A2] â†’ ë‘ ì‹¤í–‰ ëª¨ë‘ ì €ì .\n\n---\n\n## ğŸ› ï¸ ê°œì„  ì œì•ˆ  \n| ë¶„ì•¼ | ì œì•ˆ | ê·¼ê±° |\n|------|------|------|\n| **ë°ì´í„° ì¦ê°•** | 30ê°œ ì´ìƒì˜ ì§ˆë¬¸â€‘ë‹µë³€ ìŒì„ ì¶”ê°€í•˜ê³ , ì„œë¡œ ë‹¤ë¥¸ ë„ë©”ì¸ê³¼ ë¬¸ì¥ êµ¬ì¡°ë¥¼ í¬í•¨ | `quality_checks`ê°€ â€œì¶”ì„¸ ë¶„ì„ì„ ìœ„í•œ ì‹¤í–‰ ì´ë ¥ ë¶€ì¡±â€ì„ ì§€ì  |\n| **í”„ë¡¬í”„íŠ¸ ìº¡ì²˜** | ì‹¤í–‰ ì „í›„ í”„ë¡¬í”„íŠ¸ ìŠ¤ëƒ…ìƒ· ì €ì¥ ë° ê¸°ë¡ | `prompt_changes.status`Â = â€œmissingâ€ |\n| **ì§€í‘œ ì„¤ì • ê²€í† ** | `faithfulness`ì™€ `answer_relevancy` ì„ê³„ê°’ì„ ì¬ê²€í†  (ì˜ˆ: 0.6) | `thresholds.faitfulness` 0.7ëŠ” í‰ê·  0.5ì— ë¹„í•´ ë†’ì€ ê¸°ì¤€ |\n| **í†µê³„ ë¶„ì„** | í‘œë³¸ í¬ê¸°ì™€ íš¨ê³¼ í¬ê¸°ì— ëŒ€í•œ ì‹ ë¢° êµ¬ê°„ ê³„ì‚° | `stats_summary` ì •ë³´ ë¶€ì¬ |\n\n---\n\n## ğŸš€ ë‹¤ìŒ ë‹¨ê³„  \n1. **ë°ì´í„°ì…‹ í™•ì¥**: 5~10ë°° ê·œëª¨ í™•ë³´ í›„ ì¬í‰ê°€  \n2. **í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬**: Prompt ë³€í˜• ê¸°ë¡ì„ ìœ„í•´ `--system-prompt` ì˜µì…˜ ì‚¬ìš©  \n3. **ë‹¤ì¤‘ ì‹¤í–‰ ë°˜ë³µ**: ë™ì¼ ì¡°ê±´ì—ì„œ 5~10ë²ˆ ë°˜ë³µí•´ ì‹¤í–‰ ì´ë ¥ í™•ë³´  \n4. **ê²°ê³¼ ì¬ë¶„ì„**: ìƒˆë¡œìš´ ë°ì´í„°ì™€ ì„¤ì •ìœ¼ë¡œ ìŠ¤ì½”ì–´ì¹´ë“œ ì—…ë°ì´íŠ¸  \n5. **ë³´ê³ ì„œ ì—…ë°ì´íŠ¸**: ìƒˆë¡œìš´ í†µê³„ ë° ì‹ ë¢°ì„± ì§€í‘œ í¬í•¨\n\n---\n\n## ğŸ“ ë¶€ë¡(ì‚°ì¶œë¬¼)  \n| íŒŒì¼ëª… | ìš©ë„ |\n|--------|------|\n| `load_runs.json` | ë¼ë²¨ë§ ë° ë©”íƒ€ë°ì´í„° |\n| `run_change_detection.json` | êµ¬ì¡°ì  ì°¨ì´ í™•ì¸ |\n| `run_metric_comparison.json` | í˜„ì¬ ë³´ê³ ì„œ ê¸°ì¤€ ë°ì´í„° |\n\n---\n\n> **ë§ˆë¬´ë¦¬**  \ní˜„ì¬ ë¹„êµëŠ” ë‘ ì‹¤í–‰ì´ ë™ì¼í•œ ì„¤ì •Â·ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ê²°ê³¼, ì§€í‘œì— ìœ ì˜í•œ ì°¨ì´ê°€ ì—†ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‹¤ë§Œ, ìƒ˜í”Œ ìˆ˜ê°€ ì ê³  í”„ë¡¬í”„íŠ¸ ì •ë³´ê°€ ë¶€ì¡±í•˜ë¯€ë¡œ, ì¶”í›„ í™•ì¥ê³¼ ìì„¸í•œ ê¸°ë¡ì„ í†µí•´ ë³´ë‹¤ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í‰ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
      "format": "markdown",
      "llm_used": true,
      "llm_model": "ollama/gpt-oss-safeguard:20b",
      "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
      "summary": {
        "report_type": "comparison",
        "total_evidence": 6,
        "has_run": true
      },
      "evidence": [
        {
          "test_case_id": "test_001",
          "avg_score": 0.4183,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is Python?",
          "answer": "Python is a high-level programming language.",
          "contexts": [
            "Python is a programming language",
            "Python was created by Guido van Rossum"
          ],
          "ground_truth": "Python is a high-level interpreted programming language.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.8366828943604284
          },
          "evidence_id": "A1",
          "run_label": "A",
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "model_name": "ollama/gpt-oss-safeguard:20b"
        },
        {
          "test_case_id": "test_003",
          "avg_score": 0.4544,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is RAG?",
          "answer": "RAG stands for Retrieval-Augmented Generation.",
          "contexts": [
            "RAG combines retrieval and generation",
            "RAG improves LLM responses"
          ],
          "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.9087545725582776
          },
          "evidence_id": "A2",
          "run_label": "A",
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "model_name": "ollama/gpt-oss-safeguard:20b"
        },
        {
          "test_case_id": "test_002",
          "avg_score": 0.9362,
          "failed_metrics": [],
          "question": "What is machine learning?",
          "answer": "Machine learning is a subset of AI.",
          "contexts": [
            "ML is part of AI",
            "ML uses algorithms to learn from data"
          ],
          "ground_truth": "Machine learning is a method of data analysis that automates analytical model building.",
          "metrics": {
            "faithfulness": 1.0,
            "answer_relevancy": 0.8724614057329397
          },
          "evidence_id": "A3",
          "run_label": "A",
          "run_id": "0aa9fab0-6c2c-4c1c-b228-202a38a2f00c",
          "model_name": "ollama/gpt-oss-safeguard:20b"
        },
        {
          "test_case_id": "test_001",
          "avg_score": 0.4183,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is Python?",
          "answer": "Python is a high-level programming language.",
          "contexts": [
            "Python is a programming language",
            "Python was created by Guido van Rossum"
          ],
          "ground_truth": "Python is a high-level interpreted programming language.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.8366828943604284
          },
          "evidence_id": "B1",
          "run_label": "B",
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "model_name": "ollama/gpt-oss-safeguard:20b"
        },
        {
          "test_case_id": "test_003",
          "avg_score": 0.4544,
          "failed_metrics": [
            "faithfulness"
          ],
          "question": "What is RAG?",
          "answer": "RAG stands for Retrieval-Augmented Generation.",
          "contexts": [
            "RAG combines retrieval and generation",
            "RAG improves LLM responses"
          ],
          "ground_truth": "RAG is a technique that enhances LLM outputs with retrieved information.",
          "metrics": {
            "faithfulness": 0.0,
            "answer_relevancy": 0.9087545725582776
          },
          "evidence_id": "B2",
          "run_label": "B",
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "model_name": "ollama/gpt-oss-safeguard:20b"
        },
        {
          "test_case_id": "test_002",
          "avg_score": 0.9362,
          "failed_metrics": [],
          "question": "What is machine learning?",
          "answer": "Machine learning is a subset of AI.",
          "contexts": [
            "ML is part of AI",
            "ML uses algorithms to learn from data"
          ],
          "ground_truth": "Machine learning is a method of data analysis that automates analytical model building.",
          "metrics": {
            "faithfulness": 1.0,
            "answer_relevancy": 0.8724614057329397
          },
          "evidence_id": "B3",
          "run_label": "B",
          "run_id": "f1287e90-43b6-42c8-b3ac-e6cb3e06a71e",
          "model_name": "ollama/gpt-oss-safeguard:20b"
        }
      ]
    }
  }
}
