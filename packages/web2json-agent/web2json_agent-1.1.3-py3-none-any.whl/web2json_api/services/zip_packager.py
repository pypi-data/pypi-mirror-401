"""
ZIP打包器 - 将解析结果打包为可下载的ZIP文件

职责：
1. 打包parser.py、schema.json和所有结果JSON
2. 生成README.md使用说明
3. 支持单独下载parser.py
"""
import zipfile
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class ZipPackager:
    """
    ZIP打包器

    Features:
    - 打包解析器和结果文件
    - 生成使用说明
    - 流式ZIP创建（节省内存）
    """

    @staticmethod
    def create_zip(
        output_dir: Path,
        include_html: bool = False
    ) -> Path:
        """
        创建ZIP文件

        Args:
            output_dir: 输出目录（ParserAgent的输出目录）
            include_html: 是否包含HTML文件

        Returns:
            Path: ZIP文件路径
        """
        zip_path = output_dir / "parser_results.zip"

        logger.info(f"Creating ZIP file: {zip_path}")

        try:
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                # 1. 添加parser.py
                parser_path = output_dir / "parsers" / "final_parser.py"
                if parser_path.exists():
                    zf.write(parser_path, "parser.py")
                    logger.info("Added parser.py to ZIP")

                # 2. 添加schema.json
                schema_path = output_dir / "parsers" / "schema.json"
                if schema_path.exists():
                    zf.write(schema_path, "schema.json")
                    logger.info("Added schema.json to ZIP")

                # 3. 添加所有解析结果JSON
                results_dir = output_dir / "result"
                if results_dir.exists():
                    for json_file in results_dir.glob("*.json"):
                        zf.write(json_file, f"results/{json_file.name}")
                    logger.info(f"Added {len(list(results_dir.glob('*.json')))} result files to ZIP")

                # 4. 生成并添加README.md
                readme_content = ZipPackager._generate_readme(parser_path, schema_path)
                zf.writestr("README.md", readme_content)
                logger.info("Added README.md to ZIP")

                # 5. 可选：添加HTML文件
                if include_html:
                    html_dir = output_dir / "html_original"
                    if html_dir.exists():
                        for html_file in html_dir.glob("*.html"):
                            zf.write(html_file, f"html_original/{html_file.name}")
                        logger.info("Added original HTML files to ZIP")

            logger.info(f"ZIP file created successfully: {zip_path} ({zip_path.stat().st_size} bytes)")
            return zip_path

        except Exception as e:
            logger.error(f"Failed to create ZIP file: {e}", exc_info=True)
            raise

    @staticmethod
    def _generate_readme(parser_path: Path, schema_path: Path) -> str:
        """
        生成README.md使用说明

        Args:
            parser_path: parser.py路径
            schema_path: schema.json路径

        Returns:
            str: README内容
        """
        readme = """# Web2JSON Parser Results

This ZIP file contains the generated parser and parsed results.

## Contents

```
parser_results.zip
├── parser.py              # Python parser code (ready to use)
├── schema.json            # Field definitions and XPath expressions
├── results/               # Parsed JSON results (one per input HTML)
│   ├── sample_0000.json
│   ├── sample_0001.json
│   └── ...
└── README.md              # This file
```

## Usage

### Option 1: Use the generated parser directly

```python
# Import the parser
from parser import WebPageParser

# Create parser instance
parser = WebPageParser()

# Parse HTML file
with open('your_html_file.html', 'r', encoding='utf-8') as f:
    html_content = f.read()

result = parser.parse(html_content)
print(result)
```

### Option 2: Use with web2json-agent

```bash
# The parser follows web2json-agent conventions
# You can integrate it into your scraping pipeline

python parser.py <html_file_or_url>
```

## Results

All HTML files have been parsed and results are in the `results/` directory.
Each JSON file corresponds to one input HTML file.

## Schema

The `schema.json` file contains field definitions including:
- Field names and types
- XPath expressions used for extraction
- Fallback extraction strategies

You can modify the schema and regenerate the parser if needed.

## Generated by

Web2JSON Agent - AI-powered web parser generator
https://github.com/yourusername/web2json-agent
"""
        return readme

    @staticmethod
    def get_parser_file(output_dir: Path) -> Optional[Path]:
        """
        获取parser.py文件路径

        Args:
            output_dir: 输出目录

        Returns:
            Path or None: parser.py路径
        """
        parser_path = output_dir / "parsers" / "final_parser.py"
        if parser_path.exists():
            return parser_path
        return None

    @staticmethod
    def get_zip_size(output_dir: Path) -> int:
        """
        获取ZIP文件大小

        Args:
            output_dir: 输出目录

        Returns:
            int: 文件大小（字节），如果不存在返回0
        """
        zip_path = output_dir / "parser_results.zip"
        if zip_path.exists():
            return zip_path.stat().st_size
        return 0
