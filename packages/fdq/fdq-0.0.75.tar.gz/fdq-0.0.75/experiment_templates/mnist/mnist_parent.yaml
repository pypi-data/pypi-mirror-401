globals:
  project: MNIST classifier - parent
  author: Marc

models:
  simpleNet:
    comment: "You can either selected an installed module or define a custom path and class name."
    path: "~/dev/fonduecaquelon/src/networks/simpleNet.py"
    class_name: "simpleNet"
    args:
      nb_in_channels: 1
      nb_out_channels: 10
      input_shape:
        - 28
        - 28
    optimizer:
      class_name: "torch.optim.Adam"
      args:
        lr: 0.001
    lr_scheduler:
      class_name: "torch.optim.lr_scheduler.StepLR"
      args:
        step_size: 2
        gamma: 0.95

transforms:
  resize_norm_inp:
    - "ToTensor"
    - NORM:
        mean: 0.1307
        stdev: 0.3081

train:
  path: "~/dev/fonduecaquelon/experiment_templates/mnist/train_mnist.py"
  args:
    epochs: 4
    use_GPU: false
    use_AMP: false
    accumulate_grad_batches: 1
    early_stop_val_loss: 5
    early_stop_train_loss: 5
    early_stop_nan: 5

losses:
  cp_dummy:
    comment: "You can either selected an installed module or define a custom path and class name."
    path: "~/dev/fonduecaquelon/experiment_templates/mnist/dummy_crossentropy_loss.py"
    class_name: "DummyCrossEntropyLoss"
    args:
      reduction: "mean"
  cross_ent:
    class_name: "torch.nn.CrossEntropyLoss"
    args:
      reduction: "mean"

test:
  processor: "~/dev/fonduecaquelon/experiment_templates/mnist/mnist_test.py"
  test_model: "best"
  args:
    metrics:
      nb_test_samples: "100"
