"""
æ€§èƒ½æµ‹è¯•è¿è¡Œå™¨

æ‰§è¡Œæ€§èƒ½æµ‹è¯•å¹¶æ”¶é›†ç»“æœ
"""

import asyncio
import time
import statistics
from typing import List, Dict, Any
from dataclasses import dataclass, field
from datetime import datetime
import httpx
from loguru import logger

from .config import TestConfig, APITestCase
from .standards import PerformanceStandards, StandardLevel


@dataclass
class TestResult:
    """å•æ¬¡æµ‹è¯•ç»“æœ"""
    test_case_name: str
    url: str
    method: str
    status_code: int
    response_time: float  # æ¯«ç§’
    success: bool
    error_message: str = ""
    timestamp: float = field(default_factory=time.time)


@dataclass
class AggregatedResult:
    """èšåˆæµ‹è¯•ç»“æœ"""
    test_case_name: str
    url: str
    method: str
    interface_type: str

    # è¯·æ±‚ç»Ÿè®¡
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    success_rate: float = 0.0

    # å“åº”æ—¶é—´ç»Ÿè®¡ (æ¯«ç§’)
    min_response_time: float = 0.0
    max_response_time: float = 0.0
    avg_response_time: float = 0.0
    median_response_time: float = 0.0
    p50_response_time: float = 0.0
    p95_response_time: float = 0.0
    p99_response_time: float = 0.0

    # ååé‡ (requests/second)
    throughput: float = 0.0

    # æ€§èƒ½è¯„çº§
    response_time_level: StandardLevel = StandardLevel.ACCEPTABLE
    throughput_level: StandardLevel = StandardLevel.ACCEPTABLE
    success_rate_level: StandardLevel = StandardLevel.ACCEPTABLE
    overall_level: StandardLevel = StandardLevel.ACCEPTABLE

    # é”™è¯¯ä¿¡æ¯
    error_messages: List[str] = field(default_factory=list)


class PerformanceTestRunner:
    """æ€§èƒ½æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, config: TestConfig):
        self.config = config
        self.results: Dict[str, List[TestResult]] = {}
        self.start_time: float = 0
        self.end_time: float = 0

    async def run(self) -> Dict[str, AggregatedResult]:
        """
        è¿è¡Œæ€§èƒ½æµ‹è¯•

        Returns:
            èšåˆç»“æœå­—å…¸ {test_case_name: AggregatedResult}
        """
        logger.info(f"ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•: {self.config.project_name}")
        logger.info(f"   å¹¶å‘ç”¨æˆ·: {self.config.concurrent_users}")
        logger.info(f"   æŒç»­æ—¶é—´: {self.config.duration}ç§’")
        logger.info(f"   æµ‹è¯•ç”¨ä¾‹: {len(self.config.get_enabled_test_cases())}ä¸ª")

        self.start_time = time.time()

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i in range(self.config.concurrent_users):
            task = asyncio.create_task(self._user_task(i))
            tasks.append(task)
            # æ§åˆ¶å¯åŠ¨é€Ÿç‡
            await asyncio.sleep(1 / self.config.spawn_rate)

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*tasks, return_exceptions=True)

        self.end_time = time.time()

        logger.success(f"âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {self.end_time - self.start_time:.2f}ç§’")

        # èšåˆç»“æœ
        aggregated = self._aggregate_results()

        return aggregated

    async def _user_task(self, user_id: int):
        """å•ä¸ªç”¨æˆ·çš„æµ‹è¯•ä»»åŠ¡"""
        test_cases = self.config.get_enabled_test_cases()
        if not test_cases:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹")
            return

        end_time = self.start_time + self.config.duration

        async with httpx.AsyncClient(timeout=30.0) as client:
            while time.time() < end_time:
                # ä¾æ¬¡æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
                for test_case in test_cases:
                    if time.time() >= end_time:
                        break

                    result = await self._execute_test_case(client, test_case)

                    # ä¿å­˜ç»“æœ
                    if test_case.name not in self.results:
                        self.results[test_case.name] = []
                    self.results[test_case.name].append(result)

                    # æ€è€ƒæ—¶é—´
                    think_time = (
                        self.config.think_time_min +
                        (self.config.think_time_max - self.config.think_time_min) * 0.5
                    )
                    await asyncio.sleep(think_time)

    async def _execute_test_case(
        self,
        client: httpx.AsyncClient,
        test_case: APITestCase
    ) -> TestResult:
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        url = self._build_url(test_case.url)

        # æ„å»ºè¯·æ±‚å¤´
        headers = {**self.config.global_headers, **test_case.headers}

        # æ·»åŠ è®¤è¯
        if self.config.auth_type == "bearer" and self.config.auth_token:
            headers["Authorization"] = f"Bearer {self.config.auth_token}"

        start_time = time.time()
        success = False
        status_code = 0
        error_message = ""

        try:
            response = await client.request(
                method=test_case.method,
                url=url,
                headers=headers,
                params=test_case.params,
                json=test_case.json,
                data=test_case.data,
                timeout=test_case.timeout,
            )

            status_code = response.status_code
            success = 200 <= status_code < 300

            if not success:
                error_message = f"HTTP {status_code}: {response.text[:200]}"

        except httpx.TimeoutException:
            error_message = "è¯·æ±‚è¶…æ—¶"
        except httpx.ConnectError:
            error_message = "è¿æ¥å¤±è´¥"
        except Exception as e:
            error_message = str(e)

        end_time = time.time()
        response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

        return TestResult(
            test_case_name=test_case.name,
            url=url,
            method=test_case.method,
            status_code=status_code,
            response_time=response_time,
            success=success,
            error_message=error_message,
        )

    def _build_url(self, path: str) -> str:
        """æ„å»ºå®Œæ•´ URL"""
        if path.startswith("http://") or path.startswith("https://"):
            return path

        base_url = self.config.base_url.rstrip("/")
        path = path.lstrip("/")
        return f"{base_url}/{path}"

    def _aggregate_results(self) -> Dict[str, AggregatedResult]:
        """èšåˆæµ‹è¯•ç»“æœ"""
        aggregated = {}
        test_duration = self.end_time - self.start_time

        for test_case_name, results in self.results.items():
            if not results:
                continue

            # æ‰¾åˆ°å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹é…ç½®
            test_case = next(
                (tc for tc in self.config.test_cases if tc.name == test_case_name),
                None
            )
            interface_type = test_case.interface_type if test_case else "normal"

            # åŸºæœ¬ç»Ÿè®¡
            total = len(results)
            successful = sum(1 for r in results if r.success)
            failed = total - successful
            success_rate = (successful / total * 100) if total > 0 else 0

            # å“åº”æ—¶é—´ç»Ÿè®¡
            response_times = [r.response_time for r in results]
            response_times.sort()

            min_rt = min(response_times) if response_times else 0
            max_rt = max(response_times) if response_times else 0
            avg_rt = statistics.mean(response_times) if response_times else 0
            median_rt = statistics.median(response_times) if response_times else 0

            # ç™¾åˆ†ä½
            p50 = self._percentile(response_times, 0.50)
            p95 = self._percentile(response_times, 0.95)
            p99 = self._percentile(response_times, 0.99)

            # ååé‡
            throughput = total / test_duration if test_duration > 0 else 0

            # æ€§èƒ½è¯„çº§
            rt_level = PerformanceStandards.evaluate_response_time(
                avg_rt, interface_type
            )
            tp_level = PerformanceStandards.evaluate_throughput(
                throughput, interface_type
            )
            sr_level = PerformanceStandards.evaluate_success_rate(success_rate)

            # ç»¼åˆè¯„çº§ (å–æœ€å·®çš„)
            overall_level = max(
                [rt_level, tp_level, sr_level],
                key=lambda x: list(StandardLevel).index(x)
            )

            # é”™è¯¯ä¿¡æ¯
            error_messages = [
                r.error_message
                for r in results
                if not r.success and r.error_message
            ]
            unique_errors = list(set(error_messages))[:10]  # æœ€å¤š10æ¡

            aggregated[test_case_name] = AggregatedResult(
                test_case_name=test_case_name,
                url=results[0].url,
                method=results[0].method,
                interface_type=interface_type,
                total_requests=total,
                successful_requests=successful,
                failed_requests=failed,
                success_rate=success_rate,
                min_response_time=min_rt,
                max_response_time=max_rt,
                avg_response_time=avg_rt,
                median_response_time=median_rt,
                p50_response_time=p50,
                p95_response_time=p95,
                p99_response_time=p99,
                throughput=throughput,
                response_time_level=rt_level,
                throughput_level=tp_level,
                success_rate_level=sr_level,
                overall_level=overall_level,
                error_messages=unique_errors,
            )

        return aggregated

    @staticmethod
    def _percentile(data: List[float], percentile: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile)
        return sorted_data[min(index, len(sorted_data) - 1)]
