{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d31780",
   "metadata": {},
   "source": [
    "# Test SR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb49aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你的项目路径配置正确\n",
    "from src.emcfsys.EMCellFiner.hat.models.hat_model import HATModel\n",
    "from src.emcfsys.EMCellFiner.hat.models.img_utils import tensor2img\n",
    "\n",
    "# 1. 初始化模型\n",
    "path = r\"D:\\napari_EMCF\\EMCFsys\\models\\EMCellFiner.pth\"\n",
    "# 显式指定 tile_size，防止显存溢出；对于小图可以不用 tile\n",
    "model = HATModel(scale=4, tile_size=512) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# 2. 读取与预处理\n",
    "img_path = r\"D:\\napari_EMCF\\EMCFsys\\emcfsys\\image\\Bock2011_2951_XrV1ciGgTWHjepNf.tif\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "# 转换为 Numpy 并归一化\n",
    "img_np = np.array(img).astype(np.float32) / 255.\n",
    "# 转换为 Tensor: (H, W, C) -> (C, H, W) -> (1, C, H, W)\n",
    "img_torch = torch.from_numpy(img_np).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "print(f\"Input Shape: {img_torch.shape}\")\n",
    "# 3. 推理\n",
    "with torch.no_grad():\n",
    "    output = model(img_torch) \n",
    "print(f\"Output Shape: {output.shape}\")\n",
    "# 4. 后处理\n",
    "output = output.cpu()\n",
    "img_out = tensor2img(output, rgb2bgr=False, min_max=(0, 1))\n",
    "# 5. 转回 PIL 图片\n",
    "img_final = Image.fromarray(img_out)\n",
    "\n",
    "# 验证结果\n",
    "# img_final.show() \n",
    "# img_final.save(\"result_sr.png\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFiner.hat.models.inference_hat import hat_infer_numpy\n",
    "from src.emcfsys.EMCellFiner.hat.models.hat_model import HATModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "start = time.time()\n",
    "img_path = r\"D:\\napari_EMCF\\EMCFsys\\emcfsys\\image\\Bock2011_2951_XrV1ciGgTWHjepNf.tif\"\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img_np = np.array(img)\n",
    "\n",
    "model = HATModel(scale=4, tile_size=512)\n",
    "device = \"cuda\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out = hat_infer_numpy(\n",
    "    model= model,\n",
    "    image= img_np,\n",
    "    device=device,\n",
    ")\n",
    "print(out.shape)\n",
    "end = time.time()\n",
    "print(\"inference time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea63878",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c826e5",
   "metadata": {},
   "source": [
    "# test SR stack images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb8c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFiner.hat.models.inference_hat import hat_infer_numpy\n",
    "from src.emcfsys.EMCellFiner.hat.models.hat_model import HATModel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "start = time.time()\n",
    "# img_path = r\"D:\\napari_EMCF\\EMCFsys\\emcfsys\\image\\Bock2011_2951_XrV1ciGgTWHjepNf.tif\"\n",
    "# img = Image.open(img_path).convert(\"RGB\").crop([0,0,512,512])\n",
    "\n",
    "stack_path = [r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3044.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3054.jpg\",]\n",
    "\n",
    "# stack_path = [r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\",]\n",
    "\n",
    "stack_imgs = np.array([np.array(Image.open(p).convert(\"L\").resize([1024,1024])) for p in stack_path])\n",
    "\n",
    "\n",
    "model = HATModel(scale=4, tile_size=512)\n",
    "device = \"cuda\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "out = hat_infer_numpy(\n",
    "    model = model,\n",
    "    image = stack_imgs,\n",
    "    device =device,\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(\"inference time: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c885825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model('vit_small_patch16_dinov3.lvd1689m', pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n",
    "output = model(transforms(img).unsqueeze(0))  # unsqueeze single image into batch of 1\n",
    "\n",
    "top5_probabilities, top5_class_indices = torch.topk(output.softmax(dim=1) * 100, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae21c549",
   "metadata": {},
   "source": [
    "# test the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c789f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFound.train import train_loop\n",
    "import torch\n",
    "img_dir = r\"D:\\ZJU-CUHK AI collab\\QC\\DL\\masks\\image\"\n",
    "label_dir = r\"D:\\ZJU-CUHK AI collab\\QC\\DL\\masks\\label\"\n",
    "save_dir = r\"D:\\ZJU-CUHK AI collab\\QC\\DL\\masks\\models\"\n",
    "\n",
    "logs = []\n",
    "epoch_times = []\n",
    "metrics_all = []\n",
    "def cb(epoch, batch, n_batches, loss, finished_epoch=False, epoch_time=None, model_dict=None, metrics=None):\n",
    "\n",
    "    # 保存 epoch 时间\n",
    "    if finished_epoch and epoch_time is not None:\n",
    "        epoch_times.append(epoch_time)\n",
    "\n",
    "    if metrics is not None:\n",
    "        metrics_all.append(metrics)\n",
    "        \n",
    "    # 保存 batch/epoch 日志\n",
    "    logs.append((epoch, batch, n_batches, loss, finished_epoch, epoch_time, metrics))\n",
    "\n",
    "    # 输出日志\n",
    "    if batch == 0 and finished_epoch:\n",
    "        if epoch_time is not None:\n",
    "            print(f\"Epoch {epoch} finished, avg loss {loss:.4f}, time {epoch_time:.2f}s, metric {metrics}\" )\n",
    "\n",
    "\n",
    "train_loop(img_dir, \n",
    "           label_dir, \n",
    "           save_dir, \n",
    "           model_name='unet',\n",
    "           backbone_name='convnext_base',\n",
    "           pretrained = True,\n",
    "           pretrained_model=None,\n",
    "           lr=1e-4, batch_size=8, \n",
    "           epochs=1000, device=None,\n",
    "           callback=cb, target_size=(1024, 1024),\n",
    "           classes_num=4, ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ea945",
   "metadata": {},
   "outputs": [],
   "source": [
    "New best model found at epoch 84! Val IoU=0.7845\n",
    "New best model found at epoch 34! Val IoU=0.7566"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e6c9c",
   "metadata": {},
   "source": [
    "# Inference the seg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c966b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFound.inference import infer_numpy, load_model\n",
    "from src.emcfsys.EMCellFound.utils.checkpoint import load_pretrained\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from src.emcfsys.EMCellFound.models.model_factory import get_model\n",
    "from src.emcfsys.EMCellFound.models.DeepLabv3Plus import DeepLabV3Plus\n",
    "\n",
    "# img_path = r\"D:\\napari_EMCF\\EMCFsys\\emcfsys\\image\\Bock2011_2951_xZGgUFHBDISQMdco.tif\"\n",
    "img_path = r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\"\n",
    "\n",
    "\n",
    "model_path = r\"D:\\napari_EMCF\\EMCFsys\\models\\best_model_epoch99_IoU=0.8046.pth\"\n",
    "# 构建 + 加载模型\n",
    "model = load_model(model_name=\"deeplabv3plus\", \n",
    "                   backbone_name=\"emcellfound_vit_base\", \n",
    "                   num_classes=2, \n",
    "                   model_path=model_path, \n",
    "                   aux_on=False, \n",
    "                   device=\"cuda\")\n",
    "\n",
    "# 加载图像\n",
    "img = np.array(Image.open(img_path).convert(\"RGB\").resize((512, 512)))\n",
    "\n",
    "# 推理\n",
    "mask = infer_numpy(model, img, device=\"cuda\")\n",
    "print(mask.shape, np.unique(mask))\n",
    "Image.fromarray(mask*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db57e73",
   "metadata": {},
   "source": [
    "# test the infer_numpy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFound.inference import infer_numpy, load_model, infer_full_image\n",
    "from src.emcfsys.EMCellFound.utils.checkpoint import load_pretrained\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from src.emcfsys.EMCellFound.models.model_factory import get_model\n",
    "from src.emcfsys.EMCellFound.models.DeepLabv3Plus import DeepLabV3Plus\n",
    "\n",
    "\n",
    "img_path = r\"D:\\napari_EMCF\\EMCFsys\\emcfsys\\image\\Bock2011_2951_xZGgUFHBDISQMdco.tif\"\n",
    "\n",
    "stack_path = [r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3014.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3024.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3034.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3044.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3054.jpg\",]\n",
    "\n",
    "# stack_path = [r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\",]\n",
    "\n",
    "stack_imgs = np.array([np.array(Image.open(p).convert(\"RGB\")) for p in stack_path])\n",
    "print(stack_imgs.shape)\n",
    "\n",
    "\n",
    "model_path = r\"D:\\napari_EMCF\\EMCFsys\\models\\best_model_epoch99_IoU=0.8046.pth\"\n",
    "\n",
    "# 构建 + 加载模型\n",
    "\n",
    "model = load_model(model_name=\"deeplabv3plus\", \n",
    "                   backbone_name=\"emcellfound_vit_base\", \n",
    "                   num_classes=2, \n",
    "                   model_path=model_path, \n",
    "                   aux_on=False, \n",
    "                   device=\"cuda\")\n",
    "\n",
    "# 加载图像\n",
    "\n",
    "# 推理\n",
    "mask = infer_full_image(model, stack_imgs, (512,512), device=\"cuda\")\n",
    "print(mask.shape, np.unique(mask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47957a4",
   "metadata": {},
   "source": [
    "# Test slide inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d40b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFound.inference import infer_numpy, load_model, infer_full_image, infer_sliding_window\n",
    "from src.emcfsys.EMCellFound.utils.checkpoint import load_pretrained\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from src.emcfsys.EMCellFound.models.model_factory import get_model\n",
    "from src.emcfsys.EMCellFound.models.DeepLabv3Plus import DeepLabV3Plus\n",
    "\n",
    "\n",
    "img_path = r\"D:\\napari_EMCF\\EMCFsys\\emcfsys\\image\\Bock2011_2951_xZGgUFHBDISQMdco.tif\"\n",
    "\n",
    "stack_path = [r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3014.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3024.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3034.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3044.jpg\",\n",
    "              r\"D:\\CellChange\\Bock3D\\image\\3054.jpg\",]\n",
    "\n",
    "# stack_path = [r\"D:\\CellChange\\Bock3D\\image\\3004.jpg\",]\n",
    "\n",
    "stack_imgs = np.array([np.array(Image.open(p).convert(\"RGB\")) for p in stack_path])\n",
    "print(stack_imgs.shape)\n",
    "\n",
    "\n",
    "model_path = r\"D:\\napari_EMCF\\EMCFsys\\models\\best_model_epoch98_IoU=0.9024.pth\"\n",
    "\n",
    "# 构建 + 加载模型\n",
    "\n",
    "model = load_model(model_name=\"deeplabv3plus\", \n",
    "                   backbone_name=\"emcellfound_vit_base\", \n",
    "                   num_classes=2, \n",
    "                   model_path=model_path, \n",
    "                   aux_on=False, \n",
    "                   device=\"cuda\")\n",
    "\n",
    "# 加载图像\n",
    "\n",
    "# 推理\n",
    "\n",
    "mask = infer_sliding_window(model=model, image=stack_imgs, window_size= 512, \n",
    "    overlap = 0.25, out_channels=2, img_size = (512,512), device = \"cuda\",)\n",
    "\n",
    "print(mask.shape, np.unique(mask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bba3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage\n",
    "img = Image.open(r\"D:\\ZJU-CUHK AI collab\\RAYdata\\test_data0086.tif\")\n",
    "img_np_32bit = np.array(img)\n",
    "print(img_np_32bit)\n",
    "\n",
    "print(\"32bit:\", img_np_32bit.max())\n",
    "print(\"8bit:\", img_np_32bit.astype(np.uint8).max())\n",
    "\n",
    "sk_img = skimage.io.imread(r\"D:\\ZJU-CUHK AI collab\\RAYdata\\test_data0086.tif\").astype(np.uint8)\n",
    "print(\"skimage 8bit:\", sk_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ca587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img = Image.open(r\"D:\\ZJU-CUHK AI collab\\RAYdata\\0008bit.tif\")\n",
    "img_np = np.array(img)\n",
    "img_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e997a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_to_uint8(\n",
    "    img,\n",
    "    method=\"percentile\",\n",
    "    pmin=1,\n",
    "    pmax=99,\n",
    "    eps=1e-8\n",
    "):\n",
    "    \"\"\"\n",
    "    Robustly normalize arbitrary numpy image to uint8 [0,255].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Input image of any dtype (uint8/16/32/float/etc.)\n",
    "    method : str\n",
    "        'minmax' or 'percentile'\n",
    "    pmin, pmax : float\n",
    "        Percentiles used when method='percentile'\n",
    "    eps : float\n",
    "        Small value to avoid division by zero\n",
    "    \"\"\"\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(\"Input image is None\")\n",
    "\n",
    "    img = np.asarray(img)\n",
    "\n",
    "    # 1. already uint8 → return safely\n",
    "    if img.dtype == np.uint8:\n",
    "        return img\n",
    "\n",
    "    # 2. convert to float32\n",
    "    img_f = img.astype(np.float32)\n",
    "\n",
    "    # 3. handle NaN / Inf\n",
    "    img_f = np.nan_to_num(img_f, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # 4. determine range\n",
    "    if method == \"minmax\":\n",
    "        vmin = img_f.min()\n",
    "        vmax = img_f.max()\n",
    "    elif method == \"percentile\":\n",
    "        vmin = np.percentile(img_f, pmin)\n",
    "        vmax = np.percentile(img_f, pmax)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    # 5. avoid degenerate case\n",
    "    if abs(vmax - vmin) < eps:\n",
    "        return np.zeros_like(img_f, dtype=np.uint8)\n",
    "\n",
    "    # 6. normalize\n",
    "    img_norm = (img_f - vmin) / (vmax - vmin)\n",
    "    img_norm = np.clip(img_norm, 0.0, 1.0)\n",
    "\n",
    "    # 7. map to uint8\n",
    "    return (img_norm * 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334913f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_to_uint8(img_np).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff99eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(r\"D:\\ZJU-CUHK AI collab\\RAYdata\\test_data0086.tif\")\n",
    "img_np_32bit = np.array(img)\n",
    "print(img_np_32bit)\n",
    "\n",
    "print(\"32bit:\", img_np_32bit.max())\n",
    "print(\"8bit:\", img_np_32bit.astype(np.uint8).max())\n",
    "\n",
    "normalize_img = normalize_to_uint8(img_np_32bit)\n",
    "print(\"normalized 8bit:\", normalize_img.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd83565",
   "metadata": {},
   "source": [
    "# Inference Segmentation Models in a Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.emcfsys.EMCellFound.inference import load_model, infer_sliding_window\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "img_folder = r\"Z:\\3Ddataset\\Guo3DCell\\save\"\n",
    "save_folder = r\"Z:\\3Ddataset\\Guo3DCell\\mask_membrane\"\n",
    "# 1. save mask folder first\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "\n",
    "stack_path = [os.path.join(img_folder, f) for f in os.listdir(img_folder) if f.endswith(\".tif\")]\n",
    "print(stack_path)\n",
    "\n",
    "\n",
    "\n",
    "# 2. load the model\n",
    "model_path = r\"Z:\\3Ddataset\\Guo3DCell\\outputMembrane\\Guo3DMembrane\\models\\EMCF_Unet_IoU=0.7849.pth\"\n",
    "\n",
    "model = load_model(model_name=\"unet\", \n",
    "                   backbone_name=\"emcellfound_vit_base\", \n",
    "                   num_classes=2, \n",
    "                   model_path=model_path, \n",
    "                   aux_on=False, \n",
    "                   device=\"cuda\")\n",
    "\n",
    "# 3. load the images one by one and infer\n",
    "# if stack_path has lots of images, there could be memory issue\n",
    "# So we process one by one and save to disk\n",
    "# windows size 1536 works better for large images; img_size is set to 512x512 to fit model input\n",
    "for p in tqdm(stack_path):\n",
    "    image = Image.open(p).convert(\"RGB\")\n",
    "    stack_imgs = np.array([np.array(image)])\n",
    "    \n",
    "    mask = infer_sliding_window(model=model, image=stack_imgs, window_size= 1536, \n",
    "        overlap = 0.2, out_channels=2, img_size = (512,512), device = \"cuda\",)\n",
    "    \n",
    "    # 4. save the binary mask to disk\n",
    "    _ = Image.fromarray(mask[0].astype(np.uint8)*255).save(save_folder + \"/\" + os.path.basename(p).replace(\".tif\", \".png\"))\n",
    "\n",
    "\n",
    "    # 5. paste the mask using a green color to original image and save to disk for visualization\n",
    "    img = image.convert(\"RGBA\")\n",
    "    color_img = Image.new(\"RGBA\", img.size, (42, 215, 22, 0))\n",
    "    mask_alpha = (mask[0] * 128).astype(np.uint8)  # 0~128\n",
    "    mask_alpha = Image.fromarray(mask_alpha, mode=\"L\")\n",
    "    color_img.putalpha(mask_alpha)\n",
    "    overlay = Image.alpha_composite(img, color_img)\n",
    "    overlay = overlay.convert(\"RGB\")\n",
    "    _ = overlay.save(save_folder + \"/\" + os.path.basename(p).replace(\".tif\", \"_overlay.jpg\"))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38185229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EMCF_napari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
