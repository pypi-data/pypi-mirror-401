---
title: "Profile Research Agent"
description: "OSINT Intelligence Tool with Durable SSE Streaming"
---

A professional-grade profile investigation agent with:
- **Server-Sent Events (SSE)** for real-time streaming
- **Durability by Default** - research continues if you disconnect
- **Event Replay** - never miss an update by reconnecting with `last_event_id`

This example demonstrates how `enable_event_log=True` simplifies complex connection recovery logic.

## The Agent Logic

```python
import os
import asyncio
from datetime import datetime
from ai_query import tool, Field, step_count_is
from ai_query.agents import ChatAgent, SQLiteAgent, AgentServer, AgentServerConfig

# You'll need TAVILY_API_KEY env var for this example
# https://tavily.com
from tavily import TavilyClient

tavily = TavilyClient(api_key=os.getenv("TAVILY_API_KEY", ""))

class ProfileResearchAgent(ChatAgent, SQLiteAgent):
    """
    OSINT investigator that researches individuals.

    Features:
    - Persistent SQLite storage
    - Built-in event log for connection recovery
    - Web search capabilities
    """

    # Enable native event logging and replay
    enable_event_log = True
    event_retention = 86400 * 7  # Keep events for 7 days

    db_path = "./data/profiles.db"

    system = """You are a Profile Research Agent - an expert OSINT investigator.

    METHODOLOGY:
    1. Search for the person's name + context (company, location)
    2. Find social media profiles (LinkedIn, Twitter, GitHub)
    3. Analyze recent activity and interests
    4. Compile a comprehensive dossier

    Always cite sources with [Source Name](url).
    """

    initial_state = {
        "status": "idle",
        "profiles_found": [],
        "last_updated": None
    }

    @property
    def tools(self):
        @tool(description="Search the web for information about a person")
        async def search_web(
            query: str = Field(description="Search query"),
        ) -> str:
            # Send status update to the client
            await self.output.send_status(f"ðŸ”Ž Searching: {query}")

            try:
                response = tavily.search(query, max_results=5)
                results = [
                    f"- [{r['title']}]({r['url']}): {r['content'][:200]}..."
                    for r in response['results']
                ]
                return "\n".join(results)
            except Exception as e:
                return f"Search failed: {e}"

        @tool(description="Save a discovered profile URL")
        async def save_profile(
            platform: str = Field(description="Platform name (LinkedIn, Twitter, etc.)"),
            url: str = Field(description="Profile URL")
        ) -> str:
            profiles = self.state["profiles_found"] + [{"platform": platform, "url": url}]

            # Update state (persisted automatically)
            await self.set_state({
                **self.state,
                "profiles_found": profiles,
                "last_updated": datetime.now().isoformat()
            })

            # Notify client
            await self.output.send_status(f"ðŸ’¾ Saved {platform} profile", details={"url": url})
            return f"Saved {platform} profile: {url}"

        return {"search_web": search_web, "save_profile": save_profile}

    async def on_step_start(self, event):
        # Notify user when thinking starts
        await self.output.send_status(f"ðŸ¤” Analyzing (Step {event.step_number})...")

# Start the server
if __name__ == "__main__":
    # Create data directory
    os.makedirs("./data", exist_ok=True)

    config = AgentServerConfig(
        idle_timeout=1800,  # Keep alive for 30 mins
        allowed_origins=["*"]  # Allow CORS
    )

    print("ðŸ•µï¸  Profile Research Agent running on port 8080")
    AgentServer(ProfileResearchAgent, config=config).serve(port=8080)
```

## Client Implementation (Reconnection)

Here is how a frontend client handles reconnection using `Last-Event-ID`.

```javascript
const AGENT_ID = "investigation-001";
let evtSource = null;
let lastEventId = null;

function connect() {
  let url = `http://localhost:8080/agent/${AGENT_ID}/events`;

  // Append Last-Event-ID if we have one (Automatic Replay!)
  if (lastEventId) {
    url += `?last_event_id=${lastEventId}`;
  }

  console.log(`Connecting to ${url}...`);
  evtSource = new EventSource(url);

  evtSource.addEventListener("message", (e) => {
    // Update last ID for resume
    if (e.lastEventId) lastEventId = e.lastEventId;

    // Handle AI text chunk
    const data = JSON.parse(e.data);
    appendLog(data.content);
  });

  evtSource.addEventListener("status", (e) => {
    if (e.lastEventId) lastEventId = e.lastEventId;

    const data = JSON.parse(e.data);
    updateStatus(data.status);

    if (data.details?.url) {
      addProfileLink(data.details.url);
    }
  });

  evtSource.onerror = (err) => {
    console.log("Connection lost. Reconnecting in 3s...");
    evtSource.close();
    setTimeout(connect, 3000);
  };
}

// Start research via POST
async function startResearch(name) {
  await fetch(`http://localhost:8080/agent/${AGENT_ID}/chat`, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ message: `Research ${name}` })
  });
  // Events will start flowing via SSE
}
```

## Why This Rocks

1.  **Zero Boilerplate**: No need to manually manage an event loop, event store, or subscribers. `enable_event_log = True` does it all.
2.  **True Durability**: If the server crashes or restarts, the `SQLiteAgent` has the event history on disk. When the client reconnects, it gets the full history seamlessly.
3.  **Standard Standards**: Uses standard `Last-Event-ID` SSE mechanism (mapped to query param `last_event_id` by the router).
