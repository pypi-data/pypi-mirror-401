---
name: knowledge-retrieval
description: Retrieves relevant documents or passages from a pre-indexed knowledge
  base in response to a user query.
metadata:
  skill_id: domain_knowledge/knowledge_retrieval
  version: 1.0.0
  type: domain
  weight: medium
---

```markdown
# Knowledge Retrieval Skill

The **Knowledge Retrieval** skill retrieves the most relevant passages from an index generated by the **Indexing** skill, using a query embedding supplied by the **Semantic Search** skill. It returns ranked passages with relevance scores.

## Configuration (`skill.yaml`)

```yaml
# skill.yaml
name: knowledge_retrieval
version: "0.1.0"
description: "Retrieve top‑ranked passages based on query embeddings."
author: "Your Name"
license: "MIT"

# Paths to external resources
index_path: "data/index.bin"          # Built by the Indexing skill
embedding_dim: 768                    # Dimension of query embeddings
top_k: 5                              # Number of passages to return

# Optional thresholds
score_threshold: 0.1                  # Minimum relevance score to return
```

## Source Code

### `src/__init__.py`
```python
# src/__init__.py
from .query_processor import KnowledgeRetriever
from .utils import load_index, cosine_similarity

__all__ = ["KnowledgeRetriever"]
```

### `src/utils.py`
```python
# src/utils.py
import numpy as np
import faiss
import json
from pathlib import Path

def load_index(index_path: str):
    """
    Load a FAISS index that was saved by the Indexing skill.
    Returns a tuple (index, id_to_text) where:
      - index is the FAISS index object
      - id_to_text is a dict mapping FAISS row ids to passage texts
    """
    index = faiss.read_index(index_path)
    # Assume the index was saved with a side‑car JSON mapping ids -> texts
    with open(Path(index_path).with_suffix(".json"), "r") as f:
        id_to_text = json.load(f)
    return index, id_to_text

def cosine_similarity(query_vec: np.ndarray, db_vecs: np.ndarray) -> np.ndarray:
    """
    Compute cosine similarity between a query vector and a batch of DB vectors.
    Both inputs should be L2‑normalized.
    Returns a 1‑D array of similarity scores.
    """
    return np.dot(db_vecs, query_vec)
```

### `src/query_processor.py`
```python
# src/query_processor.py
import numpy as np
import json
from pathlib import Path
from typing import List, Dict, Any
from .utils import load_index, cosine_similarity

class KnowledgeRetriever:
    """
    Core class that receives a query embedding, queries the index,
    computes relevance scores, and returns the top‑k passages.
    """

    def __init__(self, config_path: str = "config/defaults.yaml"):
        import yaml
        with open(Path(config_path), "r") as f:
            self.cfg = yaml.safe_load(f)

        self.index_path = self.cfg["index_path"]
        self.top_k = self.cfg["top_k"]
        self.embedding_dim = self.cfg["embedding_dim"]

        # Load index and id->text mapping
        self.index, self.id_to_text = load_index(self.index_path)

        # Retrieve the database vectors once (they are stored in the index)
        self.db_vectors = self.index.reconstruct_numpy(0, self.index.ntotal)

    def retrieve(self, query_embedding: np.ndarray) -> List[Dict[str, Any]]:
        """
        Retrieve top‑k passages for the given query embedding.

        Args:
            query_embedding: 1‑D numpy array of shape (embedding_dim,)

        Returns:
            List of dicts, each containing:
                - "passage": retrieved text
                - "score": relevance score (cosine similarity)
                - "rank": position in the ranking (1‑based)
        """
        # Ensure the query vector is normalized
        query_norm = query_embedding / np.linalg.norm(query_embedding)

        # Compute cosine similarity between query and all DB vectors
        sims = cosine_similarity(self.db_vectors, query_norm)

        # Get top‑k indices
        top_indices = np.argpartition(-sims, self.top_k)[:self.top_k]
        top_indices = top_indices[np.argsort(-sims[top_indices])]

        results = []
        for rank, idx in enumerate(top_indices, start=1):
            passage = self.id_to_text.get(str(idx), "")
            score = float(sims[idx])
            if score < self.cfg.get("score_threshold", 0.0):
                break
            results.append({
                "passage": passage,
                "score": score,
                "rank": rank
            })
        return results
```

### `tests/test_query_processor.py`
```python
# tests/test_query_processor.py
import numpy as np
import yaml
from src.query_processor import KnowledgeRetriever
import tempfile
import os

def test_retrieve_top_k():
    # Minimal index: 3 passages, 2‑dim vectors
    index_data = {
        "vectors": np.array([[0.6, 0.8], [0.1, 0.9], [0.9, 0.4]]),
        "id_to_text": {
            "0": "Passage one.",
            "1": "Passage two.",
            "2": "Passage three."
        }
    }

    # Save temporary index and id->text mapping
    with tempfile.TemporaryDirectory() as tmpdir:
        idx_path = os.path.join(tmpdir, "index.bin")
        json_path = os.path.join(tmpdir, "id_to_text.json")
        np.save(idx_path, index_data["vectors"])
        with open(json_path, "w") as f:
            json.dump(index_data["id_to_text"], f)

        # Create a config file on the fly
        cfg = {
            "index_path": idx_path,
            "embedding_dim": 2,
            "top_k": 2,
            "score_threshold": 0.0
        }
        cfg_path = os.path.join(tmpdir, "config.yaml")
        with open(cfg_path, "w") as f:
            yaml.dump(cfg, f)

        # Build retriever
        retriever = KnowledgeRetriever(config_path=cfg_path)

        # Query embedding that should match passage 0 best
        query = np.array([0.6, 0.8])

        results = retriever.retrieve(query)

        assert len(results) == 1
        assert results[0]["passage"] == "Passage one."
        assert abs(results[0]["score"] - 1.0) < 1e-6
        assert results[0]["rank"] == 1
```

### `config/defaults.yaml`
```yaml
# config/defaults.yaml
index_path: "data/index.bin"
embedding_dim: 768
top_k: 5
score_threshold: 0.0
```

### `README.md`
```markdown
# Knowledge Retrieval Skill

## Overview
The Knowledge Retrieval skill fetches the most relevant passages from an index that was built by the **Indexing** skill. It uses a query embedding supplied by the **Semantic Search** skill to compute relevance scores and returns the top‑ranked passages.

## Installation
```bash
pip install -e .
```

## Configuration
Edit `skill.yaml` to adjust:
- `index_path`: location of the FAISS index built by the Indexing skill.
- `embedding_dim`: dimension of query embeddings (must match the index).
- `top_k`: number of passages to return.
- `score_threshold`: minimum relevance score for a passage to be returned.

## Usage
```python
from src.query_processor import KnowledgeRetriever
import numpy as np

retriever = KnowledgeRetriever()
query_emb = np.random.random(768)   # Replace with real embedding from Semantic Search
results = retriever.retrieve(query_emb)

for r in results:
    print(f"Rank {r['rank']}: Score={r['score']:.4f}")
    print(r['passage'])
    print("---")
```

## Integration
The skill is designed to be invoked after the **Semantic Search** skill produces a query embedding. It can be wired into a pipeline like:

```
User Query -> Semantic Search (embedding) -> Knowledge Retrieval (passages) -> downstream consumer
```

## Testing
Run the test suite with:
```bash
pytest
```

## License
MIT
```

---