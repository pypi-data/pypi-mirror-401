"""
japhrase ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

CLIã‹ã‚‰å„ç¨®åˆ†ææ©Ÿèƒ½ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
"""

import click
import sys
from pathlib import Path
from typing import Optional, List
import logging
import pandas as pd

from .extracter import PhraseExtracter, PRESETS
from .writing_assistant import (
    KWICAnalyzer,
    AbstractBodyChecker,
    HabitDetector,
    RevisionHeatmap,
    RankingTrajectory
)
from .writing_tools import EditorConfigGenerator, SelfRecommender
from .workflow import WorkflowDefinition, WorkflowEngine
from .use_cases import WritingWorkflow
from .config import JaphraseConfig
from .checker import QualityChecker
from .utils import read_file, export_to_csv, export_to_json

logger = logging.getLogger(__name__)


# ãƒ«ãƒ¼ãƒˆã‚°ãƒ«ãƒ¼ãƒ—
@click.group(invoke_without_command=True)
@click.version_option()
@click.pass_context
def cli(ctx):
    """
    japhrase - æ—¥æœ¬èªãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡ºãƒ»åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 

    æ–‡ç« å“è³ªã¨åŸ·ç­†åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®é«˜åº¦ãªNLPåˆ†æãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

    ã€ã‚³ã‚¢æ©Ÿèƒ½ã€‘
      - ãƒ•ãƒ¬ãƒ¼ã‚ºè‡ªå‹•æŠ½å‡º - PMI/ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åŸºç›¤ã®çµ±è¨ˆåˆ†æ
      - è¡¨è¨˜ã‚†ã‚Œæ¤œå‡º - è¡¨ç¾ã®é‡è¤‡ã¨å¤šæ§˜æ€§ã®åˆ†æ
      - åŸ·ç­†ç¿’ç™–æ¤œå‡º - ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã®å¯è¦–åŒ–
      - ã‚ã‚‰ã™ã˜ä¹–é›¢åº¦ - æœ¬æ–‡ã¨ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
      - ã‚»ãƒ«ãƒ•ãƒªã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ - éå»åŸç¨¿ã¨ã®é–¢é€£æ€§ç™ºè¦‹

    ã€ä½¿ç”¨ã‚·ãƒ¼ãƒ³ã€‘
      å­¦ä½è«–æ–‡ãƒ»å­¦è¡“è«–æ–‡ã€å°èª¬æ¨æ•²ã€ãƒ–ãƒ­ã‚°æœ€é©åŒ–ã€SNSæŠ•ç¨¿çµ±ä¸€ã€
      ç·¨é›†è€…å‘ã‘ãƒã‚§ãƒƒã‚¯ã€åŸ·ç­†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è‡ªå‹•åŒ–

    ã€é–‹å§‹æ–¹æ³•ã€‘
      japhrase COMMAND [OPTIONS] [ARGS]
      japhrase --help (è©³ç´°ãªãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º)

    ã€ä¸»è¦ã‚³ãƒãƒ³ãƒ‰ã€‘
      extract       ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è‡ªå‹•çš„ã«ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡º
      stats         ãƒ•ãƒ¬ãƒ¼ã‚ºçµ±è¨ˆã‚’è¨ˆç®—ï¼ˆJSON/CSVå‡ºåŠ›å¯¾å¿œï¼‰
      analyze       çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
      use-case      ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
      workflow      YAMLãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã‚’å®Ÿè¡Œ

    è©³ç´°ã¯å„ã‚³ãƒãƒ³ãƒ‰ã® --help ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
    """
    if ctx.invoked_subcommand is None:
        click.echo(ctx.get_help())


# ===== ã‚³ãƒãƒ³ãƒ‰: extract =====
@cli.command()
@click.argument('input_file', type=click.Path(exists=True), metavar='INPUT_FILE')
@click.option('-o', '--output', type=click.Path(), help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (CSV/JSONå½¢å¼ã§ä¿å­˜)')
@click.option('--config', type=click.Path(exists=True), help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (.japhrase.toml / .japhrase.yml)')
@click.option('--preset', type=click.Choice(list(PRESETS.keys())),
              help=f'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ—ãƒªã‚»ãƒƒãƒˆ ({", ".join(PRESETS.keys())} ã‹ã‚‰é¸æŠ)')
@click.option('--min-count', type=int, help='æœ€å°å‡ºç¾å›æ•°ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6)')
@click.option('--max-length', type=int, help='æœ€å¤§ãƒ•ãƒ¬ãƒ¼ã‚ºé•·ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 16)')
@click.option('--format', type=click.Choice(['csv', 'json', 'table']), default='table',
              help='å‡ºåŠ›å½¢å¼: table=ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤º, csv/json=ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨')
@click.option('-v', '--verbose', is_flag=True, help='è©³ç´°ãªãƒ­ã‚°ã‚’è¡¨ç¤º')
def extract(input_file, output, config, preset, min_count, max_length, format, verbose):
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’è‡ªå‹•æŠ½å‡ºï¼ˆPMI/ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ†æï¼‰

    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå‹•çš„ã«è§£æã—ã€çµ±è¨ˆçš„ã«æ„å‘³ã®ã‚ã‚‹ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•æ¤œå‡ºã«å¯¾å¿œã—ã¦ã„ã¾ã™ï¼ˆ.japhrase.toml/.ymlï¼‰ã€‚

    CLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ã‚’ä¸Šæ›¸ãã—ã¾ã™ï¼ˆå„ªå…ˆåº¦: CLI > è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã€‚

    å‡ºåŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:
      seqchar      - æŠ½å‡ºãƒ•ãƒ¬ãƒ¼ã‚º
      freq         - å‡ºç¾å›æ•°
      length       - æ–‡å­—æ•°
      originality  - ã‚ªãƒªã‚¸ãƒŠãƒªãƒ†ã‚£ä¿‚æ•° (0.0-1.0)
      periodic     - å‘¨æœŸæ€§æŒ‡æ¨™

    ä½¿ç”¨ä¾‹:
    \b
      # SNSæŠ•ç¨¿å‘ã‘ãƒ—ãƒªã‚»ãƒƒãƒˆã§æŠ½å‡º
      japhrase extract tweets.txt --preset sns -o result.csv --format csv

      # ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æŠ½å‡º
      japhrase extract paper.txt --min-count 10 --max-length 20 --format json -o output.json

      # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼ˆCLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ä¸Šæ›¸ãï¼‰
      japhrase extract draft.txt --config .japhrase.toml --preset novel -v
    """
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        cfg = JaphraseConfig(config)
        config_params = cfg.get_extractor_params()

        # ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼
        texts = read_file(input_file, encoding='auto')
        click.echo(f"ğŸ“– {len(texts)}è¡Œã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ", err=True)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ï¼ˆCLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ > è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        final_params = config_params.copy()

        if preset is not None:
            final_params['preset'] = preset
        if min_count is not None:
            final_params['min_count'] = min_count
        if max_length is not None:
            final_params['max_length'] = max_length

        # PhraseExtracter åˆæœŸåŒ–
        if 'preset' in final_params and not min_count and not max_length:
            extractor = PhraseExtracter.preset(final_params['preset'], verbose=1 if verbose else 0)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            if 'min_count' not in final_params:
                final_params['min_count'] = 6
            if 'max_length' not in final_params:
                final_params['max_length'] = 16

            extractor = PhraseExtracter(
                verbose=1 if verbose else 0,
                **{k: v for k, v in final_params.items() if k in [
                    'min_count', 'max_length', 'min_length', 'threshold_originality',
                    'weight_freq', 'weight_len', 'removes', 'knowns', 'unnecesary'
                ]}
            )

        # æŠ½å‡ºå®Ÿè¡Œ
        click.echo("ğŸ” ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡ºä¸­...", err=True)
        phrases_df = extractor.get_dfphrase(texts)

        if len(phrases_df) == 0:
            click.echo("âŒ ãƒ•ãƒ¬ãƒ¼ã‚ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", err=True)
            sys.exit(1)

        click.echo(f"âœ… {len(phrases_df)}å€‹ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ¤œå‡ºã—ã¾ã—ãŸ", err=True)

        # å‡ºåŠ›
        if format == 'table':
            click.echo(phrases_df[['seqchar', 'freq', 'length']].head(20).to_string(index=False))
        elif format == 'csv' and output:
            export_to_csv(phrases_df, output)
            click.echo(f"ğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)
        elif format == 'json' and output:
            export_to_json(phrases_df, output)
            click.echo(f"ğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)
        else:
            click.echo(phrases_df[['seqchar', 'freq', 'length']].to_string(index=False))

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: stats =====
@cli.command()
@click.argument('input_file', type=click.Path(exists=True), metavar='INPUT_FILE')
@click.option('-o', '--output', type=click.Path(), help='çµ±è¨ˆçµæœå‡ºåŠ›å…ˆ (JSON/CSVå½¢å¼)')
@click.option('--config', type=click.Path(exists=True), help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (.japhrase.toml / .japhrase.yml)')
@click.option('--preset', type=click.Choice(list(PRESETS.keys())),
              help=f'ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ—ãƒªã‚»ãƒƒãƒˆ ({", ".join(PRESETS.keys())} ã‹ã‚‰é¸æŠ)')
@click.option('--min-count', type=int, help='æœ€å°å‡ºç¾å›æ•°ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6)')
@click.option('--max-length', type=int, help='æœ€å¤§ãƒ•ãƒ¬ãƒ¼ã‚ºé•·ãƒ•ã‚£ãƒ«ã‚¿ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 16)')
@click.option('--format', type=click.Choice(['csv', 'json', 'table']), default='json',
              help='å‡ºåŠ›å½¢å¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: json - NRE v7å¯¾å¿œ)')
@click.option('--top-n', type=int, default=20, help='å‡ºåŠ›ã™ã‚‹ä¸Šä½ãƒ•ãƒ¬ãƒ¼ã‚ºæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20)')
def stats(input_file, output, config, preset, min_count, max_length, format, top_n):
    """
    ãƒ•ãƒ¬ãƒ¼ã‚ºçµ±è¨ˆã‚’è¨ˆç®—ï¼ˆJSON/CSV/ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼å¯¾å¿œï¼‰

    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æã—ã€ãƒ•ãƒ¬ãƒ¼ã‚ºã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    JSONå½¢å¼ã§ã®å‡ºåŠ›ã¯ NRE v7 ã® audit ã‚³ãƒãƒ³ãƒ‰ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã§ãã¾ã™ã€‚

    è¨ˆç®—ã•ã‚Œã‚‹çµ±è¨ˆå€¤:
      é›†è¨ˆæƒ…å ±:
        - total_phrases        ãƒ•ãƒ¬ãƒ¼ã‚ºç·æ•°
        - unique_phrases       ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ•ãƒ¬ãƒ¼ã‚ºæ•°
        - text_lines           ãƒ†ã‚­ã‚¹ãƒˆè¡Œæ•°

      é »åº¦åˆ†æ:
        - freq_mean            å‡ºç¾å›æ•°ã®å¹³å‡
        - freq_median          å‡ºç¾å›æ•°ã®ä¸­å¤®å€¤
        - freq_std_dev         å‡ºç¾å›æ•°ã®æ¨™æº–åå·®
        - freq_min/max         å‡ºç¾å›æ•°ã®æœ€å°/æœ€å¤§å€¤

      é•·ã•åˆ†æ:
        - length_mean          ãƒ•ãƒ¬ãƒ¼ã‚ºé•·ã®å¹³å‡
        - length_median        ãƒ•ãƒ¬ãƒ¼ã‚ºé•·ã®ä¸­å¤®å€¤
        - length_std_dev       ãƒ•ãƒ¬ãƒ¼ã‚ºé•·ã®æ¨™æº–åå·®

      å¤šæ§˜æ€§æŒ‡æ¨™:
        - diversity_score      è¡¨ç¾ã®å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢
        - entropy              ã‚·ãƒ£ãƒãƒ³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼

      ä¸Šä½ãƒ•ãƒ¬ãƒ¼ã‚º:
        - top_phrases          å‡ºç¾é »åº¦ä¸Šä½ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã¨çµ±è¨ˆ

    JSONå½¢å¼å‡ºåŠ›:
      NRE v7 ã® audit ã‚³ãƒãƒ³ãƒ‰ã§è‡ªå‹•çš„ã« YAML ã«å¤‰æ›å¯èƒ½ã§ã™ã€‚
      APIå½¢å¼: { "status": "success", "data": {...}, "timestamp": "..." }

    ä½¿ç”¨ä¾‹:
    \b
      # JSONã§çµ±è¨ˆã‚’å‡ºåŠ›ï¼ˆNRE v7é€£æºç”¨ï¼‰
      japhrase stats manuscript.txt -o stats.json --format json

      # ä¸Šä½100ãƒ•ãƒ¬ãƒ¼ã‚ºã®çµ±è¨ˆã‚’CSVã§å‡ºåŠ›
      japhrase stats paper.txt --format csv -o phrase_stats.csv --top-n 100

      # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«çµ±è¨ˆã‚’è¡¨ç¤º
      japhrase stats text.txt --preset novel --format table

      # ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§çµ±è¨ˆè¨ˆç®—
      japhrase stats corpus.txt --min-count 5 --max-length 20 -o output.json
    """
    try:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        cfg = JaphraseConfig(config)
        config_params = cfg.get_extractor_params()

        # ãƒ•ã‚¡ã‚¤ãƒ«èª­è¾¼
        texts = read_file(input_file, encoding='auto')
        click.echo(f"ğŸ“– {len(texts)}è¡Œã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ", err=True)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ï¼ˆCLIã‚ªãƒ—ã‚·ãƒ§ãƒ³ > è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        final_params = config_params.copy()
        if preset is not None:
            final_params['preset'] = preset
        if min_count is not None:
            final_params['min_count'] = min_count
        if max_length is not None:
            final_params['max_length'] = max_length

        # PhraseExtracter åˆæœŸåŒ–
        if 'preset' in final_params and not min_count and not max_length:
            extractor = PhraseExtracter.preset(final_params['preset'], verbose=0)
        else:
            if 'min_count' not in final_params:
                final_params['min_count'] = 6
            if 'max_length' not in final_params:
                final_params['max_length'] = 16

            extractor = PhraseExtracter(
                verbose=0,
                **{k: v for k, v in final_params.items() if k in [
                    'min_count', 'max_length', 'min_length', 'threshold_originality',
                    'weight_freq', 'weight_len', 'removes', 'knowns', 'unnecesary'
                ]}
            )

        # ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡ºå®Ÿè¡Œ
        click.echo("ğŸ” ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡ºä¸­...", err=True)
        phrases_df = extractor.get_dfphrase(texts)

        if len(phrases_df) == 0:
            click.echo("âŒ ãƒ•ãƒ¬ãƒ¼ã‚ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", err=True)
            sys.exit(1)

        click.echo(f"âœ… {len(phrases_df)}å€‹ã®ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æ¤œå‡ºã—ã¾ã—ãŸ", err=True)

        # çµ±è¨ˆè¨ˆç®—
        click.echo("ğŸ“Š çµ±è¨ˆã‚’è¨ˆç®—ä¸­...", err=True)
        import numpy as np
        from datetime import datetime

        freq_col = phrases_df['freq'].values
        length_col = phrases_df['length'].values
        originality_col = phrases_df['originality'].values if 'originality' in phrases_df.columns else np.ones_like(freq_col)

        stats_data = {
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'parameters': {
                'input_file': str(input_file),
                'min_count': final_params.get('min_count', 6),
                'max_length': final_params.get('max_length', 16),
                'preset': final_params.get('preset', 'custom')
            },
            'summary': {
                'total_phrases': int(len(phrases_df)),
                'unique_phrases': int(len(phrases_df)),
                'text_lines': int(len(texts)),
                'total_phrase_occurrences': int(freq_col.sum())
            },
            'frequency': {
                'mean': float(np.mean(freq_col)),
                'median': float(np.median(freq_col)),
                'std_dev': float(np.std(freq_col)),
                'min': int(np.min(freq_col)),
                'max': int(np.max(freq_col))
            },
            'length': {
                'mean': float(np.mean(length_col)),
                'median': float(np.median(length_col)),
                'std_dev': float(np.std(length_col)),
                'min': int(np.min(length_col)),
                'max': int(np.max(length_col))
            },
            'originality': {
                'mean': float(np.mean(originality_col)),
                'median': float(np.median(originality_col)),
                'std_dev': float(np.std(originality_col)),
                'min': float(np.min(originality_col)),
                'max': float(np.max(originality_col))
            },
            'diversity': {
                'entropy': float(-np.sum((freq_col / freq_col.sum()) * np.log2(freq_col / freq_col.sum() + 1e-10))),
                'gini_coefficient': float(2 * np.sum(np.arange(1, len(freq_col) + 1) * np.sort(freq_col)) / (len(freq_col) * np.sum(freq_col)) - (len(freq_col) + 1) / len(freq_col))
            },
            'top_phrases': []
        }

        # ä¸Šä½ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’è¿½åŠ 
        top_phrases_df = phrases_df.nlargest(min(top_n, len(phrases_df)), 'freq')
        for idx, row in top_phrases_df.iterrows():
            stats_data['top_phrases'].append({
                'phrase': str(row['seqchar']),
                'frequency': int(row['freq']),
                'length': int(row['length']),
                'originality': float(row['originality']) if 'originality' in row else 0.0
            })

        # å‡ºåŠ›
        if format == 'json':
            if output:
                export_to_json(pd.DataFrame([stats_data]), output)
                click.echo(f"âœ… JSONçµ±è¨ˆã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output}", err=True)
            else:
                import json
                click.echo(json.dumps(stats_data, ensure_ascii=False, indent=2))
        elif format == 'csv':
            if output:
                # CSVã«ã¯å¹³å¦åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
                csv_data = []
                csv_data.append({
                    'metric': 'total_phrases',
                    'value': stats_data['summary']['total_phrases']
                })
                csv_data.append({
                    'metric': 'frequency_mean',
                    'value': stats_data['frequency']['mean']
                })
                csv_data.append({
                    'metric': 'frequency_median',
                    'value': stats_data['frequency']['median']
                })
                csv_data.append({
                    'metric': 'length_mean',
                    'value': stats_data['length']['mean']
                })
                csv_data.append({
                    'metric': 'entropy',
                    'value': stats_data['diversity']['entropy']
                })
                csv_df = pd.DataFrame(csv_data)
                export_to_csv(csv_df, output)
                click.echo(f"âœ… CSVçµ±è¨ˆã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output}", err=True)
            else:
                click.echo("âŒ CSVå½¢å¼ã§ã¯ -o/--output ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®šãŒå¿…é ˆã§ã™", err=True)
                sys.exit(1)
        else:  # table
            click.echo("\n" + "=" * 70)
            click.echo("ãƒ•ãƒ¬ãƒ¼ã‚ºçµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ")
            click.echo("=" * 70)
            click.echo(f"\nã€åŸºæœ¬æƒ…å ±ã€‘")
            click.echo(f"  ãƒ•ãƒ¬ãƒ¼ã‚ºç·æ•°: {stats_data['summary']['total_phrases']}")
            click.echo(f"  ãƒ†ã‚­ã‚¹ãƒˆè¡Œæ•°: {stats_data['summary']['text_lines']}")
            click.echo(f"  ç·å‡ºç¾å›æ•°: {stats_data['summary']['total_phrase_occurrences']}")

            click.echo(f"\nã€é »åº¦çµ±è¨ˆã€‘")
            click.echo(f"  å¹³å‡: {stats_data['frequency']['mean']:.2f}")
            click.echo(f"  ä¸­å¤®å€¤: {stats_data['frequency']['median']:.2f}")
            click.echo(f"  æ¨™æº–åå·®: {stats_data['frequency']['std_dev']:.2f}")
            click.echo(f"  ç¯„å›²: {stats_data['frequency']['min']}-{stats_data['frequency']['max']}")

            click.echo(f"\nã€é•·ã•çµ±è¨ˆã€‘")
            click.echo(f"  å¹³å‡: {stats_data['length']['mean']:.2f} æ–‡å­—")
            click.echo(f"  ä¸­å¤®å€¤: {stats_data['length']['median']:.2f} æ–‡å­—")
            click.echo(f"  ç¯„å›²: {stats_data['length']['min']}-{stats_data['length']['max']} æ–‡å­—")

            click.echo(f"\nã€å¤šæ§˜æ€§æŒ‡æ¨™ã€‘")
            click.echo(f"  ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {stats_data['diversity']['entropy']:.3f}")
            click.echo(f"  ã‚¸ãƒ‹ä¿‚æ•°: {stats_data['diversity']['gini_coefficient']:.3f}")

            click.echo(f"\nã€å‡ºç¾é »åº¦ä¸Šä½ {len(stats_data['top_phrases'])} ãƒ•ãƒ¬ãƒ¼ã‚ºã€‘")
            for i, phrase_info in enumerate(stats_data['top_phrases'], 1):
                click.echo(f"  {i:2d}. {phrase_info['phrase']:<20} (å‡ºç¾: {phrase_info['frequency']:3d}å›, é•·ã•: {phrase_info['length']:2d})")
            click.echo("\n" + "=" * 70)

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: kwic =====
@cli.command()
@click.argument('input_file', type=click.Path(exists=True), metavar='INPUT_FILE')
@click.option('--phrase', required=True, help='æ¤œç´¢å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ã‚º (å¿…é ˆ)')
@click.option('-o', '--output', type=click.Path(), help='çµæœå‡ºåŠ›å…ˆãƒ•ã‚¡ã‚¤ãƒ«')
@click.option('--context', type=int, default=1, help='å‰å¾Œã®æ–‡è„ˆè¡Œæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1)')
def kwic(input_file, phrase, output, context):
    """
    ãƒ•ãƒ¬ãƒ¼ã‚ºã®å‡ºç¾ç®‡æ‰€ã‚’æ–‡è„ˆä»˜ãã§æ¤œç´¢ (KWIC: Keyword in Context)

    æŒ‡å®šã—ãŸãƒ•ãƒ¬ãƒ¼ã‚ºãŒãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã©ã“ã«å‡ºç¾ã™ã‚‹ã‹ã‚’ã€å‰å¾Œã®æ–‡è„ˆã¨å…±ã«è¡¨ç¤ºã—ã¾ã™ã€‚
    è¡¨è¨˜ã‚†ã‚Œã®ç¢ºèªã‚„ã€ãƒ•ãƒ¬ãƒ¼ã‚ºã®ä½¿ç”¨æ–¹æ³•ã®æ¤œè¨¼ã«æœ‰ç”¨ã§ã™ã€‚

    å‡ºåŠ›å½¢å¼:
      å‡ºç¾ç•ªå·    - ä½•ç•ªç›®ã®å‡ºç¾ã‹ï¼ˆå…¨ä½“ã«å¯¾ã™ã‚‹ä½ç½®ï¼‰
      è¡Œç•ªå·      - ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ã®è¡Œç•ªå·
      æ–‡å­—ä½ç½®    - ãã®è¡Œå†…ã§ã®æ–‡å­—ä½ç½®
      context     - å‰å¾Œã®æ–‡è„ˆï¼ˆãƒ•ãƒ¬ãƒ¼ã‚ºã¯ã€ã€‘ã§å›²ã¾ã‚Œã‚‹ï¼‰

    ä½¿ç”¨ä¾‹:
    \b
      # ã€Œæ©Ÿæ¢°å­¦ç¿’ã€ã®å‡ºç¾ç®‡æ‰€ã‚’ç¢ºèª
      japhrase kwic paper.txt --phrase "æ©Ÿæ¢°å­¦ç¿’" --context 2

      # ã€Œè¡¨è¨˜ã‚†ã‚Œã€ã®å‡ºç¾ç®‡æ‰€ã‚’ä¿å­˜
      japhrase kwic manuscript.txt --phrase "è¡¨è¨˜ã‚†ã‚Œ" -o kwic_results.txt
    """
    try:
        texts = read_file(input_file, encoding='auto')
        click.echo(f"ğŸ“– {len(texts)}è¡Œã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ", err=True)

        kwic = KWICAnalyzer(texts, context_lines=context)
        results = kwic.find_phrase(phrase)

        if len(results) == 0:
            click.echo(f"âŒ ãƒ•ãƒ¬ãƒ¼ã‚ºã€Œ{phrase}ã€ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", err=True)
            sys.exit(1)

        click.echo(f"âœ… {len(results)}ä»¶æ¤œå‡ºã—ã¾ã—ãŸ\n", err=True)

        # è¡¨ç¤º
        for idx, row in results.iterrows():
            click.echo(f"ã€å‡ºç¾ {row['occurrence_num']}/{row['total_occurrences']}ã€‘")
            click.echo(f"è¡Œç•ªå·: {row['line_num']}, æ–‡å­—ä½ç½®: {row['char_pos']}")
            click.echo(row['context'])
            click.echo("-" * 70)

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output:
            kwic.export_kwic_results(phrase, output)
            click.echo(f"ğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: check-divergence =====
@cli.command()
@click.argument('abstract_file', type=click.Path(exists=True))
@click.argument('body_file', type=click.Path(exists=True))
@click.option('-o', '--output', type=click.Path(), help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ')
def check_divergence(abstract_file, body_file, output):
    """
    ã‚ã‚‰ã™ã˜ã¨æœ¬æ–‡ã®ä¹–é›¢ã‚’ãƒã‚§ãƒƒã‚¯

    ä½¿ç”¨ä¾‹:
    \b
        japhrase check-divergence abstract.txt body.txt
        japhrase check-divergence abstract.txt body.txt -o report.txt
    """
    try:
        abstract_text = '\n'.join(read_file(abstract_file, encoding='auto'))
        body_text = '\n'.join(read_file(body_file, encoding='auto'))

        click.echo("ğŸ” ä¹–é›¢åˆ†æã‚’å®Ÿè¡Œä¸­...", err=True)
        checker = AbstractBodyChecker(abstract_text, body_text)

        report = checker.generate_report()
        click.echo(report)

        if output:
            checker.export_report(output)
            click.echo(f"\nğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: detect-habits =====
@cli.command()
@click.argument('input_file', type=click.Path(exists=True))
@click.option('--reference-dir', type=click.Path(exists=True), help='å‚ç…§ã‚³ãƒ¼ãƒ‘ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
@click.option('--top-n', type=int, default=10, help='è¡¨ç¤ºä¸Šä½ä»¶æ•°')
@click.option('-o', '--output', type=click.Path(), help='å‡ºåŠ›å…ˆï¼ˆCSVï¼‰')
def detect_habits(input_file, reference_dir, top_n, output):
    """
    å€‹äººã®å£ç™–ãƒ»ç¿’ç™–ã‚’æ¤œå‡º

    ä½¿ç”¨ä¾‹:
    \b
        japhrase detect-habits text.txt
        japhrase detect-habits text.txt --reference-dir corpus/ -o habits.csv
    """
    try:
        texts = read_file(input_file, encoding='auto')
        click.echo(f"ğŸ“– {len(texts)}è¡Œã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ", err=True)

        # å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
        reference_texts = None
        if reference_dir:
            ref_files = list(Path(reference_dir).glob('*.txt'))
            reference_texts = []
            for f in ref_files:
                try:
                    reference_texts.extend(read_file(str(f), encoding='auto'))
                except:
                    pass

        click.echo("ğŸ” å£ç™–ã‚’æ¤œå‡ºä¸­...", err=True)
        detector = HabitDetector(texts, reference_texts=reference_texts)
        habits = detector.detect_habits(limit=top_n)

        if len(habits) == 0:
            click.echo("âœ… ç‰¹åˆ¥ãªå£ç™–ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", err=True)
        else:
            click.echo(f"âœ… {len(habits)}å€‹ã®ç¿’ç™–ã‚’æ¤œå‡ºã—ã¾ã—ãŸ\n", err=True)
            click.echo(habits.to_string(index=False))

            if output:
                habits.to_csv(output, index=False, encoding='utf-8-sig')
                click.echo(f"\nğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: analyze =====
@cli.command()
@click.argument('input_file', type=click.Path(exists=True), metavar='INPUT_FILE')
@click.option('--abstract', type=click.Path(exists=True),
              help='ã‚ã‚‰ã™ã˜ãƒ•ã‚¡ã‚¤ãƒ« (ã‚ã‚‰ã™ã˜ vs æœ¬æ–‡ã®ä¹–é›¢åº¦ã‚’åˆ†æ)')
@click.option('--corpus-dir', type=click.Path(exists=True),
              help='éå»åŸç¨¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ã‚»ãƒ«ãƒ•ãƒªã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ç”¨)')
@click.option('-o', '--output', type=click.Path(), help='åˆ†æãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ')
@click.option('--preset', type=click.Choice(list(PRESETS.keys())), default='default',
              help=f'æŠ½å‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ—ãƒªã‚»ãƒƒãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: default)')
def analyze(input_file, abstract, corpus_dir, output, preset):
    """
    è¤‡æ•°ã®åˆ†ææ©Ÿèƒ½ã‚’çµ„ã¿åˆã‚ã›ãŸçµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

    1ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§ä»¥ä¸‹ã®åˆ†æã‚’é †åºå®Ÿè¡Œã—ã¾ã™ï¼š
      [1] ãƒ•ãƒ¬ãƒ¼ã‚ºè‡ªå‹•æŠ½å‡º (preset ã§æŒ‡å®š)
      [2] ã‚ã‚‰ã™ã˜ä¹–é›¢åº¦åˆ†æ (--abstract ã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šæ™‚)
      [3] å€‹äººã®åŸ·ç­†ç¿’ç™–æ¤œå‡º
      [4] ã‚»ãƒ«ãƒ•ãƒªã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ (--corpus-dir æŒ‡å®šæ™‚)

    å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯çµ±åˆãƒ¬ãƒãƒ¼ãƒˆã«å«ã¾ã‚Œã€å®Ÿè¡Œçµæœã¯ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤ºã¨
    ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã®ä¸¡æ–¹ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚

    ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹:
      ğŸ“‹ ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡ºçµæœ
      ğŸ”„ ã‚ã‚‰ã™ã˜ä¹–é›¢åº¦ï¼ˆ%ï¼‰
      ğŸ‘¤ æ¤œå‡ºã•ã‚ŒãŸå€‹äººã®ç¿’ç™–ï¼ˆä¸Šä½5ä»¶ï¼‰
      ğŸ” é–¢é€£è¨˜äº‹ï¼ˆéå»åŸç¨¿ã¨ã®é¡ä¼¼åº¦ï¼‰

    ä½¿ç”¨ä¾‹:
    \b
      # åŸºæœ¬çš„ãªä½¿ç”¨ (ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡ºã®ã¿)
      japhrase analyze manuscript.txt -o report.txt

      # ã‚ã‚‰ã™ã˜ä¹–é›¢åº¦ã‚‚åˆ†æ
      japhrase analyze manuscript.txt --abstract abstract.txt -o report.txt

      # éå»åŸç¨¿ã¨ã®æ¯”è¼ƒã‚‚å«ã‚ã‚‹
      japhrase analyze draft.txt --abstract abstract.txt \\
                 --corpus-dir past_articles/ -o full_report.txt

      # ç‰¹å®šãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä½¿ç”¨
      japhrase analyze novel.txt --preset novel --corpus-dir corpus/ -o analysis.txt
    """
    try:
        texts = read_file(input_file, encoding='auto')
        text = '\n'.join(texts)

        click.echo("ğŸ“Š çµ±åˆåˆ†æã‚’é–‹å§‹ã—ã¾ã™...\n", err=True)

        report = []
        report.append("=" * 70)
        report.append("japhrase çµ±åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        report.append("=" * 70)
        report.append("")

        # 1. ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º
        click.echo("  [1/4] ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’æŠ½å‡ºä¸­...", err=True)
        extractor = PhraseExtracter.preset(preset, verbose=0)
        phrases_df = extractor.get_dfphrase(texts)
        report.append(f"\nğŸ“‹ ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º\n")
        report.append(f"æ¤œå‡ºãƒ•ãƒ¬ãƒ¼ã‚ºæ•°: {len(phrases_df)}å€‹")
        if len(phrases_df) > 0:
            report.append(f"ä¸Šä½ãƒ•ãƒ¬ãƒ¼ã‚º: {', '.join(phrases_df.head(5)['seqchar'].tolist())}")

        # 2. ã‚ã‚‰ã™ã˜ãƒã‚§ãƒƒã‚¯
        if abstract:
            click.echo("  [2/4] ã‚ã‚‰ã™ã˜ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...", err=True)
            abstract_text = '\n'.join(read_file(abstract, encoding='auto'))
            checker = AbstractBodyChecker(abstract_text, text)
            divergence = checker.get_divergence_score()
            report.append(f"\nğŸ”„ ã‚ã‚‰ã™ã˜ vs æœ¬æ–‡\n")
            report.append(f"ä¹–é›¢åº¦: {divergence:.1%}")
        else:
            click.echo("  [2/4] ã‚¹ã‚­ãƒƒãƒ— (ã‚ã‚‰ã™ã˜ãªã—)", err=True)

        # 3. å£ç™–æ¤œå‡º
        click.echo("  [3/4] å£ç™–ã‚’æ¤œå‡ºä¸­...", err=True)
        detector = HabitDetector(texts)
        habits = detector.detect_habits(limit=5)
        report.append(f"\nğŸ‘¤ å€‹äººã®ç¿’ç™–\n")
        if len(habits) > 0:
            report.append(f"æ¤œå‡ºæ•°: {len(habits)}å€‹")
        else:
            report.append("æ¤œå‡ºãªã—")

        # 4. ã‚»ãƒ«ãƒ•ãƒªã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if corpus_dir:
            click.echo("  [4/4] é–¢é€£è¨˜äº‹ã‚’æ¤œç´¢ä¸­...", err=True)
            recommender = SelfRecommender(corpus_dir, min_count=1)
            related = recommender.find_related_articles(text, top_n=3)
            report.append(f"\nğŸ” é–¢é€£è¨˜äº‹\n")
            if len(related) > 0:
                report.append(f"è¦‹ã¤ã‹ã£ãŸè¨˜äº‹: {len(related)}ä»¶")
            else:
                report.append("è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            click.echo("  [4/4] ã‚¹ã‚­ãƒƒãƒ— (ã‚³ãƒ¼ãƒ‘ã‚¹ãªã—)", err=True)

        report.append("\n" + "=" * 70)
        report_text = "\n".join(report)

        click.echo(report_text)

        if output:
            with open(output, 'w', encoding='utf-8-sig') as f:
                f.write(report_text)
            click.echo(f"\nğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: workflow =====
@cli.command()
@click.argument('workflow_file', type=click.Path(exists=True))
@click.option('--parallel', is_flag=True, help='ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ')
@click.option('--max-workers', type=int, default=4, help='ä¸¦åˆ—å®Ÿè¡Œæ™‚ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°')
@click.option('-o', '--output', type=click.Path(), help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ')
@click.option('-v', '--verbose', is_flag=True, help='è©³ç´°å‡ºåŠ›')
def workflow(workflow_file, parallel, max_workers, output, verbose):
    """
    YAMLã§å®šç¾©ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ

    ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã«è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’è¨˜è¿°ã—ã€
    ä¾å­˜é–¢ä¿‚ã‚’è‡ªå‹•çš„ã«è§£æ±ºã—ãªãŒã‚‰é †åºå®Ÿè¡Œã¾ãŸã¯ä¸¦åˆ—å®Ÿè¡Œã—ã¾ã™ã€‚

    ä½¿ç”¨ä¾‹:
    \b
        japhrase workflow manuscript.yaml
        japhrase workflow manuscript.yaml --parallel --max-workers 8
        japhrase workflow manuscript.yaml -o report.txt
    """
    try:
        click.echo(f"ğŸ“‹ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’èª­è¾¼ä¸­: {workflow_file}", err=True)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®šç¾©ã‚’èª­è¾¼
        wf = WorkflowDefinition.from_yaml(workflow_file)

        click.echo(f"âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€Œ{wf.name}ã€ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ", err=True)
        click.echo(f"   ã‚¿ã‚¹ã‚¯æ•°: {len(wf.tasks)}å€‹", err=True)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼
        valid, errors = wf.validate()
        if not valid:
            click.echo(f"âŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ã‚¨ãƒ©ãƒ¼:", err=True)
            for error in errors:
                click.echo(f"   - {error}", err=True)
            sys.exit(1)

        # å®Ÿè¡Œé †åºã‚’è¡¨ç¤º
        execution_order = wf.get_execution_order()
        click.echo(f"ğŸ“Š å®Ÿè¡Œé †åº: {' â†’ '.join(execution_order)}", err=True)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
        if parallel:
            click.echo(f"ğŸš€ ä¸¦åˆ—å®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™ (ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {max_workers})...", err=True)
        else:
            click.echo("ğŸš€ é †åºå®Ÿè¡Œã‚’é–‹å§‹ã—ã¾ã™...", err=True)

        engine = WorkflowEngine()
        results = engine.execute(wf, parallel=parallel, max_workers=max_workers)

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = engine.get_report()
        click.echo(report)

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output:
            with open(output, 'w', encoding='utf-8-sig') as f:
                f.write(report)
            click.echo(f"\nğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

        # å®Œäº†çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯
        completed = sum(1 for r in results.values() if r.status.value == 'completed')
        failed = sum(1 for r in results.values() if r.status.value == 'failed')

        if failed > 0:
            click.echo(f"\nâš ï¸ {completed}/{len(results)}å€‹ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ", err=True)
            sys.exit(1)
        else:
            click.echo(f"\nâœ… ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ", err=True)

    except FileNotFoundError as e:
        click.echo(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}", err=True)
        sys.exit(1)
    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        if verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚³ãƒãƒ³ãƒ‰ =====
@cli.command()
def presets_list():
    """
    åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§ã‚’è¡¨ç¤º
    """
    click.echo("åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒªã‚»ãƒƒãƒˆ:")
    click.echo("=" * 70)
    for name, config in PRESETS.items():
        click.echo(f"\n[{name}]")
        click.echo(f"  {config['description']}")
        click.echo(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: min_count={config['min_count']}, "
                   f"max_length={config['max_length']}")


@cli.command()
def version():
    """
    ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
    """
    from . import __version__
    click.echo(f"japhrase version {__version__}")


# ===== ã‚³ãƒãƒ³ãƒ‰: use-case =====
@cli.command(name='use-case')
@click.argument('use_case', type=click.Choice([
    'academic_writing', 'novel_revision', 'blog_writing', 'sns_content', 'editing'
]))
@click.option('--body', type=click.Path(exists=True), help='æœ¬æ–‡ãƒ•ã‚¡ã‚¤ãƒ«')
@click.option('--abstract', type=click.Path(exists=True), help='ã‚ã‚‰ã™ã˜ãƒ•ã‚¡ã‚¤ãƒ«')
@click.option('--v1', type=click.Path(exists=True), help='ãƒãƒ¼ã‚¸ãƒ§ãƒ³1ï¼ˆå°èª¬æ¨æ•²ç”¨ï¼‰')
@click.option('--v2', type=click.Path(exists=True), help='ãƒãƒ¼ã‚¸ãƒ§ãƒ³2ï¼ˆå°èª¬æ¨æ•²ç”¨ï¼‰')
@click.option('--v3', type=click.Path(exists=True), help='ãƒãƒ¼ã‚¸ãƒ§ãƒ³3ï¼ˆå°èª¬æ¨æ•²ç”¨ï¼‰')
@click.option('--corpus', type=click.Path(exists=True), help='éå»åŸç¨¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
@click.option('-o', '--output', type=click.Path(), help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ')
def use_case(use_case, body, abstract, v1, v2, v3, corpus, output):
    """
    ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ¥ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ

    ç‰¹å®šã®åŸ·ç­†ã‚·ãƒŠãƒªã‚ªã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

    åˆ©ç”¨å¯èƒ½ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:
    \b
    - academic_writing: å­¦ä½è«–æ–‡ãƒ»å­¦è¡“è«–æ–‡ã®å“è³ªãƒã‚§ãƒƒã‚¯
    - novel_revision: å°èª¬åŸç¨¿ã®æ¨æ•²
    - blog_writing: ãƒ–ãƒ­ã‚°è¨˜äº‹ã®æœ€é©åŒ–
    - sns_content: SNSæŠ•ç¨¿ã®è¡¨è¨˜çµ±ä¸€
    - editing: ç·¨é›†è€…å‘ã‘ãƒã‚§ãƒƒã‚¯

    ä½¿ç”¨ä¾‹:
    \b
        japhrase use-case academic_writing --body paper.txt --abstract abstract.txt
        japhrase use-case novel_revision --v1 draft1.txt --v2 draft2.txt
        japhrase use-case blog_writing --body article.txt --corpus past_articles/
        japhrase use-case sns_content --body tweet.txt -o report.txt
    """
    try:
        click.echo(f"ğŸ“‹ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹: {use_case}", err=True)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç”Ÿæˆ
        workflow = WritingWorkflow.for_use_case(use_case)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
        report = workflow.run(
            body_file=body,
            abstract_file=abstract,
            v1=v1,
            v2=v2,
            v3=v3,
            past_corpus_dir=corpus,
            output_dir='results'
        )

        # ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
        click.echo(report)

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output:
            with open(output, 'w', encoding='utf-8-sig') as f:
                f.write(report)
            click.echo(f"\nğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

        click.echo("\nâœ… åˆ†æå®Œäº†", err=True)

    except ValueError as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)
    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


@cli.command(name='use-case-list')
def use_case_list():
    """
    åˆ©ç”¨å¯èƒ½ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º
    """
    click.echo("åˆ©ç”¨å¯èƒ½ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹:")
    click.echo("=" * 70)

    usecases = WritingWorkflow.list_usecases()
    for use_case_id, description in usecases.items():
        click.echo(f"\n[{use_case_id}]")
        click.echo(f"  {description}")


# ===== ã‚³ãƒãƒ³ãƒ‰: config =====
@cli.command()
@click.option('--file', type=click.Path(exists=True), help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
@click.option('--show-defaults', is_flag=True, help='ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚‚è¡¨ç¤º')
def config(file, show_defaults):
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¡¨ç¤º

    ä½¿ç”¨ä¾‹:
    \b
        japhrase config
        japhrase config --file .japhrase.toml
        japhrase config --show-defaults
    """
    try:
        cfg = JaphraseConfig(file)

        if cfg.config:
            click.echo(cfg.display_config())
        else:
            click.echo("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", err=True)
            if show_defaults:
                click.echo("\n=== ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š ===")
                click.echo("min_count: 6")
                click.echo("max_length: 16")
                click.echo("threshold_originality: 0.5")

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


# ===== ã‚³ãƒãƒ³ãƒ‰: check =====
@cli.command()
@click.argument('input_file', type=click.Path(exists=True))
@click.option('--config', type=click.Path(exists=True), help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (.toml/.yml)')
@click.option('-o', '--output', type=click.Path(), help='ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›å…ˆ')
def check(input_file, config, output):
    """
    æ–‡æ›¸å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆLinter ãƒ¢ãƒ¼ãƒ‰ï¼‰

    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ã„ã¦æ–‡æ›¸å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ã€‚
    - ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º
    - å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç¢ºèª
    - è¡¨è¨˜ã‚†ã‚Œæ¤œå‡º
    - æ–‡æ›¸é•·ãƒã‚§ãƒƒã‚¯
    - æ®µè½æ§‹æˆãƒã‚§ãƒƒã‚¯

    ä½¿ç”¨ä¾‹:
    \b
        japhrase check document.txt --config .japhrase.toml
        japhrase check document.txt --config .japhrase.toml -o report.txt
    """
    try:
        # ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿
        texts = read_file(input_file, encoding='auto')
        text = '\\n'.join(texts)
        click.echo(f"ğŸ“– {len(texts)}è¡Œã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ", err=True)

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        cfg = JaphraseConfig(config)
        if not cfg.config:
            click.echo("âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", err=True)
            sys.exit(1)

        # ãƒã‚§ãƒƒã‚«ãƒ¼å®Ÿè¡Œ
        click.echo("ğŸ” å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œä¸­...", err=True)
        checker = QualityChecker(text, cfg.config)
        success, errors, warnings = checker.run_all_checks()

        # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        report = checker.get_report()
        click.echo(report)

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output:
            with open(output, 'w', encoding='utf-8-sig') as f:
                f.write(report)
            click.echo(f"ğŸ’¾ {output} ã«ä¿å­˜ã—ã¾ã—ãŸ", err=True)

        # çµæœã«å¿œã˜ã¦çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’è¨­å®š
        if not success:
            sys.exit(1)

        click.echo("âœ… ãƒã‚§ãƒƒã‚¯å®Œäº†", err=True)

    except Exception as e:
        click.echo(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}", err=True)
        sys.exit(1)


def main():
    """CLIã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    cli()


if __name__ == '__main__':
    main()
