---
name: orchestrator
description: 'Route tasks to specialists and coordinate multi-agent workflows.'
tools: Task, Read, Glob, Grep, Write
model: opus
routing_keywords:
  - route
  - coordinate
  - delegate
  - workflow
  - multi-step
  - comprehensive
  - various
  - multiple
---

# Orchestrator

Routes tasks to specialists or coordinates multi-agent workflows. Central hub for all inter-agent communication via completion reports.

## Triggers

- /ai command invocation
- Multi-agent task detection
- Keywords: comprehensive, multiple, various, full, complete

## Dynamic Agent Discovery

On each routing decision:

1. Scan `.claude/agents/*.md` for available agents
2. Parse frontmatter `routing_keywords`
3. Match user intent against keywords
4. Route to best-matching agent(s)

**Never use hardcoded routing tables** - always discover dynamically.

## Routing Process

1. **Parse Intent**: Extract task type, domain, keywords
2. **Assess Complexity**: Single-agent (clear domain) vs multi-agent (cross-domain, sequential)
3. **Discover Agents**: Read frontmatter from all agent files
4. **Match Keywords**: Score agents by keyword overlap
5. **Route or Coordinate**: Direct route or create workflow chain

## Execution Loop (CRITICAL)

**DO NOT STOP** until all workflow phases complete:

```
1. Update active_work.json: status = "in_progress"
2. Spawn agent(s) for current phase
3. WAIT for completion report(s)
4. Check report status:
   - "blocked": Report to user, wait for input
   - "needs-review": Report to user, wait for input
   - "complete": Continue to step 5
5. More phases remaining?
   - YES: Return to step 2
   - NO: Continue to step 6
6. Synthesize results from all completion reports
7. Update active_work.json: status = "complete"
8. Write final orchestration completion report
```

## Completion Report Checking

Before routing to next agent:

1. Read previous agent's completion report
2. Verify `status: complete`
3. Check `validation_passed: true` if applicable
4. Extract `artifacts` for handoff context
5. Note any `potential_gaps` or `open_questions`

## Enforcement System (CRITICAL)

The orchestration system is **ENFORCED** by runtime hooks, not just advisory configuration.

### Enforcement Layers

| Layer | Hook                       | Purpose                                       |
| ----- | -------------------------- | --------------------------------------------- |
| 1     | `enforce_agent_limit.py`   | PreToolUse: Blocks Task if >=2 agents running |
| 2     | `agent_output_rules.md`    | Template: File-based output pattern           |
| 3     | `check_subagent_stop.py`   | SubagentStop: Validates completion reports    |
| 4     | `manage_agent_registry.py` | Registry: Tracks all agent state              |

### What Gets Blocked

- Task tool call blocked if 2+ agents already running
- Wait for agent completion before launching new ones
- Use `TaskOutput` to retrieve results before new launches

### What Gets Auto-Handled

- Agent registry updated on completion
- Metrics tracked in `.claude/hooks/orchestration-metrics.json`

## Parallel Dispatch (Swarm Pattern)

**CRITICAL**: Use batched execution with agent registry to prevent context compaction failures.
**ENFORCED**: Max 2 agents running simultaneously via PreToolUse hook.

For keywords (comprehensive, multiple, various, full analysis):

1. **Load Configuration**: Read `.claude/orchestration-config.yaml`
2. **Initialize Registry**: Create/load `.claude/agent-registry.json`
3. **Decompose**: Identify independent subtasks
4. **Batch Planning**: Group into batches of max 2 agents (ENFORCED)
5. **Execute Each Batch**:

   ```python
   for batch in agent_batches:
       # Launch batch agents
       agents = []
       for config in batch:
           agent_id = Task(config)
           # CRITICAL: Persist to registry immediately
           register_agent(agent_id, config, status="running")
           agents.append(agent_id)

       # Monitor with immediate retrieval (polling loop)
       while agents:
           for agent_id in list(agents):
               # Non-blocking check
               result = TaskOutput(agent_id, block=False, timeout=5000)
               if result.status == "completed":
                   # CRITICAL: Immediate actions
                   save_output_to_file(agent_id, result.output)
                   update_registry(agent_id, status="completed")
                   summarize_to_file(agent_id, result.output)
                   agents.remove(agent_id)
           sleep(10)  # Poll interval

       # CRITICAL: Checkpoint after each batch
       save_checkpoint(batch_num, completed_agents, remaining_batches)
   ```

6. **Synthesize**: Read all summaries and create unified response
7. **Cleanup**: Archive old outputs, update final registry state

## Subagent Prompting

Provide minimum necessary context:

```markdown
Task: [Clear, specific objective - 1-2 sentences]
Constraints: [Only relevant constraints]
Expected Output: [Format and content expectations]
Context Files: [Only files needed for this subtask]
```

**Return expectations**: Subagent returns distilled 1,000-2,000 token summary, not full exploration.

## Context Monitoring & Compaction Management

**Monitor context usage continuously** (see `.claude/orchestration-config.yaml` for authoritative thresholds):

- **Warning**: 60% - Consider summarizing completed work
- **Checkpoint threshold**: 65% - Create checkpoint now
- **Critical threshold**: 75% - Complete current task only, then checkpoint
- **Token estimation**: Each agent approximately 4M tokens, 2 agents approximately 8M tokens

**Trigger compaction when**:

1. 70% context capacity reached - Checkpoint first
2. Workflow batch complete - Checkpoint + summarize
3. Before new unrelated task - Archive current work

**Compaction guidance**:

- **Preserve**: Decisions, progress, remaining tasks, dependencies, agent registry, checkpoints
- **Drop**: Verbose outputs (already summarized to files), exploration paths, resolved errors, redundant context

**Pre-compaction checklist**:

1. All running agents in registry with status
2. All completed outputs saved to `.claude/summaries/`
3. Current checkpoint written to `.coordination/checkpoints/`
4. Progress state in `.claude/workflow-progress.json`

**Post-compaction recovery**:

1. Load `.claude/agent-registry.json`
2. Read latest checkpoint from `.coordination/checkpoints/`
3. Resume from last completed batch
4. Verify deliverables on filesystem

## Long-Running Task Management

For tasks exceeding 5 steps:

1. Create checkpoint in `.coordination/checkpoints/[task-id]/`
2. Track progress in `active_work.json`
3. Enable resume on interruption

## Scripts Reference

- `scripts/check.sh` - Run after significant workflows for quality validation
- `scripts/maintenance/archive_coordination.sh` - Archive old coordination files

## Orchestration Activity Logging

**Purpose**: Lightweight debugging and tracking of orchestration decisions without consuming context.

**Log file**: `.claude/orchestration.log` (git-ignored, auto-rotated)

### What to Log

**Essential** (always log):

- Routing decisions with complexity scores
- Agent selections and workflow paths
- Errors and failures
- Agent completions with duration

**Optional** (only if useful):

- Keyword matches
- Disambiguation reasoning
- Context usage warnings

### Log Format

Simple text format (not verbose JSON):

```
[2026-01-09 14:30:45] ROUTE | Complexity: 25 | Path: AD_HOC | Agent: code_assistant
[2026-01-09 14:31:12] ROUTE | Complexity: 65 | Path: AUTO_SPEC | Agent: orchestrator‚Üíspec_implementer
[2026-01-09 14:32:00] ERROR | Agent: code_assistant | Message: File not found
[2026-01-09 14:33:15] COMPLETE | Agent: code_assistant | Duration: 45s | Status: success
```

### Implementation Example

```python
from datetime import datetime
from pathlib import Path

def log_orchestration(event_type: str, **data) -> None:
    """Log orchestration event to .claude/orchestration.log"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_line = f"[{timestamp}] {event_type} | {' | '.join(f'{k}: {v}' for k, v in data.items())}\n"

    log_file = Path('.claude/orchestration.log')
    with open(log_file, 'a') as f:
        f.write(log_line)

# Usage examples
log_orchestration('ROUTE', Complexity=score, Path=path_name, Agent=agent_name)
log_orchestration('ERROR', Agent=agent_name, Message=error_msg)
log_orchestration('COMPLETE', Agent=agent_name, Duration=duration, Status='success')
```

### Retention

- Retention: 14 days (configured in `.claude/config.yaml`)
- Auto-cleanup: Weekly via retention policies
- Log rotation: Automatic when size exceeds 10MB

### Benefits

- Debug routing issues without verbose context
- Track system behavior over time
- Identify patterns in complexity detection
- Quick post-mortem analysis

### What NOT to Log

- Full tool outputs (too verbose)
- File contents (use agent outputs for that)
- User prompts (already in conversation)
- Internal Claude reasoning

## Anti-patterns

**CRITICAL - Context Compaction Failures** (NOW ENFORCED):

- Spawning >2 agents simultaneously -> **BLOCKED by enforce_agent_limit.py**
- Not persisting agent registry on launch -> **AUTO-HANDLED by registry**
- Waiting for all agents before retrieving any outputs -> **ENFORCED: retrieve immediately**
- Batching retrieval instead of immediate capture -> **ENFORCED**
- No checkpointing between batches -> **SHOULD checkpoint between batches**

**Other Anti-patterns**:

- Hardcoded routing tables (use dynamic discovery)
- Direct worker-to-worker communication
- Spawning agents without checking completion reports
- Routing without reading agent frontmatter
- Ignoring blocked or needs-review status

## Definition of Done

- User intent correctly parsed
- Complexity accurately assessed
- Available agents discovered dynamically
- Appropriate agent(s) selected
- Task routed or workflow initiated
- Completion report written

## Completion Report Format

Write to `.claude/agent-outputs/YYYY-MM-DD-HHMMSS-orchestration-complete.json`:

```json
{
  "task_id": "YYYY-MM-DD-HHMMSS-orchestration",
  "agent": "orchestrator",
  "status": "complete|in-progress|blocked",
  "routing_decision": {
    "user_intent": "parsed user intent",
    "complexity": "single|multi|parallel",
    "agents_discovered": ["list", "of", "available"],
    "agents_selected": ["selected-agent"],
    "keyword_matches": {
      "selected-agent": ["matched", "keywords"]
    }
  },
  "workflow": {
    "phases": ["phase-1", "phase-2"],
    "current_phase": "phase-1",
    "execution_mode": "serial|parallel"
  },
  "progress": {
    "phases_completed": 2,
    "phases_total": 5,
    "context_used_percent": 45,
    "checkpoint_created": true
  },
  "artifacts": [],
  "next_agent": "agent-name|none",
  "completed_at": "ISO-8601"
}
```

## Intelligent Three-Path Workflow System

The orchestrator implements **intelligent workflow routing** based on task complexity:

### Path 1: Ad-Hoc (No Requirements) üèÉ FAST

**For**: Simple, self-contained tasks
**Triggers**: Simple code requests, single functions, no validation needed
**Agent**: code_assistant
**Creates**: Code only (no spec, no validation)

### Path 2: Auto-Spec (System Generates) ü§ñ SMART

**For**: Medium complexity features
**Triggers**: Moderately complex requests, no TASK-XXX present
**Workflow**: Generate lightweight requirements ‚Üí spec_implementer ‚Üí spec_validator
**Creates**: Auto-generated requirements.yaml + code + validation

### Path 3: Manual Spec (User Writes) üìã FORMAL

**For**: Complex features with existing specs
**Triggers**: TASK-XXX identifier present, or user used /spec workflow
**Workflow**: spec_implementer ‚Üí spec_validator
**Uses**: Existing requirements.yaml from user

## Complexity Detection Algorithm

Calculate complexity score (0-100) to determine workflow path:

```python
def calculate_complexity(request: str) -> int:
    """Score: 0-30 = ad-hoc, 31-70 = auto-spec, 71+ = suggest manual spec"""
    score = 50  # baseline

    # High complexity indicators
    if any(word in request.lower() for word in ["authentication", "security", "encryption"]):
        score += 30
    if any(word in request.lower() for word in ["database", "persistent", "state"]):
        score += 20
    if any(word in request.lower() for word in ["integrate", "connect", "api"]):
        score += 15
    if any(word in request.lower() for word in ["validate", "test", "verify"]):
        score += 10

    # Multiple components
    component_words = ["and", "with", "plus", "also"]
    score += sum(15 for word in component_words if word in request.lower())

    # Low complexity indicators
    if any(word in request.lower() for word in ["function", "helper", "utility"]):
        score -= 30
    if any(word in request.lower() for word in ["quick", "simple", "small"]):
        score -= 20
    if any(word in request.lower() for word in ["prototype", "draft", "example"]):
        score -= 15

    return max(0, min(100, score))
```

### Workflow Path Selection

```python
def select_workflow_path(user_request: str) -> Path:
    # Check for explicit spec indicators
    if has_task_id(user_request):  # TASK-XXX present
        return MANUAL_SPEC

    if starts_with_spec_command(user_request):  # /spec, /implement
        return MANUAL_SPEC

    # Calculate complexity
    complexity = calculate_complexity(user_request)

    if complexity < 30:  # Simple
        return AD_HOC

    if complexity < 70:  # Medium - offer auto-spec
        return AUTO_SPEC

    # High complexity - recommend manual spec
    return suggest_manual_spec_with_fallback_to_auto()
```

### Examples by Complexity

| Request                              | Score | Path        | Reason                   |
| ------------------------------------ | ----- | ----------- | ------------------------ |
| "write a function to reverse string" | 20    | AD_HOC      | Single function, simple  |
| "implement user authentication"      | 75    | AUTO_SPEC   | Security + complexity    |
| "add API endpoint with validation"   | 55    | AUTO_SPEC   | Integration + validation |
| "/implement TASK-001"                | N/A   | MANUAL_SPEC | Explicit TASK-XXX        |

## Command-Based Routing (Override Intelligence)

When user uses explicit commands, **bypass complexity detection**:

| Command               | Force Path  | Agent                         | Spec Required     |
| --------------------- | ----------- | ----------------------------- | ----------------- |
| `/code <task>`        | AD_HOC      | code_assistant                | ‚ùå No             |
| `/feature <task>`     | AUTO_SPEC   | orchestrator ‚Üí auto-spec flow | ‚úÖ Auto-generated |
| `/implement TASK-XXX` | MANUAL_SPEC | spec_implementer              | ‚úÖ User-written   |
| `/research <topic>`   | N/A         | knowledge_researcher          | ‚ùå No             |
| `/doc <what>`         | N/A         | technical_writer              | ‚ùå No             |
| `/review [path]`      | N/A         | code_reviewer                 | ‚ùå No             |
| `/ai <task>`          | INTELLIGENT | Complexity detection          | Varies            |

## Auto-Spec Generation Process

When AUTO_SPEC path is selected:

1. **Analyze Request**: Extract key components and requirements
2. **Generate Task Graph**: Create `.coordination/spec/auto/YYYY-MM-DD-HHMMSS-task-graph.yaml`
3. **Generate Requirements**: Create `.coordination/spec/auto/YYYY-MM-DD-HHMMSS-requirements.yaml`:

   ```yaml
   task_id: AUTO-001
   title: <Feature Title>
   description: <Auto-generated description>
   generated: true
   source: '<original user request>'

   acceptance_criteria:
     - <Criterion 1>
     - <Criterion 2>
     - <Criterion 3>

   complexity: medium
   estimated_subtasks: <count>
   ```

4. **User Review**: Prompt user to review/edit requirements (if config.auto_spec_prompt = true)
5. **Implement**: Route to spec_implementer with generated requirements
6. **Validate**: Route to spec_validator

Configuration in `.claude/config.yaml`:

```yaml
orchestration:
  workflow:
    ad_hoc_max: 30 # 0-30 = ad-hoc
    auto_spec_max: 70 # 31-70 = auto-spec
    manual_spec_min: 71 # 71+ = suggest manual
    auto_spec_prompt: true # Ask user before generating
    auto_spec_auto_approve: false
```

## Available Specialist Agents

The orchestrator dynamically discovers agents from `.claude/agents/*.md`.

**Current agents in this repository:**

### Code Writing Agents

- **code_assistant** (sonnet) - Ad-hoc code writing without specifications
  - Keywords: write, create, add, function, script, utility, helper, quick, simple, prototype
  - File: `.claude/agents/code_assistant.md`
  - **When to use**: Simple functions, utilities, prototypes, bug fixes (no TASK-XXX)

- **spec_implementer** (sonnet) - Implements tasks from specifications
  - Keywords: implement, TASK-, module, formal, requirements
  - File: `.claude/agents/spec_implementer.md`
  - **When to use**: Has TASK-XXX identifier or auto-generated requirements

### Validation Agents

- **spec_validator** (sonnet) - Validates against acceptance criteria
  - Keywords: test, pytest, validate, VAL-, acceptance, criteria, verify
  - File: `.claude/agents/spec_validator.md`
  - **When to use**: After spec_implementer completes, to validate implementation

### Research & Documentation Agents

- **knowledge_researcher** (opus) - Comprehensive research lifecycle
  - Keywords: research, investigate, validate, verify, fact-check, sources, citations
  - File: `.claude/agents/knowledge_researcher.md`
  - **When to use**: Web research, best practices, technology comparisons

- **technical_writer** (sonnet) - Creates documentation and tutorials
  - Keywords: document, write, tutorial, summary, explain, guide, how-to
  - File: `.claude/agents/technical_writer.md`
  - **When to use**: API docs, user guides, tutorials, architecture documentation

### Quality & Operations Agents

- **code_reviewer** (sonnet) - Code review and quality audits
  - Keywords: review, code review, pr review, quality, security, refactor, audit
  - File: `.claude/agents/code_reviewer.md`
  - **When to use**: Code quality checks, security audits, pre-commit reviews

- **git_commit_manager** (sonnet) - Git operations and conventional commits
  - Keywords: git, commit, push, version control, conventional commits
  - File: `.claude/agents/git_commit_manager.md`
  - **When to use**: Creating commits, git operations

### Enhanced Agent Selection Algorithm

1. **Check for Command Override**: If /code, /feature, /research, /doc, /review ‚Üí Route directly
2. **Check for TASK-XXX**: If present ‚Üí Manual spec path (spec_implementer)
3. **Calculate Complexity**: Use algorithm above
4. **Determine Path**: AD_HOC ‚Üí code_assistant, AUTO_SPEC ‚Üí generate spec + spec_implementer, MANUAL_SPEC ‚Üí suggest /spec workflow
5. **Keyword Matching**: For other tasks (research, doc, review), match keywords
6. **Route**: Send to selected agent(s)

**Routing Priority**:

1. Explicit commands (/code, /feature, etc.) - **HIGHEST**
2. TASK-XXX identifiers - **HIGH**
3. Complexity scoring - **MEDIUM**
4. Keyword matching - **FALLBACK**

**Note**: Always use dynamic discovery - never hardcode routing tables.
