import asyncio
import re
import os
from typing import Dict, Any, List, Optional, Union, Pattern

from .tools import Tool
from .embeddings import EmbeddingProvider
from .providers import LLMProvider

# Optional dependencies - lazy import
try:
    import PyPDF2
    PYPDF2_AVAILABLE = True
except ImportError:
    PYPDF2_AVAILABLE = False

try:
    from textsplitter import TextSplitter
    TEXTSPLITTER_AVAILABLE = True
except ImportError:
    TEXTSPLITTER_AVAILABLE = False

try:
    from chromadb import PersistentClient
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False

# Use centralized logging (no basicConfig to prevent duplicates)
from .logging_config import get_logger
logger = get_logger("pdf_rag")

class PDFRAGTool(Tool):
    """Tool for Retrieval-Augmented Generation (RAG) using PDF documents."""
    
    def __init__(
        self,
        base_pdf_folder: str,
        base_vector_db_path: str,
        embedding_provider: EmbeddingProvider,
        llm_provider: LLMProvider,
        chunk_size: int = 1000,
        chunk_overlap: int = 200,
        k_value: int = 3
    ):
        self.base_pdf_folder = base_pdf_folder
        self.base_vector_db_path = base_vector_db_path
        self.embedding_provider = embedding_provider
        self.llm_provider = llm_provider
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.k_value = k_value
        self.text_splitter = TextSplitter()
        
        rag_patterns = [
            r"(?:find|search|lookup|information about|details on|what is|explain|summarize)\s+(.+)\s+(?:in|from|within)\s+(?:pdf|document|file)",
            r"(?:question|query|ask)\s+about\s+(.+)\s+(?:pdf|document|file)",
            r"(?:retrieve|extract)\s+(.+)\s+(?:from|in)\s+(?:pdf|document|file)"
        ]
        capabilities = [
            "pdf", "document", "retrieval", "rag", "information extraction",
            "file search", "document analysis", "text retrieval"
        ]
        
        super().__init__(
            name="pdf_rag",
            description="Retrieve and generate answers from PDF documents using RAG",
            function=self._execute_rag,
            llm_provider=llm_provider,
            detection_threshold=0.4
        )
        
        self.capability_keywords = capabilities  # Store capabilities as instance variable
        self.add_example({"name": "pdf_rag", "args": {"query": "What is the main topic of the document?"}})
        self.add_example({"name": "pdf_rag", "args": {"query": "Summarize the key points in the PDF"}})
        logger.debug("Initialized PDFRAGTool with base_pdf_folder=%s, base_vector_db_path=%s", base_pdf_folder, base_vector_db_path)
    
    def _get_or_create_vectorstore(self):
        logger.debug("Creating or retrieving vector store at %s", self.base_vector_db_path)
        try:
            client = PersistentClient(path=self.base_vector_db_path)
            
            # Wrapper for aiccel's embedding provider to work with Chroma
            class EmbeddingWrapper:
                def __init__(self, provider: EmbeddingProvider):
                    self.provider = provider
                
                def __call__(self, input: List[str]) -> List[List[float]]:
                    logger.debug("Generating embeddings for %d texts", len(input))
                    embeddings = self.provider.embed(input)
                    logger.debug("Generated %d embeddings", len(embeddings))
                    return embeddings
            
            embedding_function = EmbeddingWrapper(self.embedding_provider)
            collection = client.get_or_create_collection(
                name="pdf_documents",
                embedding_function=embedding_function
            )
            logger.debug("Vector store collection 'pdf_documents' ready")
            return collection
        except Exception as e:
            logger.error("Failed to create or retrieve vector store: %s", str(e))
            raise
    
    def _chunk_text(self, text: str, chunk_size: int, chunk_overlap: int) -> List[str]:
        logger.debug("Chunking text of length %d with chunk_size=%d, chunk_overlap=%d", len(text), chunk_size, chunk_overlap)
        chunks = []
        start = 0
        text_length = len(text)
        
        while start < text_length:
            end = min(start + chunk_size, text_length)
            # Adjust end to avoid splitting mid-word
            while end < text_length and text[end] not in [" ", "\n", ".", "!", "?"]:
                end -= 1
            if end == start:
                end = min(start + chunk_size, text_length)
            chunks.append(text[start:end])
            start += chunk_size - chunk_overlap
            if start >= text_length:
                break
        logger.debug("Created %d chunks", len(chunks))
        return chunks
    
    def _process_pdf_documents(self, pdf_folder: str, vectorstore):
        logger.debug("Processing PDFs in folder: %s", pdf_folder)
        if not os.path.exists(pdf_folder):
            logger.warning("PDF folder %s does not exist", pdf_folder)
            return f"Error: PDF folder {pdf_folder} does not exist."
        
        pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(".pdf")]
        logger.debug("Found %d PDF files: %s", len(pdf_files), pdf_files)
        
        # Get existing document IDs from vector store
        existing_ids = set(vectorstore.get()['ids'])
        logger.debug("Found %d existing document IDs in vector store", len(existing_ids))
        
        for filename in pdf_files:
            # Check if PDF is already processed by looking for its first chunk ID
            sample_id = f"{filename}_0"
            if sample_id in existing_ids:
                logger.debug("Skipping %s: already processed (ID %s found)", filename, sample_id)
                continue
                
            file_path = os.path.join(pdf_folder, filename)
            logger.debug("Processing PDF: %s", file_path)
            try:
                documents = self._load_pdf_documents(file_path)
                logger.debug("Loaded %d pages from %s", len(documents), filename)
                if not documents:
                    logger.warning("No text extracted from %s", filename)
                    continue
                category = self._categorize_document(documents, filename)
                logger.debug("Categorized %s as: %s", filename, category)
                combined_text = "\n\n".join(documents)
                texts = self._chunk_text(combined_text, self.chunk_size, self.chunk_overlap)
                logger.debug("Split %s into %d chunks", filename, len(texts))
                metadatas = [{"source": filename, "category": category} for _ in texts]
                ids = [f"{filename}_{i}" for i in range(len(texts))]
                
                # Add texts to Chroma collection
                logger.debug("Adding %d chunks to vector store for %s", len(texts), filename)
                vectorstore.add(
                    documents=texts,
                    metadatas=metadatas,
                    ids=ids
                )
                logger.debug("Successfully added chunks for %s to vector store", filename)
            except Exception as e:
                logger.error("Error processing %s: %s", filename, str(e))
                return f"Error processing {filename}: {str(e)}"
        logger.debug("Processed all PDF documents successfully")
        return "Processed all PDF documents successfully."
    
    def _load_pdf_documents(self, filepath: str) -> List[str]:
        logger.debug("Loading PDF: %s", filepath)
        try:
            with open(filepath, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                pages = [page.extract_text() for page in pdf_reader.pages if page.extract_text()]
                logger.debug("Extracted text from %d pages in %s", len(pages), filepath)
                return pages
        except Exception as e:
            logger.error("Error loading PDF %s: %s", filepath, str(e))
            return []
    
    def _categorize_document(self, documents: List[str], filename: str) -> str:
        logger.debug("Categorizing document: %s", filename)
        content = "\n".join(documents[:3])[:1000]
        prompt = (
            f"Given the following content from a document, determine the main category it belongs to.\n"
            f"Document filename: {filename}\n"
            f"Content preview: {content}...\n"
            f"Category:"
        )
        try:
            category = self.llm_provider.generate(prompt).strip()
            logger.debug("Category for %s: %s", filename, category)
            return category
        except Exception as e:
            logger.error("Error categorizing %s: %s", filename, str(e))
            return "Uncategorized"
    
    def _execute_rag(self, args: Dict[str, Any]) -> str:
        logger.debug("Executing RAG with args: %s", args)
        query = args.get("query")
        
        if not query:
            logger.warning("No query provided")
            return "Error: No query provided."
        
        try:
            # Get or create vectorstore
            vectorstore = self._get_or_create_vectorstore()
            
            # Process PDFs if folder exists
            if os.path.exists(self.base_pdf_folder):
                result = self._process_pdf_documents(self.base_pdf_folder, vectorstore)
                logger.debug("PDF processing result: %s", result)
            else:
                logger.warning("PDF folder %s does not exist", self.base_pdf_folder)
            
            # Query vectorstore
            logger.debug("Querying vector store with query: %s", query)
            results = vectorstore.query(
                query_texts=[query],
                n_results=self.k_value
            )
            logger.debug("Vector store query returned %d documents", len(results['documents'][0]) if results['documents'] else 0)
            
            if not results['documents'] or not results['documents'][0]:
                logger.warning("No relevant information found in the PDF documents")
                return "No relevant information found in the PDF documents."
            
            # Format context and sources
            context = "\n\n".join(results['documents'][0])
            sources = [f"Source: {meta['source']} (Category: {meta['category']})" 
                      for meta in results['metadatas'][0]]
            logger.debug("Retrieved context and %d sources", len(sources))
            
            # Generate answer using LLM
            prompt = (
                f"Instructions: Provide a concise and accurate answer to the query based on the provided context.\n\n"
                f"Query: {query}\n\n"
                f"Context:\n{context}\n\n"
                f"Sources:\n" + "\n".join(sources) + "\n\n"
                f"Answer:"
            )
            logger.debug("Generating answer with LLM")
            answer = self.llm_provider.generate(prompt).strip()
            logger.debug("Generated answer: %s", answer)
            
            # Combine answer with sources
            return f"{answer}\n\nSources:\n" + "\n".join(sources)
        
        except Exception as e:
            logger.error("Error executing PDF RAG: %s", str(e))
            return f"Error executing PDF RAG: {str(e)}"
    
    async def execute_async(self, args: Dict[str, Any]) -> str:
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self._execute_rag, args)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "capabilities": list(self.capability_keywords),
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "The question or query to answer based on PDF documents"
                    }
                },
                "required": ["query"]
            }
        }