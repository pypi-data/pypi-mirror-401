redis = "12800"

[train]
resume = false
epoch = 1
output_dir = "./outputs/sft_sana_image"
epsilon = 1e-5
optm_name = "AdamW"
optm_lr = 1e-4
optm_impl = "fused"
optm_weight_decay = 0.01
optm_betas = [ 0.9, 0.999,]
optm_warmup_steps = 0
optm_grad_norm_clip = 1.0
async_tp_enabled = false
compile = false
param_dtype = "bfloat16"
fsdp_reduce_dtype = "float32"
fsdp_offload = false
fsdp_reshard_after_forward = "default"
train_batch_per_replica = 1
sync_weight_interval = 1

[validation]
enable = true
freq = 10
dataset.local_dir = "local_dir"

[policy]
model_name_or_path = "Efficient-Large-Model/SANA1.5_1.6B_1024px_diffusers"
is_diffusers = true
model_gradient_checkpointing = true

[policy.diffusers_config]
offload = true
is_video = false
max_prompt_length = 300
weighting_scheme = "logit_normal"
inference_size = [1024, 1024]

[policy.lora]
r = 4
lora_alpha = 4
init_lora_weights = "gaussian"
target_modules = ["attn1.to_q", "attn1.to_k", "attn1.to_v", "attn1.to_out.0", "attn2.to_q", "attn2.to_k", "attn2.to_v", "attn2.to_out.0"]

[logging]
logger = ['console', 'wandb']
project_name = "cosmos_rl"
experiment_name = "None"

[train.train_policy]
type = "sft"
dataset.local_dir = "local_validation_dir"
mini_batch = 1


[train.ckpt]
enable_checkpoint = true
save_freq = 10
save_mode = "async"

[policy.parallelism]
n_init_replicas = 1
tp_size = 1
cp_size = 1
dp_shard_size = 8
pp_size = 1
dp_replicate_size = 1
