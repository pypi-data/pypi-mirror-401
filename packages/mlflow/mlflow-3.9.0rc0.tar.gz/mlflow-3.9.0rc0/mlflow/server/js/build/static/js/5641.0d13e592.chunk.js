"use strict";(self.webpackChunk_mlflow_mlflow=self.webpackChunk_mlflow_mlflow||[]).push([[5641],{14429:function(e,t,n){n.d(t,{KT:function(){return c},Pz:function(){return m},UY:function(){return g},VA:function(){return u},oy:function(){return d}});var a=n(46709),o=n(91105),i=n(79444);const s="startTimeLabel",l="startTime",r="endTime",d="LAST_7_DAYS",c=(0,a.createContext)(null),u=()=>{const e=(0,i.U)(),t=(0,a.useContext)(c),[n,u]=(0,o.ok)();let m,p,f;var h;t?(m=t.params.startTimeLabel||d,p=t.params.startTime,f=t.params.endTime):(m=n.get(s)||d,p=n.get(l)||void 0,f=null!==(h=n.get(r))&&void 0!==h?h:void 0);if("CUSTOM"!==m){const t=g(e.dateNow,{startTimeLabel:m});p=t.startTime,f=t.endTime}const T=(0,a.useMemo)(()=>({startTimeLabel:m,startTime:p,endTime:f}),[m,p,f]),E=(0,a.useCallback)((e,n=!1)=>{t?t.setParams(null!==e&&void 0!==e?e:{startTimeLabel:void 0,startTime:void 0,endTime:void 0},n):u(t=>(void 0===(null===e||void 0===e?void 0:e.startTime)?t.delete(l):"CUSTOM"===e.startTimeLabel&&t.set(l,e.startTime),void 0===(null===e||void 0===e?void 0:e.endTime)?t.delete(r):"CUSTOM"===e.startTimeLabel&&t.set(r,e.endTime),void 0===(null===e||void 0===e?void 0:e.startTimeLabel)?t.delete(s):t.set(s,e.startTimeLabel),t),{replace:n})},[t,u]);return[T,E,Boolean(n.has(s)||(null===t||void 0===t?void 0:t.disableAutomaticInitialization))]},m=e=>{const[t]=u(),[n]=(0,a.useState)(()=>null!==e&&void 0!==e?e:new Date);return(0,a.useMemo)(()=>{const{startTime:e,endTime:a}=g(n,t);return{startTime:e?new Date(e).getTime().toString():void 0,endTime:a?new Date(a).getTime().toString():void 0}},[n,t])};function g(e,t){return t.startTimeLabel&&"CUSTOM"!==t.startTimeLabel?function(e,t){switch(t){case"LAST_HOUR":return{startTime:new Date(new Date(e).setUTCHours((new Date).getUTCHours()-1)).toISOString(),endTime:e.toISOString()};case"LAST_24_HOURS":return{startTime:new Date(new Date(e).setUTCDate((new Date).getUTCDate()-1)).toISOString(),endTime:e.toISOString()};case"LAST_7_DAYS":return{startTime:new Date(new Date(e).setUTCDate((new Date).getUTCDate()-7)).toISOString(),endTime:e.toISOString()};case"LAST_30_DAYS":return{startTime:new Date(new Date(e).setUTCDate((new Date).getUTCDate()-30)).toISOString(),endTime:e.toISOString()};case"LAST_YEAR":return{startTime:new Date(new Date(e).setUTCFullYear((new Date).getUTCFullYear()-1)).toISOString(),endTime:e.toISOString()};case"ALL":return{startTime:void 0,endTime:e.toISOString()};default:throw new Error(`Unexpected start time label: ${t}`)}}(e,t.startTimeLabel):{startTime:t.startTime,endTime:t.endTime}}},23984:function(e,t,n){n.d(t,{I:function(){return f}});var a=n(68248),o=n(27757),i=n(82716),s=n(19112),l=n(91701),r=(n(46709),n(40724)),d=n(73408);var c={name:"ddxhyk",styles:"max-width:800px"},u={name:"ddxhyk",styles:"max-width:800px"};const m={openai:{minVersion:"2.15.1",getContent:()=>(0,d.Y)(r.A,{id:"smtq2M",defaultMessage:"Automatically log traces for OpenAI API calls by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.openai.autolog()"})}}),getCodeSource:()=>'from openai import OpenAI\n\nmlflow.openai.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nclient = OpenAI()\n\nmessages = [\n  {"role": "system", "content": "You are a helpful assistant."},\n  {"role": "user", "content": "Hello!"}\n]\n\n# Inputs and outputs of the API request will be logged in a trace\nclient.chat.completions.create(model="gpt-4o-mini", messages=messages)'},langchain:{minVersion:"2.17.2",getContent:()=>(0,d.Y)(r.A,{id:"7/urtn",defaultMessage:"Automatically log traces for LangChain or LangGraph invocations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.langchain.autolog()"})}}),getCodeSource:()=>'from langchain_openai import OpenAI\nfrom langchain_core.prompts import PromptTemplate\n\nmlflow.langchain.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nllm = OpenAI()\nprompt = PromptTemplate.from_template("Answer the following question: {question}")\nchain = prompt | llm\n\n# Invoking the chain will cause a trace to be logged\nchain.invoke("What is MLflow?")'},langgraph:{minVersion:"2.19.0",getContent:()=>(0,d.Y)(r.A,{id:"dvL+4V",defaultMessage:"Automatically log traces for LangGraph workflows by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.langchain.autolog()"})}}),getCodeSource:()=>'from langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph\nfrom typing import Annotated\n\nmlflow.langchain.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nmodel = ChatOpenAI(model="gpt-4o-mini")\n\n# Define a minimal LangGraph workflow\nclass GraphState(dict):\n    input: Annotated[str, "input"]\n\ndef call_model(state: GraphState) -> GraphState:\n    response = model.invoke(state["input"])\n    return {"input": state["input"], "response": response.content}\n\ngraph = StateGraph(GraphState)\ngraph.add_node("model", call_model)\ngraph.set_entry_point("model")\napp = graph.compile()\n\n# Executing the graph will log the steps as a trace\napp.invoke({"input": "Say hello to MLflow."})'},llama_index:{minVersion:"2.15.1",getContent:()=>(0,d.Y)(r.A,{id:"/v6KuF",defaultMessage:"Automatically log traces for LlamaIndex queries by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.llama_index.autolog()"})}}),getCodeSource:()=>'from llama_index.core import Document, VectorStoreIndex\n\nmlflow.llama_index.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nindex = VectorStoreIndex.from_documents([Document.example()])\nquery_engine = index.as_query_engine()\n\n# Querying the engine will cause a trace to be logged\nquery_engine.query("What is LlamaIndex?")'},dspy:{minVersion:"2.18.0",getContent:()=>(0,d.Y)(r.A,{id:"h1HQ14",defaultMessage:"Automatically log traces for DSPy executions by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.dspy.autolog()"})}}),getCodeSource:()=>'import dspy\n\nmlflow.dspy.autolog()\n\n# Configure the LLM to use. Please ensure that\n# the OPENAI_API_KEY environment variable is set\nlm = dspy.LM("openai/gpt-4o-mini")\ndspy.configure(lm=lm)\n\n# Define a simple chain-of-thought model and run it\nmath = dspy.ChainOfThought("question -> answer: float")\nquestion = "Two dice are tossed. What is the probability that the sum equals two?"\n\n# All intermediate outputs from the execution will be logged\nmath(question=question)'},crewai:{minVersion:"2.19.0",getContent:()=>(0,d.Y)(r.A,{id:"K8LdMX",defaultMessage:"Automatically log traces for CrewAI executions by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.crewai.autolog()"})}}),getCodeSource:()=>'from crewai import Agent, Crew, Process, Task\n\nmlflow.crewai.autolog()\n\ncity_selection_agent = Agent(\n    role="City selection expert",\n    goal="Select the best city based on weather, season, and prices",\n    backstory="An expert in analyzing travel data to pick ideal destinations",\n    allow_delegation=True,\n    verbose=True,\n)\n\nlocal_expert = Agent(\n    role="Local expert",\n    goal="Provide the best insights about the selected city",\n    backstory="A local guide with extensive information about the city",\n    verbose=True,\n)\n  \nplan_trip = Task(\n    name="Plan a trip",\n    description="""Plan a trip to a city based on weather, prices, and best local attractions. \n    Please consult with a local expert when researching things to do.""",\n    expected_output="A short summary of the trip destination and key things to do",\n    agent=city_selection_agent,\n)\n\ncrew = Crew(\n  agents=[\n    city_selection_agent,\n    local_expert,\n  ],\n  tasks=[plan_trip],\n  process=Process.sequential\n)\n\n# Ensure the "OPENAI_API_KEY" environment variable is set\n# before kicking off the crew. All intermediate agent outputs\n# will be logged in the resulting trace.\ncrew.kickoff()'},autogen:{minVersion:"2.16.2",getContent:()=>(0,d.Y)(r.A,{id:"i/pJvo",defaultMessage:"Automatically log traces for AutoGen conversations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.autogen.autolog()"})}}),getCodeSource:()=>'import os\nfrom autogen import AssistantAgent, UserProxyAgent\n\nmlflow.autogen.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nllm_config = { "model": "gpt-4o-mini", "api_key": os.environ["OPENAI_API_KEY"] }\nassistant = AssistantAgent("assistant", llm_config = llm_config)\nuser_proxy = UserProxyAgent("user_proxy", code_execution_config = False)\n\n# All intermediate executions within the chat session will be logged\nuser_proxy.initiate_chat(assistant, message = "What is MLflow?", max_turns = 1)'},anthropic:{minVersion:"2.19.0",getContent:()=>(0,d.Y)(r.A,{id:"AzOnmT",defaultMessage:"Automatically log traces for Anthropic API calls by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.anthropic.autolog()"})}}),getCodeSource:()=>'import os\nimport anthropic\n\n# Enable auto-tracing for Anthropic\nmlflow.anthropic.autolog()\n\n# Configure your API key (please ensure that the "ANTHROPIC_API_KEY" environment variable is set)\nclient = anthropic.Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])\n\n# Inputs and outputs of API calls will be logged as a trace\nmessage = client.messages.create(\n    model="claude-3-5-sonnet-20241022",\n    max_tokens=1024,\n    messages=[\n        {"role": "user", "content": "Hello, Claude"},\n    ],\n)'},bedrock:{minVersion:"2.20.0",getContent:()=>(0,d.Y)(r.A,{id:"6tKW1I",defaultMessage:"Automatically log traces for Bedrock conversations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.bedrock.autolog()"})}}),getCodeSource:()=>'import boto3\n\nmlflow.bedrock.autolog()\n\n# Ensure that your boto3 client has the necessary auth information\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\n\nmodel = "anthropic.claude-3-5-sonnet-20241022-v2:0"\nmessages = [{ "role": "user", "content": [{"text": "Hello!"}]}]\n\n# All intermediate executions within the chat session will be logged\nbedrock.converse(modelId=model, messages=messages)'},litellm:{minVersion:"2.18.0",getContent:()=>(0,d.Y)(r.A,{id:"D7SSDK",defaultMessage:"Automatically log traces for LiteLLM API calls by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.litellm.autolog()"})}}),getCodeSource:()=>'import litellm\n\nmlflow.litellm.autolog()\n\n# Ensure that the "OPENAI_API_KEY" environment variable is set\nmessages = [{"role": "user", "content": "Hello!"}]\n\n# Inputs and outputs of the API request will be logged in a trace\nlitellm.completion(model="gpt-4o-mini", messages=messages)'},gemini:{minVersion:"2.18.0",getContent:()=>(0,d.Y)(r.A,{id:"IsIgE2",defaultMessage:"Automatically log traces for Gemini conversations by calling the {code} function. For example:",values:{code:(0,d.Y)("code",{children:"mlflow.gemini.autolog()"})}}),getCodeSource:()=>'import google.genai as genai\n\nmlflow.gemini.autolog()\n\n# Replace "GEMINI_API_KEY" with your API key\nclient = genai.Client(api_key="GEMINI_API_KEY")\n\n# Inputs and outputs of the API request will be logged in a trace\nclient.models.generate_content(model="gemini-1.5-flash", contents="Hello!")'},custom:{minVersion:"2.14.3",getContent:e=>(0,d.FD)(d.FK,{children:[(0,d.Y)(o.T.Paragraph,{css:c,children:(0,d.Y)(r.A,{id:"3Z6K+n",defaultMessage:"To manually instrument your own traces, the most convenient method is to use the {code} function decorator. This will cause the inputs and outputs of the function to be captured in the trace.",values:{code:(0,d.Y)("code",{children:"@mlflow.trace"})}})}),(0,d.Y)(o.T.Paragraph,{css:u,children:(0,d.Y)(r.A,{id:"WNz02j",defaultMessage:"For more complex use cases, MLflow also provides granular APIs that can be used to control tracing behavior. For more information, please visit the <a>official documentation</a> on fluent and client APIs for MLflow Tracing.",values:{a:e=>(0,d.Y)(o.T.Link,{title:"official documentation",componentId:"codegen_no_dynamic_mlflow_web_js_src_experiment_tracking_components_traces_quickstart_tracetablequickstart.utils_366",href:"https://mlflow.org/docs/latest/llms/tracing/index.html#tracing-fluent-apis",openInNewTab:!0,children:e})}})})]}),getCodeSource:()=>'@mlflow.trace\ndef foo(a):\n    return a + bar(a)\n\n# Various attributes can be passed to the decorator\n# to modify the information contained in the span\n@mlflow.trace(name = "custom_name", attributes = { "key": "value" })\ndef bar(b):\n    return b + 1\n\n# Invoking the traced function will cause a trace to be logged\nfoo(1)'}};var g={name:"ddxhyk",styles:"max-width:800px"},p={name:"1hyob9y",styles:"position:relative;width:min-content"};const f=({flavorName:e,baseComponentId:t})=>{const{theme:n}=(0,o.u)(),{getContent:r,getCodeSource:c,minVersion:u}=m[e],f=r(t),h=c();return(0,d.FD)("div",{children:[(0,d.Y)(o.T.Text,{css:g,color:"secondary",children:f}),(0,d.FD)("div",{css:p,children:[(0,d.Y)(l.i,{componentId:"codegen_no_dynamic_mlflow_web_js_src_experiment_tracking_components_traces_quickstart_tracetablegenericquickstart_25",css:(0,a.AH)({zIndex:1,position:"absolute",top:n.spacing.xs,right:n.spacing.xs},""),showLabel:!1,copyText:h,icon:(0,d.Y)(i.CopyIcon,{})}),(0,d.Y)(s.z7,{showLineNumbers:!0,theme:n.isDarkMode?"duotoneDark":"light",style:{padding:`${n.spacing.sm}px ${n.spacing.md}px`,marginTop:n.spacing.md},language:"python",children:h})]})]})}},54741:function(e,t,n){n.d(t,{L:function(){return i}});var a=n(81641);const o=a.J1`
  query MlflowGetExperimentQuery($input: MlflowGetExperimentInput!) @component(name: "MLflow.ExperimentRunTracking") {
    mlflowGetExperiment(input: $input) {
      apiError {
        code
        message
      }
      experiment {
        artifactLocation
        creationTime
        experimentId
        lastUpdateTime
        lifecycleStage
        name
        tags {
          key
          value
        }
      }
    }
  }
`,i=({experimentId:e,options:t={}})=>{var n;const{data:i,loading:s,error:l,refetch:r}=(0,a.IT)(o,{variables:{input:{experimentId:e}},skip:!e,...t});return{loading:s,data:null===i||void 0===i||null===(n=i.mlflowGetExperiment)||void 0===n?void 0:n.experiment,refetch:r,apolloError:l,apiError:(()=>{var e;return null===i||void 0===i||null===(e=i.mlflowGetExperiment)||void 0===e?void 0:e.apiError})()}}},63394:function(e,t,n){n.d(t,{A:function(){return s},S:function(){return l}});var a=n(46709),o=n(73408);const i=(0,a.createContext)({}),s=({children:e,introductionText:t,displayVersionWarnings:n})=>(0,o.Y)(i.Provider,{value:{introductionText:t,displayVersionWarnings:n},children:e}),l=()=>(0,a.useContext)(i)},65641:function(e,t,n){n.d(t,{v:function(){return V}});var a=n(46709),o=n(82716),i=n(27757),s=n(54313),l=n(4168),r=n(27763),d=n(33656),c=n(31655),u=n(40720),m=n(88525),g=n(42747),p=n(69986),f=n(14429),h=n(66916),T=n(92338),E=n(54741),_=n(91944),I=n(44105),A=n(68248),M=n(40724),y=n(76118),w=n(23984),v=n(63394),b=n(73408);const k=({baseComponentId:e,runUuid:t})=>{const{theme:n}=(0,i.u)(),{introductionText:a}=(0,v.S)();return(0,b.FD)("div",{css:(0,A.AH)({overflow:"auto",paddingBottom:n.spacing.lg},""),children:[(0,b.Y)(o.Header,{title:(0,b.Y)(M.A,{id:"6d5JTO",defaultMessage:"No traces recorded"}),titleElementLevel:3}),(0,b.Y)(i.T.Text,{css:(0,A.AH)({display:"block",marginTop:n.spacing.md,marginBottom:n.spacing.md,maxWidth:800},""),children:a||(0,b.Y)(M.A,{id:"msYDmK",defaultMessage:"This tab displays all the traces logged to this {isRun, select, true {run} other {experiment}}. Follow the steps below to log your first trace. For more information about MLflow Tracing, visit the <a>MLflow documentation</a>.",values:{isRun:!(0,y.isNil)(t),a:e=>(0,b.Y)(i.T.Link,{componentId:"codegen_no_dynamic_mlflow_web_js_src_experiment_tracking_components_traces_quickstart_tracesviewtablenotracesquickstart_46",href:"https://mlflow.org/docs/latest/llms/tracing/index.html",openInNewTab:!0,children:e})}})}),(0,b.Y)(w.I,{flavorName:"custom",baseComponentId:e})]})},L=e=>{const{experimentIds:t,traceSearchLocations:n,loggedModelId:s,isCallDisabled:r}=e,d=(0,g.tz)(),{data:c,isLoading:u,error:m}=(0,l.Zn)({locations:n,pageSize:1,limit:1,...s?{filterByLoggedModelId:s}:{},disabled:r}),{data:p,loading:A}=(0,E.L)({experimentId:t[0]}),M=p,y=(0,_.BH)(null===M||void 0===M?void 0:M.tags),w=(y===I.Gk.GENAI_DEVELOPMENT||I.Gk.GENAI_DEVELOPMENT_INFERRED,c&&c.length>0),[v,L]=(0,f.VA)(),S=(0,a.useMemo)(()=>(0,T.p)(d),[d]),C=(0,b.Y)(i.B,{componentId:"traces-v3-empty-state-button",onClick:()=>L({startTimeLabel:"ALL"}),children:(0,b.Y)(g.sA,{id:"WpD2MA",defaultMessage:"View All"})});if(u||A)return(0,b.Y)(b.FK,{children:[...Array(10).keys()].map(e=>(0,b.Y)(o.ParagraphSkeleton,{label:"Loading...",seed:`s-${e}`},e))});if(m)return(0,b.Y)(o.Empty,{image:(0,b.Y)(i.k,{}),title:(0,b.Y)(g.sA,{id:"ZotI2j",defaultMessage:"Fetching traces failed"}),description:String(m)});if(w){var x;const e=(0,b.Y)(h.S,{}),t=(0,b.Y)(g.sA,{id:"XuzIWs",defaultMessage:'Some traces are hidden by your time range filter: "{filterLabel}"',values:{filterLabel:(0,b.Y)("strong",{children:(null===(x=S.find(e=>e.key===v.startTimeLabel))||void 0===x?void 0:x.label)||""})}});return(0,b.Y)(o.Empty,{title:(0,b.Y)(g.sA,{id:"Dhr3pC",defaultMessage:"No traces found"}),description:t,button:C,image:e})}return(0,b.Y)(k,{baseComponentId:"mlflow.traces"})};var S=n(39595),C=n(91105);var x=n(82636),N=n(27462),O=n(24432),D=n(54871);const Y=({children:e,makeHtmlFromMarkdown:t,experimentId:n})=>(0,b.Y)(l.tU,{makeHtml:t,children:e});var R={name:"1dd35ky",styles:"display:flex;flex:1;overflow:hidden"},P={name:"1dd35ky",styles:"display:flex;flex:1;overflow:hidden"},G={name:"db3fum",styles:"display:flex;flex-direction:column;width:100%;gap:8px;padding:16px"},F={name:"1w1qal4",styles:"display:flex;align-items:center;justify-content:center;width:100%;height:100%"},U={name:"1nxh63r",styles:"overflow-y:hidden;height:100%;display:flex;flex-direction:column"};const V=a.memo(({experimentId:e,endpointName:t="",timeRange:n,isLoadingExperiment:h,loggedModelId:T,additionalFilters:E,disableActions:_=!1,customDefaultSelectedColumns:I,toolbarAddons:A})=>{const M=(0,d.N9)(),y=(0,g.tz)(),w=(0,c.rE)(),[v,k]=(0,a.useState)({});(0,D.Gt)("selectedTraceIds",v);const V=(0,a.useMemo)(()=>[(0,l.$U)(e)],[e]),q=!1,z=!0,H=p.Uv,{assessmentInfos:K,allColumns:$,totalCount:W,evaluatedTraces:j,isLoading:B,error:Q,isEmpty:J,tableFilterOptions:Z}=(0,l.KW)({locations:V,timeRange:n,filterByLoggedModelId:T,disabled:q}),[X,ee]=(0,a.useState)(""),[te,ne]=(0,l.R7)(),ae=(0,S.jE)(),oe=(0,a.useMemo)(()=>E&&0!==E.length?[...E,...te]:te,[E,te]),ie=(0,a.useCallback)(e=>{const{responseHasContent:t,inputHasContent:n,tokensHasContent:a}=(0,x.l)(j);return I?e.filter(I):e.filter(e=>e.type===l.$6.ASSESSMENT||e.type===l.$6.EXPECTATION||n&&e.type===l.$6.INPUT||t&&e.type===l.$6.TRACE_INFO&&e.id===l.Rl||a&&e.type===l.$6.TRACE_INFO&&e.id===l.YO||e.type===l.$6.TRACE_INFO&&[l.XQ,l.tj,l.Te,l.$W].includes(e.id)||e.type===l.$6.INTERNAL_MONITOR_REQUEST_TIME)},[j,I]),{selectedColumns:se,toggleColumns:le,setSelectedColumns:re}=(0,l.K0)(e,$,ie),[de,ce]=(0,l.GY)(se,{key:l.Te,type:l.$6.TRACE_INFO,asc:!1}),{isInitialTimeFilterLoading:ue}=(({locations:e,isTracesEmpty:t,isTraceMetadataLoading:n,sqlWarehouseId:a,disabled:o=!1})=>{const[i]=(0,C.ok)(),[s,r,d]=(0,f.VA)(),c=t&&!n&&!d,{data:u,isLoading:m}=(0,l.Zn)({locations:e,tableSort:{key:l.Te,type:l.$6.TRACE_INFO,asc:!1},disabled:!c||o,limit:500,pageSize:500,sqlWarehouseId:a});c&&u&&u.length>0&&!m&&r({startTimeLabel:"CUSTOM",startTime:u[u.length-1].request_time,endTime:(new Date).toISOString()},!0);return{isInitialTimeFilterLoading:c&&m}})({locations:V,isTracesEmpty:J,isTraceMetadataLoading:B,disabled:z}),{data:me,isLoading:ge,isFetching:pe,error:fe}=(0,l.Zn)({locations:V,currentRunDisplayName:t,searchQuery:X,filters:oe,timeRange:n,filterByLoggedModelId:T,tableSort:de,disabled:q}),{showEditTagsModalForTrace:he,EditTagsModal:Te}=((0,u.C)(),(0,m.$)({onSuccess:()=>(0,l.BL)({queryClient:ae}),existingTagKeys:(0,l.d9)(me||[])})),{showTagAssignmentModal:Ee,TagAssignmentModal:_e}=(0,s.BR)({componentIdPrefix:"mlflow.experiment-traces",onSuccess:()=>(0,l.BL)({queryClient:ae})}),Ie=(0,N.F)({traceSearchLocations:V}),Ae=O.p,Me=(0,a.useMemo)(()=>_?{deleteTracesAction:void 0,exportToEvals:void 0,editTags:void 0}:{deleteTracesAction:Ie,exportToEvals:!0,editTags:(0,s.F9)()?{showEditTagsModalForTrace:Ee,EditTagsModal:_e}:{showEditTagsModalForTrace:he,EditTagsModal:Te}},[Ie,Ee,_e,he,Te,_]),ye=(0,a.useMemo)(()=>({currentCount:null===me||void 0===me?void 0:me.length,logCountLoading:ge,totalCount:W,maxAllowedCount:(0,l.pR)()}),[me,W,ge]),we=ge||ue||B,ve=fe||Q,be=J&&!we&&!ve;return(0,b.Y)(r.N,{rowSelection:v,setRowSelection:k,children:(0,b.Y)(l.sG,{experimentId:e,getTrace:H,renderExportTracesToDatasetsModal:Ae,children:(0,b.FD)("div",{css:U,children:[(0,b.Y)(l.w_,{experimentId:e,searchQuery:X,setSearchQuery:ee,filters:te,setFilters:ne,assessmentInfos:K,traceInfos:me,tableFilterOptions:Z,countInfo:ye,traceActions:Me,tableSort:de,setTableSort:ce,allColumns:$,selectedColumns:se,toggleColumns:le,setSelectedColumns:re,isMetadataLoading:B,metadataError:Q,usesV4APIs:z,addons:A}),!w&&be?(0,b.Y)(L,{experimentIds:[e],loggedModelId:T,traceSearchLocations:V,isCallDisabled:q}):(0,b.Y)("div",{css:R,children:(0,b.Y)("div",{css:P,children:we?(0,b.Y)("div",{css:G,children:[...Array(10).keys()].map(e=>(0,b.Y)(o.ParagraphSkeleton,{label:"Loading...",seed:`s-${e}`},e))}):ve?(0,b.Y)("div",{css:F,children:(0,b.Y)(o.Empty,{image:(0,b.Y)(i.k,{}),title:y.formatMessage({id:"Bcr4hl",defaultMessage:"Fetching traces failed"}),description:ve.message})}):(0,b.Y)(Y,{makeHtmlFromMarkdown:M,experimentId:e,children:(0,b.Y)(l._p,{experimentId:e,allColumns:$,currentTraceInfoV3:me||[],currentRunDisplayName:t,getTrace:H,assessmentInfos:K,setFilters:ne,filters:te,selectedColumns:se,tableSort:de,onTraceTagsEdit:he,displayLoadingOverlay:!1})})})})]})})})})},79444:function(e,t,n){n.d(t,{U:function(){return d},k:function(){return r}});var a=n(76118),o=n(46709),i=n(73408);const s=()=>({dateNow:new Date,lastRefreshTime:Date.now(),refresh:()=>{}}),l=(0,o.createContext)(s()),r=({config:e,children:t})=>{const n=s(),r=(0,a.merge)({},n,e),[d,c]=o.useState(r.lastRefreshTime),u=(0,o.useMemo)(()=>new Date(d),[d]),m=(0,o.useCallback)(()=>{c(Date.now())},[]);return(0,i.Y)(l.Provider,{value:{...r,dateNow:u,lastRefreshTime:d,refresh:m},children:t})},d=()=>{const e=(0,o.useContext)(l);return e||s()}},91944:function(e,t,n){n.d(t,{$g:function(){return m},BH:function(){return s},UI:function(){return c},bf:function(){return u},kk:function(){return i},q5:function(){return d},qp:function(){return r},uk:function(){return l}});var a=n(44105),o=n(77680);const i="mlflow.experimentKind",s=e=>{var t;return null===e||void 0===e||null===(t=e.find(e=>e.key===i))||void 0===t?void 0:t.value},l=e=>e===a.Gk.GENAI_DEVELOPMENT_INFERRED||e===a.Gk.CUSTOM_MODEL_DEVELOPMENT_INFERRED||e===a.Gk.NO_INFERRED_TYPE||e===a.Gk.GENAI_DEVELOPMENT||e===a.Gk.CUSTOM_MODEL_DEVELOPMENT||e===a.Gk.EMPTY,r=e=>e===a.Gk.GENAI_DEVELOPMENT||e===a.Gk.GENAI_DEVELOPMENT_INFERRED,d=e=>e===a.Gk.GENAI_DEVELOPMENT_INFERRED?a.Gk.GENAI_DEVELOPMENT:e===a.Gk.CUSTOM_MODEL_DEVELOPMENT_INFERRED?a.Gk.CUSTOM_MODEL_DEVELOPMENT:e,c={[a.Gk.GENAI_DEVELOPMENT]:(0,o.zR)({id:"PewjIJ",defaultMessage:"GenAI apps & agents"}),[a.Gk.CUSTOM_MODEL_DEVELOPMENT]:(0,o.zR)({id:"nF10K1",defaultMessage:"Machine learning"}),[a.Gk.GENAI_DEVELOPMENT_INFERRED]:(0,o.zR)({id:"ACNZd9",defaultMessage:"GenAI apps & agents"}),[a.Gk.CUSTOM_MODEL_DEVELOPMENT_INFERRED]:(0,o.zR)({id:"NUjE6C",defaultMessage:"Machine learning"}),[a.Gk.NO_INFERRED_TYPE]:(0,o.zR)({id:"qr7dhT",defaultMessage:"None"}),[a.Gk.FINETUNING]:(0,o.zR)({id:"G4x6G7",defaultMessage:"Finetuning"}),[a.Gk.REGRESSION]:(0,o.zR)({id:"OWfx/j",defaultMessage:"Regression"}),[a.Gk.CLASSIFICATION]:(0,o.zR)({id:"P/Uvf4",defaultMessage:"Classification"}),[a.Gk.FORECASTING]:(0,o.zR)({id:"qDiJI2",defaultMessage:"Forecasting"}),[a.Gk.AUTOML]:(0,o.zR)({id:"wZtuCR",defaultMessage:"AutoML"}),[a.Gk.EMPTY]:(0,o.zR)({id:"0z0lH2",defaultMessage:"None"})},u={[a.Gk.GENAI_DEVELOPMENT]:(0,o.zR)({id:"Fg/zU/",defaultMessage:"GenAI apps & agents"}),[a.Gk.CUSTOM_MODEL_DEVELOPMENT]:(0,o.zR)({id:"T/46y0",defaultMessage:"Machine learning"}),[a.Gk.GENAI_DEVELOPMENT_INFERRED]:(0,o.zR)({id:"CPO2ro",defaultMessage:"GenAI apps & agents"}),[a.Gk.CUSTOM_MODEL_DEVELOPMENT_INFERRED]:(0,o.zR)({id:"KYJxmN",defaultMessage:"Machine learning"}),[a.Gk.NO_INFERRED_TYPE]:(0,o.zR)({id:"jTqRO+",defaultMessage:"None"}),[a.Gk.FINETUNING]:(0,o.zR)({id:"61P6Da",defaultMessage:"finetuning"}),[a.Gk.REGRESSION]:(0,o.zR)({id:"W60/kq",defaultMessage:"regression"}),[a.Gk.CLASSIFICATION]:(0,o.zR)({id:"KwAeyt",defaultMessage:"classification"}),[a.Gk.FORECASTING]:(0,o.zR)({id:"VwxvII",defaultMessage:"forecasting"}),[a.Gk.AUTOML]:(0,o.zR)({id:"lFnpMi",defaultMessage:"AutoML"}),[a.Gk.EMPTY]:(0,o.zR)({id:"+khKtf",defaultMessage:"None"})},m=()=>[a.Gk.GENAI_DEVELOPMENT,a.Gk.CUSTOM_MODEL_DEVELOPMENT]},92338:function(e,t,n){function a(e){return[{key:"LAST_HOUR",label:e.formatMessage({id:"bjoGjg",defaultMessage:"Last hour"})},{key:"LAST_24_HOURS",label:e.formatMessage({id:"JChRnq",defaultMessage:"Last 24 hours"})},{key:"LAST_7_DAYS",label:e.formatMessage({id:"eQsXm7",defaultMessage:"Last 7 days"})},{key:"LAST_30_DAYS",label:e.formatMessage({id:"p1H1KR",defaultMessage:"Last 30 days"})},{key:"LAST_YEAR",label:e.formatMessage({id:"EI7moF",defaultMessage:"Last year"})},{key:"ALL",label:e.formatMessage({id:"HeNa8H",defaultMessage:"All"})},{key:"CUSTOM",label:e.formatMessage({id:"TpmJlu",defaultMessage:"Custom"})}]}n.d(t,{p:function(){return a}})}}]);