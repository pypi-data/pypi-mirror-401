# coding: utf-8

"""
    Arthur GenAI Engine

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.1.294
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from _generated.models.llm_prompt_request_config_settings import LLMPromptRequestConfigSettings

class TestLLMPromptRequestConfigSettings(unittest.TestCase):
    """LLMPromptRequestConfigSettings unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> LLMPromptRequestConfigSettings:
        """Test LLMPromptRequestConfigSettings
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `LLMPromptRequestConfigSettings`
        """
        model = LLMPromptRequestConfigSettings()
        if include_optional:
            return LLMPromptRequestConfigSettings(
                timeout = 1.337,
                temperature = 1.337,
                top_p = 1.337,
                max_tokens = 56,
                stop = '',
                presence_penalty = 1.337,
                frequency_penalty = 1.337,
                seed = 56,
                logprobs = True,
                top_logprobs = 56,
                logit_bias = [
                    _generated.models.logit_bias_item.LogitBiasItem(
                        token_id = 56, 
                        bias = -100.0, )
                    ],
                max_completion_tokens = 56,
                reasoning_effort = 'none',
                thinking = _generated.models.anthropic_thinking_param.AnthropicThinkingParam(
                    type = 'enabled', 
                    budget_tokens = 56, ),
                response_format = _generated.models.llm_response_format.LLMResponseFormat(
                    type = json_schema, 
                    json_schema = _generated.models.llm_response_schema.LLMResponseSchema(
                        name = '', 
                        description = '', 
                        schema = _generated.models.json_schema.JsonSchema(
                            type = 'object', 
                            properties = {
                                'key' : _generated.models.json_property_schema.JsonPropertySchema(
                                    type = 'string', 
                                    description = '', 
                                    enum = [
                                        ''
                                        ], 
                                    items = null, )
                                }, 
                            required = [
                                ''
                                ], 
                            additional_properties = True, ), 
                        strict = True, ), ),
                tool_choice = None,
                stream_options = _generated.models.stream_options.StreamOptions(
                    include_usage = True, )
            )
        else:
            return LLMPromptRequestConfigSettings(
        )
        """

    def testLLMPromptRequestConfigSettings(self):
        """Test LLMPromptRequestConfigSettings"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
