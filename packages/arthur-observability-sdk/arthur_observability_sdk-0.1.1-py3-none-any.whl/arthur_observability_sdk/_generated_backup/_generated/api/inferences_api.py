# coding: utf-8

"""
    Arthur GenAI Engine

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.1.294
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501

import warnings
from pydantic import validate_call, Field, StrictFloat, StrictStr, StrictInt
from typing import Any, Dict, List, Optional, Tuple, Union
from typing_extensions import Annotated

from datetime import datetime
from pydantic import Field, StrictBool, StrictInt, StrictStr
from typing import List, Optional
from typing_extensions import Annotated
from _generated.models.pagination_sort_method import PaginationSortMethod
from _generated.models.query_inferences_response import QueryInferencesResponse
from _generated.models.rule_result_enum import RuleResultEnum
from _generated.models.rule_type import RuleType

from _generated.api_client import ApiClient, RequestSerialized
from _generated.api_response import ApiResponse
from _generated.rest import RESTResponseType


class InferencesApi:
    """NOTE: This class is auto generated by OpenAPI Generator
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    def __init__(self, api_client=None) -> None:
        if api_client is None:
            api_client = ApiClient.get_default()
        self.api_client = api_client


    @validate_call
    def query_inferences_api_v2_inferences_query_get(
        self,
        task_ids: Annotated[Optional[List[Optional[StrictStr]]], Field(description="Task ID to filter on.")] = None,
        task_name: Annotated[Optional[StrictStr], Field(description="Task name to filter on.")] = None,
        conversation_id: Annotated[Optional[StrictStr], Field(description="Conversation ID to filter on.")] = None,
        inference_id: Annotated[Optional[StrictStr], Field(description="Inference ID to filter on.")] = None,
        user_id: Annotated[Optional[StrictStr], Field(description="User ID to filter on.")] = None,
        start_time: Annotated[Optional[datetime], Field(description="Inclusive start date in ISO8601 string format.")] = None,
        end_time: Annotated[Optional[datetime], Field(description="Exclusive end date in ISO8601 string format.")] = None,
        rule_types: Annotated[Optional[List[RuleType]], Field(description="List of RuleType to query for. Any inference that ran any rule in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_statuses, will return inferences with rules in the intersection of rule_types and rule_statuses.")] = None,
        rule_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for. Any inference with any rule status in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_types, will return inferences with rules in the intersection of rule_statuses and rule_types.")] = None,
        prompt_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for at inference prompt stage level. Must be 'Pass' / 'Fail'. Defaults to both.")] = None,
        response_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for at inference response stage level. Must be 'Pass' / 'Fail'. Defaults to both. Inferences missing responses will not be affected by this filter.")] = None,
        include_count: Annotated[Optional[StrictBool], Field(description="Whether to include the total count of matching inferences. Set to False to improve query performance for large datasets. Count will be returned as -1 if set to False.")] = None,
        sort: Annotated[Optional[PaginationSortMethod], Field(description="Sort the results (asc/desc)")] = None,
        page_size: Annotated[Optional[StrictInt], Field(description="Page size. Default is 10. Must be greater than 0 and less than 5000.")] = None,
        page: Annotated[Optional[StrictInt], Field(description="Page number")] = None,
        _request_timeout: Union[
            None,
            Annotated[StrictFloat, Field(gt=0)],
            Tuple[
                Annotated[StrictFloat, Field(gt=0)],
                Annotated[StrictFloat, Field(gt=0)]
            ]
        ] = None,
        _request_auth: Optional[Dict[StrictStr, Any]] = None,
        _content_type: Optional[StrictStr] = None,
        _headers: Optional[Dict[StrictStr, Any]] = None,
        _host_index: Annotated[StrictInt, Field(ge=0, le=0)] = 0,
    ) -> QueryInferencesResponse:
        """Query Inferences

        Paginated inference querying. See parameters for available filters. Includes inferences from archived tasks and rules.

        :param task_ids: Task ID to filter on.
        :type task_ids: List[Optional[str]]
        :param task_name: Task name to filter on.
        :type task_name: str
        :param conversation_id: Conversation ID to filter on.
        :type conversation_id: str
        :param inference_id: Inference ID to filter on.
        :type inference_id: str
        :param user_id: User ID to filter on.
        :type user_id: str
        :param start_time: Inclusive start date in ISO8601 string format.
        :type start_time: datetime
        :param end_time: Exclusive end date in ISO8601 string format.
        :type end_time: datetime
        :param rule_types: List of RuleType to query for. Any inference that ran any rule in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_statuses, will return inferences with rules in the intersection of rule_types and rule_statuses.
        :type rule_types: List[RuleType]
        :param rule_statuses: List of RuleResultEnum to query for. Any inference with any rule status in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_types, will return inferences with rules in the intersection of rule_statuses and rule_types.
        :type rule_statuses: List[RuleResultEnum]
        :param prompt_statuses: List of RuleResultEnum to query for at inference prompt stage level. Must be 'Pass' / 'Fail'. Defaults to both.
        :type prompt_statuses: List[RuleResultEnum]
        :param response_statuses: List of RuleResultEnum to query for at inference response stage level. Must be 'Pass' / 'Fail'. Defaults to both. Inferences missing responses will not be affected by this filter.
        :type response_statuses: List[RuleResultEnum]
        :param include_count: Whether to include the total count of matching inferences. Set to False to improve query performance for large datasets. Count will be returned as -1 if set to False.
        :type include_count: bool
        :param sort: Sort the results (asc/desc)
        :type sort: PaginationSortMethod
        :param page_size: Page size. Default is 10. Must be greater than 0 and less than 5000.
        :type page_size: int
        :param page: Page number
        :type page: int
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :type _request_timeout: int, tuple(int, int), optional
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the
                              authentication in the spec for a single request.
        :type _request_auth: dict, optional
        :param _content_type: force content-type for the request.
        :type _content_type: str, Optional
        :param _headers: set to override the headers for a single
                         request; this effectively ignores the headers
                         in the spec for a single request.
        :type _headers: dict, optional
        :param _host_index: set to override the host_index for a single
                            request; this effectively ignores the host_index
                            in the spec for a single request.
        :type _host_index: int, optional
        :return: Returns the result object.
        """ # noqa: E501

        _param = self._query_inferences_api_v2_inferences_query_get_serialize(
            task_ids=task_ids,
            task_name=task_name,
            conversation_id=conversation_id,
            inference_id=inference_id,
            user_id=user_id,
            start_time=start_time,
            end_time=end_time,
            rule_types=rule_types,
            rule_statuses=rule_statuses,
            prompt_statuses=prompt_statuses,
            response_statuses=response_statuses,
            include_count=include_count,
            sort=sort,
            page_size=page_size,
            page=page,
            _request_auth=_request_auth,
            _content_type=_content_type,
            _headers=_headers,
            _host_index=_host_index
        )

        _response_types_map: Dict[str, Optional[str]] = {
            '200': "QueryInferencesResponse",
            '422': "HTTPValidationError",
        }
        response_data = self.api_client.call_api(
            *_param,
            _request_timeout=_request_timeout
        )
        response_data.read()
        return self.api_client.response_deserialize(
            response_data=response_data,
            response_types_map=_response_types_map,
        ).data


    @validate_call
    def query_inferences_api_v2_inferences_query_get_with_http_info(
        self,
        task_ids: Annotated[Optional[List[Optional[StrictStr]]], Field(description="Task ID to filter on.")] = None,
        task_name: Annotated[Optional[StrictStr], Field(description="Task name to filter on.")] = None,
        conversation_id: Annotated[Optional[StrictStr], Field(description="Conversation ID to filter on.")] = None,
        inference_id: Annotated[Optional[StrictStr], Field(description="Inference ID to filter on.")] = None,
        user_id: Annotated[Optional[StrictStr], Field(description="User ID to filter on.")] = None,
        start_time: Annotated[Optional[datetime], Field(description="Inclusive start date in ISO8601 string format.")] = None,
        end_time: Annotated[Optional[datetime], Field(description="Exclusive end date in ISO8601 string format.")] = None,
        rule_types: Annotated[Optional[List[RuleType]], Field(description="List of RuleType to query for. Any inference that ran any rule in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_statuses, will return inferences with rules in the intersection of rule_types and rule_statuses.")] = None,
        rule_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for. Any inference with any rule status in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_types, will return inferences with rules in the intersection of rule_statuses and rule_types.")] = None,
        prompt_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for at inference prompt stage level. Must be 'Pass' / 'Fail'. Defaults to both.")] = None,
        response_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for at inference response stage level. Must be 'Pass' / 'Fail'. Defaults to both. Inferences missing responses will not be affected by this filter.")] = None,
        include_count: Annotated[Optional[StrictBool], Field(description="Whether to include the total count of matching inferences. Set to False to improve query performance for large datasets. Count will be returned as -1 if set to False.")] = None,
        sort: Annotated[Optional[PaginationSortMethod], Field(description="Sort the results (asc/desc)")] = None,
        page_size: Annotated[Optional[StrictInt], Field(description="Page size. Default is 10. Must be greater than 0 and less than 5000.")] = None,
        page: Annotated[Optional[StrictInt], Field(description="Page number")] = None,
        _request_timeout: Union[
            None,
            Annotated[StrictFloat, Field(gt=0)],
            Tuple[
                Annotated[StrictFloat, Field(gt=0)],
                Annotated[StrictFloat, Field(gt=0)]
            ]
        ] = None,
        _request_auth: Optional[Dict[StrictStr, Any]] = None,
        _content_type: Optional[StrictStr] = None,
        _headers: Optional[Dict[StrictStr, Any]] = None,
        _host_index: Annotated[StrictInt, Field(ge=0, le=0)] = 0,
    ) -> ApiResponse[QueryInferencesResponse]:
        """Query Inferences

        Paginated inference querying. See parameters for available filters. Includes inferences from archived tasks and rules.

        :param task_ids: Task ID to filter on.
        :type task_ids: List[Optional[str]]
        :param task_name: Task name to filter on.
        :type task_name: str
        :param conversation_id: Conversation ID to filter on.
        :type conversation_id: str
        :param inference_id: Inference ID to filter on.
        :type inference_id: str
        :param user_id: User ID to filter on.
        :type user_id: str
        :param start_time: Inclusive start date in ISO8601 string format.
        :type start_time: datetime
        :param end_time: Exclusive end date in ISO8601 string format.
        :type end_time: datetime
        :param rule_types: List of RuleType to query for. Any inference that ran any rule in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_statuses, will return inferences with rules in the intersection of rule_types and rule_statuses.
        :type rule_types: List[RuleType]
        :param rule_statuses: List of RuleResultEnum to query for. Any inference with any rule status in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_types, will return inferences with rules in the intersection of rule_statuses and rule_types.
        :type rule_statuses: List[RuleResultEnum]
        :param prompt_statuses: List of RuleResultEnum to query for at inference prompt stage level. Must be 'Pass' / 'Fail'. Defaults to both.
        :type prompt_statuses: List[RuleResultEnum]
        :param response_statuses: List of RuleResultEnum to query for at inference response stage level. Must be 'Pass' / 'Fail'. Defaults to both. Inferences missing responses will not be affected by this filter.
        :type response_statuses: List[RuleResultEnum]
        :param include_count: Whether to include the total count of matching inferences. Set to False to improve query performance for large datasets. Count will be returned as -1 if set to False.
        :type include_count: bool
        :param sort: Sort the results (asc/desc)
        :type sort: PaginationSortMethod
        :param page_size: Page size. Default is 10. Must be greater than 0 and less than 5000.
        :type page_size: int
        :param page: Page number
        :type page: int
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :type _request_timeout: int, tuple(int, int), optional
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the
                              authentication in the spec for a single request.
        :type _request_auth: dict, optional
        :param _content_type: force content-type for the request.
        :type _content_type: str, Optional
        :param _headers: set to override the headers for a single
                         request; this effectively ignores the headers
                         in the spec for a single request.
        :type _headers: dict, optional
        :param _host_index: set to override the host_index for a single
                            request; this effectively ignores the host_index
                            in the spec for a single request.
        :type _host_index: int, optional
        :return: Returns the result object.
        """ # noqa: E501

        _param = self._query_inferences_api_v2_inferences_query_get_serialize(
            task_ids=task_ids,
            task_name=task_name,
            conversation_id=conversation_id,
            inference_id=inference_id,
            user_id=user_id,
            start_time=start_time,
            end_time=end_time,
            rule_types=rule_types,
            rule_statuses=rule_statuses,
            prompt_statuses=prompt_statuses,
            response_statuses=response_statuses,
            include_count=include_count,
            sort=sort,
            page_size=page_size,
            page=page,
            _request_auth=_request_auth,
            _content_type=_content_type,
            _headers=_headers,
            _host_index=_host_index
        )

        _response_types_map: Dict[str, Optional[str]] = {
            '200': "QueryInferencesResponse",
            '422': "HTTPValidationError",
        }
        response_data = self.api_client.call_api(
            *_param,
            _request_timeout=_request_timeout
        )
        response_data.read()
        return self.api_client.response_deserialize(
            response_data=response_data,
            response_types_map=_response_types_map,
        )


    @validate_call
    def query_inferences_api_v2_inferences_query_get_without_preload_content(
        self,
        task_ids: Annotated[Optional[List[Optional[StrictStr]]], Field(description="Task ID to filter on.")] = None,
        task_name: Annotated[Optional[StrictStr], Field(description="Task name to filter on.")] = None,
        conversation_id: Annotated[Optional[StrictStr], Field(description="Conversation ID to filter on.")] = None,
        inference_id: Annotated[Optional[StrictStr], Field(description="Inference ID to filter on.")] = None,
        user_id: Annotated[Optional[StrictStr], Field(description="User ID to filter on.")] = None,
        start_time: Annotated[Optional[datetime], Field(description="Inclusive start date in ISO8601 string format.")] = None,
        end_time: Annotated[Optional[datetime], Field(description="Exclusive end date in ISO8601 string format.")] = None,
        rule_types: Annotated[Optional[List[RuleType]], Field(description="List of RuleType to query for. Any inference that ran any rule in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_statuses, will return inferences with rules in the intersection of rule_types and rule_statuses.")] = None,
        rule_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for. Any inference with any rule status in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_types, will return inferences with rules in the intersection of rule_statuses and rule_types.")] = None,
        prompt_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for at inference prompt stage level. Must be 'Pass' / 'Fail'. Defaults to both.")] = None,
        response_statuses: Annotated[Optional[List[RuleResultEnum]], Field(description="List of RuleResultEnum to query for at inference response stage level. Must be 'Pass' / 'Fail'. Defaults to both. Inferences missing responses will not be affected by this filter.")] = None,
        include_count: Annotated[Optional[StrictBool], Field(description="Whether to include the total count of matching inferences. Set to False to improve query performance for large datasets. Count will be returned as -1 if set to False.")] = None,
        sort: Annotated[Optional[PaginationSortMethod], Field(description="Sort the results (asc/desc)")] = None,
        page_size: Annotated[Optional[StrictInt], Field(description="Page size. Default is 10. Must be greater than 0 and less than 5000.")] = None,
        page: Annotated[Optional[StrictInt], Field(description="Page number")] = None,
        _request_timeout: Union[
            None,
            Annotated[StrictFloat, Field(gt=0)],
            Tuple[
                Annotated[StrictFloat, Field(gt=0)],
                Annotated[StrictFloat, Field(gt=0)]
            ]
        ] = None,
        _request_auth: Optional[Dict[StrictStr, Any]] = None,
        _content_type: Optional[StrictStr] = None,
        _headers: Optional[Dict[StrictStr, Any]] = None,
        _host_index: Annotated[StrictInt, Field(ge=0, le=0)] = 0,
    ) -> RESTResponseType:
        """Query Inferences

        Paginated inference querying. See parameters for available filters. Includes inferences from archived tasks and rules.

        :param task_ids: Task ID to filter on.
        :type task_ids: List[Optional[str]]
        :param task_name: Task name to filter on.
        :type task_name: str
        :param conversation_id: Conversation ID to filter on.
        :type conversation_id: str
        :param inference_id: Inference ID to filter on.
        :type inference_id: str
        :param user_id: User ID to filter on.
        :type user_id: str
        :param start_time: Inclusive start date in ISO8601 string format.
        :type start_time: datetime
        :param end_time: Exclusive end date in ISO8601 string format.
        :type end_time: datetime
        :param rule_types: List of RuleType to query for. Any inference that ran any rule in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_statuses, will return inferences with rules in the intersection of rule_types and rule_statuses.
        :type rule_types: List[RuleType]
        :param rule_statuses: List of RuleResultEnum to query for. Any inference with any rule status in the list will be returned. Defaults to all statuses. If used in conjunction with with rule_types, will return inferences with rules in the intersection of rule_statuses and rule_types.
        :type rule_statuses: List[RuleResultEnum]
        :param prompt_statuses: List of RuleResultEnum to query for at inference prompt stage level. Must be 'Pass' / 'Fail'. Defaults to both.
        :type prompt_statuses: List[RuleResultEnum]
        :param response_statuses: List of RuleResultEnum to query for at inference response stage level. Must be 'Pass' / 'Fail'. Defaults to both. Inferences missing responses will not be affected by this filter.
        :type response_statuses: List[RuleResultEnum]
        :param include_count: Whether to include the total count of matching inferences. Set to False to improve query performance for large datasets. Count will be returned as -1 if set to False.
        :type include_count: bool
        :param sort: Sort the results (asc/desc)
        :type sort: PaginationSortMethod
        :param page_size: Page size. Default is 10. Must be greater than 0 and less than 5000.
        :type page_size: int
        :param page: Page number
        :type page: int
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :type _request_timeout: int, tuple(int, int), optional
        :param _request_auth: set to override the auth_settings for an a single
                              request; this effectively ignores the
                              authentication in the spec for a single request.
        :type _request_auth: dict, optional
        :param _content_type: force content-type for the request.
        :type _content_type: str, Optional
        :param _headers: set to override the headers for a single
                         request; this effectively ignores the headers
                         in the spec for a single request.
        :type _headers: dict, optional
        :param _host_index: set to override the host_index for a single
                            request; this effectively ignores the host_index
                            in the spec for a single request.
        :type _host_index: int, optional
        :return: Returns the result object.
        """ # noqa: E501

        _param = self._query_inferences_api_v2_inferences_query_get_serialize(
            task_ids=task_ids,
            task_name=task_name,
            conversation_id=conversation_id,
            inference_id=inference_id,
            user_id=user_id,
            start_time=start_time,
            end_time=end_time,
            rule_types=rule_types,
            rule_statuses=rule_statuses,
            prompt_statuses=prompt_statuses,
            response_statuses=response_statuses,
            include_count=include_count,
            sort=sort,
            page_size=page_size,
            page=page,
            _request_auth=_request_auth,
            _content_type=_content_type,
            _headers=_headers,
            _host_index=_host_index
        )

        _response_types_map: Dict[str, Optional[str]] = {
            '200': "QueryInferencesResponse",
            '422': "HTTPValidationError",
        }
        response_data = self.api_client.call_api(
            *_param,
            _request_timeout=_request_timeout
        )
        return response_data.response


    def _query_inferences_api_v2_inferences_query_get_serialize(
        self,
        task_ids,
        task_name,
        conversation_id,
        inference_id,
        user_id,
        start_time,
        end_time,
        rule_types,
        rule_statuses,
        prompt_statuses,
        response_statuses,
        include_count,
        sort,
        page_size,
        page,
        _request_auth,
        _content_type,
        _headers,
        _host_index,
    ) -> RequestSerialized:

        _host = None

        _collection_formats: Dict[str, str] = {
            'task_ids': 'multi',
            'rule_types': 'multi',
            'rule_statuses': 'multi',
            'prompt_statuses': 'multi',
            'response_statuses': 'multi',
        }

        _path_params: Dict[str, str] = {}
        _query_params: List[Tuple[str, str]] = []
        _header_params: Dict[str, Optional[str]] = _headers or {}
        _form_params: List[Tuple[str, str]] = []
        _files: Dict[
            str, Union[str, bytes, List[str], List[bytes], List[Tuple[str, bytes]]]
        ] = {}
        _body_params: Optional[bytes] = None

        # process the path parameters
        # process the query parameters
        if task_ids is not None:
            
            _query_params.append(('task_ids', task_ids))
            
        if task_name is not None:
            
            _query_params.append(('task_name', task_name))
            
        if conversation_id is not None:
            
            _query_params.append(('conversation_id', conversation_id))
            
        if inference_id is not None:
            
            _query_params.append(('inference_id', inference_id))
            
        if user_id is not None:
            
            _query_params.append(('user_id', user_id))
            
        if start_time is not None:
            if isinstance(start_time, datetime):
                _query_params.append(
                    (
                        'start_time',
                        start_time.strftime(
                            self.api_client.configuration.datetime_format
                        )
                    )
                )
            else:
                _query_params.append(('start_time', start_time))
            
        if end_time is not None:
            if isinstance(end_time, datetime):
                _query_params.append(
                    (
                        'end_time',
                        end_time.strftime(
                            self.api_client.configuration.datetime_format
                        )
                    )
                )
            else:
                _query_params.append(('end_time', end_time))
            
        if rule_types is not None:
            
            _query_params.append(('rule_types', rule_types))
            
        if rule_statuses is not None:
            
            _query_params.append(('rule_statuses', rule_statuses))
            
        if prompt_statuses is not None:
            
            _query_params.append(('prompt_statuses', prompt_statuses))
            
        if response_statuses is not None:
            
            _query_params.append(('response_statuses', response_statuses))
            
        if include_count is not None:
            
            _query_params.append(('include_count', include_count))
            
        if sort is not None:
            
            _query_params.append(('sort', sort.value))
            
        if page_size is not None:
            
            _query_params.append(('page_size', page_size))
            
        if page is not None:
            
            _query_params.append(('page', page))
            
        # process the header parameters
        # process the form parameters
        # process the body parameter


        # set the HTTP header `Accept`
        if 'Accept' not in _header_params:
            _header_params['Accept'] = self.api_client.select_header_accept(
                [
                    'application/json'
                ]
            )


        # authentication setting
        _auth_settings: List[str] = [
            'API Key'
        ]

        return self.api_client.param_serialize(
            method='GET',
            resource_path='/api/v2/inferences/query',
            path_params=_path_params,
            query_params=_query_params,
            header_params=_header_params,
            body=_body_params,
            post_params=_form_params,
            files=_files,
            auth_settings=_auth_settings,
            collection_formats=_collection_formats,
            _host=_host,
            _request_auth=_request_auth
        )


