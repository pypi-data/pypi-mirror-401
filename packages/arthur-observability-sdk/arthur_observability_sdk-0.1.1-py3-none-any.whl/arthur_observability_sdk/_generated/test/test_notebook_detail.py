# coding: utf-8

"""
    Arthur GenAI Engine

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.1.294
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from arthur_observability_sdk._generated.models.notebook_detail import NotebookDetail

class TestNotebookDetail(unittest.TestCase):
    """NotebookDetail unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> NotebookDetail:
        """Test NotebookDetail
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `NotebookDetail`
        """
        model = NotebookDetail()
        if include_optional:
            return NotebookDetail(
                id = '',
                task_id = '',
                name = '',
                description = '',
                created_at = '',
                updated_at = '',
                state = arthur_observability_sdk._generated.models.notebook_state.NotebookState(
                    prompt_configs = [
                        null
                        ], 
                    prompt_variable_mapping = [
                        arthur_observability_sdk._generated.models.prompt_variable_mapping.PromptVariableMapping(
                            variable_name = '', 
                            source = arthur_observability_sdk._generated.models.dataset_column_variable_source.DatasetColumnVariableSource(
                                type = 'dataset_column', 
                                dataset_column = arthur_observability_sdk._generated.models.dataset_column_source.DatasetColumnSource(
                                    name = '', ), ), )
                        ], 
                    dataset_ref = arthur_observability_sdk._generated.models.dataset_ref.DatasetRef(
                        id = '', 
                        name = '', 
                        version = 56, ), 
                    dataset_row_filter = [
                        arthur_observability_sdk._generated.models.new_dataset_version_row_column_item_request.NewDatasetVersionRowColumnItemRequest(
                            column_name = '', 
                            column_value = '', )
                        ], 
                    eval_list = [
                        arthur_observability_sdk._generated.models.eval_ref.EvalRef(
                            name = '', 
                            version = 56, 
                            variable_mapping = [
                                arthur_observability_sdk._generated.models.eval_variable_mapping.EvalVariableMapping(
                                    variable_name = '', 
                                    source = null, )
                                ], )
                        ], ),
                experiments = [
                    arthur_observability_sdk._generated.models.prompt_experiment_summary.PromptExperimentSummary(
                        id = '', 
                        name = '', 
                        description = '', 
                        created_at = '', 
                        finished_at = '', 
                        status = 'queued', 
                        dataset_id = '', 
                        dataset_name = '', 
                        dataset_version = 56, 
                        total_rows = 56, 
                        completed_rows = 56, 
                        failed_rows = 56, 
                        total_cost = '', 
                        prompt_configs = [
                            null
                            ], )
                    ]
            )
        else:
            return NotebookDetail(
                id = '',
                task_id = '',
                name = '',
                created_at = '',
                updated_at = '',
                state = arthur_observability_sdk._generated.models.notebook_state.NotebookState(
                    prompt_configs = [
                        null
                        ], 
                    prompt_variable_mapping = [
                        arthur_observability_sdk._generated.models.prompt_variable_mapping.PromptVariableMapping(
                            variable_name = '', 
                            source = arthur_observability_sdk._generated.models.dataset_column_variable_source.DatasetColumnVariableSource(
                                type = 'dataset_column', 
                                dataset_column = arthur_observability_sdk._generated.models.dataset_column_source.DatasetColumnSource(
                                    name = '', ), ), )
                        ], 
                    dataset_ref = arthur_observability_sdk._generated.models.dataset_ref.DatasetRef(
                        id = '', 
                        name = '', 
                        version = 56, ), 
                    dataset_row_filter = [
                        arthur_observability_sdk._generated.models.new_dataset_version_row_column_item_request.NewDatasetVersionRowColumnItemRequest(
                            column_name = '', 
                            column_value = '', )
                        ], 
                    eval_list = [
                        arthur_observability_sdk._generated.models.eval_ref.EvalRef(
                            name = '', 
                            version = 56, 
                            variable_mapping = [
                                arthur_observability_sdk._generated.models.eval_variable_mapping.EvalVariableMapping(
                                    variable_name = '', 
                                    source = null, )
                                ], )
                        ], ),
                experiments = [
                    arthur_observability_sdk._generated.models.prompt_experiment_summary.PromptExperimentSummary(
                        id = '', 
                        name = '', 
                        description = '', 
                        created_at = '', 
                        finished_at = '', 
                        status = 'queued', 
                        dataset_id = '', 
                        dataset_name = '', 
                        dataset_version = 56, 
                        total_rows = 56, 
                        completed_rows = 56, 
                        failed_rows = 56, 
                        total_cost = '', 
                        prompt_configs = [
                            null
                            ], )
                    ],
        )
        """

    def testNotebookDetail(self):
        """Test NotebookDetail"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
