---
title: "Quick Start"
description: "Get up and running with Merit in 2 minutes"
---

## Install Merit

Merit requires Python 3.12 or higher. Install directly from GitHub using `uv` (recommended) or `pip`:

<CodeGroup>

```bash uv (recommended)
# Install uv if you haven't already
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install Merit from GitHub
uv pip install git+https://github.com/appMerit/merit.git
```

```bash pip
pip install git+https://github.com/appMerit/merit.git
```

</CodeGroup>

## Write Your First Test

Create a file called `test_chatbot.py`:

```python test_chatbot.py
import merit

def chatbot(prompt: str) -> str:
    """Your AI system under test."""
    return f"Hello, {prompt}!"

def merit_chatbot_responds():
    """Test that chatbot responds correctly."""
    response = chatbot("World")
    assert response == "Hello, World!"
    assert len(response) > 0
```

## Run Your Tests

```bash
merit
```

You'll see output like:

```
Merit Test Runner
=================

Collected 1 test

test_chatbot.py::merit_chatbot_responds âœ“

==================== 1 passed in 0.12s ====================
```

## Add AI-Powered Assertions

Now let's add an LLM-as-a-Judge assertion. First, set up your Merit API credentials:

```bash .env
# Required for AI predicates
MERIT_API_BASE_URL=https://api.appmerit.com
MERIT_API_KEY=your_merit_api_key_here
```

<Note>
AI predicates call the Merit cloud service. You need a Merit API key - [contact us](mailto:daniel@appmerit.com) to get access.
</Note>

Update your test to use AI predicates:

```python test_chatbot.py
import merit
from merit.predicates import has_facts

def chatbot(prompt: str) -> str:
    return "Paris is the capital of France. It's known for the Eiffel Tower."

async def merit_chatbot_facts():
    """Test that chatbot provides accurate facts."""
    response = chatbot("Tell me about Paris")
    
    # AI-powered assertion checks if facts are present
    assert await has_facts(response, "Paris is the capital of France")
```

Run again:

```bash
merit
```

## Use Parametrization

Test multiple inputs easily:

```python test_chatbot.py
import merit

def chatbot(prompt: str) -> str:
    return f"Hello, {prompt}!"

@merit.parametrize(
    "name,expected",
    [
        ("World", "Hello, World!"),
        ("Alice", "Hello, Alice!"),
        ("Bob", "Hello, Bob!"),
    ],
)
def merit_chatbot_greetings(name: str, expected: str):
    """Test multiple greetings."""
    response = chatbot(name)
    assert response == expected
```

This runs 3 tests automatically, one for each parameter set.

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Core Concepts"
    icon="book"
    href="/core/writing-tests"
  >
    Learn about resources, test cases, and more
  </Card>
  <Card
    title="AI Predicates"
    icon="brain"
    href="/predicates/overview"
  >
    Explore all LLM-as-a-Judge assertions
  </Card>
  <Card
    title="Advanced Features"
    icon="rocket"
    href="/advanced/parametrize"
  >
    Tags, filters, repeat tests, and tracing
  </Card>
  <Card
    title="Error Analysis"
    icon="chart-line"
    href="/analyzer/overview"
  >
    Analyze failures with Merit Analyzer
  </Card>
</CardGroup>
