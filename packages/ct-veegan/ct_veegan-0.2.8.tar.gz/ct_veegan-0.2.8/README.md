
# ğŸ“˜ CT-VeeGAN

**Dokumentasi Lengkap & Panduan Penggunaan**

CT-VeeGAN adalah pustaka Python untuk **menangani ketidakseimbangan data (data imbalance) pada teks berurutan**, seperti kalimat atau dokumen, yang telah direpresentasikan dalam bentuk **word embeddings**.

Berbeda dari pendekatan oversampling biasa, CT-VeeGAN **tidak hanya menyeimbangkan jumlah data**, tetapi juga **menjaga struktur urutan kata** agar data sintetis tetap realistis secara semantik dan temporal.

---

## ğŸ” Masalah yang Diselesaikan

| Metode              | Kelemahan                          |
| ------------------- | ---------------------------------- |
| SMOTE standar       | Merusak struktur urutan (sequence) |
| GAN teks biasa      | Sulit stabil, sering mode collapse |
| Random oversampling | Duplikasi data â†’ overfitting       |

**CT-VeeGAN** menggabungkan keunggulan **SMOTEENN + GAN berbasis LSTM** untuk mengatasi semua kelemahan tersebut.

---

## ğŸ§  Konsep Utama

CT-VeeGAN menggunakan **pendekatan hibrida dua tahap**:

1. **SMOTEENN**
   Menyeimbangkan distribusi data secara statistik (global).

2. **LSTM-GAN (WGAN-GP)**
   Merekonstruksi ulang urutan kata agar:

   * koheren
   * memiliki korelasi temporal
   * tidak sekadar duplikat

---

## ğŸ“¦ Fitur Utama

CT-VeeGAN terdiri dari **tiga komponen inti**:

---

### A. Wrapper (`wrapper.py`) â€” *Penggunaan Instan*

> **Gunakan ini jika ingin hasil cepat tanpa training ulang**

Fungsi utama:

* `balance()`

Fitur:

* ğŸ”½ Auto-download model pretrained (Bahasa Indonesia)
* ğŸ”„ Alur otomatis:

  ```
  Sequence â†’ Flatten â†’ SMOTEENN â†’ Latent Reconstruction â†’ LSTM Generator
  ```

Cocok jika:

* Seq_Len = **105**
* Token_Dim = **400**
* Menggunakan embedding Word2Vec/FastText serupa

---

### B. Trainer (`trainer.py`) â€” *Pelatihan Kustom*

> **Gunakan ini jika dimensi data berbeda**

Fitur:

* Training dari nol
* Fine-tuning model lama
* Auto-save checkpoint terbaik

Wajib digunakan jika:

* Token dimension â‰  400 (misal BERT 768)
* Panjang sequence â‰  105
* Dataset sangat spesifik

---

### C. Utilities (`utils.py`) â€” *Pendukung*

Fungsi penting:

* Vector â†’ Text (cosine similarity)
* Gradient Penalty (WGAN-GP)
* Helper evaluasi

---

## âš™ï¸ Instalasi

```bash
pip install torch numpy scikit-learn imbalanced-learn gensim tqdm requests datasets
```

---

## âš ï¸ Persiapan Data (WAJIB)

CT-VeeGAN **tidak menerima teks mentah**.

### Format Input yang Benar

```text
(N, Seq_Len, Token_Dim)
```

| Parameter | Arti                              |
| --------- | --------------------------------- |
| N         | Jumlah kalimat                    |
| Seq_Len   | Panjang kalimat (setelah padding) |
| Token_Dim | Dimensi embedding                 |

### Contoh

```python
X.shape = (1000, 105, 400)
```

---

## ğŸ”„ Cara Kerja CT-VeeGAN

1ï¸âƒ£ **Vectorization**
Kalimat â†’ Word embeddings

2ï¸âƒ£ **Flattening**
Data 3D â†’ 2D agar kompatibel dengan SMOTE

3ï¸âƒ£ **SMOTEENN**
Menyeimbangkan kelas secara statistik

4ï¸âƒ£ **Reconstruction Network**
Mengubah data sintetis kasar â†’ latent vector

5ï¸âƒ£ **LSTM Generator**
Latent â†’ sequence kalimat yang koheren

---

## ğŸ§ª Tutorial 1 â€” Penggunaan Cepat (Wrapper)

Gunakan jika **dimensi data sama dengan model pretrained**.

```python
import numpy as np
from ct_veegan.wrapper import CTVeeGANWrapper

X_train = np.random.randn(100, 105, 400).astype(np.float32)
y_train = np.array([0]*90 + [1]*10)

ct_gan = CTVeeGANWrapper(
    seq_len=105,
    token_dim=400,
    device='cuda'
)

X_final, y_final, mask = ct_gan.balance(
    X_train=X_train,
    y_train=y_train,
    minor_class=1,
    noise_scale=0.05
)
```

ğŸ“Œ **Output**:

* `X_final`: data asli + sintetis
* `y_final`: label baru
* `mask`: penanda data sintetis

---

## ğŸ§ª Tutorial 2 â€” Training Kustom (Trainer)

Gunakan jika:

* BERT embedding
* Seq len berbeda
* Dataset domain khusus

```python
from ct_veegan.trainer import Trainer
from ct_veegan.models import LSTMGenerator, LSTMDiscriminator

trainer = Trainer(lr_g=1e-4)

trainer.G = LSTMGenerator(
    latent_dim=128,
    latent_step_dim=32,
    num_classes=2,
    embed_dim=32,
    seq_len=50,
    token_dim=768,
    hidden_dim=256
).to(trainer.device)

trainer.D = LSTMDiscriminator(
    num_classes=2,
    embed_dim=32,
    seq_len=50,
    token_dim=768,
    hidden_dim=256
).to(trainer.device)

trainer.train(dataloader, epochs=50)
```

---

## ğŸ“Š Validasi Kualitas Data Sintetis

âœ… **Disarankan**:

* PCA / t-SNE visualization
* Uji klasifikasi downstream
* Bandingkan recall kelas minoritas

âŒ **Hindari**:

* Menggunakan data sintetis untuk test set
* Noise terlalu besar

---

## âš ï¸ Error Umum & Solusi

| Error           | Penyebab                        |
| --------------- | ------------------------------- |
| `size mismatch` | seq_len / token_dim tidak cocok |
| GAN collapse    | noise terlalu kecil             |
| Data rusak      | noise terlalu besar             |

---

## ğŸ“‚ Struktur Proyek

```
project_root/
â”œâ”€â”€ ct_veegan/
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â”œâ”€â”€ wrapper.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ script_saya.py
â””â”€â”€ requirements.txt
```

---

## ğŸ™ Kredit

Dikembangkan untuk penelitian penanganan **data teks Bahasa Indonesia yang tidak seimbang**.

Pretrained model:
**github.com/Benylaode/ct_veegans**


