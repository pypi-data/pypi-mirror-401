"""
Embedding Service Demo - å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€çš„ EmbeddingService

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†:
1. å¦‚ä½•é…ç½® EmbeddingService (æœ¬åœ°æ¨¡å‹, API, vLLM)
2. å¦‚ä½•åœ¨ Pipeline ä¸­ä½¿ç”¨ embedding service
3. å¦‚ä½•å®ç°é«˜æ€§èƒ½æ‰¹å¤„ç†
4. å¦‚ä½•ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–æ€§èƒ½

Requirements:
    pip install isage-middleware>=0.2.0
"""

import os


def demo_basic_embedding_service():
    """ç¤ºä¾‹ 1: åŸºæœ¬çš„ Embedding Service ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1: åŸºæœ¬ Embedding Service")
    print("=" * 60)

    from sage.common.components.sage_embedding import EmbeddingService

    # æ£€æŸ¥æ˜¯å¦åœ¨æµ‹è¯•æ¨¡å¼
    is_test_mode = os.getenv("SAGE_TEST_MODE") == "true" or os.getenv("CI") == "true"

    # é…ç½®: åœ¨æµ‹è¯•æ¨¡å¼ä½¿ç”¨ mockï¼Œå¦åˆ™ä½¿ç”¨ HuggingFace æ¨¡å‹
    if is_test_mode:
        config = {
            "method": "mockembedder",
            "dimension": 384,  # æ¨¡æ‹Ÿ bge-small-zh-v1.5 çš„ç»´åº¦
            "batch_size": 32,
            "normalize": True,
            "cache_enabled": True,
            "cache_size": 1000,
        }
    else:
        config = {
            "method": "hf",
            "model": "BAAI/bge-small-zh-v1.5",
            "batch_size": 32,
            "normalize": True,
            "cache_enabled": True,
            "cache_size": 1000,
        }

    service = EmbeddingService(config)
    service.setup()

    # è·å–æœåŠ¡ä¿¡æ¯
    info = service.process({"task": "info"})
    print("\næœåŠ¡ä¿¡æ¯:")
    print(f"  æ–¹æ³•: {info['method']}")
    print(f"  æ¨¡å‹: {info['model']}")
    print(f"  ç»´åº¦: {info['dimension']}")
    print(f"  ç¼“å­˜: {info['cache_enabled']}")

    # å•ä¸ªæ–‡æœ¬ embedding
    result = service.process(
        {"task": "embed", "inputs": "ä½ å¥½ä¸–ç•Œ", "options": {"return_stats": True}}
    )

    print("\nå•ä¸ªæ–‡æœ¬ embedding:")
    print(f"  ç»´åº¦: {result['dimension']}")
    print(f"  å‘é‡å‰5ä¸ªå€¼: {result['vectors'][0][:5]}")
    print(f"  ç»Ÿè®¡: {result['stats']}")

    # æ‰¹é‡æ–‡æœ¬ embedding
    texts = [
        "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒ",
        "æ·±åº¦å­¦ä¹ æ¨åŠ¨äº†AIå‘å±•",
        "è‡ªç„¶è¯­è¨€å¤„ç†å¾ˆé‡è¦",
    ]

    result = service.process({"task": "embed", "inputs": texts, "options": {"return_stats": True}})

    print("\næ‰¹é‡æ–‡æœ¬ embedding:")
    print(f"  æ–‡æœ¬æ•°é‡: {result['count']}")
    print(f"  è®¡ç®—æ•°é‡: {result['stats']['computed']}")
    print(f"  ç¼“å­˜æ•°é‡: {result['stats']['cached']}")

    # å†æ¬¡æŸ¥è¯¢ç›¸åŒæ–‡æœ¬ (æµ‹è¯•ç¼“å­˜)
    result2 = service.process(
        {
            "task": "embed",
            "inputs": texts[:2],  # é‡å¤å‰ä¸¤ä¸ªæ–‡æœ¬
            "options": {"return_stats": True},
        }
    )

    print("\nç¼“å­˜æµ‹è¯•:")
    print(f"  ç¼“å­˜å‘½ä¸­: {result2['stats']['cached']}/{result2['count']}")
    print(f"  å‘½ä¸­ç‡: {result2['stats']['cache_hit_rate']:.2%}")

    service.cleanup()


def demo_vllm_embedding_service():
    """Demo 2: ä½¿ç”¨ vLLM ä½œä¸º Embedding åç«¯ (éœ€è¦ GPU)"""
    print("\n" + "=" * 60)
    print("Demo 2: vLLM Embedding Service (é«˜æ€§èƒ½)")
    print("=" * 60)

    # æ³¨æ„: è¿™ä¸ªç¤ºä¾‹éœ€è¦å®é™…çš„ vLLM service è¿è¡Œ
    print("\né…ç½®ç¤ºä¾‹:")
    config_example = """
services:
  vllm:
    class: sage.llm.VLLMService
    config:
      model_id: "BAAI/bge-base-en-v1.5"
      embedding_model_id: "BAAI/bge-base-en-v1.5"
      auto_download: true
      engine:
        tensor_parallel_size: 1
        gpu_memory_utilization: 0.9

  embedding:
    class: sage.common.components.sage_embedding.EmbeddingService
    config:
      method: "vllm"
      vllm_service_name: "vllm"
      batch_size: 256  # vLLM å¯ä»¥å¤„ç†å¤§æ‰¹é‡
      normalize: true
      cache_enabled: true

# åœ¨ pipeline/operator ä¸­ä½¿ç”¨:
result = self.call_service("embedding", payload={
    "task": "embed",
    "inputs": large_document_list,  # å¯ä»¥æ˜¯æˆåƒä¸Šä¸‡ä¸ªæ–‡æ¡£
    "options": {
        "batch_size": 256,
        "return_stats": True
    }
})
    """
    print(config_example)


def demo_multi_embedding_pipeline():
    """Demo 3: å¤š Embedding Service çš„ Pipeline"""
    print("\n" + "=" * 60)
    print("Demo 3: å¤š Embedding ç­–ç•¥ Pipeline")
    print("=" * 60)

    pipeline_config = """
# ä½¿ç”¨åœºæ™¯: RAG ç³»ç»Ÿ
# - æŸ¥è¯¢ä½¿ç”¨å¿«é€Ÿæœ¬åœ°æ¨¡å‹ (ä½å»¶è¿Ÿ)
# - æ–‡æ¡£ç´¢å¼•ä½¿ç”¨é«˜è´¨é‡äº‘ç«¯æ¨¡å‹ (é«˜ç²¾åº¦)
# - æ‰¹é‡å¤„ç†ä½¿ç”¨ vLLM (é«˜åå)

services:
  # 1. å¿«é€Ÿæœ¬åœ° embedding (ç”¨äºå®æ—¶æŸ¥è¯¢)
  embedding_fast:
    class: sage.common.components.sage_embedding.EmbeddingService
    config:
      method: "hf"
      model: "BAAI/bge-small-zh-v1.5"  # å°æ¨¡å‹, å¿«é€Ÿ
      batch_size: 32
      cache_enabled: true

  # 2. é«˜è´¨é‡äº‘ç«¯ embedding (ç”¨äºç¦»çº¿ç´¢å¼•)
  embedding_quality:
    class: sage.common.components.sage_embedding.EmbeddingService
    config:
      method: "openai"
      model: "text-embedding-3-large"
      api_key: "${OPENAI_API_KEY}"
      batch_size: 100

  # 3. vLLM é«˜åå embedding (ç”¨äºå¤§è§„æ¨¡æ‰¹å¤„ç†)
  vllm:
    class: sage.llm.VLLMService
    config:
      model_id: "BAAI/bge-large-en-v1.5"

  embedding_batch:
    class: sage.common.components.sage_embedding.EmbeddingService
    config:
      method: "vllm"
      vllm_service_name: "vllm"
      batch_size: 512

operators:
  # æŸ¥è¯¢ embedding - ä½¿ç”¨å¿«é€Ÿæœ¬åœ°æ¨¡å‹
  - name: query_embed
    type: custom
    code: |
      result = self.call_service("embedding_fast", payload={
          "task": "embed",
          "inputs": payload["query"]
      })
      payload["query_vector"] = result["vectors"][0]
      return payload

  # æ–‡æ¡£ embedding - æ ¹æ®æƒ…å†µé€‰æ‹©
  - name: document_embed
    type: custom
    code: |
      docs = payload["documents"]

      # å°æ‰¹é‡: ä½¿ç”¨æœ¬åœ°æ¨¡å‹
      if len(docs) < 100:
          service = "embedding_fast"
      # å¤§æ‰¹é‡: ä½¿ç”¨ vLLM
      elif len(docs) > 1000:
          service = "embedding_batch"
      # é‡è¦æ–‡æ¡£: ä½¿ç”¨é«˜è´¨é‡äº‘ç«¯
      elif payload.get("high_quality"):
          service = "embedding_quality"
      else:
          service = "embedding_fast"

      result = self.call_service(service, payload={
          "task": "embed",
          "inputs": [d["text"] for d in docs]
      })

      for doc, vec in zip(docs, result["vectors"]):
          doc["embedding"] = vec

      return payload
    """

    print(pipeline_config)


def demo_embedding_operator():
    """Demo 4: åˆ›å»ºè‡ªå®šä¹‰çš„ Embedding Operator"""
    print("\n" + "=" * 60)
    print("Demo 4: è‡ªå®šä¹‰ Embedding Operator")
    print("=" * 60)

    operator_code = '''
from sage.libs.operators import BaseOperator
from typing import Any, Dict, List

class SmartEmbeddingOperator(BaseOperator):
    """æ™ºèƒ½ Embedding Operator - æ ¹æ®è´Ÿè½½è‡ªåŠ¨é€‰æ‹©ç­–ç•¥"""

    def __init__(
        self,
        embedding_service: str = "embedding",
        batch_size: int = 32,
        cache_threshold: int = 10,  # å°äºæ­¤æ•°é‡å¯ç”¨ç¼“å­˜
        vllm_threshold: int = 1000,  # å¤§äºæ­¤æ•°é‡ä½¿ç”¨ vLLM
    ):
        self.embedding_service = embedding_service
        self.batch_size = batch_size
        self.cache_threshold = cache_threshold
        self.vllm_threshold = vllm_threshold

    def process(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        texts = payload.get("texts", [])

        if not texts:
            payload["embeddings"] = []
            return payload

        # æ™ºèƒ½é€‰æ‹©ç­–ç•¥
        options = {
            "batch_size": self.batch_size,
            "return_stats": True,
        }

        # å°æ‰¹é‡: å¯ç”¨ç¼“å­˜
        if len(texts) <= self.cache_threshold:
            # å‡è®¾æœ‰ç¼“å­˜é…ç½®çš„ service
            service = self.embedding_service + "_cached"
        # å¤§æ‰¹é‡: ä½¿ç”¨ vLLM
        elif len(texts) >= self.vllm_threshold:
            service = self.embedding_service + "_vllm"
            options["batch_size"] = min(512, len(texts))
        else:
            service = self.embedding_service

        # è°ƒç”¨ embedding service
        result = self.call_service(service, payload={
            "task": "embed",
            "inputs": texts,
            "options": options
        })

        # é™„åŠ ç»“æœ
        payload["embeddings"] = result["vectors"]
        payload["embedding_dimension"] = result["dimension"]
        payload["embedding_stats"] = result.get("stats", {})

        self.logger.info(
            f"Embedded {len(texts)} texts using {service}, "
            f"cache_hit_rate={result['stats'].get('cache_hit_rate', 0):.2%}"
        )

        return payload


# ä½¿ç”¨ç¤ºä¾‹
class RAGPipeline:
    def build(self):
        return {
            "operators": [
                {
                    "name": "load_query",
                    "type": "QueryLoaderOperator"
                },
                {
                    "name": "embed_query",
                    "type": "SmartEmbeddingOperator",
                    "config": {
                        "embedding_service": "embedding",
                        "batch_size": 32,
                        "cache_threshold": 10,
                    }
                },
                {
                    "name": "retrieve",
                    "type": "VectorSearchOperator",
                    "config": {
                        "top_k": 5
                    }
                },
                {
                    "name": "generate",
                    "type": "LLMGenerateOperator"
                }
            ]
        }
'''
    print(operator_code)


def demo_performance_comparison():
    """Demo 5: æ€§èƒ½å¯¹æ¯” - ä¸åŒ embedding æ–¹æ³•"""
    print("\n" + "=" * 60)
    print("Demo 5: æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)

    comparison = """
æµ‹è¯•åœºæ™¯: 1000 ä¸ªæ–‡æ¡£, æ¯ä¸ªæ–‡æ¡£å¹³å‡ 100 tokens

æ–¹æ³•              ååé‡      å»¶è¿Ÿ      æˆæœ¬      æ¨èä½¿ç”¨åœºæ™¯
-----------------------------------------------------------------
hash              10000/s     <1ms      å…è´¹      å¿«é€ŸåŸå‹, æµ‹è¯•
mockembedder      5000/s      <1ms      å…è´¹      å•å…ƒæµ‹è¯•

hf (small)        100/s       10ms      å…è´¹      å®æ—¶æŸ¥è¯¢, é¢„ç®—æœ‰é™
hf (base)         50/s        20ms      å…è´¹      å¹³è¡¡æ€§èƒ½å’Œè´¨é‡
hf (large)        20/s        50ms      å…è´¹      é«˜è´¨é‡ç¦»çº¿å¤„ç†

openai (small)    1000/s      10ms      $$$       å¤§è§„æ¨¡äº‘ç«¯éƒ¨ç½²
openai (large)    500/s       20ms      $$$$      æœ€é«˜è´¨é‡è¦æ±‚

jina              800/s       15ms      $$        ä¸­ç­‰è§„æ¨¡, å¤šè¯­è¨€
zhipu             600/s       20ms      $$        ä¸­æ–‡ä¼˜åŒ–

vLLM (GPU)        2000/s      5ms       ç¡¬ä»¶      å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒ
vLLM (å¤šGPU)      5000/s      3ms       ç¡¬ä»¶      è¶…å¤§è§„æ¨¡éƒ¨ç½²

æ¨èé…ç½®:

  1. å¼€å‘/æµ‹è¯•:
     method: "hash" æˆ– "mockembedder"

  2. å°è§„æ¨¡ç”Ÿäº§ (< 1M æ–‡æ¡£):
     method: "hf", model: "BAAI/bge-small-zh-v1.5"

  3. ä¸­ç­‰è§„æ¨¡ (1M - 10M æ–‡æ¡£):
     æŸ¥è¯¢: method: "hf", cache_enabled: true
     ç´¢å¼•: method: "openai" æˆ– "jina"

  4. å¤§è§„æ¨¡ç”Ÿäº§ (> 10M æ–‡æ¡£):
     method: "vllm", vllm_service_name: "vllm"
     é…ç½®å¤š GPU ä»¥æé«˜ååé‡

  5. æˆæœ¬æ•æ„Ÿ:
     method: "hf" (å®Œå…¨å…è´¹, éœ€è¦ GPU ç¡¬ä»¶)

  6. è´¨é‡ä¼˜å…ˆ:
     method: "openai", model: "text-embedding-3-large"
"""
    print(comparison)


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("Embedding Service ç¤ºä¾‹é›†")
    print("=" * 60)

    demos = [
        ("åŸºæœ¬ä½¿ç”¨", demo_basic_embedding_service),
        ("vLLM åç«¯", demo_vllm_embedding_service),
        ("å¤š Embedding ç­–ç•¥", demo_multi_embedding_pipeline),
        ("è‡ªå®šä¹‰ Operator", demo_embedding_operator),
        ("æ€§èƒ½å¯¹æ¯”", demo_performance_comparison),
    ]

    # æ£€æŸ¥æ˜¯å¦åœ¨æµ‹è¯•æ¨¡å¼
    is_test_mode = os.getenv("SAGE_TEST_MODE") == "true" or os.getenv("CI") == "true"

    if is_test_mode:
        # æµ‹è¯•æ¨¡å¼ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        print("\nğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šè‡ªåŠ¨è¿è¡Œæ‰€æœ‰ç¤ºä¾‹\n")
        for name, demo_func in demos:
            try:
                demo_func()
            except Exception as e:
                print(f"\nâŒ {name} å¤±è´¥: {e}")
    else:
        # äº¤äº’æ¨¡å¼ï¼šè®©ç”¨æˆ·é€‰æ‹©
        print("\nå¯ç”¨ç¤ºä¾‹:")
        for i, (name, _) in enumerate(demos, 1):
            print(f"  {i}. {name}")

        print("\né€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹ (1-5, æˆ– 'all' è¿è¡Œå…¨éƒ¨, 'q' é€€å‡º):")
        choice = input("> ").strip().lower()

        if choice == "q":
            return
        elif choice == "all":
            for name, demo_func in demos:
                try:
                    demo_func()
                except Exception as e:
                    print(f"\nâŒ {name} å¤±è´¥: {e}")
        elif choice.isdigit() and 1 <= int(choice) <= len(demos):
            name, demo_func = demos[int(choice) - 1]
            try:
                demo_func()
            except Exception as e:
                print(f"\nâŒ {name} å¤±è´¥: {e}")
                import traceback

                traceback.print_exc()
        else:
            print("æ— æ•ˆé€‰æ‹©")

    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ç»“æŸ")
    print("=" * 60)


if __name__ == "__main__":
    main()
