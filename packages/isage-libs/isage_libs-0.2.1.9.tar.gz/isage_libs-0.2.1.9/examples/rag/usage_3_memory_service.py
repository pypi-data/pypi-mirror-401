"""
Usage 3: MemoryService Integration
==================================

å°† unlearning é›†æˆåˆ° MemoryService ä¸­ã€‚

é€‚ç”¨åœºæ™¯ï¼š
- RAG ç³»ç»Ÿä¸­çš„éšç§é—å¿˜
- éœ€è¦ä» VDB ä¸­æ£€ç´¢å’Œæ›´æ–°å‘é‡
- ä¸è®°å¿†ç®¡ç†ç³»ç»Ÿé›†æˆ
- å®Œæ•´çš„æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†

ä¼˜åŠ¿ï¼š
- ä¸ VDB collection æ— ç¼é›†æˆ
- æ”¯æŒå‘é‡æ£€ç´¢å’Œæ›´æ–°
- é—å¿˜æ“ä½œçš„æŒä¹…åŒ–
- éšç§é¢„ç®—ç®¡ç†
"""

import os
from typing import Any

import numpy as np

from sage.common.utils.logging.custom_logger import CustomLogger
from sage.kernel.api.service.base_service import BaseService
from sage.libs.privacy.unlearning import UnlearningEngine
from sage.middleware.components.sage_mem.neuromem.memory_collection.vdb_collection import (
    VDBMemoryCollection,
)
from sage.middleware.components.sage_mem.neuromem.memory_manager import MemoryManager


class DPMemoryService(BaseService):
    """
    å¸¦å·®åˆ†éšç§çš„å†…å­˜æœåŠ¡

    æ”¯æŒä½¿ç”¨ DP é—å¿˜æ“ä½œä» VDB ä¸­å®‰å…¨åˆ é™¤æ•°æ®ã€‚
    """

    def __init__(self, data_dir: str | None = None, epsilon: float = 1.0, delta: float = 1e-5):
        super().__init__()

        # åˆå§‹åŒ–å†…å­˜ç®¡ç†å™¨
        if data_dir is None:
            data_dir = os.path.join(os.getcwd(), "data", "dp_memory_service")
        os.makedirs(data_dir, exist_ok=True)

        self.manager = MemoryManager(data_dir)
        self.logger.info(f"Initialized DPMemoryService with data_dir={data_dir}")

        # åˆå§‹åŒ– DP unlearning engine
        self.unlearning_engine = UnlearningEngine(
            epsilon=epsilon,
            delta=delta,
            total_budget_epsilon=100.0,
            enable_compensation=True,
        )

        self.logger.info(f"Initialized UnlearningEngine with Îµ={epsilon}, Î´={delta}")

    def create_collection(self, collection_name: str, config: dict | None = None) -> bool:
        """åˆ›å»º VDB collection"""
        try:
            if config is None:
                config = {
                    "name": collection_name,
                    "backend_type": "VDB",
                    "description": f"DP-enabled collection: {collection_name}",
                }

            collection = self.manager.create_collection(config)

            if collection is None:
                self.logger.warning(f"Failed to create collection: {collection_name}")
                return False

            # åˆ›å»ºé»˜è®¤ç´¢å¼•
            index_config = {
                "name": "global_index",
                "embedding_model": "mockembedder",
                "dim": 128,
                "backend_type": "FAISS",
                "description": "Global index for similarity search",
            }
            collection.create_index(index_config)  # type: ignore[attr-defined]
            # Note: index initialization with vectors happens when data is inserted
            # via store_memory which calls collection.insert with pre-computed vectors

            self.logger.info(f"âœ“ Created collection: {collection_name}")
            return True

        except Exception as e:
            self.logger.error(f"Error creating collection: {e}")
            return False

    def store_memory(
        self,
        collection_name: str,
        content: str,
        vector: np.ndarray,
        metadata: dict[str, Any] | None = None,
    ) -> str | None:
        """
        å­˜å‚¨è®°å¿†åˆ° VDB collection

        Args:
            collection_name: Collection åç§°
            content: æ–‡æœ¬å†…å®¹
            vector: å‘é‡è¡¨ç¤º
            metadata: å…ƒæ•°æ®

        Returns:
            Memory ID æˆ– None
        """
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                self.logger.error(f"Collection not found: {collection_name}")
                return None

            # ç¡®ä¿æ˜¯ VDB ç±»å‹çš„ collection
            if not isinstance(collection, VDBMemoryCollection):
                self.logger.error(f"Collection {collection_name} is not a VDB collection")
                return None

            # VDBMemoryCollection.insert ä½¿ç”¨ (index_name, raw_data, vector, metadata)
            memory_id = collection.insert(
                index_name="global_index",
                raw_data=content,
                vector=vector,
                metadata=metadata,
            )

            self.logger.debug(f"Stored memory: {memory_id}")
            return memory_id

        except Exception as e:
            self.logger.error(f"Error storing memory: {e}")
            return None

    def retrieve_memories(
        self, collection_name: str, query_vector: np.ndarray, topk: int = 5
    ) -> list[dict[str, Any]]:
        """
        æ£€ç´¢ç›¸ä¼¼çš„è®°å¿†

        Args:
            collection_name: Collection åç§°
            query_vector: æŸ¥è¯¢å‘é‡
            topk: è¿”å›ç»“æœæ•°é‡

        Returns:
            ç›¸ä¼¼è®°å¿†åˆ—è¡¨
        """
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                self.logger.error(f"Collection not found: {collection_name}")
                return []

            results = collection.retrieve(  # type: ignore[call-arg]
                query_vector=query_vector,
                index_name="global_index",
                topk=topk,
                with_metadata=True,
            )

            return results  # type: ignore[return-value]

        except Exception as e:
            self.logger.error(f"Error retrieving memories: {e}")
            return []

    def forget_with_dp(
        self,
        collection_name: str,
        memory_ids: list[str],
        perturbation_strategy: str = "adaptive",
    ) -> dict[str, Any]:
        """
        ä½¿ç”¨å·®åˆ†éšç§é—å¿˜æŒ‡å®šçš„è®°å¿†

        Args:
            collection_name: Collection åç§°
            memory_ids: è¦é—å¿˜çš„è®°å¿† IDs
            perturbation_strategy: æ‰°åŠ¨ç­–ç•¥

        Returns:
            é—å¿˜æ“ä½œç»“æœ
        """
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                self.logger.error(f"Collection not found: {collection_name}")
                return {
                    "success": False,
                    "error": f"Collection not found: {collection_name}",
                }

            # ä» VDB index è·å–è¦é—å¿˜çš„å‘é‡
            index = collection.index_info.get("global_index", {}).get("index")  # type: ignore[attr-defined]
            if index is None:
                self.logger.error(f"Index not found in collection: {collection_name}")
                return {"success": False, "error": "Index not found"}

            vectors_to_forget = []
            valid_ids = []

            for mem_id in memory_ids:
                # ä» vector_store è·å–å‘é‡
                if hasattr(index, "vector_store") and mem_id in index.vector_store:
                    vector = index.vector_store[mem_id]
                    vectors_to_forget.append(vector)
                    valid_ids.append(mem_id)
                else:
                    self.logger.warning(f"Vector not found for memory ID: {mem_id}")

            if not vectors_to_forget:
                self.logger.warning("No vectors found to forget")
                return {"success": False, "error": "No vectors found"}

            # è·å–æ‰€æœ‰å‘é‡ç”¨äºè¡¥å¿
            all_vectors = []
            all_ids = []
            if hasattr(index, "vector_store"):
                for vid, vector in index.vector_store.items():
                    if vid not in self.unlearning_engine.privacy_accountant.get_remaining_budget():
                        all_vectors.append(vector)
                        all_ids.append(vid)

            vectors_array = np.array(vectors_to_forget)
            if all_vectors:
                all_vectors_array = np.array(all_vectors)
            else:
                all_vectors_array = vectors_array

            self.logger.info(f"Starting DP unlearning for {len(valid_ids)} memories...")

            # æ‰§è¡Œ DP é—å¿˜
            result = self.unlearning_engine.unlearn_vectors(
                vectors_to_forget=vectors_array,
                vector_ids_to_forget=valid_ids,
                all_vectors=all_vectors_array,
                all_vector_ids=all_ids,
                perturbation_strategy=perturbation_strategy,
            )

            if not result.success:
                error_msg = result.metadata.get("error", "Unknown error")
                self.logger.error(f"Unlearning failed: {error_msg}")
                return {"success": False, "error": error_msg}

            # è·å–æ‰°åŠ¨åçš„å‘é‡
            perturbed_vectors = result.metadata.get("perturbed_vectors", [])

            # æ›´æ–° VDB ä¸­çš„å‘é‡
            updated_count = 0
            for mem_id, perturbed_vec in zip(valid_ids, perturbed_vectors):
                try:
                    # æ›´æ–°å‘é‡
                    if hasattr(index, "update"):
                        index.update(mem_id, perturbed_vec)
                    else:
                        # å¤‡é€‰ï¼šåˆ é™¤åé‡æ–°æ’å…¥
                        index.delete(mem_id)
                        index.insert(perturbed_vec, mem_id)
                    updated_count += 1
                except Exception as e:
                    self.logger.error(f"Failed to update vector for {mem_id}: {e}")

            # æŒä¹…åŒ–æ›´æ”¹
            self.manager.store_collection(collection_name)

            self.logger.info(f"âœ“ Successfully forgotten {updated_count} memories")

            # è¿”å›ç»“æœ
            status = self.unlearning_engine.get_privacy_status()
            remaining = status["remaining_budget"]

            return {
                "success": True,
                "num_forgotten": updated_count,
                "privacy_cost": {
                    "epsilon": result.privacy_cost[0],
                    "delta": result.privacy_cost[1],
                },
                "remaining_budget": {
                    "epsilon": remaining["epsilon_remaining"],
                    "delta": remaining["delta_remaining"],
                },
                "budget_utilization": status["accountant_summary"]["budget_utilization"],
            }

        except Exception as e:
            self.logger.error(f"Error in forget_with_dp: {e}")
            return {"success": False, "error": str(e)}

    def get_privacy_status(self) -> dict[str, Any]:
        """è·å–å½“å‰éšç§é¢„ç®—çŠ¶æ€"""
        return self.unlearning_engine.get_privacy_status()


def example_basic_dp_memory():
    """ç¤ºä¾‹1ï¼šåŸºç¡€ DP Memory Service"""
    print("\n" + "=" * 70)
    print("Example 1: Basic DP Memory Service")
    print("=" * 70)

    # åˆ›å»ºæœåŠ¡
    service = DPMemoryService(epsilon=1.0, delta=1e-5)

    # åˆ›å»º collection
    service.create_collection("documents")

    # å­˜å‚¨ä¸€äº›è®°å¿†
    print("\nğŸ“ Storing memories...")
    memory_ids = []
    for i in range(5):
        content = f"This is document {i} with sensitive information"
        vector = np.random.randn(128).astype(np.float32)
        vector = vector / (np.linalg.norm(vector) + 1e-10)
        metadata = {"doc_index": i, "category": "sensitive" if i % 2 == 0 else "normal"}

        mem_id = service.store_memory(
            collection_name="documents",
            content=content,
            vector=vector,
            metadata=metadata,
        )
        if mem_id:
            memory_ids.append(mem_id)
            print(f"  âœ“ Stored memory {i}: {mem_id[:8]}...")

    # æ£€ç´¢
    print("\nğŸ” Retrieving memories...")
    query_vector = np.random.randn(128).astype(np.float32)
    query_vector = query_vector / (np.linalg.norm(query_vector) + 1e-10)
    results = service.retrieve_memories("documents", query_vector, topk=3)
    print(f"  Found {len(results)} results")

    # é—å¿˜å…¶ä¸­ä¸€äº›
    print("\nğŸ”’ Forgetting sensitive documents...")
    if memory_ids:
        forget_ids = memory_ids[::2]  # æ¯éš”ä¸€ä¸ªé—å¿˜
        result = service.forget_with_dp(
            collection_name="documents",
            memory_ids=forget_ids,
            perturbation_strategy="selective",
        )

        print(f"  Success: {result['success']}")
        if result["success"]:
            print(f"  Forgotten: {result['num_forgotten']} documents")
            print(f"  Privacy cost: Îµ={result['privacy_cost']['epsilon']:.4f}")
            print(f"  Remaining budget: Îµ={result['remaining_budget']['epsilon']:.4f}")

    print()


def example_privacy_budget_management():
    """ç¤ºä¾‹2ï¼šéšç§é¢„ç®—ç®¡ç†"""
    print("\n" + "=" * 70)
    print("Example 2: Privacy Budget Management")
    print("=" * 70)

    service = DPMemoryService(epsilon=0.5, delta=1e-5)
    service.create_collection("sensitive_data")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    memory_ids = []
    for i in range(10):
        content = f"Document {i}"
        vector = np.random.randn(128).astype(np.float32)
        vector = vector / (np.linalg.norm(vector) + 1e-10)
        mem_id = service.store_memory("sensitive_data", content, vector)
        if mem_id:
            memory_ids.append(mem_id)

    print("\nğŸ“Š Privacy Budget Tracking:")

    # å¤šæ¬¡é—å¿˜æ“ä½œ
    forget_count = 0
    for batch_idx in range(3):
        # æ¯æ‰¹é—å¿˜ 2 ä¸ª
        batch_ids = memory_ids[batch_idx * 2 : (batch_idx + 1) * 2]
        if not batch_ids:
            break

        result = service.forget_with_dp(
            collection_name="sensitive_data",
            memory_ids=batch_ids,
            perturbation_strategy="uniform",
        )

        forget_count += 1

        if result["success"]:
            print(f"  Batch {forget_count}: Success")
            print(f"    Forgotten: {result['num_forgotten']}")
            print(f"    Remaining Îµ: {result['remaining_budget']['epsilon']:.4f}")
        else:
            print(f"  Batch {forget_count}: Failed - {result['error']}")
            break

    print()


def example_multi_collection():
    """ç¤ºä¾‹3ï¼šå¤š Collection ç®¡ç†"""
    print("\n" + "=" * 70)
    print("Example 3: Multi-Collection Management")
    print("=" * 70)

    service = DPMemoryService(epsilon=1.0)

    # åˆ›å»ºå¤šä¸ª collection
    collections = ["public", "internal", "confidential"]
    for col_name in collections:
        service.create_collection(col_name)
        print(f"  âœ“ Created collection: {col_name}")

    # å‘ä¸åŒ collection å­˜å‚¨æ•°æ®
    print("\nğŸ“ Storing data to different collections...")
    for col_name in collections:
        for i in range(3):
            content = f"{col_name} document {i}"
            vector = np.random.randn(128).astype(np.float32)
            vector = vector / (np.linalg.norm(vector) + 1e-10)
            mem_id = service.store_memory(col_name, content, vector)
            if mem_id:
                print(f"  âœ“ {col_name}: {mem_id[:8]}...")

    # ä» confidential collection é—å¿˜ä¸€äº›æ•°æ®
    print("\nğŸ”’ Forgetting from confidential collection...")
    query_vector = np.random.randn(128).astype(np.float32)
    query_vector = query_vector / (np.linalg.norm(query_vector) + 1e-10)
    results = service.retrieve_memories("confidential", query_vector, topk=2)
    if results:
        # è·å–ç¬¬ä¸€ä¸ªç»“æœçš„ IDï¼ˆè¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆï¼Œå®é™…éœ€è¦è¿½è¸ª IDï¼‰
        print(f"  Found {len(results)} documents in confidential collection")

    print()


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 70)
    print("SAGE Unlearning Library - MemoryService Integration")
    print("=" * 70)
    print("\nè¿™äº›ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å°† unlearning é›†æˆåˆ° MemoryServiceã€‚")
    print("é€‚åˆï¼šRAG ç³»ç»Ÿçš„éšç§é—å¿˜ã€VDB é›†æˆã€æ•°æ®ç”Ÿå‘½å‘¨æœŸç®¡ç†\n")

    # ç¦ç”¨è°ƒè¯•æ—¥å¿—
    CustomLogger.disable_global_console_debug()

    # è¿è¡Œç¤ºä¾‹
    example_basic_dp_memory()
    example_privacy_budget_management()
    example_multi_collection()

    print("=" * 70)
    print("âœ… All examples completed successfully!")
    print("=" * 70)
    print("\nğŸ’¡ Next steps:")
    print("  1. Integrate with real embedding models")
    print("  2. Implement custom forgetting policies")
    print("  3. See basic_unlearning_demo.py for full RAG example\n")


if __name__ == "__main__":
    main()
