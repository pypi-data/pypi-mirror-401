"""
Usage 4: Complete RAG System with DP Unlearning
===============================================

å®Œæ•´çš„ RAG ç³»ç»Ÿä¸­çš„éšç§é—å¿˜åœºæ™¯ã€‚

é€‚ç”¨åœºæ™¯ï¼š
- å®Œæ•´çš„ RAG Pipeline
- ç”¨æˆ·è¯·æ±‚åˆ é™¤æ•°æ®
- ç»„ç»‡æ•°æ®åˆ é™¤ä¹‰åŠ¡ï¼ˆGDPR ç­‰ï¼‰
- æ¶æ„æ•°æ®æ¸…ç†

ç‰¹æ€§ï¼š
- æ£€ç´¢ â†’ ç­›é€‰ â†’ é—å¿˜ â†’ æ›´æ–° çš„å®Œæ•´æµç¨‹
- å¤šä¸ªæŸ¥è¯¢çš„æ‰¹é‡å¤„ç†
- éšç§é¢„ç®—è·Ÿè¸ª
- æ“ä½œæ—¥å¿—å’Œå®¡è®¡
"""

import os
from datetime import datetime
from typing import Any

import numpy as np

from sage.common.utils.logging.custom_logger import CustomLogger
from sage.kernel.api.service.base_service import BaseService
from sage.libs.privacy.unlearning import UnlearningEngine
from sage.middleware.components.sage_mem.neuromem.memory_collection.vdb_collection import (
    VDBMemoryCollection,
)
from sage.middleware.components.sage_mem.neuromem.memory_manager import MemoryManager


class RAGUnlearningSystem(BaseService):
    """RAG ç³»ç»Ÿä¸­çš„éšç§é—å¿˜ç®¡ç†"""

    def __init__(self, data_dir: str | None = None, epsilon: float = 1.0):
        super().__init__()

        if data_dir is None:
            data_dir = os.path.join(os.getcwd(), "data", "rag_unlearning")
        os.makedirs(data_dir, exist_ok=True)

        self.data_dir = data_dir
        self.manager = MemoryManager(data_dir)
        self.unlearning_engine = UnlearningEngine(
            epsilon=epsilon,
            delta=1e-5,
            total_budget_epsilon=100.0,
            enable_compensation=True,
        )

        # å®¡è®¡æ—¥å¿—
        self.audit_log = []

        self.logger.info("RAGUnlearningSystem initialized")

    def initialize_rag_corpus(self, collection_name: str, documents: list[dict[str, Any]]) -> bool:
        """
        åˆå§‹åŒ– RAG corpus

        Args:
            collection_name: Collection åç§°
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« 'id', 'content', 'vector', 'metadata'

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆ›å»º collection
            collection = self.manager.create_collection(
                {
                    "name": collection_name,
                    "backend_type": "VDB",
                    "description": f"RAG corpus: {collection_name}",
                }
            )

            if collection is None:
                return False

            # åˆ›å»ºç´¢å¼•
            index_config = {
                "name": "content_index",
                "embedding_model": "mockembedder",
                "dim": 128,
                "backend_type": "FAISS",
                "description": "Content search index",
            }
            collection.create_index(index_config)  # type: ignore[attr-defined]

            # ç¡®ä¿æ˜¯ VDB collection
            if not isinstance(collection, VDBMemoryCollection):
                self.logger.error("Collection is not a VDB collection")
                return False

            # æ’å…¥æ–‡æ¡£ - VDBMemoryCollection.insert(content, index_names, vector, metadata)
            for doc in documents:
                collection.insert(
                    content=doc["content"],
                    index_names="content_index",
                    vector=doc["vector"],
                    metadata=doc.get("metadata", {}),
                )

            # Index is initialized through individual inserts, no need for init_index
            self.manager.store_collection(collection_name)

            self.logger.info(f"âœ“ Initialized RAG corpus with {len(documents)} documents")
            self._audit_log("INIT_CORPUS", collection_name, len(documents))

            return True

        except Exception as e:
            self.logger.error(f"Error initializing corpus: {e}")
            return False

    def retrieve_relevant_documents(
        self, collection_name: str, query_vector: np.ndarray, topk: int = 5
    ) -> list[dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                return []

            # ç¡®ä¿æ˜¯ VDB collection
            if not isinstance(collection, VDBMemoryCollection):
                self.logger.error("Collection is not a VDB collection")
                return []

            # VDBMemoryCollection.retrieve(query_vector, index_name, topk, ...)
            results = collection.retrieve(
                query_vector=query_vector,
                index_name="content_index",
                topk=topk,
                with_metadata=True,
            )

            # retrieve å¯èƒ½è¿”å› None
            if results is None:
                return []

            return results  # type: ignore[return-value]

        except Exception as e:
            self.logger.error(f"Error retrieving documents: {e}")
            return []

    def forget_documents(
        self,
        collection_name: str,
        document_ids: list[str],
        reason: str = "user_request",
        user_id: str | None = None,
    ) -> dict[str, Any]:
        """
        é—å¿˜æŒ‡å®šçš„æ–‡æ¡£

        Args:
            collection_name: Collection åç§°
            document_ids: è¦é—å¿˜çš„æ–‡æ¡£ IDs
            reason: é—å¿˜åŸå› 
            user_id: å‘èµ·é—å¿˜çš„ç”¨æˆ· ID

        Returns:
            æ“ä½œç»“æœ
        """
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                return {"success": False, "error": "Collection not found"}

            index = collection.index_info.get("content_index", {}).get("index")  # type: ignore[attr-defined]
            if index is None:
                return {"success": False, "error": "Index not found"}

            # æ”¶é›†è¦é—å¿˜çš„å‘é‡
            vectors_to_forget = []
            valid_ids = []

            for doc_id in document_ids:
                if hasattr(index, "vector_store") and doc_id in index.vector_store:
                    vector = index.vector_store[doc_id]
                    vectors_to_forget.append(vector)
                    valid_ids.append(doc_id)

            if not vectors_to_forget:
                return {"success": False, "error": "No documents found to forget"}

            # è·å–æ‰€æœ‰å‘é‡ç”¨äºè¡¥å¿
            all_vectors = []
            all_ids = []
            if hasattr(index, "vector_store"):
                for vid, vector in index.vector_store.items():
                    if vid not in valid_ids:  # æ’é™¤è¦é—å¿˜çš„å‘é‡
                        all_vectors.append(vector)
                        all_ids.append(vid)

            self.logger.info(f"Starting DP unlearning for {len(valid_ids)} documents...")

            # æ‰§è¡Œ DP é—å¿˜
            vectors_array = np.array(vectors_to_forget)
            all_vectors_array = np.array(all_vectors) if all_vectors else vectors_array

            result = self.unlearning_engine.unlearn_vectors(
                vectors_to_forget=vectors_array,
                vector_ids_to_forget=valid_ids,
                all_vectors=all_vectors_array,
                all_vector_ids=all_ids,
                perturbation_strategy="adaptive",
            )

            if not result.success:
                error = result.metadata.get("error", "Unknown error")
                self.logger.error(f"Unlearning failed: {error}")
                return {"success": False, "error": error}

            # æ›´æ–° VDB ä¸­çš„å‘é‡
            perturbed_vectors = result.metadata.get("perturbed_vectors", [])
            updated_count = 0

            for doc_id, perturbed_vec in zip(valid_ids, perturbed_vectors):
                try:
                    if hasattr(index, "update"):
                        index.update(doc_id, perturbed_vec)
                    else:
                        index.delete(doc_id)
                        index.insert(perturbed_vec, doc_id)
                    updated_count += 1
                except Exception as e:
                    self.logger.error(f"Failed to update vector for {doc_id}: {e}")

            # æŒä¹…åŒ–
            self.manager.store_collection(collection_name)

            # è®°å½•å®¡è®¡æ—¥å¿—
            self._audit_log(
                "FORGET_DOCUMENTS",
                collection_name,
                len(valid_ids),
                extra={
                    "reason": reason,
                    "user_id": user_id,
                    "privacy_cost": result.privacy_cost,
                },
            )

            status = self.unlearning_engine.get_privacy_status()
            remaining = status["remaining_budget"]

            self.logger.info(f"âœ“ Successfully forgotten {updated_count} documents")

            return {
                "success": True,
                "num_forgotten": updated_count,
                "privacy_cost": {
                    "epsilon": result.privacy_cost[0],
                    "delta": result.privacy_cost[1],
                },
                "remaining_budget": {
                    "epsilon": remaining["epsilon_remaining"],
                    "delta": remaining["delta_remaining"],
                },
            }

        except Exception as e:
            self.logger.error(f"Error in forget_documents: {e}")
            return {"success": False, "error": str(e)}

    def handle_user_deletion_request(
        self, collection_name: str, user_id: str, user_keywords: list[str] | None = None
    ) -> dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æ•°æ®åˆ é™¤è¯·æ±‚ï¼ˆå¦‚ GDPR åˆ é™¤æƒï¼‰

        Args:
            collection_name: Collection åç§°
            user_id: ç”¨æˆ· ID
            user_keywords: ç”¨æˆ·ç‰¹å®šå…³é”®è¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                return {"success": False, "error": "Collection not found"}

            # æŸ¥æ‰¾å±äºè¯¥ç”¨æˆ·çš„æ‰€æœ‰æ–‡æ¡£
            all_ids = collection.get_all_ids()
            user_docs = []

            for doc_id in all_ids:
                metadata = collection.metadata_storage.get(doc_id)
                if metadata and metadata.get("user_id") == user_id:
                    user_docs.append(doc_id)

            if not user_docs:
                self.logger.info(f"No documents found for user {user_id}")
                return {
                    "success": True,
                    "num_forgotten": 0,
                    "message": "No documents to delete",
                }

            self.logger.info(f"Found {len(user_docs)} documents for user {user_id}")

            # é—å¿˜ç”¨æˆ·æ‰€æœ‰æ–‡æ¡£
            result = self.forget_documents(
                collection_name=collection_name,
                document_ids=user_docs,
                reason="user_deletion_request",
                user_id=user_id,
            )

            if result["success"]:
                self.logger.info(f"âœ“ Deleted all data for user {user_id}")

            return result

        except Exception as e:
            self.logger.error(f"Error handling deletion request: {e}")
            return {"success": False, "error": str(e)}

    def handle_malicious_content_removal(
        self, collection_name: str, detection_keywords: list[str]
    ) -> dict[str, Any]:
        """
        å¤„ç†æ¶æ„å†…å®¹ç§»é™¤

        Args:
            collection_name: Collection åç§°
            detection_keywords: æ¶æ„å†…å®¹å…³é”®è¯

        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            collection = self.manager.get_collection(collection_name)
            if collection is None:
                return {"success": False, "error": "Collection not found"}

            # æŸ¥æ‰¾åŒ…å«æ¶æ„å†…å®¹çš„æ–‡æ¡£
            all_ids = collection.get_all_ids()
            malicious_docs = []

            for doc_id in all_ids:
                content = collection.text_storage.get(doc_id)
                if content:
                    for keyword in detection_keywords:
                        if keyword.lower() in content.lower():
                            malicious_docs.append(doc_id)
                            break

            if not malicious_docs:
                self.logger.info("No malicious content detected")
                return {
                    "success": True,
                    "num_forgotten": 0,
                    "message": "No malicious content found",
                }

            self.logger.warning(f"Detected {len(malicious_docs)} documents with malicious content")

            # é—å¿˜æ¶æ„å†…å®¹
            result = self.forget_documents(
                collection_name=collection_name,
                document_ids=malicious_docs,
                reason="malicious_content",
                user_id="system",
            )

            return result

        except Exception as e:
            self.logger.error(f"Error handling malicious content: {e}")
            return {"success": False, "error": str(e)}

    def get_audit_log(self) -> list[dict[str, Any]]:
        """è·å–å®¡è®¡æ—¥å¿—"""
        return self.audit_log

    def _audit_log(self, operation: str, collection: str, count: int, extra: dict | None = None):
        """è®°å½•å®¡è®¡äº‹ä»¶"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "operation": operation,
            "collection": collection,
            "count": count,
            "extra": extra or {},
        }
        self.audit_log.append(log_entry)


def example_basic_rag():
    """ç¤ºä¾‹1ï¼šåŸºç¡€ RAG ç³»ç»Ÿ"""
    print("\n" + "=" * 70)
    print("Example 1: Basic RAG System with Unlearning")
    print("=" * 70)

    system = RAGUnlearningSystem(epsilon=1.0)

    # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
    documents = [
        {
            "id": "doc_001",
            "content": "Machine learning is a subset of artificial intelligence",
            "metadata": {"user_id": "user_1", "category": "public"},
        },
        {
            "id": "doc_002",
            "content": "Deep learning uses neural networks with multiple layers",
            "metadata": {"user_id": "user_1", "category": "public"},
        },
        {
            "id": "doc_003",
            "content": "Natural language processing is used for text analysis",
            "metadata": {"user_id": "user_2", "category": "public"},
        },
        {
            "id": "doc_004",
            "content": "Computer vision helps machines understand images",
            "metadata": {"user_id": "user_2", "category": "sensitive"},
        },
        {
            "id": "doc_005",
            "content": "Reinforcement learning enables agents to learn from interaction",
            "metadata": {"user_id": "user_3", "category": "public"},
        },
    ]

    # ä¸ºæ¯ä¸ªæ–‡æ¡£æ·»åŠ éšæœºå‘é‡
    for doc in documents:
        doc["vector"] = np.random.randn(128).astype(np.float32)
        doc["vector"] = doc["vector"] / (np.linalg.norm(doc["vector"]) + 1e-10)

    # åˆå§‹åŒ– corpus
    system.initialize_rag_corpus("knowledge_base", documents)

    # æ£€ç´¢
    print("\nğŸ” Retrieving documents...")
    query_vector = np.random.randn(128).astype(np.float32)
    query_vector = query_vector / (np.linalg.norm(query_vector) + 1e-10)
    results = system.retrieve_relevant_documents("knowledge_base", query_vector, topk=3)
    print(f"  Found {len(results)} relevant documents")

    # ç”¨æˆ·è¯·æ±‚åˆ é™¤
    print("\nğŸ—‘ï¸ Processing user deletion request...")
    result = system.handle_user_deletion_request("knowledge_base", "user_1")
    print(f"  Success: {result['success']}")
    if result["success"]:
        print(f"  Deleted: {result['num_forgotten']} documents")
        if "privacy_cost" in result:
            print(f"  Privacy cost: Îµ={result['privacy_cost']['epsilon']:.4f}")

    print()


def example_malicious_content():
    """ç¤ºä¾‹2ï¼šæ¶æ„å†…å®¹æ£€æµ‹å’Œç§»é™¤"""
    print("\n" + "=" * 70)
    print("Example 2: Malicious Content Detection and Removal")
    print("=" * 70)

    system = RAGUnlearningSystem(epsilon=1.0)

    # åˆ›å»ºåŒ…å«ä¸€äº›æ¶æ„å†…å®¹çš„æ–‡æ¡£
    documents = [
        {
            "id": "doc_001",
            "content": "This is normal technical content about machine learning",
            "metadata": {"user_id": "user_1", "category": "normal"},
        },
        {
            "id": "doc_002",
            "content": "Spam content: click here for free money!!!",
            "metadata": {"user_id": "user_2", "category": "spam"},
        },
        {
            "id": "doc_003",
            "content": "More legitimate deep learning information",
            "metadata": {"user_id": "user_1", "category": "normal"},
        },
        {
            "id": "doc_004",
            "content": "Malware distribution: download now!!!",
            "metadata": {"user_id": "user_3", "category": "malicious"},
        },
    ]

    for doc in documents:
        doc["vector"] = np.random.randn(128).astype(np.float32)
        doc["vector"] = doc["vector"] / (np.linalg.norm(doc["vector"]) + 1e-10)

    system.initialize_rag_corpus("content_db", documents)

    # æ£€æµ‹å¹¶ç§»é™¤æ¶æ„å†…å®¹
    print("\nğŸš¨ Detecting malicious content...")
    result = system.handle_malicious_content_removal(
        "content_db", detection_keywords=["spam", "malware", "!!!"]
    )

    print(f"  Success: {result['success']}")
    if result["success"]:
        print(f"  Removed: {result['num_forgotten']} malicious documents")

    print()


def example_audit_log():
    """ç¤ºä¾‹3ï¼šå®¡è®¡æ—¥å¿—"""
    print("\n" + "=" * 70)
    print("Example 3: Audit Log and Compliance")
    print("=" * 70)

    system = RAGUnlearningSystem(epsilon=1.0)

    # åˆ›å»ºæ–‡æ¡£
    documents = []
    for i in range(10):
        documents.append(
            {
                "id": f"doc_{i:03d}",
                "content": f"Document {i} content",
                "metadata": {"user_id": f"user_{i % 3}", "category": "normal"},
                "vector": np.random.randn(128).astype(np.float32)
                / np.linalg.norm(np.random.randn(128).astype(np.float32)),
            }
        )

    system.initialize_rag_corpus("audit_test", documents)

    # æ‰§è¡Œå¤šä¸ªæ“ä½œ
    print("\nğŸ“ Performing operations...")

    # ç”¨æˆ· 0 åˆ é™¤è¯·æ±‚
    system.handle_user_deletion_request("audit_test", "user_0")
    print("  âœ“ User deletion request processed")

    # æ¶æ„å†…å®¹æ£€æµ‹ï¼ˆæ— æ¶æ„å†…å®¹ï¼‰
    system.handle_malicious_content_removal("audit_test", ["malware"])
    print("  âœ“ Malicious content check completed")

    # æ˜¾ç¤ºå®¡è®¡æ—¥å¿—
    print("\nğŸ“‹ Audit Log:")
    for entry in system.get_audit_log():
        print(
            f"  {entry['timestamp']}: {entry['operation']} on {entry['collection']} ({entry['count']} items)"
        )

    print()


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\n" + "=" * 70)
    print("SAGE Unlearning - Complete RAG System Examples")
    print("=" * 70)
    print("\nè¿™äº›ç¤ºä¾‹å±•ç¤ºäº†åœ¨å®Œæ•´ RAG ç³»ç»Ÿä¸­ä½¿ç”¨éšç§é—å¿˜ã€‚")
    print("åŒ…æ‹¬ï¼šç”¨æˆ·åˆ é™¤è¯·æ±‚ã€æ¶æ„å†…å®¹ç§»é™¤ã€åˆè§„å®¡è®¡\n")

    CustomLogger.disable_global_console_debug()

    # è¿è¡Œç¤ºä¾‹
    example_basic_rag()
    example_malicious_content()
    example_audit_log()

    print("=" * 70)
    print("âœ… All examples completed successfully!")
    print("=" * 70)
    print("\nğŸ’¡ Key Takeaways:")
    print("  1. Unlearning åº“æä¾›çµæ´»çš„éšç§ä¿æŠ¤æœºåˆ¶")
    print("  2. æ”¯æŒå¤šç§é—å¿˜åœºæ™¯ï¼ˆç”¨æˆ·è¯·æ±‚ã€æ¶æ„å†…å®¹ç­‰ï¼‰")
    print("  3. å®Œæ•´çš„å®¡è®¡æ—¥å¿—ç”¨äºåˆè§„")
    print("  4. éšç§é¢„ç®—ç®¡ç†ç¡®ä¿æ•´ä½“éšç§ä¿è¯\n")


if __name__ == "__main__":
    main()
