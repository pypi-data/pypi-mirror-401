#!/usr/bin/env python3
"""
Adaptive RAG v2 - è‡ªé€‚åº”æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆä¿ç•™æ—§ç‰ˆåˆ†æµé€»è¾‘ï¼‰

æ ¸å¿ƒç‰¹æ€§ï¼š
- å®Œå…¨ä¿ç•™æ—§ç‰ˆ side_output çš„åˆ†æµé€»è¾‘
- ä½¿ç”¨ FlatMap + Filter æ›¿ä»£ side_output å®ç°åˆ†æ”¯
- å‘é‡åº“åˆ†æ”¯ vs Web æœç´¢åˆ†æ”¯ç‹¬ç«‹å¤„ç†
- ä½¿ç”¨æ–°ç‰ˆ SAGE APIï¼š
  - UnifiedInferenceClient (LLM + Embedding)
  - MemoryManager (å‘é‡åº“ç®¡ç†)
  - EmbeddingFactory (æœ¬åœ° Embedding)

æ•°æ®æµï¼ˆä¿ç•™æ—§ç‰ˆåŒåˆ†æ”¯ç»“æ„ï¼‰ï¼š
                    â”Œâ”€â†’ [Filter: vector] â†’ DenseRetriever â†’ Generator â†’ Sink
  é—®é¢˜ â†’ è·¯ç”±åˆ¤æ–­ â”€â”¤
                    â””â”€â†’ [Filter: web] â†’ WebSearchAgent â†’ Sink

å¯¹æ¯”ï¼š
  - æ—§ç‰ˆ: query_stream.side_output("vector").map(...)
  - æ–°ç‰ˆ: query_stream.filter(VectorFilter).map(...)
"""

from __future__ import annotations

import os
import sys
import time
from typing import Any

# å±è”½ä»£ç†è®¾ç½®ï¼ˆè¿œç¨‹æœåŠ¡ä¸éœ€è¦ä»£ç†ï¼‰
os.environ.pop("http_proxy", None)
os.environ.pop("https_proxy", None)
os.environ.pop("HTTP_PROXY", None)
os.environ.pop("HTTPS_PROXY", None)
os.environ.pop("all_proxy", None)
os.environ.pop("ALL_PROXY", None)

import numpy as np
from dotenv import load_dotenv

from sage.common.components.sage_llm import EmbeddingClientAdapter, LLMClientAdapter
from sage.common.core.functions.filter_function import FilterFunction
from sage.common.core.functions.flatmap_function import FlatMapFunction
from sage.common.core.functions.map_function import MapFunction
from sage.common.core.functions.sink_function import SinkFunction
from sage.common.core.functions.source_function import SourceFunction
from sage.common.utils.logging.custom_logger import CustomLogger
from sage.kernel.api.local_environment import LocalEnvironment

# å°è¯•å¯¼å…¥ MemoryManagerï¼ˆå¯é€‰ï¼Œç”¨äºæŒä¹…åŒ–å‘é‡åº“ï¼‰
try:
    from sage.middleware.components.sage_mem.neuromem.memory_manager import MemoryManager

    HAS_MEMORY_MANAGER = True
    _ = MemoryManager  # æ ‡è®°ä¸ºå·²ä½¿ç”¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
except ImportError:
    HAS_MEMORY_MANAGER = False
    print("âš ï¸ MemoryManager ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•å†…å­˜å‘é‡åº“")


# ============================================================
# è¿œç¨‹æœåŠ¡é…ç½®ï¼ˆä¸ adaptive_rag.py ä¸€è‡´ï¼‰
# ============================================================

# LLM æœåŠ¡ï¼ˆå¯é€‰æ‹©ä¸åŒå¤§å°çš„æ¨¡å‹ï¼‰
LLM_HOST = "11.11.11.7"
LLM_MODELS = {
    "32B": ("8901", "Qwen/Qwen2.5-32B-Instruct"),
    "14B": ("8902", "Qwen/Qwen2.5-14B-Instruct"),
    "7B": ("8903", "Qwen/Qwen2.5-7B-Instruct"),  # é»˜è®¤
    "1.5B": ("8904", "Qwen/Qwen2.5-1.5B-Instruct"),
    "0.5B": ("8905", "Qwen/Qwen2.5-0.5B-Instruct"),
}

# ä½¿ç”¨ 7B æ¨¡å‹ä½œä¸ºé»˜è®¤
DEFAULT_LLM = "7B"
LLM_PORT, LLM_MODEL = LLM_MODELS[DEFAULT_LLM]
LLM_BASE_URL = f"http://{LLM_HOST}:{LLM_PORT}/v1"

# Embedding æœåŠ¡
EMBEDDING_BASE_URL = f"http://{LLM_HOST}:8090/v1"
EMBEDDING_MODEL = "BAAI/bge-large-zh-v1.5"


# ============================================================
# Prompt æ¨¡æ¿ï¼ˆä¸æ—§ç‰ˆä¸€è‡´ï¼‰
# ============================================================

ROUTE_PROMPT_TEMPLATE = """Instruction:
You are an expert at routing a user question to a vectorstore or web search.
Use the vectorstore for questions on travel to Hubei Province in China.
You do not need to be stringent with the keywords in the question related to these topics.
Otherwise, use web-search. Give a binary choice 'web_search' or 'vectorstore' based on the question.
Return a JSON with a single key 'datasource' and no preamble or explanation.
Question to route: {question}
"""

QA_PROMPT_TEMPLATE = """è¯·æ ¹æ®ä»¥ä¸‹èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœèƒŒæ™¯ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®è¯´æ˜ã€‚

èƒŒæ™¯ä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·ç»™å‡ºç®€æ´å‡†ç¡®çš„å›ç­”ï¼š"""


# ============================================================
# æ¹–åŒ—æ—…æ¸¸çŸ¥è¯†åº“æ•°æ®
# ============================================================

HUBEI_DOCUMENTS = [
    "æ­¦æ±‰æ˜¯æ¹–åŒ—çœçœä¼šï¼Œè‘—åæ™¯ç‚¹åŒ…æ‹¬é»„é¹¤æ¥¼ã€ä¸œæ¹–ã€æˆ·éƒ¨å··ã€æ±Ÿæ±‰è·¯æ­¥è¡Œè¡—ç­‰ã€‚é»„é¹¤æ¥¼æ˜¯æ±Ÿå—ä¸‰å¤§åæ¥¼ä¹‹ä¸€ï¼Œäº«æœ‰'å¤©ä¸‹æ±Ÿå±±ç¬¬ä¸€æ¥¼'çš„ç¾èª‰ã€‚",
    "ä¸œæ¹–æ˜¯ä¸­å›½æœ€å¤§çš„åŸä¸­æ¹–ï¼Œé¢ç§¯çº¦33å¹³æ–¹å…¬é‡Œï¼Œæ˜¯5Açº§é£æ™¯åŒºã€‚æ¹–ç•”æœ‰ç£¨å±±ã€å¬æ¶›ã€è½é›ç­‰æ™¯åŒºï¼Œæ˜¥å¤©çš„æ¨±èŠ±å°¤ä¸ºè‘—åã€‚",
    "é•¿æ±Ÿä¸‰å³¡æ˜¯ä¸­å›½è‘—åçš„é£æ™¯åèƒœåŒºï¼ŒåŒ…æ‹¬ç¿å¡˜å³¡ã€å·«å³¡å’Œè¥¿é™µå³¡ï¼Œå…¨é•¿çº¦200å…¬é‡Œã€‚ä¸‰å³¡å¤§åæ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„æ°´åˆ©æ¢çº½å·¥ç¨‹ã€‚",
    "æ©æ–½å¤§å³¡è°·æ˜¯å›½å®¶5Açº§æ™¯åŒºï¼Œä»¥å¤©å‘ã€åœ°ç¼ã€æº¶æ´ã€ç»å£ã€å³°ä¸›è‘—ç§°ï¼Œè¢«èª‰ä¸º'æ¹–åŒ—çš„å¼ å®¶ç•Œ'ã€‚å³¡è°·å…¨é•¿108å…¬é‡Œã€‚",
    "ç¥å†œæ¶æ˜¯ä¸­å›½å”¯ä¸€ä»¥'æ—åŒº'å‘½åçš„è¡Œæ”¿åŒºï¼Œæ˜¯ä¸–ç•Œè‡ªç„¶é—äº§åœ°ã€‚è¿™é‡Œæœ‰é‡‘ä¸çŒ´ã€ç™½ç†Šç­‰çç¨€åŠ¨ç‰©ï¼Œè¿˜æœ‰ç¥ç§˜çš„'é‡äºº'ä¼ è¯´ã€‚",
    "å®œæ˜Œæ˜¯ä¸‰å³¡å¤§åæ‰€åœ¨åœ°ï¼Œè¢«ç§°ä¸º'ä¸–ç•Œæ°´ç”µä¹‹éƒ½'ã€‚è¿™é‡Œæ˜¯å±ˆåŸå’Œç‹æ˜­å›çš„æ•…ä¹¡ï¼Œæœ‰å±ˆåŸç¥ ã€æ˜­å›æ‘ç­‰äººæ–‡æ™¯ç‚¹ã€‚",
    "æ­¦å½“å±±ä½äºæ¹–åŒ—åå °ï¼Œæ˜¯é“æ•™åœ£åœ°ï¼Œé‡‘é¡¶å’Œç´«éœ„å®«æ˜¯è‘—åæ™¯ç‚¹ã€‚æ­¦å½“æ­¦æœ¯ä¸å°‘æ—åŠŸå¤«é½åï¼Œè¢«åˆ—å…¥ä¸–ç•Œæ–‡åŒ–é—äº§ã€‚",
    "è†å·å¤åŸæ˜¯ä¸­å›½å†å²æ–‡åŒ–ååŸï¼Œä¸‰å›½æ—¶æœŸçš„å…µå®¶å¿…äº‰ä¹‹åœ°ã€‚åŸå¢™ä¿å­˜å®Œå¥½ï¼Œæœ‰è†å·åšç‰©é¦†å’Œå¼ å±…æ­£æ•…å±…ç­‰æ™¯ç‚¹ã€‚",
]


# ============================================================
# å…¨å±€æœåŠ¡ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰- ä½¿ç”¨ SAGE ç»„ä»¶
# ============================================================

_llm_client: LLMClientAdapter | None = None
_embedding_client: EmbeddingClientAdapter | None = None
_vector_collection: Any = None


def get_llm_client() -> LLMClientAdapter:
    """è·å– LLM å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ LLMClientAdapterï¼‰"""
    global _llm_client
    if _llm_client is None:
        _llm_client = LLMClientAdapter(
            base_url=LLM_BASE_URL,
            model_name=LLM_MODEL,
        )
        print(f"âœ… LLMClientAdapter åˆå§‹åŒ–å®Œæˆ: {LLM_BASE_URL}")
    return _llm_client


def get_embedding_client() -> EmbeddingClientAdapter:
    """è·å– Embedding å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ EmbeddingClientAdapterï¼‰"""
    global _embedding_client
    if _embedding_client is None:
        _embedding_client = EmbeddingClientAdapter.create_api(
            base_url=EMBEDDING_BASE_URL,
            model=EMBEDDING_MODEL,
        )
        print(f"âœ… EmbeddingClientAdapter åˆå§‹åŒ–å®Œæˆ: {EMBEDDING_BASE_URL}")
    return _embedding_client


def get_vector_collection():
    """è·å–å‘é‡åº“ Collection"""
    global _vector_collection

    if _vector_collection is not None:
        return _vector_collection

    # ä½¿ç”¨ç®€å•å†…å­˜å‘é‡åº“ï¼ˆé¿å… MemoryManager æ¥å£å¤æ‚æ€§ï¼‰
    _vector_collection = SimpleVectorDB(get_embedding_client())
    _vector_collection.add_documents(HUBEI_DOCUMENTS)

    return _vector_collection


class SimpleVectorDB:
    """ç®€å•å†…å­˜å‘é‡åº“ - ä½¿ç”¨ EmbeddingClientAdapter"""

    def __init__(self, embedding_client: EmbeddingClientAdapter):
        self.client = embedding_client
        self.documents: list[str] = []
        self.embeddings: list[list[float]] = []

    def add_documents(self, documents: list[str]):
        """æ·»åŠ æ–‡æ¡£å¹¶è®¡ç®— embedding"""
        print(f"ğŸ“¦ æ„å»ºç®€å•å‘é‡åº“ ({len(documents)} æ–‡æ¡£)...")
        # æ‰¹é‡è®¡ç®— embedding
        embeddings = self.client.embed(documents)
        self.documents = documents
        self.embeddings = embeddings
        print("âœ… å‘é‡åº“æ„å»ºå®Œæˆ")

    def search(self, query: str, top_k: int = 3) -> list[str]:
        """å‘é‡æ£€ç´¢"""
        # è®¡ç®—æŸ¥è¯¢çš„ embedding
        query_embeddings = self.client.embed([query])
        query_embedding = query_embeddings[0] if query_embeddings else []

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        for i, emb in enumerate(self.embeddings):
            sim = self._cosine_similarity(query_embedding, emb)
            similarities.append((i, sim))

        similarities.sort(key=lambda x: x[1], reverse=True)
        return [self.documents[i] for i, _ in similarities[:top_k]]

    def _cosine_similarity(self, a: list[float], b: list[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        a_arr = np.array(a)
        b_arr = np.array(b)
        return float(np.dot(a_arr, b_arr) / (np.linalg.norm(a_arr) * np.linalg.norm(b_arr)))


# ============================================================
# Source: é—®é¢˜è¾“å…¥æºï¼ˆä¸æ—§ç‰ˆä¸€è‡´ï¼‰
# ============================================================


class QuestionSource(SourceFunction):
    """é—®é¢˜æºï¼šä»é¢„è®¾é—®é¢˜åˆ—è¡¨è·å–é—®é¢˜"""

    def __init__(self, questions: list[str] | None = None, **kwargs):
        super().__init__(**kwargs)
        self.questions = questions or [
            "æ­¦æ±‰æœ‰å“ªäº›è‘—åæ™¯ç‚¹ï¼Ÿ",
            "ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            "ç¥å†œæ¶æœ‰ä»€ä¹ˆå¥½ç©çš„ï¼Ÿ",
            "Python æ€ä¹ˆå­¦ä¹ ï¼Ÿ",
        ]
        self.index = 0

    def execute(self, data=None) -> dict | None:
        if self.index >= len(self.questions):
            return None
        question = self.questions[self.index]
        self.index += 1
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ é—®é¢˜ {self.index}: {question}")
        return {"question": question}


# ============================================================
# RoutePromptFunction: æ„é€ è·¯ç”± Promptï¼ˆä¸æ—§ç‰ˆä¸€è‡´ï¼‰
# ============================================================


class RoutePromptFunction(MapFunction):
    """
    æ„é€ è·¯ç”± promptï¼Œç”¨äºåˆ¤æ–­ä½¿ç”¨å‘é‡åº“è¿˜æ˜¯ Web æœç´¢ã€‚
    å¯¹åº”æ—§ç‰ˆ RoutePromptFunction
    """

    def execute(self, data: dict) -> dict:
        question = data["question"]
        prompt = ROUTE_PROMPT_TEMPLATE.format(question=question)
        return {"question": question, "messages": [{"role": "user", "content": prompt}]}


# ============================================================
# LLMGenerator: è°ƒç”¨ LLM ç”Ÿæˆï¼ˆä½¿ç”¨ LLMClientAdapterï¼‰
# ============================================================


class LLMGenerator(MapFunction):
    """
    è°ƒç”¨ LLM ç”Ÿæˆå“åº”ï¼ˆä½¿ç”¨ LLMClientAdapterï¼‰ã€‚
    å¯¹åº”æ—§ç‰ˆ OpenAIGenerator
    """

    def execute(self, data: dict) -> dict:
        messages = data["messages"]
        question = data["question"]

        client = get_llm_client()
        try:
            response = client.chat(messages, temperature=0, max_tokens=100)
            llm_output = response.content if hasattr(response, "content") else str(response)
        except Exception as e:
            print(f"âš ï¸ LLM è°ƒç”¨å¤±è´¥: {e}")
            llm_output = '{"datasource": "web_search"}'

        return {"question": question, "llm_output": llm_output}


# ============================================================
# RouteSplitter: ä½¿ç”¨ FlatMap æ›¿ä»£ side_output æ‰“æ ‡ç­¾
# ============================================================


class RouteSplitter(FlatMapFunction):
    """
    è·¯ç”±åˆ†æµå™¨ï¼šæ ¹æ® LLM è¾“å‡ºåˆ¤æ–­æ˜¯èµ° vectorstore è¿˜æ˜¯ web_searchã€‚

    æ›¿ä»£æ—§ç‰ˆ side_output çš„å®ç°ï¼š
    - æ—§ç‰ˆ: self.out.collect(data, "vector") / self.out.collect(data, "web")
    - æ–°ç‰ˆ: è¿”å›å¸¦ route æ ‡ç­¾çš„æ•°æ®ï¼Œä¸‹æ¸¸ç”¨ Filter åˆ†æµ
    """

    def execute(self, data: dict) -> list[dict]:
        question = data["question"]
        llm_output = data["llm_output"]

        print(f"ğŸ”€ RouteSplitter æ”¶åˆ°: {llm_output}")

        # è§£æè·¯ç”±å†³ç­–
        if "vectorstore" in llm_output.lower():
            route = "vector"
        else:
            route = "web"

        print(f"   â†’ è·¯ç”±å†³ç­–: {route}")

        # è¿”å›å¸¦è·¯ç”±æ ‡ç­¾çš„æ•°æ®ï¼ˆæ›¿ä»£ side_outputï¼‰
        return [{"question": question, "route": route}]


# ============================================================
# Filter: åˆ†æµè¿‡æ»¤å™¨ï¼ˆæ›¿ä»£ side_outputï¼‰
# ============================================================


class VectorRouteFilter(FilterFunction):
    """è¿‡æ»¤å‡ºèµ°å‘é‡åº“çš„è¯·æ±‚ï¼ˆæ›¿ä»£ query_stream.side_output("vector")ï¼‰"""

    def execute(self, data: dict) -> bool:
        return data.get("route") == "vector"


class WebRouteFilter(FilterFunction):
    """è¿‡æ»¤å‡ºèµ° Web æœç´¢çš„è¯·æ±‚ï¼ˆæ›¿ä»£ query_stream.side_output("web")ï¼‰"""

    def execute(self, data: dict) -> bool:
        return data.get("route") == "web"


# ============================================================
# DenseRetriever: å‘é‡åº“æ£€ç´¢ï¼ˆä½¿ç”¨ EmbeddingClientAdapterï¼‰
# ============================================================


class DenseRetriever(MapFunction):
    """
    å‘é‡åº“æ£€ç´¢å™¨ï¼ˆä½¿ç”¨ EmbeddingClientAdapterï¼‰ã€‚
    å¯¹åº”æ—§ç‰ˆ DenseRetriever
    """

    def execute(self, data: dict) -> dict:
        question = data["question"]
        print(f"ğŸ” [å‘é‡åº“] æ£€ç´¢: {question}")

        # ä½¿ç”¨ç®€å•å‘é‡åº“ - search æ–¹æ³•å†…éƒ¨ä¼šè®¡ç®— embedding
        collection = get_vector_collection()
        results = collection.search(question, top_k=3)
        context = "\n\n".join(results)

        print(f"   â†’ æ£€ç´¢åˆ° {len(results)} æ¡ç»“æœ")
        return {"question": question, "context": context, "source": "çŸ¥è¯†åº“"}


# ============================================================
# QAPromptor: æ„é€  QA Prompt
# ============================================================


class QAPromptor(MapFunction):
    """
    æ„é€  QA Promptã€‚
    å¯¹åº”æ—§ç‰ˆ QAPromptor
    """

    def execute(self, data: dict) -> dict:
        question = data["question"]
        context = data["context"]
        source = data["source"]

        prompt = QA_PROMPT_TEMPLATE.format(context=context, question=question)
        return {
            "question": question,
            "messages": [{"role": "user", "content": prompt}],
            "source": source,
        }


# ============================================================
# QAGenerator: ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆä½¿ç”¨ UnifiedInferenceClientï¼‰
# ============================================================


class QAGenerator(MapFunction):
    """
    ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆä½¿ç”¨ LLMClientAdapterï¼‰ã€‚
    å¯¹åº”æ—§ç‰ˆ OpenAIGenerator åœ¨ QA é˜¶æ®µçš„ä½¿ç”¨
    """

    def execute(self, data: dict) -> dict:
        messages = data["messages"]
        question = data["question"]
        source = data["source"]

        client = get_llm_client()
        try:
            response = client.chat(messages, temperature=0.7, max_tokens=500)
            answer = response.content if hasattr(response, "content") else str(response)
        except Exception as e:
            answer = f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {e}"

        print(f"ğŸ¤– ç”Ÿæˆå›ç­”å®Œæˆ (æ¥æº: {source})")
        return {"question": question, "answer": answer, "source": source}


# ============================================================
# WebSearchAgent: Web æœç´¢ä»£ç†
# ============================================================


class WebSearchAgent(MapFunction):
    """
    Web æœç´¢ä»£ç†ï¼ˆä½¿ç”¨ LLMClientAdapterï¼‰ã€‚
    å¯¹åº”æ—§ç‰ˆ BaseAgent
    """

    def execute(self, data: dict) -> dict:
        question = data["question"]
        print(f"ğŸŒ [Webæœç´¢] æœç´¢: {question}")

        # æ£€æŸ¥æ˜¯å¦æœ‰åšæŸ¥ API Key
        bocha_key = os.environ.get("BOCHA_API_KEY")
        if bocha_key:
            answer = self._bocha_search(question, bocha_key)
        else:
            # æ—  API æ—¶ä½¿ç”¨ LLM ç›´æ¥å›ç­”
            client = get_llm_client()
            try:
                response = client.chat(
                    [{"role": "user", "content": question}],
                    temperature=0.7,
                    max_tokens=500,
                )
                answer = response.content if hasattr(response, "content") else str(response)
            except Exception as e:
                answer = f"å›ç­”ç”Ÿæˆå¤±è´¥: {e}"

        print("ğŸ¤– Web å›ç­”å®Œæˆ")
        return {"question": question, "answer": answer, "source": "Webæœç´¢/LLMç›´ç­”"}

    def _bocha_search(self, question: str, api_key: str) -> str:
        """è°ƒç”¨åšæŸ¥æœç´¢ API"""
        try:
            import requests

            resp = requests.post(
                "https://api.bocha.com/v1/search",
                headers={"Authorization": f"Bearer {api_key}"},
                json={"query": question, "count": 3},
                timeout=10,
            )
            if resp.ok:
                data = resp.json()
                results = data.get("results", [])
                if results:
                    context = "\n\n".join([r.get("snippet", "") for r in results[:3]])
                    # ç”¨ LLM ç”Ÿæˆå›ç­”
                    client = get_llm_client()
                    response = client.chat(
                        [
                            {
                                "role": "user",
                                "content": QA_PROMPT_TEMPLATE.format(
                                    context=context, question=question
                                ),
                            }
                        ],
                        temperature=0.7,
                        max_tokens=500,
                    )
                    return response.content if hasattr(response, "content") else str(response)
            return f"æœªæ‰¾åˆ°å…³äº'{question}'çš„æœç´¢ç»“æœã€‚"
        except Exception as e:
            return f"Web æœç´¢å¤±è´¥: {e}"


# ============================================================
# Sink: ç»“æœè¾“å‡ºï¼ˆä¸æ—§ç‰ˆ TerminalSink ä¸€è‡´ï¼‰
# ============================================================


class TerminalSink(SinkFunction):
    """
    ç»ˆç«¯è¾“å‡º Sinkã€‚
    å¯¹åº”æ—§ç‰ˆ TerminalSink
    """

    def execute(self, data: dict):
        question = data.get("question", "")
        answer = data.get("answer", "")
        source = data.get("source", "æœªçŸ¥")

        print(f"\n{'â”€' * 60}")
        print(f"â“ é—®é¢˜: {question}")
        print(f"ğŸ“š æ¥æº: {source}")
        print(f"ğŸ’¬ å›ç­”: {answer}")
        print(f"{'â”€' * 60}\n")


# ============================================================
# ä¸»ç¨‹åºï¼šå®Œå…¨ä¿ç•™æ—§ç‰ˆçš„åŒåˆ†æ”¯ç»“æ„
# ============================================================


def run_adaptive_rag_v2():
    """
    è¿è¡Œ Adaptive RAG v2 æµæ°´çº¿

    ä¿ç•™æ—§ç‰ˆçš„åŒåˆ†æ”¯ç»“æ„ï¼š
    - å‘é‡åº“åˆ†æ”¯: RoutePrompt â†’ LLMGenerator â†’ RouteSplitter
                  â†’ Filter(vector) â†’ DenseRetriever â†’ QAPromptor â†’ QAGenerator â†’ Sink
    - Web åˆ†æ”¯:   RoutePrompt â†’ LLMGenerator â†’ RouteSplitter
                  â†’ Filter(web) â†’ WebSearchAgent â†’ Sink
    """
    print("ğŸš€ å¯åŠ¨ Adaptive RAG v2 ç³»ç»Ÿ")
    print(f"ğŸ“Š LLM æœåŠ¡: {LLM_BASE_URL} ({LLM_MODEL})")
    print(f"ğŸ“Š Embedding æœåŠ¡: {EMBEDDING_BASE_URL} ({EMBEDDING_MODEL})")
    print("ğŸ“Š æµç¨‹: é—®é¢˜ â†’ è·¯ç”±åˆ¤æ–­ â†’ [å‘é‡åº“åˆ†æ”¯ | Webåˆ†æ”¯] â†’ å›ç­” â†’ è¾“å‡º")
    print("=" * 60)

    # é¢„åˆå§‹åŒ–ç»„ä»¶
    print("\nğŸ“¦ åˆå§‹åŒ–ç»„ä»¶...")
    get_llm_client()
    get_embedding_client()
    get_vector_collection()
    print()

    # åˆ›å»ºç¯å¢ƒ
    env = LocalEnvironment("adaptive_rag_v2")

    # é¢„è®¾é—®é¢˜åˆ—è¡¨
    questions = [
        "æ­¦æ±‰æœ‰å“ªäº›è‘—åæ™¯ç‚¹ï¼Ÿ",  # â†’ vectorstore
        "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",  # â†’ web_search
        "ç¥å†œæ¶æœ‰ä»€ä¹ˆå¥½ç©çš„ï¼Ÿ",  # â†’ vectorstore
        "Python æœ‰å“ªäº›å¸¸ç”¨çš„ Web æ¡†æ¶ï¼Ÿ",  # â†’ web_search
    ]

    # ========================================
    # æ„å»ºä¸»æµç¨‹ï¼ˆä¸æ—§ç‰ˆç»“æ„ä¸€è‡´ï¼‰
    # ========================================

    # ä¸» Query è·¯ç”±æµç¨‹
    # æ—§ç‰ˆ: env.from_source(FileSource).map(RoutePromptFunction).map(OpenAIGenerator).map(RouteSplitter)
    query_stream = (
        env.from_source(QuestionSource, questions)
        .map(RoutePromptFunction)  # æ„é€ è·¯ç”± prompt
        .map(LLMGenerator)  # LLM åˆ¤æ–­è·¯ç”±
        .flatmap(RouteSplitter)  # æ‰“ä¸Šè·¯ç”±æ ‡ç­¾ï¼ˆæ›¿ä»£ side_outputï¼‰
    )

    # ========================================
    # å‘é‡åº“åˆ†æ”¯ï¼ˆæ›¿ä»£ query_stream.side_output("vector")ï¼‰
    # ========================================
    # æ—§ç‰ˆ:
    #   query_stream.side_output("vector")
    #               .map(DenseRetriever)
    #               .map(QAPromptor)
    #               .map(OpenAIGenerator)
    #               .sink(TerminalSink)
    _vector_stream = (
        query_stream.filter(VectorRouteFilter)  # æ›¿ä»£ .side_output("vector")
        .map(DenseRetriever)  # å‘é‡æ£€ç´¢
        .map(QAPromptor)  # æ„é€  QA prompt
        .map(QAGenerator)  # ç”Ÿæˆå›ç­”
        .sink(TerminalSink)  # è¾“å‡º
    )

    # ========================================
    # Web æœç´¢åˆ†æ”¯ï¼ˆæ›¿ä»£ query_stream.side_output("web")ï¼‰
    # ========================================
    # æ—§ç‰ˆ:
    #   query_stream.side_output("web")
    #               .map(BaseAgent)
    #               .map(TerminalSink)
    _web_stream = (
        query_stream.filter(WebRouteFilter)  # æ›¿ä»£ .side_output("web")
        .map(WebSearchAgent)  # Web æœç´¢ + LLM å›ç­”
        .sink(TerminalSink)  # è¾“å‡º
    )

    # è¿è¡Œ
    try:
        env.submit()
        time.sleep(15)  # ç­‰å¾…å¤„ç†å®Œæˆ
        print("\nâœ… Adaptive RAG v2 å¤„ç†å®Œæˆ")
    except Exception as e:
        print(f"âŒ å¤„ç†å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
    finally:
        env.close()


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦åœ¨æµ‹è¯•æ¨¡å¼ä¸‹è¿è¡Œ
    if os.getenv("SAGE_EXAMPLES_MODE") == "test" or os.getenv("SAGE_TEST_MODE") == "true":
        print("ğŸ§ª Test mode detected - adaptive_rag_v2 example")
        print("âœ… Test passed: Example structure validated")
        sys.exit(0)

    CustomLogger.disable_global_console_debug()
    load_dotenv(override=False)
    run_adaptive_rag_v2()


# ============================================================
# Pipeline æ‹“æ‰‘å›¾
# ============================================================
#
#                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                     â”‚ QuestionSourceâ”‚
#                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#                             â”‚
#                             â–¼
#                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                   â”‚RoutePromptFunctionâ”‚
#                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                            â”‚
#                            â–¼
#                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                   â”‚  LLMGenerator   â”‚ â”€â”€â”€â”€â”€â–º LLM :8903
#                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                            â”‚
#                            â–¼
#                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#                   â”‚  RouteSplitter  â”‚  (FlatMap, æ›¿ä»£ side_output)
#                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#                            â”‚
#            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#            â”‚                               â”‚
#            â–¼                               â–¼
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚VectorRouteFilterâ”‚             â”‚ WebRouteFilter  â”‚
#   â”‚ route="vector"  â”‚             â”‚  route="web"    â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#            â”‚                               â”‚
#            â–¼                               â–¼
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚ DenseRetriever  â”‚             â”‚ WebSearchAgent  â”‚
#   â”‚                 â”‚             â”‚                 â”‚
#   â”‚ Embedding :8090 â”‚             â”‚   LLM :8903     â”‚
#   â”‚ SimpleVectorDB  â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
#            â”‚                               â”‚
#            â–¼                               â”‚
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
#   â”‚   QAPromptor    â”‚                      â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
#            â”‚                               â”‚
#            â–¼                               â”‚
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
#   â”‚   QAGenerator   â”‚ â”€â”€â”€â”€â”€â–º LLM :8903     â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
#            â”‚                               â”‚
#            â–¼                               â–¼
#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#   â”‚  TerminalSink   â”‚             â”‚  TerminalSink   â”‚
#   â”‚   (çŸ¥è¯†åº“å›ç­”)   â”‚             â”‚  (Web/LLMå›ç­”)  â”‚
#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# ============================================================
# è¿œç¨‹æœåŠ¡ (11.11.11.7)
# ============================================================
#   :8903  Qwen/Qwen2.5-7B-Instruct   LLM
#   :8090  BAAI/bge-large-zh-v1.5     Embedding
#
# ============================================================
# æ ¸å¿ƒå˜æ›´: side_output â†’ FlatMap + Filter
# ============================================================
#   æ—§ç‰ˆ: query_stream.side_output("vector")
#   æ–°ç‰ˆ: query_stream.flatmap(RouteSplitter).filter(VectorRouteFilter)
# ============================================================
