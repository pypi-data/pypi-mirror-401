import json
import re
import subprocess
import tempfile
from copy import copy, deepcopy
from pathlib import Path
from typing import Any, Literal, TypeAlias

from datamodel_code_generator import (
    InputFileType,
    LiteralType,
    PythonVersion,
    generate,
)
from datamodel_code_generator.enums import DataModelType

from inspect_flow._types.flow_types import FlowSpec

GenType = Literal["Dict", "MatrixDict"]

GENERATED_CODE_COMMENT = [
    "# generated by type_gen.py (using datamodel-codegen)\n",
    "\n",
]

ADDITIONAL_IMPORTS = [
    "from typing_extensions import TypedDict\n",
    "from inspect_ai.model import BatchConfig, CachePolicy, GenerateConfig, ResponseSchema\n",
    "from inspect_ai.util import SandboxEnvironmentSpec\n",
    "from inspect_ai.approval._policy import ApprovalPolicyConfig\n",
    "from inspect_flow._types.flow_types import FlowAgent, FlowEpochs, FlowModel, FlowScorer, FlowSolver, NotGiven\n",
]

STR_AS_CLASS = ["FlowTask", "FlowModel", "FlowSolver", "FlowAgent"]

MATRIX_CLASS_FIELDS = {
    "FlowTask": ["args", "solver", "model", "config", "model_roles"],
    "FlowModel": ["config"],
    "FlowSolver": ["args"],
    "FlowAgent": ["args"],
    "GenerateConfig": [
        "system_message",
        "max_tokens",
        "top_p",
        "temperature",
        "stop_seqs",
        "best_of",
        "frequency_penalty",
        "presence_penalty",
        "logit_bias",
        "seed",
        "top_k",
        "num_choices",
        "logprobs",
        "top_logprobs",
        "parallel_tool_calls",
        "internal_tools",
        "max_tool_output",
        "cache_prompt",
        "reasoning_effort",
        "reasoning_tokens",
        "reasoning_summary",
        "reasoning_history",
        "response_schema",
        "extra_body",
    ],
}

Schema: TypeAlias = dict[str, Any]


def _field_type_to_list(field_schema: Schema) -> None:
    field_type: Schema
    if "type" in field_schema:
        type = field_schema["type"]
        if type == "array":
            field_type = {"type": type, "items": field_schema["items"]}
            del field_schema["items"]
        else:
            field_type = {"type": type}
        del field_schema["type"]
    elif "anyOf" in field_schema:
        any_of: list[Schema] = field_schema["anyOf"]
        del field_schema["anyOf"]
        field_type = {"anyOf": any_of}
    else:
        # Any type
        field_type = {}

    field_schema["anyOf"] = [{"type": "array", "items": field_type}, {"type": "null"}]
    if "default" not in field_schema:
        field_schema["default"] = None


def _root_type_as_def(schema: Schema) -> None:
    """Move the root type to $defs. This ensures all types can be handled uniformly."""
    defs: Schema = schema["$defs"]
    del schema["$defs"]
    root_type = copy(schema)
    schema.clear()
    defs[root_type["title"]] = root_type
    schema["$defs"] = defs


def _create_dict(dict_def: Schema) -> None:
    properties: Schema = dict_def["properties"]
    if "name" in properties:
        value = properties["name"]
        if "type" in value and value["type"] == "string" and "default" not in value:
            del value["type"]
            value["anyOf"] = [{"type": "string"}, {"type": "null"}]
            value["default"] = None


def _create_matrix_dict(dict_def: Schema, title: str) -> None:
    properties: Schema = dict_def["properties"]
    for name, value in list(properties.items()):
        if name in MATRIX_CLASS_FIELDS[title]:
            _field_type_to_list(value)
        else:
            del properties[name]


def _create_type(defs: Schema, title: str, base_type: Schema, type: GenType) -> None:
    dict_def = deepcopy(base_type)
    if type == "Dict":
        _create_dict(dict_def)
    else:
        _create_matrix_dict(dict_def, title)

    new_title = title + type
    dict_def["title"] = new_title
    defs[new_title] = dict_def


def _update_field_refs(field_schema: Schema, parent_list: list[Schema] | None) -> None:
    if "anyOf" in field_schema:
        any_of_list: list[Schema] = field_schema["anyOf"]
        for field in list(any_of_list):
            _update_field_refs(field, any_of_list)
    if "items" in field_schema:
        items_def = field_schema["items"]
        _update_field_refs(items_def, None)
    if "additionalProperties" in field_schema:
        additional_properties = field_schema["additionalProperties"]
        if isinstance(additional_properties, dict):
            _update_field_refs(additional_properties, None)
    if "$ref" in field_schema:
        type: str = field_schema["$ref"]
        split = type.split("/")
        type_name = split[-1]
        if type_name in STR_AS_CLASS:
            if parent_list:
                parent_list.append({"type": "string"})
            else:
                del field_schema["$ref"]
                ref_list = [{"$ref": type}, {"type": "string"}]
                field_schema["anyOf"] = ref_list


def _update_refs(type_def: Schema) -> None:
    properties: Schema = type_def["properties"]
    for field_value in properties.values():
        _update_field_refs(field_value, None)


def _create_dict_types(schema: Schema, initial_defs: Schema) -> None:
    defs: Schema = schema["$defs"]
    for title, type_def in initial_defs.items():
        if title in MATRIX_CLASS_FIELDS:
            _create_type(defs, title, type_def, "Dict")
            _create_type(defs, title, type_def, "MatrixDict")


def _update_def_titles_and_refs(schema: Schema) -> None:
    defs: Schema = schema["$defs"]
    for type_def in dict(defs).values():
        _update_refs(type_def)


class GeneratedCode:
    comment: list[str] = GENERATED_CODE_COMMENT
    imports: list[str] = ADDITIONAL_IMPORTS
    classes: list[str] = []

    def lines(self) -> list[str]:
        return self.comment + self.imports + self.classes


def _generate_dict_code() -> GeneratedCode:
    schema = FlowSpec.model_json_schema()
    _root_type_as_def(schema)
    _update_def_titles_and_refs(schema)
    initial_defs: dict[str, Schema] = schema["$defs"]
    schema["$defs"] = {}
    _create_dict_types(schema, initial_defs)

    with tempfile.NamedTemporaryFile(mode="w+", suffix=".py") as tmp_file:
        generated_type_file = Path(tmp_file.name)

        generate(
            json.dumps(schema),
            input_file_type=InputFileType.JsonSchema,
            output=generated_type_file,
            output_model_type=DataModelType.TypingTypedDict,
            target_python_version=PythonVersion.PY_310,
            use_generic_container_types=True,
            use_field_description=True,
            use_schema_description=True,
            use_default_kwarg=True,
            enum_field_as_literal=LiteralType.All,
        )

        with open(generated_type_file, "r") as f:
            dict_lines = f.readlines()

        code = GeneratedCode()
        _add_generated_code(code, dict_lines, "dict")

    return code


def _add_docstr_line(line: str, result: list[str]) -> None:
    indent = line[: len(line) - len(line.lstrip())]
    split = line.strip().split("\\n")
    result.extend([f"{indent}{li}\n" if li else "\n" for li in split])


def _expand_docstring_newlines(lines: list[str]) -> list[str]:
    r"""Convert literal \\n in docstrings to actual newlines."""
    result: list[str] = []
    in_docstring = False

    for line in lines:
        stripped = line.strip()

        # Check if this line starts a docstring
        if not in_docstring and stripped.startswith('"""'):
            if not (stripped.endswith('"""') and len(stripped) >= 6):
                in_docstring = True
            _add_docstr_line(line, result)
        elif in_docstring:
            if stripped.endswith('"""'):
                in_docstring = False
            _add_docstr_line(line, result)
        else:
            result.append(line)

    return result


def _convert_multiline_docstrings_to_single_line(lines: list[str]) -> list[str]:
    """Convert multi-line docstrings to single-line format when they contain only one line of text."""
    result: list[str] = []
    in_docstring = False
    docstring_lines: list[str] = []
    docstring_indent = ""
    original_lines = []

    for line in lines:
        stripped = line.strip()

        # Check if this line starts a docstring
        if not in_docstring and stripped.startswith('"""'):
            # Check if it's already a single-line docstring
            if stripped.endswith('"""') and len(stripped) > 6:
                result.append(line)
                continue
            # Start collecting a multi-line docstring
            in_docstring = True
            original_lines = [line]
            docstring_indent = line[: len(line) - len(line.lstrip())]
            docstring_lines = [stripped[3:]]  # Remove opening """
        elif in_docstring:
            # Check if this line ends the docstring
            if stripped.endswith('"""'):
                # Add the final content (without closing """)
                content = stripped[:-3].strip()
                if content:
                    docstring_lines.append(content)

                # Filter out empty lines
                non_empty_lines = [line for line in docstring_lines if line.strip()]

                # Only convert to single-line if there's exactly one line of content
                if len(non_empty_lines) == 1:
                    full_docstring = non_empty_lines[0].strip()
                    result.append(f'{docstring_indent}"""{full_docstring}"""\n')
                else:
                    result.extend(original_lines)
                    result.append(line)

                in_docstring = False
            else:
                # Continue collecting docstring content
                original_lines.append(line)
                docstring_lines.append(line)
        else:
            result.append(line)

    return result


def _add_generated_code(
    code: GeneratedCode, lines: list[str], mode: Literal["dict", "pydantic"]
) -> None:
    section = "comment"
    for line in lines:
        if section == "comment":
            # Do not maintain the comment (it includes a timestamp which changes each time)
            if line.strip().startswith("from"):
                section = "imports"

        if section == "imports":
            if line.strip().startswith("class") or line[0] == "@":
                section = "classes"
            elif line.strip().startswith("Model:"):
                # Not sure where this line comes from, but don't want it
                continue
            elif "TypeAlias = Any" in line:
                # Skip this line which datamodel-codegen adds for some reason
                continue
            else:
                # Remove TypedDict from the import line but keep other imports
                modified_line = re.sub(r",?\s*TypedDict\s*", "", line)
                code.imports.append(modified_line)

        if section == "classes":
            if line.strip().startswith("class"):
                code.classes.append(line)
            elif line[0].isspace() or line[0] == "@":
                code.classes.append(line)


def _fix_docstrings(code: GeneratedCode) -> None:
    # First pass: expand literal \n in docstrings to actual newlines
    code.classes = _expand_docstring_newlines(code.classes)

    # Second pass: convert multi-line docstrings to single-line when they contain only one line
    code.classes = _convert_multiline_docstrings_to_single_line(code.classes)


def _write_generated_code(file_name: str, code: GeneratedCode) -> None:
    output_file = Path(__file__).parent / file_name

    with open(output_file, "w") as f:
        f.writelines(code.lines())
    subprocess.run(["ruff", "check", "--fix", str(output_file)], check=True)
    subprocess.run(["ruff", "format", str(output_file)], check=True)


def main():
    code = _generate_dict_code()
    _fix_docstrings(code)
    _write_generated_code("generated.py", code)


if __name__ == "__main__":
    main()
