# generated by type_gen.py (using datamodel-codegen)

from __future__ import annotations

from collections.abc import Mapping, Sequence
from typing import Any, Literal

from inspect_ai.approval._policy import ApprovalPolicyConfig
from inspect_ai.model import BatchConfig, CachePolicy, GenerateConfig, ResponseSchema
from inspect_ai.util import SandboxEnvironmentSpec
from typing_extensions import NotRequired, TypedDict

from inspect_flow._types.flow_types import (
    FlowAgent,
    FlowEpochs,
    FlowModel,
    FlowScorer,
    FlowSolver,
    NotGiven,
)


class FlowAgentDict(TypedDict, closed=True):
    """Configuration for an Agent."""

    name: NotRequired[str | NotGiven | None]
    """Name of the agent. Required to be set by the time the agent is created."""
    args: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Additional args to pass to agent constructor."""
    flow_metadata: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Optional. Metadata stored in the flow config. Not passed to the agent."""
    type: NotRequired[Literal["agent"]]
    """Type needed to differentiated solvers and agents in solver lists."""


class FlowAgentMatrixDict(TypedDict, closed=True):
    """Configuration for an Agent."""

    args: NotRequired[Sequence[Mapping[str, Any] | NotGiven | None] | None]
    """Additional args to pass to agent constructor."""


class FlowModelDict(TypedDict, closed=True):
    """Configuration for a Model."""

    name: NotRequired[str | NotGiven | None]
    """Name of the model to use. Required to be set by the time the model is created."""
    role: NotRequired[str | NotGiven | None]
    """Optional named role for model (e.g. for roles specified at the task or eval level). Provide a default as a fallback in the case where the role hasn't been externally specified."""
    default: NotRequired[str | NotGiven | None]
    """Optional. Fallback model in case the specified model or role is not found. Should be a fully qualified model name (e.g. openai/gpt-4o)."""
    config: NotRequired[GenerateConfig | NotGiven | None]
    """Configuration for model. Config values will be override settings on the FlowTask and FlowSpec."""
    base_url: NotRequired[str | NotGiven | None]
    """Optional. Alternate base URL for model."""
    api_key: NotRequired[str | NotGiven | None]
    """Optional. API key for model."""
    memoize: NotRequired[bool | NotGiven | None]
    """Use/store a cached version of the model based on the parameters to get_model(). Defaults to True."""
    model_args: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Additional args to pass to model constructor."""
    flow_metadata: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Optional. Metadata stored in the flow config. Not passed to the model."""


class FlowModelMatrixDict(TypedDict, closed=True):
    """Configuration for a Model."""

    config: NotRequired[Sequence[GenerateConfig | NotGiven | None] | None]
    """Configuration for model. Config values will be override settings on the FlowTask and FlowSpec."""


class FlowSolverDict(TypedDict, closed=True):
    """Configuration for a Solver."""

    name: NotRequired[str | NotGiven | None]
    """Name of the solver. Required to be set by the time the solver is created."""
    args: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Additional args to pass to solver constructor."""
    flow_metadata: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Optional. Metadata stored in the flow config. Not passed to the solver."""


class FlowSolverMatrixDict(TypedDict, closed=True):
    """Configuration for a Solver."""

    args: NotRequired[Sequence[Mapping[str, Any] | NotGiven | None] | None]
    """Additional args to pass to solver constructor."""


class FlowTaskDict(TypedDict, closed=True):
    """
    Configuration for an evaluation task.

    Tasks are the basis for defining and running evaluations.
    """

    name: NotRequired[str | NotGiven | None]
    """Task name. Any of registry name ("inspect_evals/mbpp"), file name ("./my_task.py"), or a file name and attr ("./my_task.py@task_name"). Required to be set by the time the task is created."""
    args: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Additional args to pass to task constructor"""
    solver: NotRequired[
        str | FlowSolver | Sequence[str | FlowSolver] | FlowAgent | NotGiven | None
    ]
    """Solver or list of solvers. Defaults to generate(), a normal call to the model."""
    scorer: NotRequired[str | FlowScorer | Sequence[str | FlowScorer] | NotGiven | None]
    """Scorer or list of scorers used to evaluate model output."""
    model: NotRequired[str | FlowModel | NotGiven | None]
    """Default model for task (Optional, defaults to eval model)."""
    config: NotRequired[GenerateConfig | NotGiven]
    """Model generation config for default model (does not apply to model roles). Will override config settings on the FlowSpec. Will be overridden by settings on the FlowModel."""
    model_roles: NotRequired[Mapping[str, FlowModel | str] | NotGiven | None]
    """Named roles for use in `get_model()`."""
    sandbox: NotRequired[
        str | tuple[str, str] | SandboxEnvironmentSpec | NotGiven | None
    ]
    """Sandbox environment type (or optionally a str or tuple with a shorthand spec)"""
    approval: NotRequired[str | ApprovalPolicyConfig | NotGiven | None]
    """Tool use approval policies. Either a path to an approval policy config file or an approval policy config. Defaults to no approval policy."""
    epochs: NotRequired[int | FlowEpochs | NotGiven | None]
    """Epochs to repeat samples for and optional score reducer function(s) used to combine sample scores (defaults to "mean")"""
    fail_on_error: NotRequired[bool | float | NotGiven | None]
    """`True` to fail on first sample error (default); `False` to never fail on sample errors; Value between 0 and 1 to fail if a proportion of total samples fails. Value greater than 1 to fail eval if a count of samples fails."""
    continue_on_fail: NotRequired[bool | NotGiven | None]
    """`True` to continue running and only fail at the end if the `fail_on_error` condition is met. `False` to fail eval immediately when the `fail_on_error` condition is met (default)."""
    message_limit: NotRequired[int | NotGiven | None]
    """Limit on total messages used for each sample."""
    token_limit: NotRequired[int | NotGiven | None]
    """Limit on total tokens used for each sample."""
    time_limit: NotRequired[int | NotGiven | None]
    """Limit on clock time (in seconds) for samples."""
    working_limit: NotRequired[int | NotGiven | None]
    """Limit on working time (in seconds) for sample. Working time includes model generation, tool calls, etc. but does not include time spent waiting on retries or shared resources."""
    version: NotRequired[int | str | NotGiven]
    """Version of task (to distinguish evolutions of the task spec or breaking changes to it)"""
    metadata: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Additional metadata to associate with the task."""
    sample_id: NotRequired[str | int | Sequence[str | int] | NotGiven | None]
    """Evaluate specific sample(s) from the dataset."""
    flow_metadata: NotRequired[Mapping[str, Any] | NotGiven | None]
    """Optional. Metadata stored in the flow config. Not passed to the task."""


class FlowTaskMatrixDict(TypedDict, closed=True):
    """
    Configuration for an evaluation task.

    Tasks are the basis for defining and running evaluations.
    """

    args: NotRequired[Sequence[Mapping[str, Any] | NotGiven | None] | None]
    """Additional args to pass to task constructor"""
    solver: NotRequired[
        Sequence[
            str | FlowSolver | Sequence[str | FlowSolver] | FlowAgent | NotGiven | None
        ]
        | None
    ]
    """Solver or list of solvers. Defaults to generate(), a normal call to the model."""
    model: NotRequired[Sequence[str | FlowModel | NotGiven | None] | None]
    """Default model for task (Optional, defaults to eval model)."""
    config: NotRequired[Sequence[GenerateConfig | NotGiven] | None]
    """Model generation config for default model (does not apply to model roles). Will override config settings on the FlowSpec. Will be overridden by settings on the FlowModel."""
    model_roles: NotRequired[
        Sequence[Mapping[str, FlowModel | str] | NotGiven | None] | None
    ]
    """Named roles for use in `get_model()`."""


class GenerateConfigDict(TypedDict):
    """Model generation options."""

    max_retries: NotRequired[int | None]
    timeout: NotRequired[int | None]
    attempt_timeout: NotRequired[int | None]
    max_connections: NotRequired[int | None]
    system_message: NotRequired[str | None]
    max_tokens: NotRequired[int | None]
    top_p: NotRequired[float | None]
    temperature: NotRequired[float | None]
    stop_seqs: NotRequired[Sequence[str] | None]
    best_of: NotRequired[int | None]
    frequency_penalty: NotRequired[float | None]
    presence_penalty: NotRequired[float | None]
    logit_bias: NotRequired[Mapping[str, float] | None]
    seed: NotRequired[int | None]
    top_k: NotRequired[int | None]
    num_choices: NotRequired[int | None]
    logprobs: NotRequired[bool | None]
    top_logprobs: NotRequired[int | None]
    parallel_tool_calls: NotRequired[bool | None]
    internal_tools: NotRequired[bool | None]
    max_tool_output: NotRequired[int | None]
    cache_prompt: NotRequired[Literal["auto"] | bool | None]
    verbosity: NotRequired[Literal["low", "medium", "high"] | None]
    effort: NotRequired[Literal["low", "medium", "high"] | None]
    reasoning_effort: NotRequired[
        Literal["none", "minimal", "low", "medium", "high", "xhigh"] | None
    ]
    reasoning_tokens: NotRequired[int | None]
    reasoning_summary: NotRequired[
        Literal["none", "concise", "detailed", "auto"] | None
    ]
    reasoning_history: NotRequired[Literal["none", "all", "last", "auto"] | None]
    response_schema: NotRequired[ResponseSchema | None]
    extra_body: NotRequired[Mapping[str, Any] | None]
    cache: NotRequired[bool | CachePolicy | None]
    batch: NotRequired[bool | int | BatchConfig | None]


class GenerateConfigMatrixDict(TypedDict):
    """Model generation options."""

    system_message: NotRequired[Sequence[str | None] | None]
    max_tokens: NotRequired[Sequence[int | None] | None]
    top_p: NotRequired[Sequence[float | None] | None]
    temperature: NotRequired[Sequence[float | None] | None]
    stop_seqs: NotRequired[Sequence[Sequence[str] | None] | None]
    best_of: NotRequired[Sequence[int | None] | None]
    frequency_penalty: NotRequired[Sequence[float | None] | None]
    presence_penalty: NotRequired[Sequence[float | None] | None]
    logit_bias: NotRequired[Sequence[Mapping[str, float] | None] | None]
    seed: NotRequired[Sequence[int | None] | None]
    top_k: NotRequired[Sequence[int | None] | None]
    num_choices: NotRequired[Sequence[int | None] | None]
    logprobs: NotRequired[Sequence[bool | None] | None]
    top_logprobs: NotRequired[Sequence[int | None] | None]
    parallel_tool_calls: NotRequired[Sequence[bool | None] | None]
    internal_tools: NotRequired[Sequence[bool | None] | None]
    max_tool_output: NotRequired[Sequence[int | None] | None]
    cache_prompt: NotRequired[Sequence[Literal["auto"] | bool | None] | None]
    reasoning_effort: NotRequired[
        Sequence[Literal["none", "minimal", "low", "medium", "high", "xhigh"] | None]
        | None
    ]
    reasoning_tokens: NotRequired[Sequence[int | None] | None]
    reasoning_summary: NotRequired[
        Sequence[Literal["none", "concise", "detailed", "auto"] | None] | None
    ]
    reasoning_history: NotRequired[
        Sequence[Literal["none", "all", "last", "auto"] | None] | None
    ]
    response_schema: NotRequired[Sequence[ResponseSchema | None] | None]
    extra_body: NotRequired[Sequence[Mapping[str, Any] | None] | None]
