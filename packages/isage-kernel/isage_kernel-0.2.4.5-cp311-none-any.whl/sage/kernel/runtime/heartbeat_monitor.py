"""
HeartbeatMonitor V2 - ç®€åŒ–ç‰ˆå¿ƒè·³ç›‘æ§å™¨

é‡‡ç”¨ Pull æ¨¡å¼ç›´æ¥ä» Ray Task è·å–å¿ƒè·³ï¼Œæ— éœ€ HeartbeatCollector ä¸­ä»‹

æ ¸å¿ƒæ”¹è¿›:
1. ç›´æ¥è°ƒç”¨ ray_task.get_heartbeat_stats() è·å–å¿ƒè·³ä¿¡æ¯
2. è°ƒç”¨å¤±è´¥ç›´æ¥è§¦å‘ handle_failure (ä»»åŠ¡å·²å´©æºƒ)
3. è¿ç»­å¤šæ¬¡å¿ƒè·³ä¿¡æ¯å¼‚å¸¸ä¹Ÿè§¦å‘é‡å¯
4. æ›´ç®€æ´çš„æ¶æ„ï¼Œå‡å°‘ç»„ä»¶ä¾èµ–
"""

import logging
import threading
import time
from typing import TYPE_CHECKING, Any, Union

from sage.kernel.utils.ray.actor import ActorWrapper

if TYPE_CHECKING:
    from sage.kernel.runtime.dispatcher import Dispatcher
    from sage.kernel.runtime.task.base_task import BaseTask


class HeartbeatMonitor:
    """

    èŒè´£:
    1. å®šæœŸç›´æ¥è°ƒç”¨ Ray Task çš„ get_heartbeat_stats() è·å–å¿ƒè·³
    2. å¦‚æœè°ƒç”¨å¤±è´¥ï¼ˆä»»åŠ¡å´©æºƒ/ä¸å¯è¾¾ï¼‰â†’ ç«‹å³è§¦å‘ handle_failure
    3. å¦‚æœå¿ƒè·³ä¿¡æ¯å¼‚å¸¸ï¼ˆå¦‚è¿ç»­å¤šæ¬¡ä¸ºç©ºæˆ–ä¸æ­£å¸¸ï¼‰â†’ è§¦å‘ handle_failure

    è§¦å‘å®¹é”™çš„æ¡ä»¶:
    A. è°ƒç”¨ get_heartbeat_stats() æŠ¥é”™ (ä»»åŠ¡å´©æºƒ/ç½‘ç»œæ•…éšœ)
    B. è¿ç»­ max_missed_checks æ¬¡å¿ƒè·³ä¿¡æ¯ä¸ºç©ºæˆ–å¼‚å¸¸
    C. è¿ç»­ max_missed_checks æ¬¡å¿ƒè·³æ—¶é—´æˆ³æœªæ›´æ–°

    ä¼˜åŠ¿:
    - æ— éœ€ HeartbeatCollector ä¸­ä»‹ï¼Œå‡å°‘ç»„ä»¶
    - è°ƒç”¨å¤±è´¥å³å¯åˆ¤æ–­ä»»åŠ¡æ­»äº¡ï¼Œå“åº”æ›´å¿«
    - å¿ƒè·³æ•°æ®å®æ—¶è·å–ï¼Œæ— å»¶è¿Ÿ
    """

    def __init__(
        self,
        dispatcher: "Dispatcher",
        check_interval: float = 5.0,
        max_missed_checks: int = 3,
        call_timeout: float = 2.0,
    ):
        """
        åˆå§‹åŒ– HeartbeatMonitorV2

        Args:
            dispatcher: Dispatcher å®ä¾‹ (ç”¨äºè°ƒç”¨ handle_failure å’Œè·å– task å¼•ç”¨)
            check_interval: æ£€æŸ¥é—´éš” (ç§’)
            max_missed_checks: æœ€å¤§å…è®¸é”™è¿‡çš„æ£€æŸ¥æ¬¡æ•° (é»˜è®¤3æ¬¡)
            call_timeout: è°ƒç”¨ Ray task æ–¹æ³•çš„è¶…æ—¶æ—¶é—´ (ç§’)
        """
        self.dispatcher = dispatcher
        self.check_interval = check_interval
        self.max_missed_checks = max_missed_checks
        self.call_timeout = call_timeout

        # è®¡ç®—å®é™…è¶…æ—¶æ—¶é—´ (ç”¨äºæ—¥å¿—æ˜¾ç¤º)
        self.effective_timeout = check_interval * max_missed_checks

        # ç›‘æ§çº¿ç¨‹æ§åˆ¶
        self._monitor_thread: threading.Thread | None = None
        self._running = False
        self._stop_event = threading.Event()
        self._task_states: dict[str, dict[str, Any]] = {}
        self._states_lock = threading.Lock()

        # ç›‘æ§ç»Ÿè®¡
        self._stats = {
            "total_checks": 0,
            "total_call_failures": 0,
            "total_heartbeat_stale": 0,
            "total_failures_handled": 0,
            "last_check_time": None,
        }

        # Logger
        self.logger = logging.getLogger("HeartbeatMonitor")

        self.logger.info(
            f"âœ… HeartbeatMonitor initialized: "
            f"check_interval={check_interval}s, "
            f"max_missed_checks={max_missed_checks}, "
            f"effective_timeout={self.effective_timeout}s, "
            f"call_timeout={call_timeout}s"
        )

    def start(self):
        """å¯åŠ¨ç›‘æ§çº¿ç¨‹"""
        if self._running:
            self.logger.warning("HeartbeatMonitor already running")
            return

        self._running = True
        self._stop_event.clear()

        self._monitor_thread = threading.Thread(
            target=self._monitor_loop, name="HeartbeatMonitor", daemon=True
        )
        self._monitor_thread.start()

        self.logger.info("ğŸ” HeartbeatMonitor started")

    def stop(self):
        """åœæ­¢ç›‘æ§çº¿ç¨‹"""
        if not self._running:
            return

        self._running = False
        self._stop_event.set()

        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self._monitor_thread and self._monitor_thread.is_alive():
            self._monitor_thread.join(timeout=5.0)

            if self._monitor_thread.is_alive():
                self.logger.warning("Monitor thread did not stop gracefully")

        self.logger.info("ğŸ” HeartbeatMonitor stopped")

    def is_running(self) -> bool:
        """æ£€æŸ¥ç›‘æ§æ˜¯å¦è¿è¡Œä¸­"""
        return self._running

    def _get_active_tasks(self) -> dict[str, Union["BaseTask", ActorWrapper]]:
        """
        ä» Dispatcher è·å–æ‰€æœ‰æ´»è·ƒä»»åŠ¡çš„å¼•ç”¨

        """
        try:
            return self.dispatcher.tasks  # type: ignore[return-value]
        except Exception as e:
            self.logger.error(f"âŒ Failed to get active tasks from Dispatcher: {e}")
            return {}

    def _pull_heartbeat(
        self, task_id: str, task: Union["BaseTask", ActorWrapper]
    ) -> dict[str, Any] | None:
        """
        ä» Ray Task æ‹‰å–å¿ƒè·³ä¿¡æ¯

        Args:
            task_id: ä»»åŠ¡ ID
            task: Task å®ä¾‹æˆ– ActorWrapper

        Returns:
            å¿ƒè·³ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœè°ƒç”¨å¤±è´¥è¿”å› None
        """
        try:
            # è°ƒç”¨ Ray Task çš„ get_heartbeat_stats() æ–¹æ³•
            heartbeat = task.get_heartbeat_stats()  # type: ignore[union-attr]
            self.logger.debug(f"ğŸ’“ Pulled heartbeat from {task_id}: {heartbeat}")
            return heartbeat  # type: ignore[return-value]

        except Exception as e:
            # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼ˆåŒ…æ‹¬ Ray ç›¸å…³å¼‚å¸¸ï¼‰
            if "GetTimeoutError" in str(type(e).__name__):
                self.logger.warning(
                    f"âš ï¸  Timeout pulling heartbeat from {task_id} (timeout={self.call_timeout}s)"
                )
            elif "RayActorError" in str(type(e).__name__):
                self.logger.error(f"âŒ RayActorError when pulling heartbeat from {task_id}: {e}")
            else:
                self.logger.error(
                    f"âŒ Unexpected error pulling heartbeat from {task_id}: {e}",
                    exc_info=True,
                )
            return None

    def _validate_heartbeat(self, heartbeat: dict[str, Any] | None) -> bool:
        """
        éªŒè¯å¿ƒè·³ä¿¡æ¯æ˜¯å¦æ­£å¸¸

        Args:
            heartbeat: å¿ƒè·³ä¿¡æ¯å­—å…¸

        Returns:
            True å¦‚æœå¿ƒè·³æ­£å¸¸ï¼ŒFalse å¦‚æœå¼‚å¸¸
        """
        if heartbeat is None:
            return False

        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ["task_id", "timestamp", "status", "packet_count"]
        if not all(field in heartbeat for field in required_fields):
            self.logger.warning(f"âš ï¸  Heartbeat missing required fields: {heartbeat}")
            return False

        # æ£€æŸ¥ timestamp æ˜¯å¦åˆç†ï¼ˆä¸èƒ½æ˜¯æœªæ¥æ—¶é—´æˆ–è¿‡äºä¹…è¿œï¼‰
        timestamp = heartbeat.get("timestamp", 0)
        current_time = time.time()

        if timestamp <= 0:
            self.logger.warning(f"âš ï¸  Invalid timestamp: {timestamp}")
            return False

        if timestamp > current_time + 10:  # ä¸èƒ½è¶…å‰è¶…è¿‡10ç§’
            self.logger.warning(f"âš ï¸  Future timestamp: {timestamp}")
            return False

        # æ£€æŸ¥ is_running çŠ¶æ€
        if not heartbeat.get("is_running", False):
            self.logger.warning(f"âš ï¸  Task not running: {heartbeat}")
            return False

        return True

    def _monitor_loop(self):
        """
        ç›‘æ§ä¸»å¾ªç¯ (åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œ)

        æ£€æµ‹é€»è¾‘:
        1. ä» Dispatcher è·å–æ‰€æœ‰æ´»è·ƒä»»åŠ¡
        2. å¯¹æ¯ä¸ªä»»åŠ¡è°ƒç”¨ get_heartbeat_stats() æ‹‰å–å¿ƒè·³
        3. å¦‚æœè°ƒç”¨å¤±è´¥ â†’ consecutive_failures += 1
        4. å¦‚æœå¿ƒè·³æ— æ•ˆ â†’ consecutive_failures += 1
        5. å¦‚æœå¿ƒè·³æœ‰æ•ˆä½†æœªæ›´æ–° â†’ consecutive_stale += 1
        6. å¦‚æœå¿ƒè·³æœ‰æ•ˆä¸”å·²æ›´æ–° â†’ é‡ç½®æ‰€æœ‰è®¡æ•°å™¨
        7. è¶…è¿‡é˜ˆå€¼ â†’ è§¦å‘ handle_failure
        """
        self.logger.info("ğŸ” Monitor loop started")

        while self._running:
            try:
                current_time = time.time()

                # === æ­¥éª¤ 1: è·å–æ‰€æœ‰æ´»è·ƒä»»åŠ¡ ===
                active_tasks = self._get_active_tasks()

                if not active_tasks:
                    self.logger.debug("No active tasks to monitor")
                    # æ¸…ç†çŠ¶æ€
                    with self._states_lock:
                        self._task_states.clear()
                else:
                    self.logger.debug(f"ğŸ“Š Monitoring {len(active_tasks)} tasks")

                # === æ­¥éª¤ 2: æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„å¿ƒè·³ ===
                failed_tasks = []

                with self._states_lock:
                    for task_id, task in active_tasks.items():
                        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€ï¼ˆå¦‚æœæ˜¯æ–°ä»»åŠ¡ï¼‰
                        if task_id not in self._task_states:
                            self._task_states[task_id] = {
                                "last_valid_timestamp": 0,
                                "last_packet_count": 0,
                                "consecutive_failures": 0,
                                "consecutive_stale": 0,
                                "last_check_time": current_time,
                            }

                        state = self._task_states[task_id]

                        # === æ‹‰å–å¿ƒè·³ ===
                        heartbeat = self._pull_heartbeat(task_id, task)

                        # === æƒ…å†µ A: è°ƒç”¨å¤±è´¥ (ä»»åŠ¡å¯èƒ½å´©æºƒ) ===
                        if heartbeat is None:
                            state["consecutive_failures"] += 1
                            self._stats["total_call_failures"] += 1

                            self.logger.warning(
                                f"âš ï¸  Task {task_id} heartbeat call failed: "
                                f"consecutive_failures={state['consecutive_failures']}/{self.max_missed_checks}"
                            )

                            if state["consecutive_failures"] >= self.max_missed_checks:
                                self.logger.error(
                                    f"ğŸš¨ Task {task_id} FAILURE: "
                                    f"consecutive call failures={state['consecutive_failures']}"
                                )
                                failed_tasks.append((task_id, "call_failure", heartbeat))

                            continue

                        # === æƒ…å†µ B: å¿ƒè·³ä¿¡æ¯æ— æ•ˆ ===
                        if not self._validate_heartbeat(heartbeat):
                            state["consecutive_failures"] += 1

                            self.logger.warning(
                                f"âš ï¸  Task {task_id} heartbeat invalid: "
                                f"consecutive_failures={state['consecutive_failures']}/{self.max_missed_checks}"
                            )

                            if state["consecutive_failures"] >= self.max_missed_checks:
                                self.logger.error(
                                    f"ğŸš¨ Task {task_id} FAILURE: "
                                    f"consecutive invalid heartbeats={state['consecutive_failures']}"
                                )
                                failed_tasks.append((task_id, "invalid_heartbeat", heartbeat))

                            continue

                        # === æƒ…å†µ C: å¿ƒè·³æœ‰æ•ˆï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–° ===
                        current_timestamp = heartbeat.get("timestamp", 0)
                        current_packet_count = heartbeat.get("packet_count", 0)

                        last_timestamp = state["last_valid_timestamp"]
                        last_packet_count = state["last_packet_count"]

                        # åˆ¤æ–­å¿ƒè·³æ˜¯å¦æœ‰å®è´¨æ€§æ›´æ–°
                        # 1. timestamp å˜åŒ–
                        # 2. packet_count å¢åŠ  (è¡¨ç¤ºä»»åŠ¡åœ¨å¤„ç†æ•°æ®)
                        has_update = (
                            current_timestamp > last_timestamp
                            or current_packet_count > last_packet_count
                        )

                        if has_update:
                            # === å¿ƒè·³æœ‰æ›´æ–°ï¼Œé‡ç½®æ‰€æœ‰è®¡æ•°å™¨ ===
                            self.logger.debug(
                                f"ğŸ’“ Task {task_id} heartbeat updated: "
                                f"timestamp={current_timestamp:.1f} (was {last_timestamp:.1f}), "
                                f"packet_count={current_packet_count} (was {last_packet_count})"
                            )

                            state["last_valid_timestamp"] = current_timestamp
                            state["last_packet_count"] = current_packet_count
                            state["consecutive_failures"] = 0
                            state["consecutive_stale"] = 0
                            state["last_check_time"] = current_time

                        else:
                            # === å¿ƒè·³æœªæ›´æ–°ï¼ˆstaleï¼‰ ===
                            state["consecutive_stale"] += 1
                            self._stats["total_heartbeat_stale"] += 1

                            time_since_last = current_time - last_timestamp

                            self.logger.warning(
                                f"âš ï¸  Task {task_id} heartbeat stale: "
                                f"consecutive_stale={state['consecutive_stale']}/{self.max_missed_checks}, "
                                f"time_since_last={time_since_last:.1f}s"
                            )

                            if state["consecutive_stale"] >= self.max_missed_checks:
                                self.logger.error(
                                    f"ğŸš¨ Task {task_id} FAILURE: "
                                    f"consecutive stale heartbeats={state['consecutive_stale']}, "
                                    f"time_since_last={time_since_last:.1f}s"
                                )
                                failed_tasks.append((task_id, "stale_heartbeat", heartbeat))

                    # === æ¸…ç†å·²ä¸å­˜åœ¨çš„ä»»åŠ¡ ===
                    disappeared_tasks = set(self._task_states.keys()) - set(active_tasks.keys())
                    for task_id in disappeared_tasks:
                        self.logger.info(f"ğŸ—‘ï¸  Task {task_id} removed from monitoring")
                        self._task_states.pop(task_id, None)

                # === æ­¥éª¤ 3: å¤„ç†å¤±è´¥ä»»åŠ¡ ===
                if failed_tasks:
                    self.logger.warning(f"âš ï¸  Detected {len(failed_tasks)} failed tasks")

                    for task_id, failure_type, heartbeat in failed_tasks:
                        self.logger.error(
                            f"ğŸš¨ Handling FAILURE: task_id={task_id}, "
                            f"type={failure_type}, heartbeat={heartbeat}"
                        )

                        # è°ƒç”¨ Dispatcher å¤„ç†æ•…éšœ
                        try:
                            Exception(f"Heartbeat failure: {failure_type}")

                            # è°ƒç”¨å®¹é”™å¤„ç†å™¨çš„ handle_failure
                            # CheckpointBasedRecovery ä¼šï¼š
                            # 1. æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤ï¼ˆæœ‰ checkpoint + æœªè¶…è¿‡é‡è¯•æ¬¡æ•°ï¼‰
                            # 2. å¦‚æœå¯ä»¥ï¼Œè°ƒç”¨ dispatcher.restart_task_with_state
                            # 3. å¤„ç†æ‰€æœ‰å®¹é”™é€»è¾‘ï¼ˆé‡è¯•ç­–ç•¥ã€çŠ¶æ€æ¢å¤ç­‰ï¼‰
                            # self.dispatcher.fault_handler.handle_failure(task_id, error)
                            self._stats["total_failures_handled"] += 1

                            # ä»ç›‘æ§çŠ¶æ€ä¸­ç§»é™¤ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
                            with self._states_lock:
                                self._task_states.pop(task_id, None)

                        except Exception as e:
                            self.logger.error(
                                f"âŒ Failed to handle failure for {task_id}: {e}",
                                exc_info=True,
                            )

                # === æ­¥éª¤ 4: æ›´æ–°ç»Ÿè®¡ ===
                self._stats["total_checks"] += 1
                self._stats["last_check_time"] = current_time

                # === æ­¥éª¤ 5: ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥ ===
                if self._stop_event.wait(timeout=self.check_interval):
                    # æ”¶åˆ°åœæ­¢ä¿¡å·
                    break

            except Exception as e:
                self.logger.error(f"âŒ Unexpected error in monitor loop: {e}", exc_info=True)
                # é¿å…æ— é™é”™è¯¯å¾ªç¯
                time.sleep(1.0)

        self.logger.info("ğŸ” Monitor loop stopped")

    def get_stats(self) -> dict[str, Any]:
        """
        è·å–ç›‘æ§ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        with self._states_lock:
            active_tasks = len(self._task_states)
            task_states_snapshot = {
                task_id: {
                    "consecutive_failures": state["consecutive_failures"],
                    "consecutive_stale": state["consecutive_stale"],
                    "time_since_update": time.time() - state["last_valid_timestamp"],
                }
                for task_id, state in self._task_states.items()
            }

        return {
            "running": self._running,
            "check_interval": self.check_interval,
            "max_missed_checks": self.max_missed_checks,
            "effective_timeout": self.effective_timeout,
            "call_timeout": self.call_timeout,
            "active_tasks": active_tasks,
            "task_states": task_states_snapshot,
            **self._stats,
        }

    def get_task_status(self, task_id: str) -> dict[str, Any] | None:
        """
        è·å–æŒ‡å®šä»»åŠ¡çš„ç›‘æ§çŠ¶æ€

        Args:
            task_id: ä»»åŠ¡ ID

        Returns:
            ç›‘æ§çŠ¶æ€ä¿¡æ¯,å¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        with self._states_lock:
            state = self._task_states.get(task_id)

            if state is None:
                return None

            current_time = time.time()

            return {
                "task_id": task_id,
                "last_valid_timestamp": state["last_valid_timestamp"],
                "last_packet_count": state["last_packet_count"],
                "consecutive_failures": state["consecutive_failures"],
                "consecutive_stale": state["consecutive_stale"],
                "time_since_update": current_time - state["last_valid_timestamp"],
                "is_at_risk": (
                    state["consecutive_failures"] >= self.max_missed_checks - 1
                    or state["consecutive_stale"] >= self.max_missed_checks - 1
                ),
                "is_failed": (
                    state["consecutive_failures"] >= self.max_missed_checks
                    or state["consecutive_stale"] >= self.max_missed_checks
                ),
            }


__all__ = ["HeartbeatMonitor"]
