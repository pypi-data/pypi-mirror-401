import os
import time
from typing import TYPE_CHECKING, Any

from sage.common.utils.logging.custom_logger import CustomLogger
from sage.kernel.fault_tolerance.factory import (
    create_fault_handler_from_config,
    create_lifecycle_manager,
)
from sage.kernel.runtime.heartbeat_monitor import HeartbeatMonitor
from sage.kernel.scheduler.api import BaseScheduler
from sage.kernel.utils.helpers import wait_for_all_stopped
from sage.kernel.utils.ray.actor import ActorWrapper
from sage.kernel.utils.ray.ray_utils import ensure_ray_initialized

if TYPE_CHECKING:
    from sage.kernel.api.base_environment import BaseEnvironment
    from sage.kernel.runtime.context.service_context import ServiceContext
    from sage.kernel.runtime.graph.execution_graph import ExecutionGraph
    from sage.kernel.runtime.service.local_service_task import LocalServiceTask
    from sage.kernel.runtime.task.local_task import LocalTask


# è¿™ä¸ªdispatcherå¯ä»¥ç›´æ¥æ‰“åŒ…ä¼ ç»™ray sage daemon service
class Dispatcher:
    def __init__(self, graph: "ExecutionGraph", env: "BaseEnvironment"):
        self.total_stop_signals = graph.total_stop_signals
        self.received_stop_signals = 0
        self.graph = graph
        self.env = env
        self.name: str = env.name
        self.remote = env.platform == "remote"
        # self.nodes: Dict[str, Union[ActorHandle, LocalDAGNode]] = {}
        self.tasks: dict[str, LocalTask | ActorWrapper] = {}
        self.services: dict[str, LocalServiceTask | ActorWrapper] = {}  # å­˜å‚¨æœåŠ¡å®ä¾‹
        self.is_running: bool = False
        # è®°å½•ä¸»ç¯å¢ƒçš„åˆå§‹èŠ‚ç‚¹åˆ—è¡¨ï¼ˆä¸åŒ…æ‹¬ Service å†…éƒ¨èŠ‚ç‚¹ï¼‰
        self.main_env_nodes: set[str] = set()
        # HeartbeatMonitor å®ä¾‹ (ç›‘æ§çº¿ç¨‹)
        self.heartbeat_monitor: HeartbeatMonitor | None = None

        # å®¹é”™é…ç½®
        self.fault_tolerance_config = {
            "enabled": False,  # æ˜¯å¦å¯ç”¨å®¹é”™
            "heartbeat_interval": 5.0,  # å¿ƒè·³é—´éš” (ç§’)
            "heartbeat_timeout": 15.0,  # è¶…æ—¶é˜ˆå€¼ (ç§’)
            "max_restart_attempts": 3,  # æœ€å¤§é‡å¯æ¬¡æ•°
        }

        # å¯¹äº remote ç¯å¢ƒï¼Œå…ˆç¡®ä¿ Ray å·²åˆå§‹åŒ–ï¼Œè¿™æ · NodeSelector æ‰èƒ½è·å–èŠ‚ç‚¹ä¿¡æ¯
        if env.platform == "remote":
            ensure_ray_initialized()

        # ä½¿ç”¨è°ƒåº¦å™¨å’Œå®¹é”™ç®¡ç†å™¨ï¼ˆé‡æ„åæ¶æ„ï¼‰
        # è°ƒåº¦å™¨ï¼šçº¯å†³ç­–è€…ï¼ˆè¿”å› PlacementDecisionï¼‰
        # PlacementExecutorï¼šçº¯æ‰§è¡Œè€…ï¼ˆæ¥æ”¶å†³ç­–ï¼Œæ‰§è¡Œæ”¾ç½®ï¼‰
        # Dispatcherï¼šåè°ƒè€…ï¼ˆå†³ç­– â†’ æ‰§è¡Œï¼‰

        # åˆå§‹åŒ–è°ƒåº¦å™¨
        self.scheduler: BaseScheduler
        if hasattr(env, "scheduler") and env.scheduler is not None:
            self.scheduler = env.scheduler
        else:
            from sage.kernel.scheduler.impl import FIFOScheduler

            self.scheduler = FIFOScheduler(platform=env.platform)

        # åˆå§‹åŒ–æ”¾ç½®æ‰§è¡Œå™¨ï¼ˆç”± Dispatcher æŒæœ‰ï¼Œä¸åœ¨ Scheduler ä¸­ï¼‰
        from sage.kernel.scheduler.placement import PlacementExecutor

        self.placement_executor = PlacementExecutor()

        # ä» Environment é…ç½®åˆ›å»ºå®¹é”™å¤„ç†å™¨
        fault_tolerance_config = env.config.get("fault_tolerance", {})
        self.fault_handler = create_fault_handler_from_config(fault_tolerance_config)
        self.lifecycle_manager = create_lifecycle_manager()

        self.setup_logging_system()

        # æ³¨å…¥ logger åˆ°å®¹é”™ç®¡ç†å™¨
        self.fault_handler.logger = self.logger
        if hasattr(self.lifecycle_manager, "logger"):
            self.lifecycle_manager.logger = self.logger  # type: ignore
        self.fault_handler.dispatcher = self

        self.logger.info(f"Dispatcher '{self.name}' construction complete")
        if fault_tolerance_config:
            strategy = fault_tolerance_config.get("strategy", "restart")
            self.logger.info(f"Fault tolerance enabled: strategy={strategy}")
        if env.platform == "remote":
            self.logger.info(f"Dispatcher '{self.name}' is running in remote mode")

    def enable_fault_tolerance(
        self,
        heartbeat_interval: float = 5.0,
        heartbeat_timeout: float = 15.0,
        max_restart_attempts: int = 3,
    ):
        """
        å¯ç”¨ Remote ç¯å¢ƒæ•…éšœå®¹é”™

        Args:
            heartbeat_interval: å¿ƒè·³å‘é€é—´éš” (ç§’)
            heartbeat_timeout: å¿ƒè·³è¶…æ—¶é˜ˆå€¼ (ç§’)
            max_restart_attempts: æœ€å¤§é‡å¯å°è¯•æ¬¡æ•°
        """
        self.fault_tolerance_config.update(
            {
                "enabled": True,
                "heartbeat_interval": heartbeat_interval,
                "heartbeat_timeout": heartbeat_timeout,
                "max_restart_attempts": max_restart_attempts,
            }
        )

        self.logger.info(
            f"ğŸ›¡ï¸  Fault tolerance enabled: "
            f"interval={heartbeat_interval}s, timeout={heartbeat_timeout}s"
        )

    def _init_heartbeat_monitor(self):
        """
        åˆå§‹åŒ– HeartbeatMonitor ç›‘æ§çº¿ç¨‹

        åœ¨æ‰€æœ‰ä»»åŠ¡åˆ›å»ºåè°ƒç”¨,å¼€å§‹å¿ƒè·³ç›‘æ§
        """
        if not self.fault_tolerance_config["enabled"]:
            return

        if self.heartbeat_monitor is not None:
            self.logger.warning("HeartbeatMonitor already initialized")
            return

        try:
            from sage.kernel.runtime.heartbeat_monitor import HeartbeatMonitor

            # åˆ›å»º HeartbeatMonitor
            self.heartbeat_monitor = HeartbeatMonitor(
                dispatcher=self,
                check_interval=self.fault_tolerance_config["heartbeat_interval"],
            )
            # å¯åŠ¨ç›‘æ§çº¿ç¨‹
            self.heartbeat_monitor.start()

            self.logger.info("ğŸ” HeartbeatMonitor started")

        except Exception as e:
            self.logger.error(f"âŒ Failed to initialize HeartbeatMonitor: {e}", exc_info=True)

    def receive_stop_signal(self):
        """
        æ¥æ”¶åœæ­¢ä¿¡å·å¹¶å¤„ç†
        """
        self.logger.info("Dispatcher received stop signal.")
        self.received_stop_signals += 1
        if self.received_stop_signals >= self.total_stop_signals:
            self.logger.info(
                f"Received all {self.total_stop_signals} stop signals, stopping dispatcher for batch job."
            )
            self.cleanup()
            return True
        else:
            return False

    def receive_node_stop_signal(self, node_name: str) -> bool:
        """
        æ¥æ”¶å•ä¸ªèŠ‚ç‚¹çš„åœæ­¢ä¿¡å·

        Args:
            node_name: åœæ­¢çš„èŠ‚ç‚¹åç§°

        Returns:
            bool: å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½å·²åœæ­¢è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        self.logger.info(f"Dispatcher received node stop signal from: {node_name}")

        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
        if node_name not in self.tasks:
            self.logger.warning(f"Node {node_name} not found in tasks")
            return False

        # å¦‚æœè¿™æ˜¯ä¸€ä¸ªæºèŠ‚ç‚¹ï¼Œç›´æ¥é€šçŸ¥æ‰€æœ‰ç›¸å…³çš„ JoinOperator
        self._notify_join_operators_on_source_stop(node_name)

        # åœæ­¢å¹¶æ¸…ç†æŒ‡å®šèŠ‚ç‚¹
        try:
            # å†æ¬¡æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨ï¼ˆé˜²æ­¢ç«æ€æ¡ä»¶ï¼šåœ¨æ£€æŸ¥åã€æ‰§è¡Œå‰èŠ‚ç‚¹è¢«å…¶ä»–è°ƒç”¨åˆ é™¤ï¼‰
            if node_name not in self.tasks:
                self.logger.warning(
                    f"Node {node_name} was already removed from tasks (possible duplicate stop signal)"
                )
                return False

            task = self.tasks[node_name]
            task.stop()
            task.cleanup()

            # å¯¹äº Ray Actorï¼Œéœ€è¦æ˜¾å¼ kill ä»¥é‡Šæ”¾èµ„æº
            if self.remote and hasattr(task, "kill_actor"):
                kill_success = task.kill_actor(no_restart=True)
                self.logger.debug(
                    f"Kill actor {node_name}: {'success' if kill_success else 'skipped/failed'}"
                )

            # ä»ä»»åŠ¡åˆ—è¡¨ä¸­ç§»é™¤
            del self.tasks[node_name]

            # é€šçŸ¥è°ƒåº¦å™¨ä»»åŠ¡å·²å®Œæˆï¼ˆé‡Šæ”¾èµ„æºï¼‰
            if hasattr(self.scheduler, "task_completed"):
                try:
                    self.scheduler.task_completed(node_name)
                except Exception as scheduler_err:
                    self.logger.warning(
                        f"Scheduler task_completed notification failed for {node_name}: {scheduler_err}"
                    )

            self.logger.info(f"Node {node_name} stopped and cleaned up")

        except KeyError:
            # èŠ‚ç‚¹åœ¨å¤„ç†è¿‡ç¨‹ä¸­è¢«å…¶ä»–è°ƒç”¨åˆ é™¤ï¼ˆç«æ€æ¡ä»¶ï¼‰
            self.logger.warning(
                f"Node {node_name} was removed during stop process (concurrent stop signals)"
            )
            return False
        except Exception as e:
            self.logger.error(f"Error stopping node {node_name}: {e}", exc_info=True)
            return False

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä¸» Pipeline çš„èŠ‚ç‚¹éƒ½å·²åœæ­¢
        # ä½¿ç”¨åœ¨ submit() æ—¶è®°å½•çš„ main_env_nodes é›†åˆ
        # åªæœ‰ä¸»ç¯å¢ƒçš„èŠ‚ç‚¹éƒ½åœæ­¢äº†ï¼Œæ‰è§¦å‘æ¸…ç†
        remaining_main_nodes = [name for name in self.main_env_nodes if name in self.tasks]

        if len(remaining_main_nodes) == 0:
            self.logger.info("All main pipeline nodes stopped, batch processing completed")
            self.logger.info(
                f"Remaining service pipeline nodes: {len(self.tasks)} ({list(self.tasks.keys())})"
            )
            self.is_running = False

            # å½“æ‰€æœ‰ä¸»èŠ‚ç‚¹åœæ­¢åï¼Œæ¸…ç†æœåŠ¡
            if len(self.services) > 0:
                self.logger.info(
                    f"Cleaning up {len(self.services)} services after main pipeline completed"
                )
                self._cleanup_services_after_batch_completion()

            return True
        else:
            # ç»Ÿè®¡ä¸åŒç±»å‹çš„èŠ‚ç‚¹æ•°é‡ç”¨äºæ—¥å¿—
            service_nodes = [name for name in self.tasks.keys() if name not in self.main_env_nodes]
            self.logger.info(
                f"Remaining main pipeline nodes: {len(remaining_main_nodes)} {remaining_main_nodes}, "
                f"service pipeline nodes: {len(service_nodes)}, "
                f"total tasks: {len(self.tasks)}, services: {len(self.services)}"
            )
            return False

    def _notify_join_operators_on_source_stop(self, source_node_name: str):
        """å½“æºèŠ‚ç‚¹åœæ­¢æ—¶ï¼Œç›´æ¥é€šçŸ¥ç›¸å…³çš„ JoinOperator"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯æºèŠ‚ç‚¹ï¼ˆä»¥ "Source" å¼€å¤´ï¼‰
        if not source_node_name.startswith("Source"):
            return

        # æŸ¥æ‰¾æ‰€æœ‰çš„ JoinOperator
        for task_name, task in self.tasks.items():
            if (
                hasattr(task, "operator")
                and hasattr(task.operator, "handle_stop_signal")
                and hasattr(task.operator, "__class__")
                and "JoinOperator" in task.operator.__class__.__name__
            ):
                # è¿™æ˜¯ä¸€ä¸ª JoinOperatorï¼Œåˆ›å»ºä¸€ä¸ªåœæ­¢ä¿¡å·å¹¶ç›´æ¥å‘é€
                from sage.kernel.runtime.communication.packet import StopSignal

                stop_signal = StopSignal(source_node_name)

                try:
                    # ç›´æ¥è°ƒç”¨ JoinOperator çš„ handle_stop_signal æ–¹æ³•
                    if hasattr(task.operator, "handle_stop_signal"):
                        task.operator.handle_stop_signal(stop_signal)  # type: ignore
                        self.logger.info(
                            f"Notified JoinOperator {task_name} about source {source_node_name} stopping"
                        )
                except Exception as e:
                    self.logger.error(f"Failed to notify JoinOperator {task_name}: {e}")

    def _cleanup_services_after_batch_completion(self):
        """åœ¨æ‰¹å¤„ç†å®Œæˆåæ¸…ç†æ‰€æœ‰æœåŠ¡"""
        self.logger.info("Cleaning up services after batch completion")

        if self.remote:
            # æ¸…ç† Ray æœåŠ¡ (ä½¿ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨)
            # æ˜ç¡®ç¦æ­¢ Ray Actor é‡å¯ï¼Œç¡®ä¿å®Œå…¨æ¸…ç†
            try:
                self.lifecycle_manager.cleanup_all(
                    tasks={}, services=self.services, cleanup_timeout=5.0, no_restart=True
                )
            except Exception as e:
                self.logger.error(f"Error cleaning up Ray services: {e}")
        else:
            # æ¸…ç†æœ¬åœ°æœåŠ¡
            for service_name, service_task in list(self.services.items()):
                try:
                    # å…ˆåœæ­¢æœåŠ¡ï¼ˆå¦‚æœè¿˜åœ¨è¿è¡Œï¼‰
                    if hasattr(service_task, "is_running") and service_task.is_running:
                        self.logger.debug(f"Stopping service task: {service_name}")
                        if hasattr(service_task, "stop"):
                            service_task.stop()

                    # æ¸…ç†æœåŠ¡ï¼ˆæ— è®ºæ˜¯å¦åœ¨è¿è¡Œï¼‰
                    if hasattr(service_task, "cleanup"):
                        self.logger.debug(f"Cleaning up service task: {service_name}")
                        service_task.cleanup()

                    self.logger.info(f"Service task '{service_name}' cleaned up successfully")
                except Exception as e:
                    self.logger.error(f"Error cleaning up service task {service_name}: {e}")

        # æ¸…ç©ºæœåŠ¡å­—å…¸
        self.services.clear()
        self.logger.info("All services cleaned up")

    def _preinitialize_queue_descriptors(self):
        """
        åœ¨ä»»åŠ¡å¯åŠ¨å‰é¢„åˆå§‹åŒ–æ‰€æœ‰é˜Ÿåˆ—æè¿°ç¬¦

        è¿™ä¸ªæ–¹æ³•éå†æ‰€æœ‰ä»»åŠ¡çš„ä¸Šä¸‹æ–‡,è®¿é—®é˜Ÿåˆ—æè¿°ç¬¦çš„queue_instanceå±æ€§,
        å¼ºåˆ¶åœ¨ä¸»è¿›ç¨‹/driver contextä¸­å®ŒæˆRay Actorçš„åˆ›å»ºå’Œåˆå§‹åŒ–,
        é¿å…åœ¨Ray Taskæ‰§è¡ŒæœŸé—´æ‡’åˆå§‹åŒ–å¯¼è‡´çš„æ­»é”é—®é¢˜ã€‚
        """
        self.logger.info("Pre-initializing all queue descriptors to avoid deadlocks...")
        import time

        start_time = time.time()

        initialized_qds = set()  # ä½¿ç”¨é›†åˆè®°å½•å·²åˆå§‹åŒ–çš„é˜Ÿåˆ—(é€šè¿‡idå»é‡)

        # éå†æ‰€æœ‰ä»»åŠ¡,åˆå§‹åŒ–å…¶ä¸Šä¸‹æ–‡ä¸­çš„é˜Ÿåˆ—æè¿°ç¬¦
        for node_name, task in self.tasks.items():
            if not hasattr(task, "ctx") or task.ctx is None:
                continue

            ctx = task.ctx
            qd_list = []

            # æ”¶é›†è¾“å…¥é˜Ÿåˆ—æè¿°ç¬¦
            if hasattr(ctx, "input_qd") and ctx.input_qd is not None:
                qd_list.append(("input_qd", ctx.input_qd))

            # æ”¶é›†å“åº”é˜Ÿåˆ—æè¿°ç¬¦
            if hasattr(ctx, "response_qd") and ctx.response_qd is not None:
                qd_list.append(("response_qd", ctx.response_qd))

            # æ”¶é›†æ‰€æœ‰ä¸‹æ¸¸è¿æ¥çš„é˜Ÿåˆ—æè¿°ç¬¦
            if hasattr(ctx, "downstream_groups"):
                for output_index, connections in ctx.downstream_groups.items():
                    for parallel_idx, connection in connections.items():
                        if hasattr(connection, "queue_descriptor"):
                            qd_list.append(
                                (
                                    f"downstream_{output_index}_{parallel_idx}",
                                    connection.queue_descriptor,
                                )
                            )

            # åˆå§‹åŒ–è¿™äº›é˜Ÿåˆ—æè¿°ç¬¦
            for qd_name, qd in qd_list:
                qd_id = id(qd)
                if qd_id not in initialized_qds:
                    try:
                        # è®¿é—®queue_instanceå±æ€§è§¦å‘åˆå§‹åŒ–
                        _ = qd.queue_instance
                        initialized_qds.add(qd_id)
                        self.logger.debug(
                            f"Initialized queue descriptor: {qd_name} for task {node_name}"
                        )
                    except Exception as e:
                        self.logger.warning(
                            f"Failed to pre-initialize {qd_name} for {node_name}: {e}"
                        )

        elapsed = time.time() - start_time
        self.logger.info(
            f"Queue descriptor pre-initialization completed: {len(initialized_qds)} unique queues initialized in {elapsed:.3f}s"
        )

    def setup_logging_system(self):
        base_dir = self.env.env_base_dir if self.env.env_base_dir is not None else "."
        self.logger = CustomLogger(
            [
                ("console", "INFO"),  # æ§åˆ¶å°æ˜¾ç¤ºé‡è¦ä¿¡æ¯
                (
                    os.path.join(base_dir, "Dispatcher.log"),
                    "DEBUG",
                ),  # è¯¦ç»†æ—¥å¿—
                (os.path.join(base_dir, "Error.log"), "ERROR"),  # é”™è¯¯æ—¥å¿—
            ],
            name=f"Dispatcher_{self.name}",
        )

    def start(self):
        # ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨æ‰€æœ‰æœåŠ¡ä»»åŠ¡
        for service_name, service_task in self.services.items():
            try:
                if hasattr(service_task, "start_running"):
                    service_task.start_running()
                elif hasattr(service_task, "_actor"):
                    # ActorWrapperåŒ…è£…çš„æœåŠ¡ (_actor æ˜¯ ActorWrapper çš„å±æ€§)
                    import ray

                    actor_ref = service_task._actor  # type: ignore[attr-defined]
                    if hasattr(actor_ref, "start_running"):
                        ray.get(actor_ref.start_running.remote())  # type: ignore
                self.logger.debug(f"Started service task: {service_name}")
            except Exception as e:
                self.logger.error(
                    f"Failed to start service task {service_name}: {e}", exc_info=True
                )

        # ç¬¬å››æ­¥ï¼šæäº¤æ‰€æœ‰èŠ‚ç‚¹å¼€å§‹è¿è¡Œ
        task_list = list(self.tasks.items())
        self.logger.info(
            f"Preparing to start {len(task_list)} tasks: {[name for name, _ in task_list]}"
        )

        for node_name, task in task_list:
            try:
                self.logger.debug(f"Starting node: {node_name} (type: {type(task).__name__})")
                task.start_running()
                self.logger.debug(f"Started node: {node_name}")
            except Exception as e:
                self.logger.error(f"Failed to start node {node_name}: {e}", exc_info=True)

        self.logger.info(
            f"Job submission completed: {len(self.tasks)} nodes, {len(self.services)} service tasks"
        )
        if self.fault_tolerance_config["enabled"] and self.remote:
            self._init_heartbeat_monitor()
        self.is_running = True

    def _create_service_context(self, service_name: str) -> "ServiceContext | None":
        """
        è·å–service taskçš„ServiceContextï¼ˆä»execution graphä¸­å·²åˆ›å»ºçš„service nodeè·å–ï¼‰

        Args:
            service_name: æœåŠ¡åç§°

        Returns:
            ä»execution graphä¸­è·å–çš„ServiceContextï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
        """
        try:
            # ä»execution graphçš„service_nodesä¸­æŸ¥æ‰¾å¯¹åº”çš„service_node
            service_node = None
            for _node_name, node in self.graph.service_nodes.items():
                # é€šè¿‡service_factoryçš„åç§°åŒ¹é…
                if (
                    hasattr(node, "service_factory")
                    and node.service_factory
                    and node.service_factory.service_name == service_name
                ):
                    service_node = node
                    break

            if service_node is None:
                self.logger.error(
                    f"Service node for service '{service_name}' not found in execution graph"
                )
                return None

            # ç›´æ¥è¿”å›å·²ç»åˆ›å»ºå¥½çš„ServiceContext
            if not hasattr(service_node, "ctx") or service_node.ctx is None:
                self.logger.error(
                    f"ServiceContext not found in service node for service '{service_name}'"
                )
                return None

            self.logger.debug(
                f"Retrieved ServiceContext for service '{service_name}' from execution graph"
            )
            return service_node.ctx

        except Exception as e:
            self.logger.error(
                f"Failed to retrieve ServiceContext for service {service_name}: {e}",
                exc_info=True,
            )
            return None

    # Dispatcher will submit the job to LocalEngine or Ray Server.
    def submit(self):
        """
        ç¼–è¯‘å›¾ç»“æ„ï¼Œåˆ›å»ºèŠ‚ç‚¹å¹¶å»ºç«‹è¿æ¥

        é‡æ„åçš„æµç¨‹ï¼š
        1. è°ƒç”¨ Scheduler è·å–è°ƒåº¦å†³ç­–
        2. æ ¹æ®å†³ç­–ç­‰å¾…ï¼ˆå¦‚æœéœ€è¦å»¶è¿Ÿè°ƒåº¦ï¼‰
        3. è°ƒç”¨ PlacementExecutor æ‰§è¡Œç‰©ç†æ”¾ç½®
        4. å¯åŠ¨æ‰€æœ‰ä»»åŠ¡
        """
        self.logger.info(f"Compiling Job for graph: {self.name}")

        # ç¬¬ä¸€æ­¥ï¼šè°ƒåº¦æ‰€æœ‰æœåŠ¡ä»»åŠ¡
        for service_node_name, service_node in self.graph.service_nodes.items():
            service_name = None
            try:
                service_name = service_node.service_name

                # ä¸ºserviceåˆ›å»ºä¸“ç”¨çš„runtime context
                service_ctx = self._create_service_context(service_name)

                # === æ–°æ¶æ„ï¼šScheduler â†’ Decision â†’ Placement ===
                # 1. è·å–è°ƒåº¦å†³ç­–
                decision = self.scheduler.make_service_decision(service_node)

                self.logger.debug(f"Service scheduling decision for '{service_name}': {decision}")

                # 2. æ ¹æ®å†³ç­–ç­‰å¾…ï¼ˆå¦‚æœéœ€è¦å»¶è¿Ÿï¼‰
                if decision.delay > 0:
                    self.logger.debug(
                        f"Delaying service placement of '{service_name}' by {decision.delay}s"
                    )
                    time.sleep(decision.delay)

                # 3. æ‰§è¡Œç‰©ç†æ”¾ç½®
                service_task = self.placement_executor.place_service(
                    service_node=service_node,
                    decision=decision,
                    runtime_ctx=service_ctx,
                )
                self.services[service_name] = service_task

                self.logger.debug(
                    f"Placed service task '{service_name}' of type '{service_task.__class__.__name__}'"
                )
            except Exception as e:
                error_service = service_name if service_name else service_node_name
                self.logger.error(
                    f"Failed to schedule and place service task {error_service}: {e}",
                    exc_info=True,
                )
                # å¯ä»¥é€‰æ‹©ç»§ç»­æˆ–åœæ­¢ï¼Œè¿™é‡Œé€‰æ‹©ç»§ç»­ä½†è®°å½•é”™è¯¯

        # ç¬¬äºŒæ­¥ï¼šè°ƒåº¦æ‰€æœ‰è®¡ç®—ä»»åŠ¡èŠ‚ç‚¹
        # è®°å½•ä¸»ç¯å¢ƒçš„èŠ‚ç‚¹åç§°ï¼ˆç”¨äºåœæ­¢æ£€æµ‹ï¼‰
        #
        # é—®é¢˜ï¼šself.graph.nodes åŒ…å«æ‰€æœ‰èŠ‚ç‚¹ï¼ˆä¸» Pipeline + Service Pipeline å†…éƒ¨èŠ‚ç‚¹ï¼‰
        # è§£å†³ï¼šé€šè¿‡èŠ‚ç‚¹åç§°æ¨¡å¼è¯†åˆ«ä¸» Pipeline èŠ‚ç‚¹ï¼ˆç™½åå•ç­–ç•¥ï¼‰
        #
        # Service Pipeline çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆSource/Sink + å†…éƒ¨ Map èŠ‚ç‚¹ï¼‰éƒ½ä¸åº”è¯¥è¢«è®¡å…¥ä¸»èŠ‚ç‚¹
        # ç­–ç•¥ï¼šåªä¿ç•™ä¸å±äºä»»ä½• Service Pipeline çš„èŠ‚ç‚¹
        #
        # åˆ¤æ–­æ–¹æ³•ï¼šæ£€æŸ¥èŠ‚ç‚¹çš„ operator ç±»å‹
        # - PipelineServiceSource/Sink: Service Pipeline è¾¹ç•Œ
        # - å…¶ä»– Batch/Mapï¼šéœ€è¦è¿›ä¸€æ­¥åˆ¤æ–­
        #
        # æ›´ç®€å•çš„æ–¹æ³•ï¼šè®°å½•åœ¨ Service Pipeline æ·»åŠ å‰çš„èŠ‚ç‚¹æ•°
        # ä½†ç”±äº Service Pipeline å…ˆåˆ›å»ºï¼Œæˆ‘ä»¬éœ€è¦åå‘è¯†åˆ«
        #
        # æœ€å¯é çš„æ–¹æ³•ï¼šæ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨æŸä¸ª Service Pipeline çš„ sourceâ†’sink è·¯å¾„ä¸Š
        # ä½†è¿™éœ€è¦å›¾éå†ï¼Œå¤ªå¤æ‚
        #
        # å®ç”¨ç­–ç•¥ï¼šå…ˆè®°å½•æ‰€æœ‰èŠ‚ç‚¹ï¼Œsubmit å®Œæˆååªä¿ç•™ä¸» Pipeline èŠ‚ç‚¹
        # ä½†æˆ‘ä»¬åœ¨è¿™é‡Œæ— æ³•çŸ¥é“å“ªäº›æ˜¯ä¸»èŠ‚ç‚¹...
        #
        # æ¢ä¸ªè§’åº¦ï¼šæ‰€æœ‰èŠ‚ç‚¹å…±äº«åŒä¸€ä¸ª envï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç”¨æˆ·ä»£ç ä¸­æ ‡è®°
        # æˆ–è€…ï¼šService Pipeline çš„èŠ‚ç‚¹éƒ½ä¼šè¿æ¥åˆ° PipelineServiceSource/Sink
        #
        # æœ€ç»ˆæ–¹æ¡ˆï¼šé€’å½’æŸ¥æ‰¾æ‰€æœ‰è¿æ¥åˆ° PipelineServiceSource/Sink çš„èŠ‚ç‚¹
        service_pipeline_nodes = set()

        # æ‰¾å‡ºæ‰€æœ‰ PipelineServiceSource å’Œ PipelineServiceSink èŠ‚ç‚¹
        for node_name in self.graph.nodes.keys():
            if node_name.startswith("PipelineServiceSource") or node_name.startswith(
                "PipelineServiceSink"
            ):
                service_pipeline_nodes.add(node_name)

        # é€’å½’æ‰¾å‡ºæ‰€æœ‰è¿æ¥åˆ°è¿™äº›èŠ‚ç‚¹çš„èŠ‚ç‚¹
        # ä½¿ç”¨ BFS éå†å›¾
        from collections import deque

        queue = deque(service_pipeline_nodes)
        visited = set(service_pipeline_nodes)

        while queue:
            current_node = queue.popleft()
            # æŸ¥æ‰¾æ‰€æœ‰è¿æ¥åˆ°å½“å‰èŠ‚ç‚¹çš„è¾¹
            for edge_name, edge in self.graph.edges.items():
                # å¦‚æœè¾¹çš„èµ·ç‚¹æˆ–ç»ˆç‚¹æ˜¯å½“å‰èŠ‚ç‚¹ï¼Œå°†å¦ä¸€ç«¯æ·»åŠ åˆ° service_pipeline_nodes
                if (
                    edge.upstream_node.name == current_node
                    and edge.downstream_node
                    and edge.downstream_node.name not in visited
                ):
                    service_pipeline_nodes.add(edge.downstream_node.name)
                    visited.add(edge.downstream_node.name)
                    queue.append(edge.downstream_node.name)
                elif (
                    edge.downstream_node
                    and edge.downstream_node.name == current_node
                    and edge.upstream_node.name not in visited
                ):
                    service_pipeline_nodes.add(edge.upstream_node.name)
                    visited.add(edge.upstream_node.name)
                    queue.append(edge.upstream_node.name)

        # ä¸»èŠ‚ç‚¹ = æ‰€æœ‰èŠ‚ç‚¹ - Service Pipeline èŠ‚ç‚¹
        self.main_env_nodes = {
            name for name in self.graph.nodes.keys() if name not in service_pipeline_nodes
        }
        self.logger.info(
            f"Main environment nodes (total: {len(self.main_env_nodes)}): {self.main_env_nodes}"
        )
        self.logger.info(
            f"Service pipeline nodes (total: {len(service_pipeline_nodes)}): {service_pipeline_nodes}"
        )

        for node_name, graph_node in self.graph.nodes.items():
            try:
                # === æ–°æ¶æ„ï¼šScheduler â†’ Decision â†’ Placement ===
                # æ³¨å…¥ dispatcher å¼•ç”¨åˆ° context (ç”¨äºå®¹é”™å¤„ç†)
                # ctx åœ¨æ­¤æ—¶å·²ç»è¢«åˆ›å»ºï¼Œä¸ä¼šä¸º None
                graph_node.ctx.dispatcher = self  # type: ignore[union-attr]

                # 1. è·å–è°ƒåº¦å†³ç­–
                decision = self.scheduler.make_decision(graph_node)

                self.logger.debug(f"Task scheduling decision for '{node_name}': {decision}")

                # 2. æ ¹æ®å†³ç­–ç­‰å¾…ï¼ˆå¦‚æœéœ€è¦å»¶è¿Ÿè°ƒåº¦ï¼‰
                if decision.delay > 0:
                    self.logger.debug(
                        f"Delaying task placement of '{node_name}' by {decision.delay}s"
                    )
                    time.sleep(decision.delay)

                # 3. æ‰§è¡Œç‰©ç†æ”¾ç½®
                task = self.placement_executor.place_task(
                    task_node=graph_node, decision=decision, runtime_ctx=graph_node.ctx
                )
                self.tasks[node_name] = task

                self.logger.debug(
                    f"Placed task '{node_name}' of type '{task.__class__.__name__}' "
                    f"on node '{decision.target_node or 'default'}'"
                )
            except Exception as e:
                self.logger.error(
                    f"Failed to schedule and place task {node_name}: {e}", exc_info=True
                )
                raise e

        # è¿æ¥å…³ç³»å·²ç»åœ¨execution graphå±‚é€šè¿‡task contextè®¾ç½®å¥½äº†ï¼Œæ— éœ€åœ¨æ­¤å¤„è®¾ç½®

        # é¢„åˆå§‹åŒ–æ‰€æœ‰é˜Ÿåˆ—æè¿°ç¬¦(é˜²æ­¢åœ¨Ray Taskå†…éƒ¨æ‡’åˆå§‹åŒ–å¯¼è‡´æ­»é”)
        self._preinitialize_queue_descriptors()

        try:
            self.start()
        except Exception as e:
            self.logger.error(f"Error starting dispatcher: {e}", exc_info=True)
            raise e

    def stop(self):
        """åœæ­¢æ‰€æœ‰ä»»åŠ¡å’ŒæœåŠ¡"""
        if self.heartbeat_monitor is not None:
            self.logger.info("ğŸ” Stopping HeartbeatMonitor...")
            self.heartbeat_monitor.stop()
            self.heartbeat_monitor = None

        if not self.is_running:
            self.logger.warning("Dispatcher is not running")
            return

        self.logger.info(f"Stopping dispatcher '{self.name}'")

        # å‘é€åœæ­¢ä¿¡å·ç»™æ‰€æœ‰ä»»åŠ¡
        for node_name, node_instance in self.tasks.items():
            try:
                node_instance.stop()
                self.logger.debug(f"Sent stop signal to node: {node_name}")
            except Exception as e:
                self.logger.error(f"Error stopping node {node_name}: {e}")

        # åœæ­¢æ‰€æœ‰æœåŠ¡ä»»åŠ¡
        for service_name, service_task in self.services.items():
            try:
                service_task.stop()
                self.logger.debug(f"Stopped service task: {service_name}")
            except Exception as e:
                self.logger.error(f"Error stopping service task {service_name}: {e}")

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡åœæ­¢ï¼ˆæœ€å¤šç­‰å¾…10ç§’ï¼‰
        self._wait_for_tasks_stop(timeout=10.0)

        self.is_running = False
        self.logger.info("Dispatcher stopped")

    def _wait_for_tasks_stop(self, timeout: float = 10.0):
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡åœæ­¢"""
        wait_for_all_stopped(self.tasks, timeout=timeout, logger=self.logger)

    def cleanup(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        self.logger.info(f"Cleaning up dispatcher '{self.name}'")

        try:
            # åœæ­¢æ‰€æœ‰ä»»åŠ¡å’ŒæœåŠ¡
            if self.is_running:
                self.stop()

            self.logger.info(
                f"Cleanup: remote={self.remote}, tasks={len(self.tasks)}, services={len(self.services)}"
            )

            if self.remote:
                # ä½¿ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨æ¸…ç†æ‰€æœ‰Rayèµ„æº
                # æ˜ç¡®ç¦æ­¢ Ray Actor é‡å¯ï¼Œç¡®ä¿å®Œå…¨æ¸…ç†
                self.logger.info("Using lifecycle_manager to cleanup Ray actors...")
                results = self.lifecycle_manager.cleanup_all(
                    tasks=self.tasks, services=self.services, cleanup_timeout=5.0, no_restart=True
                )
                # è®°å½•æ¸…ç†ç»“æœ
                for task_id, (cleanup_ok, kill_ok) in results.items():
                    self.logger.info(
                        f"  Cleanup result for {task_id}: cleanup={cleanup_ok}, kill={kill_ok}"
                    )
            else:
                # æ¸…ç†æœ¬åœ°ä»»åŠ¡ï¼ˆä½¿ç”¨åˆ—è¡¨å‰¯æœ¬é¿å…è¿­ä»£æ—¶å­—å…¸å¤§å°æ”¹å˜ï¼‰
                for node_name, task in list(self.tasks.items()):
                    try:
                        task.cleanup()
                        self.logger.debug(f"Cleaned up task: {node_name}")
                    except Exception as e:
                        self.logger.error(f"Error cleaning up task {node_name}: {e}")

                # æ¸…ç†æœ¬åœ°æœåŠ¡ä»»åŠ¡ï¼ˆä½¿ç”¨åˆ—è¡¨å‰¯æœ¬é¿å…è¿­ä»£æ—¶å­—å…¸å¤§å°æ”¹å˜ï¼‰
                for service_name, service_task in list(self.services.items()):
                    try:
                        if hasattr(service_task, "cleanup"):
                            service_task.cleanup()
                        self.logger.debug(f"Cleaned up service task: {service_name}")
                    except Exception as e:
                        self.logger.error(f"Error cleaning up service task {service_name}: {e}")

            # æ¸…ç©ºä»»åŠ¡å’ŒæœåŠ¡å­—å…¸
            self.tasks.clear()
            self.services.clear()

            self.logger.info("Dispatcher cleanup completed")

        except Exception as e:
            self.logger.error(f"Error during dispatcher cleanup: {e}")

    def get_task_status(self) -> dict[str, Any]:
        """è·å–æ‰€æœ‰ä»»åŠ¡çš„çŠ¶æ€"""
        status = {}

        for node_name, task in self.tasks.items():
            try:
                task_status = {
                    "name": node_name,
                    "running": getattr(task, "is_running", False),
                    "processed_count": getattr(task, "_processed_count", 0),
                    "error_count": getattr(task, "_error_count", 0),
                }
                status[node_name] = task_status
            except Exception as e:
                status[node_name] = {"name": node_name, "error": str(e)}

        return status

    def get_service_status(self) -> dict[str, Any]:
        """è·å–æ‰€æœ‰æœåŠ¡ä»»åŠ¡çš„çŠ¶æ€"""
        status = {}

        for service_name, service_task in self.services.items():
            try:
                if hasattr(service_task, "get_statistics"):
                    service_status = service_task.get_statistics()
                elif hasattr(service_task, "_actor"):
                    # ActorWrapperåŒ…è£…çš„æœåŠ¡ (_actor æ˜¯ ActorWrapper çš„å±æ€§)
                    actor_ref = service_task._actor  # type: ignore[attr-defined]
                    if hasattr(actor_ref, "get_statistics"):
                        service_status = actor_ref.get_statistics()  # type: ignore
                    else:
                        service_status = {
                            "service_name": service_name,
                            "type": service_task.__class__.__name__,
                            "status": "unknown",
                        }
                else:
                    service_status = {
                        "service_name": service_name,
                        "type": service_task.__class__.__name__,
                        "status": "unknown",
                    }
                status[service_name] = service_status
            except Exception as e:
                status[service_name] = {"service_name": service_name, "error": str(e)}

        return status

    def restart_task(self, task_id: str, restore_state: dict | None = None) -> bool:
        """
        é‡å¯ä»»åŠ¡ï¼ˆç”¨äºå®¹é”™æ¢å¤ï¼‰

        Args:
            task_id: è¦é‡å¯çš„ä»»åŠ¡ ID
            restore_state: å¯é€‰çš„çŠ¶æ€ï¼Œå¦‚æœæä¾›åˆ™åœ¨å¯åŠ¨å‰æ¢å¤

        Returns:
            True å¦‚æœé‡å¯æˆåŠŸ
        """
        self.logger.info(f"ğŸ”„ Restarting task {task_id}")

        if task_id not in self.tasks:
            self.logger.error(f"âŒ Task {task_id} not found")
            return False

        try:
            task = self.tasks[task_id]

            # === æ­¥éª¤ 1: åœæ­¢æ—§ä»»åŠ¡ ===
            if hasattr(task, "is_running") and task.is_running:
                self.logger.debug(f"Stopping old task {task_id}...")
                if hasattr(task, "stop"):
                    task.stop()

                # ç­‰å¾…ä»»åŠ¡åœæ­¢
                import time

                max_wait = 5.0
                waited = 0.0
                while hasattr(task, "is_running") and task.is_running and waited < max_wait:
                    time.sleep(0.1)
                    waited += 0.1

                if hasattr(task, "is_running") and task.is_running:
                    self.logger.warning(f"âš ï¸ Task {task_id} did not stop gracefully")

            # === æ­¥éª¤ 2: æ¸…ç†æ—§ä»»åŠ¡èµ„æº ===
            if hasattr(task, "cleanup"):
                try:
                    self.logger.debug(f"Cleaning up old task {task_id}...")
                    task.cleanup()
                except Exception as cleanup_error:
                    self.logger.warning(f"âš ï¸ Error during cleanup: {cleanup_error}")

            # === æ­¥éª¤ 3: è·å– graph node å¹¶é‡æ–°åˆ›å»ºä»»åŠ¡ ===
            graph_node = self.graph.nodes.get(task_id)
            if not graph_node:
                self.logger.error(f"âŒ Graph node for {task_id} not found")
                return False

            # é‡æ–°æ³¨å…¥ dispatcher å¼•ç”¨åˆ° context
            if graph_node.ctx is not None:
                graph_node.ctx.dispatcher = self

            self.logger.debug(f"Creating new task instance for {task_id}...")

            decision = self.scheduler.make_decision(graph_node)
            new_task = self.placement_executor.place_task(
                task_node=graph_node, decision=decision, runtime_ctx=graph_node.ctx
            )

            # æ›¿æ¢æ—§ä»»åŠ¡
            self.tasks[task_id] = new_task

            self.logger.info(f"âœ… New task instance created for {task_id}")

            # === æ­¥éª¤ 4: å¦‚æœæœ‰çŠ¶æ€ï¼Œå…ˆæ¢å¤çŠ¶æ€ ===
            if restore_state and hasattr(new_task, "restore_state"):
                self.logger.debug(f"Restoring state for {task_id}...")
                try:
                    new_task.restore_state(restore_state)
                    self.logger.info(f"âœ… State restored for task {task_id}")
                except Exception as restore_error:
                    self.logger.error(
                        f"âŒ Failed to restore state for {task_id}: {restore_error}",
                        exc_info=True,
                    )
                    return False

            # === æ­¥éª¤ 5: å¯åŠ¨æ–°ä»»åŠ¡ ===
            self.logger.debug(f"Starting new task {task_id}...")
            new_task.start_running()

            self.logger.info(f"ğŸ‰ Task {task_id} restarted successfully")
            return True

        except Exception as e:
            self.logger.error(f"âŒ Failed to restart task {task_id}: {e}", exc_info=True)
            return False

    def restart_task_with_state(self, task_id: str, state: dict) -> bool:
        """
        é‡å¯ä»»åŠ¡å¹¶æ¢å¤çŠ¶æ€ï¼ˆä¸“é—¨ç”¨äº checkpoint æ¢å¤ï¼‰

        è¿™æ˜¯ restart_task çš„ä¾¿æ·æ–¹æ³•ï¼Œæ˜ç¡®è¡¨ç¤ºè¦æ¢å¤çŠ¶æ€

        Args:
            task_id: è¦é‡å¯çš„ä»»åŠ¡ ID
            state: è¦æ¢å¤çš„çŠ¶æ€

        Returns:
            True å¦‚æœé‡å¯å’Œæ¢å¤æˆåŠŸ
        """
        return self.restart_task(task_id, restore_state=state)
