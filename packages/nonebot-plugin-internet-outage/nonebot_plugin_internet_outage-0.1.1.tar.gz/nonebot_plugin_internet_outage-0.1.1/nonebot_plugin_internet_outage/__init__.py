from nonebot.plugin import PluginMetadata
from pydantic import BaseModel
from nonebot import get_bots, logger, get_plugin_config, require
from nonebot.adapters.onebot.v11 import Message

import httpx
import json
import datetime
from pathlib import Path

# -----------------------------
# æ’ä»¶é…ç½®
# -----------------------------
class InternetOutageConfig(BaseModel):
    outage_debug: bool = False
    outage_proxies: str = None
    outage_group_id: list[int | str] = []
    outage_cf_token: str

__plugin_meta__ = PluginMetadata(
    name="å…¨çƒäº’è”ç½‘ä¸­æ–­ç›‘æµ‹",
    description="åŸºäº Cloudflare Radar çš„å…¨çƒæ–­ç½‘äº‹ä»¶è‡ªåŠ¨æ¨é€",
    usage="è‡ªåŠ¨è¿è¡Œ",
    type="application",
    homepage="https://github.com/CN171-1/nonebot-plugin-internet-outage",
    supported_adapters={"~onebot.v11"},
    config=InternetOutageConfig,
)

config = get_plugin_config(InternetOutageConfig)

proxy = config.outage_proxies
group_ids = config.outage_group_id
CF_TOKEN = config.outage_cf_token

TRAFFIC_API = "https://api.cloudflare.com/client/v4/radar/traffic_anomalies"
OUTAGE_API = "https://api.cloudflare.com/client/v4/radar/annotations/outages"

OUTAGE_CAUSE_MAP = {
    "GOVERNMENT_DIRECTED": "æ”¿åºœå‘½ä»¤",
    "MILITARY_ACTION": "å†›äº‹è¡ŒåŠ¨å½±å“",
    "CABLE_CUT": "å…‰ç¼†æ–­è£‚",
    "POWER_OUTAGE": "å¤§è§„æ¨¡åœç”µ",
    "TECHNICAL_PROBLEM": "é‡å¤§æŠ€æœ¯æ•…éšœ",
    "NETWORK_CONGESTION": "ç½‘ç»œä¸¥é‡æ‹¥å¡",
    "UNKNOWN": "åŸå› æš‚ä¸æ˜ç¡®",
    "WEATHER": "è‡ªç„¶ç¾å®³",
    "MISCONFIGURATION": "é…ç½®é”™è¯¯",
    "DNS": "DNS æ•…éšœ",
}

OUTAGE_TYPE_MAP = {
    "NATIONWIDE": "å…¨å›½çº§ä¸­æ–­",
    "REGIONAL": "åŒºåŸŸçº§ä¸­æ–­",
    "NETWORK": "è¿è¥å•† / ç½‘ç»œçº§ä¸­æ–­",
    "PLATFORM": "å¹³å°çº§ä¸­æ–­",
}

require("nonebot_plugin_localstore")
require("nonebot_plugin_apscheduler")

import nonebot_plugin_localstore as store
from nonebot_plugin_apscheduler import scheduler

class StorageManager:
    def __init__(self):
        self.data_dir = Path(store.get_plugin_data_dir())
        self.data_dir.mkdir(parents=True, exist_ok=True)

    async def get_seen_dict(self, key: str) -> dict:
        file = self.data_dir / f"{key}.json"
        if file.exists():
            try:
                with open(file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception:
                return {}
        return {}

    async def save_seen_dict(self, key: str, data: dict):
        file = self.data_dir / f"{key}.json"
        with open(file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    async def is_first_run(self, key: str) -> bool:
        return not (self.data_dir / f"{key}.json").exists()

storage = StorageManager()

async def get_json(url: str, params: dict = None, timeout: int = 30) -> dict:
    """è·å–JSONæ•°æ®"""
    headers = {"Authorization": f"Bearer {CF_TOKEN}"}
    try:
        async with httpx.AsyncClient(timeout=timeout, headers=headers, proxy=proxy) as client:
            response = await client.get(url, params=params)
            response.raise_for_status()
            return response.json()
    except Exception as e:
        logger.error(f"è¯·æ±‚å¤±è´¥ {url}: {e}")
        return {}

async def fetch_traffic_anomalies():
    params = {"type": "LOCATION", "status": "VERIFIED", "dateRange": "7d"}
    data = await get_json(TRAFFIC_API, params)
    return data.get("result", {}).get("trafficAnomalies", [])

async def fetch_outages():
    params = {"dateRange": "7d"}
    data = await get_json(OUTAGE_API, params)
    return data.get("result", {}).get("annotations", [])

def match_outage(anomaly, outages):
    country = anomaly["locationDetails"]["code"]
    a_start = datetime.datetime.fromisoformat(anomaly["startDate"].replace("Z", "+00:00"))
    for o in outages:
        if country not in o["locations"]:
            continue
        o_start = datetime.datetime.fromisoformat(o["startDate"].replace("Z", "+00:00"))
        if abs((a_start - o_start).total_seconds()) <= 900:
            return o
    return None

def build_message(outage):
    loc = outage["locationsDetails"][0]["name"]
    cause = outage["outage"]["outageCause"]
    cause_cn = OUTAGE_CAUSE_MAP.get(cause, cause)
    otype = outage["outage"]["outageType"]
    otype_cn = OUTAGE_TYPE_MAP.get(otype, otype)
    return Message(
        f"ğŸŒ äº’è”ç½‘ä¸­æ–­äº‹ä»¶\n\n"
        f"ğŸ“ å›½å®¶ï¼š{loc}\n"
        f"ğŸ•’ å¼€å§‹æ—¶é—´ï¼š{outage['startDate']} UTC\n"
        f"ğŸ“¡ å½±å“èŒƒå›´ï¼š{otype_cn}\n"
        f"âš ï¸ åŸå› ï¼š{cause_cn}\n\n"
        f"ğŸ“ è¯´æ˜ï¼š\n{outage['description']}\n\n"
        f"ğŸ”— æ¥æºï¼š\n{outage['linkedUrl']}"
    )

def build_message_from_anomaly(anomaly):
    loc = anomaly["locationDetails"]["name"]
    start = anomaly["startDate"]
    return Message(
        f"âš ï¸ äº’è”ç½‘æµé‡å¼‚å¸¸\n\n"
        f"ğŸ“ å›½å®¶ï¼š{loc}\n"
        f"ğŸ•’ å¼€å§‹æ—¶é—´ï¼š{start} UTC\n"
        f"ğŸ’¡ å¤‡æ³¨ï¼šè¯¥äº‹ä»¶ä¸ºæµé‡å¼‚å¸¸ï¼Œå°šæœªç¡®è®¤ä¸­æ–­ã€‚"
    )

async def broadcast(message: Message):
    bots = get_bots()
    if not bots:
        return
    bot = list(bots.values())[0]
    if not group_ids:
        logger.warning("æœªé…ç½®æ¨é€ç¾¤ï¼Œè·³è¿‡")
        return
    for gid in group_ids:
        try:
            await bot.send_group_msg(group_id=int(gid), message=message)
        except Exception as e:
            logger.error(f"æ¨é€è‡³ç¾¤ {gid} å¤±è´¥: {e}")


@scheduler.scheduled_job(
    "interval",
    minutes=10,
    id="internet_outage_monitor",
    misfire_grace_time=20
)
async def outage_schedule():
    key = "outage_events"
    anomalies = await fetch_traffic_anomalies()
    outages = await fetch_outages()
    seen = await storage.get_seen_dict(key)
    first_run = await storage.is_first_run(key)

    # å…ˆå¤„ç† anomalies -> outage åŒ¹é…
    for a in anomalies:
        uuid = a["uuid"]
        outage = match_outage(a, outages)

        if uuid not in seen:
            # æ–°äº‹ä»¶
            if outage:
                msg = build_message(outage)
                sent_type = "anomaly + outage"
                if not first_run:
                    await broadcast(msg)
                logger.info(
                    f"å‘ç°æ–­ç½‘äº‹ä»¶ï¼ˆanomaly + outageï¼‰ï¼š[{a['locationDetails']['code']}] "
                    f"{outage['outage']['outageCause']}"
                )
            else:
                msg = build_message_from_anomaly(a)
                sent_type = "anomaly"
                if not first_run:
                    await broadcast(msg)
                logger.info(
                    f"å‘ç°æ–­ç½‘äº‹ä»¶ï¼ˆä»… anomalyï¼‰ï¼š[{a['locationDetails']['code']}] UNKNOWN"
                )
            seen[uuid] = {"sent_type": sent_type}

        else:
            # å·²å­˜åœ¨
            prev_type = seen[uuid]["sent_type"]
            if prev_type == "anomaly" and outage:
                # å‡çº§ä¸º outage
                msg = build_message(outage)
                await broadcast(msg)
                logger.info(
                    f"æ›´æ–°æ–­ç½‘äº‹ä»¶ï¼ˆanomaly -> outageï¼‰ï¼š[{a['locationDetails']['code']}] "
                    f"{outage['outage']['outageCause']}"
                )
                seen[uuid]["sent_type"] = "anomaly -> outage"

    # å†å¤„ç†ä»… outagesï¼Œæ²¡æœ‰å¯¹åº” anomaly çš„æƒ…å†µ
    for o in outages:
        # æ‰¾å‡º location å¯¹åº”çš„ anomaly
        found = False
        for a in anomalies:
            if match_outage(a, [o]):
                found = True
                break
        if not found:
            # ä»… outage
            loc_codes = o["locations"]
            uuid = f"outage_{loc_codes[0]}_{o['startDate']}"  # ç”Ÿæˆå”¯ä¸€æ ‡è¯†
            if uuid not in seen:
                msg = build_message(o)
                if not first_run:
                    await broadcast(msg)
                logger.info(
                    f"å‘ç°æ–­ç½‘äº‹ä»¶ï¼ˆä»… outageï¼‰ï¼š{loc_codes} {o['outage']['outageCause']}"
                )
                seen[uuid] = {"sent_type": "outage"}

    await storage.save_seen_dict(key, seen)
