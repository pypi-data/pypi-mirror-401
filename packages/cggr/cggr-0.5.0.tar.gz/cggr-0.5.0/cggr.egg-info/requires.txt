torch>=2.0.0

[all]
triton>=2.0.0
flash-attn>=2.0.0
transformers
rich
pytest

[benchmark]
transformers
rich

[cuda]
triton>=2.0.0

[dev]
pytest
rich

[flash]
flash-attn>=2.0.0
