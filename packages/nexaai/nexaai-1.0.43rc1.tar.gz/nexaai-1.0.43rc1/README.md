# nexaai

> **Run next-generation LLMs and VLMs locally, natively, and at top speed on any hardware.**

**nexaai** is the official Python SDK for NexaSDK/NexaML:  
An NPUâ€‘first crossâ€‘platform inference engine that powers LLMs, VLMs, embeddings, audio, and vision models across NPU, GPU, and CPUâ€”on desktop, mobile, automotive, and IoT.

---

## Features

- ğŸš€ **NPUâ€‘First Performance** â€” Accelerated AI with automatic device selection and backend optimizations.
- ğŸ”® **Dayâ€‘0 Architecture Support** â€” Run new LLMs, VLMs, ASR, and CV models immediately (GGUF, MLX, .nexa, and more).
- ğŸ§© **True Multimodality** â€” Seamless pipelines for text, vision, and audio.
- ğŸ¤– **OpenAI-Compatible Server** â€” Supports serving, chat, and function calling.
- ğŸ† **Crossâ€‘Platform** â€” macOS (Apple Silicon), Windows (x64, ARM64), Linux, mobile, embedded.

---

## What is it?

nexaai offers a clean Python API over NexaMLâ€™s runtime. Build modern AI applicationsâ€”chatbots, copilots, vision toolsâ€”that run fully **on-device** with maximal hardware utilization. Designed for rapid adoption of new models and formats, especially with NPU acceleration.

---

## Installation & Quickstart

Please refer to our official docs for up-to-date install steps, environment notes, and code examples:

- **Overview:** [NexaAI Python SDK Overview](https://docs.nexa.ai/nexa-sdk-python/overview)
- **Quickstart:** [Quickstart Guide](https://docs.nexa.ai/nexa-sdk-python/quickstart)

The docs include supported Python versions, backend requirements (NPU, MLX, GPU, CPU), and ready-to-run examples for LLMs, VLMs, embeddings, and audio.

---

## Links

- ğŸ“š **Docs:** https://docs.nexa.ai/nexa-sdk-python/overview
- ğŸ **Issues/Discussions:** [NexaAI Issues](https://github.com/NexaAI/nexa-sdk/issues)
- ğŸ’¬ **Community:**
  - [Discord](https://discord.com/invite/nexa-ai)
  - [Slack](https://nexa-ai-community.slack.com/ssb/redirect)

---
