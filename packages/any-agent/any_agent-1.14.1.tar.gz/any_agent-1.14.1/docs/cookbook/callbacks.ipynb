{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using Callbacks\n",
    "\n",
    "This cookbook shows you how to monitor, control, and secure your agents using callbacks. \n",
    "We'll build three callbacks of increasing complexity: counting tool usage, enforcing \n",
    "rate limits, and protecting sensitive data.\n",
    "\n",
    "You can find more information about callbacks in the [docs](https://mozilla-ai.github.io/any-agent/agents/callbacks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'any-agent' --quiet\n",
    "%pip install ddgs --quiet\n",
    "\n",
    "import warnings\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "# Suppress technical warnings to reduce noise for the user\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Configure LLM Keys \n",
    "\n",
    "For this tutorial, we'll use Mistral's mistral-small-latest (fast and affordable).\n",
    "You could also use:\n",
    "- `gpt-4o-mini` \n",
    "- `claude-3-5-sonnet-latest` \n",
    "- Any other model supported by any-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"MISTRAL_API_KEY\" not in os.environ:\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = getpass(\"Enter your Mistral API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent import AgentConfig, AnyAgent\n",
    "from any_agent.tools import search_web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Running an agent (with default callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "`any-agent` comes with a default callback that will always be used unless you pass a value to `AgentConfig.callbacks`:\n",
    "\n",
    "- [`ConsolePrintSpan`](https://mozilla-ai.github.io/any-agent/api/callbacks/#any_agent.callbacks.span_print.ConsolePrintSpan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AnyAgent.create(\n",
    "    \"tinyagent\",\n",
    "    AgentConfig(model_id=\"mistral:mistral-small-latest\", tools=[search_web]),\n",
    ")\n",
    "\n",
    "## Let's run a simple web search\n",
    "agent_trace = agent.run(\"What are 5 LLM agent frameworks that are trending in 2025?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Count Tool Usage (`Context.shared`)\n",
    "\n",
    "To control our agent, we first need to measure it. We will create a `StepCounter` callback.\n",
    "\n",
    "**The Callback Contract:**\n",
    "1. Callbacks receive a `context` object.\n",
    "2. They can store data in `context.shared`.\n",
    "3. They **must** return the `context` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent.callbacks import Callback, Context\n",
    "from any_agent.tracing.attributes import GenAI\n",
    "\n",
    "\n",
    "class ToolUsageCounter(Callback):\n",
    "    def before_tool_execution(self, context: Context, *args, **kwargs) -> Context:\n",
    "        # 1. Initialize our counter if it doesn't exist yet\n",
    "        if \"tool_usage_count\" not in context.shared:\n",
    "            context.shared[\"tool_usage_count\"] = 0\n",
    "\n",
    "        # 2. Increment the counter\n",
    "        context.shared[\"tool_usage_count\"] += 1\n",
    "\n",
    "        # 3. Print for visibility (optional)\n",
    "        current_count = context.shared[\"tool_usage_count\"]\n",
    "        tool_name = context.current_span.attributes.get(GenAI.TOOL_NAME)\n",
    "        print(f\"ðŸ§® Tracker: Tool '{tool_name}' called. (Count: {current_count})\")\n",
    "\n",
    "        # 4. MUST return context\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Enforce Rate Limits\n",
    "\n",
    "Now that we are counting steps, we can act on that data. \n",
    "\n",
    "We will create a `BudgetLimit` callback. If the tool usage exceeds our limit, we will raise an exception to immediately halt the agent. This prevents run-away costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BudgetLimit(Callback):\n",
    "    def __init__(self, max_tools: int):\n",
    "        self.max_tools = max_tools\n",
    "\n",
    "    def before_tool_execution(self, context: Context, *args, **kwargs) -> Context:\n",
    "        # We can access the data set by the previous callback!\n",
    "        current_count = context.shared.get(\"tool_usage_count\", 0)\n",
    "\n",
    "        if current_count > self.max_tools:\n",
    "            msg = f\"Exceeded limit of {self.max_tools} tool calls\"\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Let's put this all together.\n",
    "\n",
    "1. We register our callbacks in `AgentConfig`.\n",
    "2. We use `get_default_callbacks()` to keep the nice console logging.\n",
    "3. We give the agent a **hard task** that requires multiple steps (\"Find the weather in 3 different cities\") to intentionally trigger our limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent.callbacks import get_default_callbacks\n",
    "\n",
    "# 1. Configure Agent with our custom stack\n",
    "config = AgentConfig(\n",
    "    model_id=\"mistral:mistral-small-latest\",\n",
    "    tools=[search_web],\n",
    "    callbacks=[\n",
    "        ToolUsageCounter(),  # Runs first: Counts the step\n",
    "        BudgetLimit(\n",
    "            max_tools=2\n",
    "        ),  # Runs second: Checks the limit (set low to force a crash)\n",
    "        *get_default_callbacks(),  # Runs last: Logs to console\n",
    "    ],\n",
    ")\n",
    "\n",
    "agent = AnyAgent.create(\"tinyagent\", config)\n",
    "\n",
    "# 2. Run with a complex prompt\n",
    "print(\"--- Starting Stress Test ---\")\n",
    "try:\n",
    "    agent.run(\"Find the current weather in Tokyo, New York, and London.\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nâœ… Success! The agent was stopped: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Bonus : Protect Sensitive Data\n",
    "\n",
    "Beyond stopping the agent, callbacks can also **modify data** before it gets logged to your [traces](https://mozilla-ai.github.io/any-agent/tracing/). This is critical for preventing Sensitive Information (PII) from leaking into your logs. \n",
    "\n",
    "In the example below, we are going to implement a callback that:\n",
    "1. Detects `INPUT_MESSAGES` in `Context.current_span`. \n",
    "2. Writes this text to a secure local file. \n",
    "3. **Replaces** the content in the current span with a reference link, so the trace remains clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from any_agent.callbacks.base import Callback\n",
    "from any_agent.callbacks.context import Context\n",
    "\n",
    "\n",
    "class SensitiveDataOffloader(Callback):\n",
    "    def __init__(self, output_dir: str) -> None:\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    def before_llm_call(self, context: Context, *args, **kwargs) -> Context:\n",
    "        span = context.current_span\n",
    "\n",
    "        # 1. Check if we have input messages to scrub\n",
    "        if input_messages := span.attributes.get(GenAI.INPUT_MESSAGES):\n",
    "            # 2. Generate a secure filename based on the trace id\n",
    "            output_file = self.output_dir / f\"{span.get_span_context().trace_id}.txt\"\n",
    "\n",
    "            # 3. \"Offload\" the data to the secure location\n",
    "            output_file.write_text(str(input_messages))\n",
    "\n",
    "            # 4. Replace the span attribute with a reference\n",
    "            span.set_attribute(\n",
    "                GenAI.INPUT_MESSAGES, json.dumps({\"ref\": str(output_file)})\n",
    "            )\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "We can now provide our callback to the agent. \n",
    "\n",
    "You can find more information in [our docs](https://mozilla-ai.github.io/any-agent/agents/callbacks/#providing-your-own-callbacks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_agent.callbacks import get_default_callbacks\n",
    "\n",
    "agent = AnyAgent.create(\n",
    "    \"tinyagent\",\n",
    "    AgentConfig(\n",
    "        model_id=\"mistral:mistral-small-latest\",\n",
    "        tools=[search_web],\n",
    "        callbacks=[SensitiveDataOffloader(\"sensitive-info\"), *get_default_callbacks()],\n",
    "    ),\n",
    ")\n",
    "agent_trace = agent.run(\"What are 5 LLM agent frameworks that are trending in 2025?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that sensitive data was offloaded\n",
    "import os\n",
    "\n",
    "files = os.listdir(\"sensitive-info\")\n",
    "print(f\"Created {len(files)} secure file(s)\")\n",
    "\n",
    "# Peek at what was saved (first 200 chars)\n",
    "with open(f\"sensitive-info/{files[0]}\") as f:\n",
    "    print(f\"Offloaded data preview: {f.read()[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "As you can see in the console output, the input messages in the trace have been now replaced by a reference to the external destination."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
