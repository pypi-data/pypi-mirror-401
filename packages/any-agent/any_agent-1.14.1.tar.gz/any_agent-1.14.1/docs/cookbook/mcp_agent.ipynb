{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an agent with MCP\n",
    "\n",
    "The [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) (MCP) introduced by Anthropic has proven to be a popular method for providing an AI agent with access to a variety of tools. [This Huggingface blog post ](https://huggingface.co/blog/Kseniase/mcp) has a nice explanation of MCP.  In this tutorial, we'll build an agent that is able to leverage MCP server provided tools.\n",
    "\n",
    "Note: because this tutorial relies upon advanced stdio/stderr communication using the MCP Server, it cannot be run on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "any-agent uses the python asyncio module to support async functionality. When running in Jupyter notebooks, this means we need to enable the use of nested event loops. We'll install any-agent and enable this below using nest_asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'any-agent' 'mcp-server-time' --quiet\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Agent\n",
    "\n",
    "Now it's time to configure the agent! At this stage you have a few choices:\n",
    "\n",
    "### Pick the framework\n",
    "\n",
    "We support a variety of underlying agent frameworks (OpenAI, Smolagents, Langchain, TinyAgent, etc), which all have their own particular agentic AI implementations. For this tutorial's simple use case, any of the frameworks should work just fine, but any-agent makes it easy to try out a different framework later, if we so choose. For this example, we will use the [TinyAgent](frameworks/tinyagent.md) framework.  \n",
    "\n",
    "### Pick an LLM\n",
    "\n",
    "Regardless of which agent framework you choose, each framework supports any-llm, which is a proxy that allows us to use whichever LLM inside the framework, hosted by any provider. For example, we could use a local model via llama.cpp or llamafile, a Google-hosted gGemini model, or a AWS bedrock hosted Llama model. For this example, let's use Mistral AI's mistral:mistral-small-latest.\n",
    "\n",
    "### Pick which tools to use\n",
    "\n",
    " In this example, we'll add a few MCP servers that we host locally, which means we'll use a Stdio MCP server. If an MCP Server is already running and hosted elsewhere, you can use an SSE connection to access it. You can browse some of the officially supported MCP servers [here](https://github.com/modelcontextprotocol/servers/tree/main?tab=readme-ov-file).\n",
    "\n",
    " Let's use two MCP servers: \n",
    " \n",
    " * [Time](https://github.com/modelcontextprotocol/servers/tree/main/src/time): so the agent can know what time/day it is.\n",
    " * [Airbnb](https://github.com/openbnb-org/mcp-server-airbnb): so the agent can browse airbnb listings (Needs [npx](https://docs.npmjs.com/cli/v8/commands/npx))\n",
    "\n",
    " We will also add a custom send_message tool, that way it can ask us additional questions before getting its final answer!\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from getpass import getpass\n",
    "\n",
    "if \"MISTRAL_API_KEY\" not in os.environ:\n",
    "    print(\"MISTRAL_API_KEY not found in environment!\")\n",
    "    api_key = getpass(\"Please enter your MISTRAL_API_KEY: \")\n",
    "    os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
    "    print(\"MISTRAL_API_KEY set for this session!\")\n",
    "else:\n",
    "    print(\"MISTRAL_API_KEY found in environment.\")\n",
    "\n",
    "# Quick Environment Check (Airbnb tool requires npx/Node.js)\\n\",\n",
    "if not shutil.which(\"npx\"):\n",
    "    print(\n",
    "        \"⚠️ Warning: 'npx' was not found in your path. The Airbnb tool requires Node.js/npm to run.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from any_agent import AgentConfig, AnyAgent\n",
    "from any_agent.config import MCPStdio\n",
    "\n",
    "time_tool = MCPStdio(\n",
    "    command=sys.executable,\n",
    "    args=[\"-u\", \"-m\", \"mcp_server_time\", \"--local-timezone\", \"America/New_York\"],\n",
    "    tools=[\n",
    "        \"get_current_time\",\n",
    "    ],\n",
    "    client_session_timeout_seconds=30,\n",
    ")\n",
    "\n",
    "print(\"Done init time_tool\")\n",
    "# This MCP tool relies upon npx https://docs.npmjs.com/cli/v8/commands/npx which comes standard with npm\n",
    "airbnb_tool = MCPStdio(\n",
    "    command=\"npx\",\n",
    "    args=[\"-y\", \"@openbnb/mcp-server-airbnb\", \"--ignore-robots-txt\"],\n",
    "    client_session_timeout_seconds=30,\n",
    ")\n",
    "print(\"Done init airbnb_tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a custom tool that we will provide to the agent. For the agent to use the tool, we must provide a docstring\n",
    "# and also have proper python typing for input and output parameters\n",
    "def send_message(message: str) -> str:\n",
    "    \"\"\"Display a message to the user and wait for their response.\n",
    "\n",
    "    Args:\n",
    "        message: str\n",
    "            The message to be displayed to the user.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from the user.\n",
    "\n",
    "    \"\"\"\n",
    "    if os.environ.get(\"IN_PYTEST\") == \"1\":\n",
    "        return \"2 people, next weekend, low budget. Do not ask for any more information or confirmation.\"\n",
    "    return input(message + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start creating agent\")\n",
    "try:\n",
    "    agent = await AnyAgent.create_async(\n",
    "        \"tinyagent\",  # See all options in https://mozilla-ai.github.io/any-agent/\n",
    "        AgentConfig(\n",
    "            model_id=\"mistral:mistral-large-latest\",\n",
    "            tools=[time_tool, airbnb_tool, send_message],\n",
    "        ),\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to create agent: {e}\")\n",
    "print(\"Done creating agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Now we've configured our agent, so it's time to run it! Since it has access to airbnb listings as well as the current time, it's a perfect fit for helping me find a nice airbnb for the weekend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "I am planning a trip to New York, NY for next weekend. Please act as my travel planner.\n",
    "\n",
    "Follow these steps in strict order:\n",
    "1. **Time Check:** Use the time tool to identify the specific dates for \"next weekend.\"\n",
    "2. **Information Gathering:** Ask me about my budget and number of guests. Do NOT search yet.\n",
    "3. **Wait:** Wait for my response.\n",
    "4. **Search:** ONLY after I reply, search for listings.\n",
    "   **CRITICAL:** You MUST set the `location` parameter explicitly to \"New York, NY\" in the tool call.\n",
    "\"\"\"\n",
    "\n",
    "agent_trace = await agent.run_async(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `agent.run` method returns an AgentTrace object, which has a few convenient attributes for displaying some interesting information about the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_trace.final_output)  # Final answer\n",
    "print(f\"Duration: {agent_trace.duration.total_seconds():.2f} seconds\")\n",
    "print(f\"Total Tokens: {agent_trace.tokens.total_tokens:,}\")\n",
    "print(f\"Total Cost (USD): {agent_trace.cost.total_cost:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
