#!/usr/bin/python3
# coding: utf-8
# Copyright (c) 2024 Huawei Technologies Co., Ltd.
# openUBMC is licensed under Mulan PSL v2.
# You can use this software according to the terms and conditions of the Mulan PSL v2.
# You may obtain a copy of Mulan PSL v2 at:
#         http://license.coscl.org.cn/MulanPSL2
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND,
# EITHER EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT,
# MERCHANTABILITY OR FIT FOR A PARTICULAR PURPOSE.
# See the Mulan PSL v2 for more details.

import os
import glob
import logging

from .log_parser import LogParser
from .case_matcher import CaseMatcher


class UnifiedErrorAnalyzer:
    """ç»Ÿä¸€çš„é”™è¯¯åˆ†æå™¨ - ç»“åˆå‘½ä»¤å¤±è´¥å’Œæ—¥å¿—åˆ†æ"""

    def __init__(self, cases):
        self.log_parser = LogParser()
        self.case_matcher = CaseMatcher()
        self.cases = cases

    @staticmethod
    def _find_log_files_in_directory(directory, recursive=True):
        """
        åœ¨ç›®å½•ä¸­æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶

        Args:
            directory: ç›®å½•è·¯å¾„
            recursive: æ˜¯å¦é€’å½’æŸ¥æ‰¾å­ç›®å½•
        """
        log_files = []

        if recursive:
            # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ .log æ–‡ä»¶
            pattern = os.path.join(directory, "**", "*.log")
            log_files = glob.glob(pattern, recursive=True)
        else:
            # åªæŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„ .log æ–‡ä»¶
            pattern = os.path.join(directory, "*.log")
            log_files = glob.glob(pattern)

        # ä¹Ÿå¯ä»¥æŸ¥æ‰¾å…¶ä»–å¸¸è§çš„æ—¥å¿—æ–‡ä»¶æ‰©å±•å
        additional_patterns = [
            os.path.join(directory, "**", "*.log.*"),  # æ»šåŠ¨æ—¥å¿—æ–‡ä»¶
            os.path.join(directory, "**", "*.txt"),  # æ–‡æœ¬æ—¥å¿—æ–‡ä»¶
            os.path.join(directory, "**", "*.err"),  # é”™è¯¯æ—¥å¿—æ–‡ä»¶
        ]

        for pattern in additional_patterns:
            log_files.extend(glob.glob(pattern, recursive=True))

        # å»é‡å¹¶è¿”å›
        return list(set(log_files))

    @staticmethod
    def _extract_error_code_from_failure(failure):
        """ä»å¤±è´¥ä¿¡æ¯ä¸­æå–é”™è¯¯ä»£ç """
        error = failure.get("error", "")
        error_type = failure.get("error_type", "")

        # æ ¹æ®é”™è¯¯ç±»å‹å’Œå†…å®¹ç”Ÿæˆé”™è¯¯ä»£ç 
        if "TimeoutExpired" in error_type:
            return "COMMAND_TIMEOUT"
        elif "CalledProcessError" in error_type:
            return "COMMAND_FAILED"
        elif "FileNotFoundError" in error_type:
            return "COMMAND_NOT_FOUND"
        elif "PermissionError" in error_type:
            return "PERMISSION_DENIED"
        else:
            return "COMMAND_ERROR"

    @staticmethod
    def _format_failure_log(failure):
        """æ ¼å¼åŒ–å¤±è´¥æ—¥å¿—"""
        parts = []

        if failure.get("command_key"):
            parts.append(f"[{failure['command_key']}]")

        parts.append(failure["command_str"])
        parts.append("[FAILED]")

        exec_time = failure.get("execution_time", 0)
        parts.append(f"[{exec_time:.2f}s]")

        if "error" in failure:
            parts.append(f"[ERROR: {failure['error']}]")

        return " ".join(parts)

    @staticmethod
    def _deduplicate_cases(cases):
        """æ¡ˆä¾‹å»é‡"""
        seen_signatures = set()
        unique_cases = []

        for case in cases:
            # åˆ›å»ºæ›´ä¸¥æ ¼çš„æ¡ˆä¾‹ç­¾å
            title = case.get("title", "")

            # ä½¿ç”¨åŸå§‹æ—¥å¿—å†…å®¹ï¼ˆå»é™¤ANSIé¢œè‰²ç ï¼‰è¿›è¡Œå»é‡
            raw_log = case["log_data"].get("raw_log", "")

            # å»é™¤ANSIé¢œè‰²ç 
            import re

            ansi_escape = re.compile(r"\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])")
            clean_log = ansi_escape.sub("", raw_log).strip()

            # åˆ›å»ºåŸºäºæ ‡é¢˜å’Œæ¸…ç†åæ—¥å¿—å†…å®¹çš„ç­¾å
            signature = f"{title}_{hash(clean_log)}"

            if signature not in seen_signatures:
                seen_signatures.add(signature)
                unique_cases.append(case)

        return unique_cases

    @staticmethod
    def _output_unified_case(case, case_number):
        """è¾“å‡ºç»Ÿä¸€æ ¼å¼çš„æ¡ˆä¾‹"""
        source = case["log_data"].get("source", "unknown")
        if source == "log_file":
            source_icon = "ğŸ“"
            source_text = "æ—¥å¿—æ–‡ä»¶"
            file_path = case["log_data"].get("file_path", "unknown")
            file_name = file_path
        else:
            source_icon = "ğŸ”§"
            source_text = "å‘½ä»¤æ‰§è¡Œ"
            file_name = None

        logging.info(
            f"{source_icon} æ¡ˆä¾‹ {case_number}: {case.get('title', 'æœªå‘½åæ¡ˆä¾‹')}"
        )
        logging.info("â”€" * 50)

        logging.info(f"   ğŸ• å‘ç”Ÿæ—¶é—´: {case['log_data']['timestamp']}")
        logging.info(f"   ğŸ“ æ¥æº: {source_text}")

        if file_name:
            logging.info(f"   ğŸ“„ æ–‡ä»¶: {file_path}")

        logging.info(f"   ğŸ“ é—®é¢˜æè¿°: {case.get('description', '')}")

        if case.get("steps"):
            logging.info("   ğŸ‘£ é‡ç°æ­¥éª¤:")
            for j, step in enumerate(case.get("steps", []), 1):
                logging.info(f"      {j}. {step}")

        logging.info("   ğŸ“„ ç›¸å…³è¾“å‡º:")
        logging.info(f"      {case['log_data']['raw_log']}")

        # å¦‚æœæ˜¯å‘½ä»¤å¤±è´¥æ¡ˆä¾‹ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
        if source == "command_failure" and "command_data" in case:
            cmd_data = case["command_data"]
            logging.info("   ğŸ”§ å‘½ä»¤è¯¦æƒ…:")
            logging.info(f"      å‘½ä»¤: {cmd_data['command_str']}")
            logging.info(f"      æ‰§è¡Œæ—¶é—´: {cmd_data['execution_time']:.2f}ç§’")
            logging.info(f"      é”™è¯¯ç±»å‹: {cmd_data.get('error_type', 'Unknown')}")

        if case.get("solution"):
            logging.info(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ: {case['solution']}")

        logging.info("â”€" * 50)

    def analyze_errors(self, log_sources, command_failures=None):
        """
        ç»Ÿä¸€åˆ†æé”™è¯¯ï¼šæ”¯æŒå¤šç§æ—¥å¿—æº

        Args:
            log_sources: å¯ä»¥æ˜¯ä»¥ä¸‹ç±»å‹ï¼š
                        - å•ä¸ªæ–‡ä»¶è·¯å¾„ (str)
                        - æ–‡ä»¶è·¯å¾„åˆ—è¡¨ (list)
                        - æ–‡ä»¶å¤¹è·¯å¾„ (str) - ä¼šåˆ†æè¯¥æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ .log æ–‡ä»¶
            command_failures: å‘½ä»¤å¤±è´¥ä¿¡æ¯åˆ—è¡¨
        """
        logging.info("\n" + "=" * 60)
        logging.info("ğŸ” å¼€å§‹ç»Ÿä¸€é”™è¯¯åˆ†æ")
        logging.info("=" * 60)

        # è§£ææ—¥å¿—æº
        log_files = self._resolve_log_sources(log_sources)

        if not log_files:
            logging.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•æ—¥å¿—æ–‡ä»¶")
            return []

        all_cases = []
        all_log_entries = []

        # 1. åˆ†ææ‰€æœ‰æ—¥å¿—æ–‡ä»¶
        for log_file in log_files:
            file_cases, file_entries = self._analyze_single_log_file(log_file)
            all_cases.extend(file_cases)
            all_log_entries.extend(file_entries)

        # 2. åˆ†æå‘½ä»¤å¤±è´¥ä¿¡æ¯
        if command_failures:
            command_cases = self._analyze_command_failures(command_failures)
            all_cases.extend(command_cases)

        # 3. åˆå¹¶å’Œå»é‡
        unique_cases = self._deduplicate_cases(all_cases)

        # 4. è¾“å‡ºåˆ†æç»“æœ
        self._output_unified_analysis(
            unique_cases, log_files, command_failures, all_log_entries
        )

        return unique_cases

    def _resolve_log_sources(self, log_sources):
        """
        è§£ææ—¥å¿—æºï¼Œè¿”å›æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Args:
            log_sources: å•ä¸ªæ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶åˆ—è¡¨æˆ–æ–‡ä»¶å¤¹è·¯å¾„
        """
        if isinstance(log_sources, str):
            # å•ä¸ªè·¯å¾„
            if os.path.isfile(log_sources):
                # å•ä¸ªæ–‡ä»¶
                return [log_sources]
            elif os.path.isdir(log_sources):
                # æ–‡ä»¶å¤¹ - æŸ¥æ‰¾æ‰€æœ‰ .log æ–‡ä»¶
                return self._find_log_files_in_directory(log_sources)
            else:
                # å¯èƒ½æ˜¯é€šé…ç¬¦æ¨¡å¼
                return glob.glob(log_sources)

        elif isinstance(log_sources, list):
            # æ–‡ä»¶åˆ—è¡¨
            all_files = []
            for source in log_sources:
                if os.path.isfile(source):
                    all_files.append(source)
                elif os.path.isdir(source):
                    all_files.extend(self._find_log_files_in_directory(source))
                else:
                    # é€šé…ç¬¦æ¨¡å¼
                    all_files.extend(glob.glob(source))
            return all_files

        else:
            return []

    def _analyze_single_log_file(self, log_file_path):
        """åˆ†æå•ä¸ªæ—¥å¿—æ–‡ä»¶"""
        try:
            log_entries = self.log_parser.parse_logs(log_file_path)
            cases = self.cases
            matched_cases = self.case_matcher.match_cases(log_entries, cases)

            # æ ‡è®°æ¥æºæ–‡ä»¶
            for case in matched_cases:
                case["log_data"]["source"] = "log_file"
                case["log_data"]["file_path"] = log_file_path

            return matched_cases, log_entries

        except Exception as e:
            logging.error(f"  âŒ åˆ†ææ–‡ä»¶å¤±è´¥ {log_file_path}: {e}")
            return [], []

    def _analyze_command_failures(self, command_failures):
        """åˆ†æå‘½ä»¤å¤±è´¥ä¿¡æ¯"""
        cases = self.cases
        matched_cases = []

        for failure in command_failures:
            # å°†å‘½ä»¤å¤±è´¥ä¿¡æ¯è½¬æ¢ä¸ºæ—¥å¿—æ ¼å¼è¿›è¡Œåˆ†æ
            log_entry = self._convert_failure_to_log_entry(failure)

            # åŒ¹é…æ¡ˆä¾‹
            case = self.case_matcher.find_matching_case(log_entry, cases)
            if case:
                enriched_case = self.case_matcher.enrich_case_with_log(case, log_entry)
                enriched_case["command_data"] = failure  # ä¿ç•™åŸå§‹å‘½ä»¤æ•°æ®
                matched_cases.append(enriched_case)

        return matched_cases

    def _convert_failure_to_log_entry(self, failure):
        """å°†å‘½ä»¤å¤±è´¥ä¿¡æ¯è½¬æ¢ä¸ºæ—¥å¿—æ¡ç›®æ ¼å¼"""
        return {
            "timestamp": failure["timestamp"],
            "level": "ERROR",
            "module": "CommandExecutor",
            "message": f"Command failed: {failure['command_str']} - {failure['error']}",
            "error_code": self._extract_error_code_from_failure(failure),
            "parameters": {
                "command": failure["command_str"],
                "execution_time": failure["execution_time"],
                "error_type": failure["error_type"],
            },
            "raw_line": self._format_failure_log(failure),
            "source": "command_failure",
        }

    def _load_cases(self):
        """åŠ è½½æ¡ˆä¾‹æ¨¡æ¿"""
        import yaml

        try:
            with open(self.case_file_path, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f)
                return data.get("cases", [])
        except Exception as e:
            logging.error(f"âŒ åŠ è½½æ¡ˆä¾‹æ–‡ä»¶å¤±è´¥: {e}")
            return []

    def _output_unified_analysis(
        self, cases, log_files, command_failures, all_log_entries
    ):
        """è¾“å‡ºç»Ÿä¸€åˆ†æç»“æœ"""
        if not cases:
            logging.warning("\nâœ… æ²¡æœ‰å‘ç°åŒ¹é…çš„é”™è¯¯æ¡ˆä¾‹")
            return

        # ç»Ÿè®¡ä¿¡æ¯
        log_cases = [c for c in cases if c["log_data"].get("source") == "log_file"]
        command_cases = [
            c
            for c in cases
            if c["log_data"].get("source") == "command_failure"
        ]

        # æŒ‰æ–‡ä»¶ç»Ÿè®¡
        file_stats = {}
        for case in log_cases:
            file_path = case["log_data"].get("file_path", "unknown")
            file_stats[file_path] = file_stats.get(file_path, 0) + 1

        logging.info(f"   ğŸ“Š ç»Ÿä¸€åˆ†æå®Œæˆ!")
        logging.info(f"   åˆ†ææ–‡ä»¶æ•°é‡: {len(log_files)} ä¸ª")
        logging.info(f"   æ—¥å¿—æ¡ç›®æ€»æ•°: {len(all_log_entries)} æ¡")
        logging.info(f"   æ—¥å¿—æ–‡ä»¶æ¡ˆä¾‹: {len(log_cases)} ä¸ª")
        logging.info(f"   å‘½ä»¤å¤±è´¥æ¡ˆä¾‹: {len(command_cases)} ä¸ª")
        logging.info(f"   æ€»æ¡ˆä¾‹: {len(cases)} ä¸ª")

        if command_failures:
            logging.info(f"   åˆ†æçš„å‘½ä»¤å¤±è´¥: {len(command_failures)} ä¸ª")

        # è¾“å‡ºæ‰€æœ‰æ¡ˆä¾‹
        logging.info("\n" + "=" * 60)
        logging.info("ğŸ“‹ è¯¦ç»†é”™è¯¯åˆ†æ")
        logging.info("=" * 60)

        for i, case in enumerate(cases, 1):
            self._output_unified_case(case, i)
