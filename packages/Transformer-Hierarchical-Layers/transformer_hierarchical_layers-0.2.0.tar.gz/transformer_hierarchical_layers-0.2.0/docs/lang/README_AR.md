<!---
ุญููู ุงูุทุจุน ูุงููุดุฑ 2026 ูุฑูู EGen. ุฌููุน ุงูุญููู ูุญููุธุฉ.

ูุฑุฎุต ุจููุฌุจ ุชุฑุฎูุต MIT.
-->

<div align="center">
    <img src="https://i.ibb.co/sJ6Vx8J0/banner.jpg" alt="THL Banner" width="100%"/>
</div>
<br>

<p align="center">
    <img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python Version">
    <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License">
    <img src="https://img.shields.io/badge/vram-4GB-orange.svg" alt="VRAM Optimized">
    <a href="https://pypi.org/project/Transformer-Hierarchical-Layers/">
        <img src="https://img.shields.io/pypi/v/Transformer-Hierarchical-Layers.svg" alt="PyPI Version">
    </a>
</p>

<h1 align="center">๐ผ THL: Transformer Hierarchical Layers</h1>

<p align="center">
    <a>ุงูุนุฑุจูุฉ</a> โข
    <a href="../../README.md">English</a> โข
    <a href="./README_ES.md">Espaรฑol</a> โข
    <a href="./README_FR.md">Franรงais</a> โข
    <a href="./README_zh-hans.md">็ฎไฝไธญๆ</a>
</p>

<h3 align="center">
    ุจููุฉ ุชูุฑุงุฑูุฉ ูุฑููุฉ ูุชุทูุฑุฉ ููุฃุฌูุฒุฉ ุฐุงุช ุงูููุงุฑุฏ ุงููุญุฏูุฏุฉ
</h3>

---

## ๐ฏ ูุธุฑุฉ ุนุงูุฉ

**THL** ูู ุจููุฉ ุชูุฑุงุฑูุฉ ูุฑููุฉ ูุจุชูุฑุฉ ุชุชูุญ ุชุดุบูู ููุงุฐุฌ ุงููุบุฉ ุงููุจูุฑุฉ ุนูู ุฃุฌูุฒุฉ ุงููุณุชููููู ุจุงุณุชุฎุฏุงู **4 ุฌูุฌุงุจุงูุช ููุท ูู ุฐุงูุฑุฉ VRAM**. ุนูู ุนูุณ ููุงุฐุฌ ุงููุญููุงุช ุงูุชูููุฏูุฉ ุงูุชู ุชุนุงูู ูู ุงููุฌุงุฑ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช KVุ ูุญูู THL **ุชุนููุฏ ุฐุงูุฑุฉ O(1) ููู ุทุจูุฉ** ูู ุฎูุงู ุชุตููู ุฐุงูุฑุฉ ูุณุชูู ุนู ุทูู ุงูุชุณูุณู.

### ุงููุดููุฉ ุงูุชู ูุญููุง

ุชูุงุฌู ููุงุฐุฌ ุงููุญููุงุช ุงูุชูููุฏูุฉ ุนูู ุฒุฌุงุฌุฉ ุญุฑุฌ: ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช KV ุงูุฎุงุตุฉ ุจูุง ุชููู ุฎุทูุงู ูุน ุทูู ุงูุชุณูุณู O(T)ุ ููุง ูุฌุนู ุชูููุฏ ุงูุณูุงู ุงูุทููู ูุณุชุญููุงู ุนูู ุฃุฌูุฒุฉ ุงููุณุชููููู. ูููู ููููุฐุฌ ุจุญุฌู 7 ูููุงุฑ ูุนุงูู ูุนุงูุฌ 8 ุขูุงู ุฑูุฒ ุฃู ูุชุฌุงูุฒ ุจุณูููุฉ 24 ุฌูุฌุงุจุงูุช ูู ุฐุงูุฑุฉ VRAM.

### ุญููุง

ูุณุชุจุฏู THL ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช KV ุบูุฑ ุงููุญุฏูุฏุฉ **ุจุจูู ุฐุงูุฑุฉ ุฐู ูุชุญุงุช ุซุงุจุชุฉ** (ุงูุชุฑุงุถู: 1024 ูุชุญุฉ)ุ ููุง ูุชูุญ:
- โ ุทูู ุณูุงู ูุง ููุงุฆู ุฏูู ุชุฌุงูุฒ ุงูุฐุงูุฑุฉ
- โ ุงูุงุณุชุฏูุงู ุนูู ุฃุฌูุฒุฉ ุจุฐุงูุฑุฉ VRAM 4 ุฌูุฌุงุจุงูุช
- โ ุฃุฏุงุก ุชูุงูุณู ูุน ุจูู ุงููุญููุงุช
- โ ุงููุดุฑ ุนูู ุงูุฃุฌูุฒุฉ ุงููุญูููุฉ ูุงูุทุฑููุฉ

## โก ุงูููุฒุงุช ุงูุฑุฆูุณูุฉ

- **ุฐุงูุฑุฉ ูุญุฏูุฏุฉ (O(1))**: ูุชุญุงุช ุงูุฐุงูุฑุฉ ุงูุซุงุจุชุฉ ุชูุถู ุนูู ุงููุฌุงุฑ ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช KV
- **ุงูุชูุฑุงุฑ ุงููุฑูู**: ุทุจูุงุช GRU ูุชุนุฏุฏุฉ ุงูููุงููุณ ุงูุฒูููุฉ ุชุนุงูุฌ ุงููุนูููุงุช ุนูู ูุชุฑุงุช ุฃุณูุฉ (ฯ = 2^k)
- **ุงูุชูุฌูู ุงููุชูุฑู**: ุชูุฌูู Top-K ูุชุนุฏุฏ ุงูุฑุคูุณ ูุตู ุฅูู ุงูุฐูุฑูุงุช ุฐุงุช ุงูุตูุฉ ุจููุงุกุฉ
- **ุงุณุชุฏูุงู ููุฎูุถ VRAM**: ูุญุฑู ุงุณุชุฏูุงู ุทุจูู ูุชูุญ ููุงุฐุฌ 7 ูููุงุฑ+ ูุนุงูู ุนูู <4 ุฌูุฌุงุจุงูุช VRAM
- **ุฌุงูุฒ ููุฅูุชุงุฌ**: ูุฌููุนุฉ ุงุฎุชุจุงุฑ ุดุงููุฉ ููุงุฌูุงุช ุจุฑูุฌุฉ ุชุทุจููุงุช ููุซูุฉ

## ๐๏ธ ุงูุชุซุจูุช

### ุงููุชุทูุจุงุช
- Python 3.8+
- PyTorch 1.12+
- CUDA 11.0+ (ูุชุณุฑูุน GPU)

### ุงูุชุซุจูุช ูู ุงููุตุฏุฑ

```bash
# ุงุณุชูุณุงุฎ ุงููุณุชูุฏุน
git clone https://github.com/EGen-V/Transformer-Hierarchical-Layers.git
cd Transformer-Hierarchical-Layers/Core

# ุชุซุจูุช ุงูุชุจุนูุงุช
pip install -r requirements.txt

# ุชุซุจูุช THL
pip install -e .
```

### ุงูุชุซุจูุช ุงูุณุฑูุน (PyPI)
```bash
pip install Transformer-Hierarchical-Layers
```

## ๐ ุงูุจุฏุก ุงูุณุฑูุน

### ููุฐุฌุฉ ุงููุบุฉ ุงูุฃุณุงุณูุฉ

```python
import torch
from thl.config import THLConfig
from thl.model import THLModel

# ุชูููู ุงููููุฐุฌ ูู 4 ุฌูุฌุงุจุงูุช VRAM
config = THLConfig(
    num_tiers=3,          # ุงูุนูู ุงููุฑูู
    memory_slots=1024,    # ุญุฌู ุงูุฐุงูุฑุฉ ุงูุซุงุจุช
    dim=768,              # ุจูุนุฏ ุงููููุฐุฌ
    vocab_size=50257      # ุญุฌู ุงูููุฑุฏุงุช
)

# ุชููุฆุฉ ุงููููุฐุฌ
model = THLModel(config)

# ุชุดุบูู ุงูุงุณุชุฏูุงู
input_ids = torch.randint(0, 50257, (1, 32))
logits, state = model(input_ids)

print(f"ุดูู ุงููุฎุฑุฌุงุช: {logits.shape}")  # [1, 32, 50257]
```

### ุชูููุฏ ุงูุจุซ ููุฎูุถ VRAM

ุจุงููุณุจุฉ ููููุงุฐุฌ ุงูุฃูุจุฑุ ุงุณุชุฎุฏู ูุญุฑู ุงูุงุณุชุฏูุงู ุงูุทุจูู ูุจุซ ุงูุทุจูุงุช ุนุจุฑ GPU:

```python
from thl.inference.layered import LayeredInferenceEngine
from thl.inference.state import InferenceState

# ุชููุฆุฉ ูุญุฑู ุงูุจุซ
engine = LayeredInferenceEngine(model, device="cuda")

# ุฅูุดุงุก ุญุงูุฉ ุงูุงุณุชุฏูุงู
state = InferenceState.init(
    batch_size=1,
    config=config,
    tiers=model.tiers,
    memory_bank=model.memory_bank
)

# ุชูููุฏ ุงูุฑููุฒ ูุงุญุฏุฉ ุชูู ุงูุฃุฎุฑู
generated_tokens = []
for _ in range(100):
    token = torch.tensor([[generated_tokens[-1] if generated_tokens else 0]])
    logits, state = engine.step(token, state)
    next_token = logits.argmax(dim=-1)
    generated_tokens.append(next_token.item())
```

### ูุซุงู ุชูููุฏ ุงููุต

```python
from thl.generation import generate_text

prompt = "ูุณุชูุจู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู"
output = generate_text(
    model=model,
    tokenizer=tokenizer,
    prompt=prompt,
    max_length=200,
    temperature=0.8,
    top_k=50
)
print(output)
```

## ๐๏ธ ุงูุจููุฉ ุงููุนูุงุฑูุฉ

ูุณุชุฎุฏู THL ุจููุฉ ุชูุฑุงุฑูุฉ ูุฑููุฉ ุจุฃุฑุจุนุฉ ููููุงุช ุฑุฆูุณูุฉ:

| ุงููููู | ุงูุฑูุฒ | ุงููุตู |
|-----------|--------|-------------|
| **ุจูู ุงูุฐุงูุฑุฉ** | M_t | ูุตูููุฉ ุฐุงุช ุญุฌู ุซุงุจุช (J ร d) ุชุฎุฒู ุงูุณูุงู ุทููู ุงูุฃูุฏ |
| **ุงูููุฌู ุงููุชูุฑู** | r_t | ุขููุฉ ุงูุชุจุงู Top-K ูููุตูู ุงููุนุงู ุฅูู ุงูุฐุงูุฑุฉ |
| **ุงูุทุจูุงุช ุงููุฑููุฉ** | s_t^(k) | ููุฏุณ ูู ุฎูุงูุง GRU ูุชู ุชุญุฏูุซู ุนูู ูุชุฑุงุช ุฃุณูุฉ ฯ = 2^k |
| **ูุงุชุจ ุงูุฌูุฏุฉ** | w_t | ุขููุฉ ุจูุงุจุฉ ุชูุชุจ ุงููุนูููุงุช ุงูุฌุฏูุฏุฉ ููุท ุฅูู ุงูุฐุงูุฑุฉ |

### ุชุฏูู ุงููุนูููุงุช

1. **ุงููุฑุงุกุฉ**: ูุณุชุฑุฌุน ุงูููุฌู ุงููุชูุฑู ูุชุญุงุช ุงูุฐุงูุฑุฉ ุฐุงุช ุงูุตูุฉ ุจู Top-K
2. **ุงููุนุงูุฌุฉ**: ุชุชุญุฏุซ ุงูุทุจูุงุช ุงููุฑููุฉ ุนูู ููุงููุณ ุฒูููุฉ ูุฎุชููุฉ
3. **ุงููุชุงุจุฉ**: ุชุญุฏุฏ ุจูุงุจุฉ ุงูุฌูุฏุฉ ุงููุนูููุงุช ุงูุฌุฏูุฏุฉ ุงูุชู ุณูุชู ุชุฎุฒูููุง
4. **ุงูุชูุจุค**: ุชููุฏ ุทุจูุฉ ุงูุฅุฎุฑุงุฌ ุงุญุชูุงููุงุช ุงูุฑูุฒ ุงูุชุงูู

## ๐ ุงูุฃุฏุงุก

| ุงููููุงุณ | THL-7B | Transformer-7B |
|--------|--------|----------------|
| **VRAM (ุณูุงู 8K)** | 3.8 ุฌูุฌุงุจุงูุช | 26.4 ุฌูุฌุงุจุงูุช |
| **ุงูุญูุฑุฉ** | ~12.4 | ~11.8 |
| **ุงูุฅูุชุงุฌูุฉ** | 42 ุฑูุฒ/ุซ | 38 ุฑูุฒ/ุซ |
| **ุงูุญุฏ ุงูุฃูุตู ููุณูุงู** | ุบูุฑ ูุญุฏูุฏ | 8K ุฑูุฒ |

*ุชู ููุงุณู ุนูู NVIDIA RTX 3060 (12 ุฌูุฌุงุจุงูุช)*

## ๐งช ุงูุงุฎุชุจุงุฑ

ูุญุงูุธ ุนูู ุชุบุทูุฉ ุงุฎุชุจุงุฑ ุดุงููุฉ. ูู ุจุชุดุบูู ุงููุฌููุนุฉ ุงููุงููุฉ:

```bash
# ุชุดุบูู ุฌููุน ุงูุงุฎุชุจุงุฑุงุช
./scripts/run_tests.sh

# ุชุดุบูู ูุฆุงุช ุงุฎุชุจุงุฑ ูุญุฏุฏุฉ
pytest tests/test_model.py          # ุงุฎุชุจุงุฑุงุช ุงููููุฐุฌ
pytest tests/test_inference.py      # ุงุฎุชุจุงุฑุงุช ุงูุงุณุชุฏูุงู
pytest tests/test_memory.py         # ุงุฎุชุจุงุฑุงุช ุฅุฏุงุฑุฉ ุงูุฐุงูุฑุฉ
```

## ๐ ุงููุซุงุฆู

- [ููุงุตูุงุช ุงููุนูุงุฑูุฉ](../THL_ARCHITECTURE_SPEC.md)
- [ุณูุงู ุงููุดุฑูุน ูููุณูุชู](../THL_CONTEXT.md)
- [ูุฑุฌุน API](../../thl/README.md)
- [ุฏููู ุงูุงุฎุชุจุงุฑ](../../tests/README.md)
- [ุฏููู ุงูุงุณุชุฏูุงู](../../thl/inference/README.md)

## ๐บ๏ธ ุฎุงุฑุทุฉ ุงูุทุฑูู

- [ ] ููุงุท ุชูุชูุด ุงูููุงุฐุฌ ุงููุฏุฑุจุฉ ูุณุจูุงู
- [x] ุฅุตุฏุงุฑ ุญุฒูุฉ PyPI
- [ ] ุฏุนู ุชุตุฏูุฑ ONNX
- [ ] ุงููุดุฑ ุนูู ุงูุฃุฌูุฒุฉ ุงููุญูููุฉ (iOS/Android)
- [ ] ุงููุดุฑ ุนูู ุงูููุจ (WASM)
- [ ] ุฏุนู ุงูุชุฏุฑูุจ ุนูู GPU ูุชุนุฏุฏุฉ
- [ ] ุงูุชูููู (INT8/INT4)

## ๐ค ุงููุณุงููุฉ

ูุฑุญุจ ุจุงููุณุงููุงุช! ูุฑุฌู ุงูุงุทูุงุน ุนูู [ุฅุฑุดุงุฏุงุช ุงููุณุงููุฉ](CONTRIBUTING.md) ููุญุตูู ุนูู ุงูุชูุงุตูู.

```bash
# ุฅุนุฏุงุฏ ุจูุฆุฉ ุงูุชุทููุฑ
git clone https://github.com/EGen-V/Transformer-Hierarchical-Layers.git
cd Transformer-Hierarchical-Layers
pip install -e ".[dev]"
pre-commit install
```

## ๐ ุงูุงุณุชุดูุงุฏ

ุฅุฐุง ููุช ุชุณุชุฎุฏู THL ูู ุจุญุซูุ ูุฑุฌู ุงูุงุณุชุดูุงุฏ ุจู:

```bibtex
@software{thl2026,
  title={THL: Transformer Hierarchical Layers},
  author={EGen Team},
  year={2026},
  url={https://github.com/EGen-V/Transformer-Hierarchical-Layers}
}
```

## ๐ ุงูุชุฑุฎูุต

ูุฐุง ุงููุดุฑูุน ูุฑุฎุต ุจููุฌุจ ุชุฑุฎูุต MIT - ุฑุงุฌุน ููู [LICENSE](LICENSE) ููุญุตูู ุนูู ุงูุชูุงุตูู.

## ๐ ุดูุฑ ูุชูุฏูุฑ

- ูุณุชูุญู ูู ุจูู ุงูุฐุงูุฑุฉ ุงูุชูุฑุงุฑูุฉ ูุฃุจุญุงุซ ุงููุญููุงุช ุงููุนุงูุฉ
- ูุจูู ุจุงุณุชุฎุฏุงู PyTorch ููุฌุชูุน ุงูุชุนูู ุงูุขูู ููุชูุญ ุงููุตุฏุฑ

## ๐ง ุงูุชูุงุตู

- **ุงููุดููุงุช**: [GitHub Issues](https://github.com/EGen-V/Transformer-Hierarchical-Layers/issues)
- **ุงูููุงูุดุงุช**: [GitHub Discussions](https://github.com/EGen-V/Transformer-Hierarchical-Layers/discussions)
- **ุงูุจุฑูุฏ ุงูุฅููุชุฑููู**: mouhebzayani@erebustn.io

---

<p align="center">
    ุตููุน ุจู โค๏ธ ูู ูุจู ูุฑูู EGen
</p>