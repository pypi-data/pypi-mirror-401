{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb26c2c",
   "metadata": {},
   "source": [
    "# Drift Detection at Runtime (IBM Runtime local mode + devqubit)\n",
    "\n",
    "This notebook is a **minimal, end-to-end** example of *runtime drift detection* for quantum workloads.\n",
    "\n",
    "We:\n",
    "1. Build a small **calibration-sensitive benchmark circuit**.\n",
    "2. Establish a **baseline** run (your “known-good” reference).\n",
    "3. Execute several **candidate** runs that emulate production conditions.\n",
    "4. Use **devqubit** to:\n",
    "   - capture artifacts (including a device snapshot/fingerprints),\n",
    "   - compute a distribution distance (**TVD**),\n",
    "   - enforce a simple **policy** (CI/CD-style verification),\n",
    "   - generate a **JUnit** report for pipelines.\n",
    "\n",
    "> Notes  \n",
    "> - We use **IBM Runtime local testing mode** (`FakeManilaV2`) so the notebook runs without IBM credentials.  \n",
    "> - In production you would point the same code at a real backend/session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from importlib.metadata import entry_points\n",
    "\n",
    "\n",
    "def has_adapter(name: str) -> bool:\n",
    "    eps = entry_points().select(group=\"devqubit.adapters\")\n",
    "    return any(ep.name == name for ep in eps)\n",
    "\n",
    "\n",
    "if not has_adapter(\"qiskit-runtime\"):\n",
    "    raise ImportError(\n",
    "        \"devqubit Qiskit Runtime adapter is not installed.\\n\"\n",
    "        \"Install with: pip install 'devqubit[qiskit-runtime]'\"\n",
    "    )\n",
    "\n",
    "print(\"Qiskit Runtime adapter available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import qiskit_aer\n",
    "\n",
    "    _ = qiskit_aer.__version__\n",
    "    _AER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    _AER_AVAILABLE = False\n",
    "\n",
    "# --- Imports ---\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Mapping, Tuple\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit_ibm_runtime import SamplerV2\n",
    "from qiskit_ibm_runtime.fake_provider import FakeManilaV2\n",
    "\n",
    "if _AER_AVAILABLE:\n",
    "    from qiskit_aer import AerSimulator\n",
    "    from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "\n",
    "from devqubit import (\n",
    "    track,\n",
    "    wrap_backend,\n",
    "    create_registry,\n",
    "    create_store,\n",
    "    diff,\n",
    "    verify,\n",
    ")\n",
    "\n",
    "from devqubit.compare import VerifyPolicy\n",
    "from devqubit.ci import write_junit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Configuration and local workspace.\"\"\"\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DriftDemoConfig:\n",
    "    \"\"\"Configuration for the drift demo.\"\"\"\n",
    "\n",
    "    project_name: str = \"production_monitoring\"\n",
    "    workspace_dir: str = \".devqubit_drift_demo\"\n",
    "\n",
    "    seed: int = 42\n",
    "    n_qubits: int = 3\n",
    "    optimization_level: int = 2\n",
    "\n",
    "    shots_baseline: int = 4096\n",
    "    shots_candidates: Tuple[int, ...] = (256, 4096, 8192)\n",
    "    top_k: int = 3\n",
    "\n",
    "    tvd_max: float = 0.03\n",
    "\n",
    "    drift_depol_1q: float = 0.01\n",
    "    drift_depol_2q: float = 0.03\n",
    "\n",
    "\n",
    "CFG = DriftDemoConfig()\n",
    "\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    \"\"\"Seed Python and NumPy RNGs.\"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# --- Fresh workspace ---\n",
    "WORKSPACE = Path(CFG.workspace_dir)\n",
    "if WORKSPACE.exists():\n",
    "    shutil.rmtree(WORKSPACE)\n",
    "WORKSPACE.mkdir(parents=True)\n",
    "\n",
    "store = create_store(f\"file://{WORKSPACE}/objects\")\n",
    "registry = create_registry(f\"file://{WORKSPACE}\")\n",
    "\n",
    "\n",
    "# Local testing backend (no credentials required)\n",
    "fake_backend = FakeManilaV2()\n",
    "print(f\"Backend snapshot: {fake_backend.name} ({fake_backend.num_qubits} qubits)\")\n",
    "print(f\"Workspace: {WORKSPACE.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c18df",
   "metadata": {},
   "source": [
    "## 1) Benchmark circuit\n",
    "\n",
    "We want a circuit that is *sensitive* to calibration quality (single-qubit rotations, entangling gates, and some depth).  \n",
    "The output distribution becomes our “health signal” over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3d9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benchmark_circuit(n_qubits: int) -> QuantumCircuit:\n",
    "    \"\"\"Create a small benchmark circuit for calibration monitoring.\"\"\"\n",
    "\n",
    "    qc = QuantumCircuit(n_qubits, name=\"calibration_benchmark\")\n",
    "\n",
    "    # Layer 1: prepare superposition\n",
    "    for q in range(n_qubits):\n",
    "        qc.h(q)\n",
    "\n",
    "    # Layer 2: chain entanglement\n",
    "    for q in range(n_qubits - 1):\n",
    "        qc.cx(q, q + 1)\n",
    "\n",
    "    # Layer 3: rotations (gate-error sensitive)\n",
    "    for q in range(n_qubits):\n",
    "        qc.rz(np.pi / 4, q)\n",
    "        qc.rx(np.pi / 3, q)\n",
    "\n",
    "    # Layer 4: more entanglement (depth)\n",
    "    for q in range(n_qubits - 1):\n",
    "        qc.cx(q, q + 1)\n",
    "\n",
    "    qc.measure_all()\n",
    "    return qc\n",
    "\n",
    "\n",
    "def concentration_topk(counts: Mapping[str, int], k: int) -> float:\n",
    "    \"\"\"Compute concentration of the top-k most likely outcomes.\"\"\"\n",
    "\n",
    "    total = sum(counts.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    top = sorted(counts.values(), reverse=True)[:k]\n",
    "    return float(sum(top)) / float(total)\n",
    "\n",
    "\n",
    "def shannon_entropy_bits(counts: Mapping[str, int], eps: float = 1e-12) -> float:\n",
    "    \"\"\"Compute Shannon entropy (in bits) of a discrete distribution.\"\"\"\n",
    "\n",
    "    total = sum(counts.values())\n",
    "    if total == 0:\n",
    "        return 0.0\n",
    "    probs = np.array(list(counts.values()), dtype=float) / float(total)\n",
    "    return float(-np.sum(probs * np.log2(probs + eps)))\n",
    "\n",
    "\n",
    "def make_sampler(mode, default_shots: int) -> SamplerV2:\n",
    "    \"\"\"Create a SamplerV2 instance with a default shot budget.\"\"\"\n",
    "\n",
    "    sampler = SamplerV2(mode=mode)\n",
    "    # In V2 primitives, default_shots is the simplest way to control sampling budget.\n",
    "    sampler.options.default_shots = int(default_shots)\n",
    "    return sampler\n",
    "\n",
    "\n",
    "def make_drift_backend(\n",
    "    depol_1q: float,\n",
    "    depol_2q: float,\n",
    "    seed: int,\n",
    "):\n",
    "    \"\"\"Create an Aer backend that emulates 'worse calibration' (optional).\"\"\"\n",
    "    if not _AER_AVAILABLE:\n",
    "        return None\n",
    "\n",
    "    noise_model = NoiseModel()\n",
    "\n",
    "    # Typical IBM basis instructions after transpilation.\n",
    "    one_qubit_instr = [\"rz\", \"sx\", \"x\", \"id\"]\n",
    "    two_qubit_instr = [\"cx\"]\n",
    "\n",
    "    noise_model.add_all_qubit_quantum_error(\n",
    "        depolarizing_error(depol_1q, 1),\n",
    "        one_qubit_instr,\n",
    "    )\n",
    "    noise_model.add_all_qubit_quantum_error(\n",
    "        depolarizing_error(depol_2q, 2),\n",
    "        two_qubit_instr,\n",
    "    )\n",
    "\n",
    "    return AerSimulator(noise_model=noise_model, seed_simulator=seed)\n",
    "\n",
    "\n",
    "def run_and_log_benchmark(\n",
    "    *,\n",
    "    project: str,\n",
    "    store,\n",
    "    registry,\n",
    "    sampler: SamplerV2,\n",
    "    circuit_isa: QuantumCircuit,\n",
    "    params: Mapping[str, object],\n",
    "    tags: Mapping[str, str],\n",
    ") -> str:\n",
    "    \"\"\"Execute the benchmark circuit and log a devqubit run.\"\"\"\n",
    "\n",
    "    with track(\n",
    "        project=project,\n",
    "        store=store,\n",
    "        registry=registry,\n",
    "    ) as run:\n",
    "        tracked_sampler = wrap_backend(run, sampler)\n",
    "\n",
    "        run.log_params(dict(params))\n",
    "        run.set_tags(dict(tags))\n",
    "\n",
    "        job = tracked_sampler.run([circuit_isa])\n",
    "        pub_result = job.result()[0]\n",
    "        counts = pub_result.data.meas.get_counts()\n",
    "\n",
    "        run.log_metrics(\n",
    "            {\n",
    "                \"concentration_topk\": concentration_topk(counts, k=CFG.top_k),\n",
    "                \"unique_outcomes\": int(len(counts)),\n",
    "                \"entropy_bits\": shannon_entropy_bits(counts),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return run.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8345c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build + transpile circuit once\n",
    "circuit = create_benchmark_circuit(CFG.n_qubits)\n",
    "print(circuit.draw())\n",
    "\n",
    "pm = generate_preset_pass_manager(\n",
    "    backend=fake_backend,\n",
    "    optimization_level=CFG.optimization_level,\n",
    ")\n",
    "circuit_isa = pm.run(circuit)\n",
    "\n",
    "print(\"\\nTranspiled (ISA) circuit:\")\n",
    "print(circuit_isa.draw(fold=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba77685",
   "metadata": {},
   "source": [
    "## 2) Establish a baseline (reference)\n",
    "\n",
    "A baseline is the “known-good” distribution we compare against later.  \n",
    "We store it in the devqubit registry as the project baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_sampler = make_sampler(\n",
    "    mode=fake_backend,\n",
    "    default_shots=CFG.shots_baseline,\n",
    ")\n",
    "\n",
    "baseline_id = run_and_log_benchmark(\n",
    "    project=CFG.project_name,\n",
    "    store=store,\n",
    "    registry=registry,\n",
    "    sampler=baseline_sampler,\n",
    "    circuit_isa=circuit_isa,\n",
    "    params={\n",
    "        \"circuit_name\": \"calibration_benchmark\",\n",
    "        \"n_qubits\": CFG.n_qubits,\n",
    "        \"shots\": CFG.shots_baseline,\n",
    "        \"optimization_level\": CFG.optimization_level,\n",
    "        \"backend\": fake_backend.name,\n",
    "    },\n",
    "    tags={\"role\": \"baseline\", \"scenario\": \"baseline\"},\n",
    ")\n",
    "\n",
    "registry.set_baseline(CFG.project_name, baseline_id)\n",
    "print(f\"Baseline run set: {baseline_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21bfb1",
   "metadata": {},
   "source": [
    "## 3) Inspect the captured device snapshot / fingerprints\n",
    "\n",
    "devqubit stores a snapshot that helps you answer:  \n",
    "**“Did the hardware configuration/calibration change between runs?”**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b25009",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_rec = registry.load(baseline_id)\n",
    "\n",
    "print(\"Device Snapshot\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "device_snap = baseline_rec.record.get(\"device_snapshot\", {})\n",
    "if device_snap:\n",
    "    print(f\"Backend:     {device_snap.get('backend_name')}\")\n",
    "    print(f\"Captured at: {device_snap.get('captured_at')}\")\n",
    "    print(f\"Qubits:      {device_snap.get('num_qubits')}\")\n",
    "\n",
    "    cal = device_snap.get(\"calibration\", {})\n",
    "    if cal:\n",
    "        print(\"\\nCalibration summary (median):\")\n",
    "        for key in (\"t1_us\", \"t2_us\", \"readout_error\"):\n",
    "            if key in cal:\n",
    "                print(f\"  {key:>13s}: {cal[key].get('median', 'N/A')}\")\n",
    "else:\n",
    "    print(\"(No device snapshot found — depends on backend/mode.)\")\n",
    "\n",
    "print(\"\\nFingerprints:\")\n",
    "for key, value in baseline_rec.fingerprints.items():\n",
    "    print(f\"  {key}: {value[:48]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa5d7f6",
   "metadata": {},
   "source": [
    "## 4) Candidate runs\n",
    "\n",
    "We run the *same* transpiled circuit under different conditions:\n",
    "\n",
    "- **shot variability** (common in practice when budgets change),\n",
    "- optionally, a **worse calibration** scenario (if `qiskit-aer` is installed).\n",
    "\n",
    "All candidates are tagged as `role=candidate`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Scenario:\n",
    "    \"\"\"A production scenario to execute.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    shots: int\n",
    "    mode: object\n",
    "    backend_name: str\n",
    "\n",
    "\n",
    "scenarios: List[Scenario] = [\n",
    "    Scenario(\n",
    "        \"low_shots\",\n",
    "        \"Reduced shot budget\",\n",
    "        CFG.shots_candidates[0],\n",
    "        fake_backend,\n",
    "        fake_backend.name,\n",
    "    ),\n",
    "    Scenario(\n",
    "        \"stable\",\n",
    "        \"Normal operation\",\n",
    "        CFG.shots_candidates[1],\n",
    "        fake_backend,\n",
    "        fake_backend.name,\n",
    "    ),\n",
    "    Scenario(\n",
    "        \"high_shots\",\n",
    "        \"Higher precision run\",\n",
    "        CFG.shots_candidates[2],\n",
    "        fake_backend,\n",
    "        fake_backend.name,\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Optional: add a more realistic drift scenario using Aer noise model tweaks\n",
    "drift_backend = make_drift_backend(\n",
    "    depol_1q=CFG.drift_depol_1q,\n",
    "    depol_2q=CFG.drift_depol_2q,\n",
    "    seed=CFG.seed,\n",
    ")\n",
    "\n",
    "if drift_backend is not None:\n",
    "    scenarios.append(\n",
    "        Scenario(\n",
    "            \"calibration_drift\",\n",
    "            \"Extra depolarizing noise (Aer-based drift)\",\n",
    "            CFG.shots_candidates[1],\n",
    "            drift_backend,\n",
    "            \"aer_simulator\",\n",
    "        )\n",
    "    )\n",
    "    print(\"Added Aer-based drift scenario.\")\n",
    "else:\n",
    "    print(\"Aer-based drift scenario skipped (qiskit-aer not installed).\")\n",
    "\n",
    "\n",
    "production_run_ids: List[str] = []\n",
    "\n",
    "print(\"\\nExecuting scenarios...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for sc in scenarios:\n",
    "    sampler = make_sampler(mode=sc.mode, default_shots=sc.shots)\n",
    "\n",
    "    run_id = run_and_log_benchmark(\n",
    "        project=CFG.project_name,\n",
    "        store=store,\n",
    "        registry=registry,\n",
    "        sampler=sampler,\n",
    "        circuit_isa=circuit_isa,\n",
    "        params={\n",
    "            \"circuit_name\": \"calibration_benchmark\",\n",
    "            \"n_qubits\": CFG.n_qubits,\n",
    "            \"shots\": sc.shots,\n",
    "            \"optimization_level\": CFG.optimization_level,\n",
    "            \"backend\": sc.backend_name,\n",
    "            \"scenario_description\": sc.description,\n",
    "        },\n",
    "        tags={\"role\": \"candidate\", \"scenario\": sc.name},\n",
    "    )\n",
    "\n",
    "    production_run_ids.append(run_id)\n",
    "    print(f\"{sc.name:>18s} -> run_id={run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d23c9",
   "metadata": {},
   "source": [
    "## 5) Drift analysis (baseline vs candidates)\n",
    "\n",
    "We compare distributions using **Total Variation Distance (TVD)**, which on discrete domains is:\n",
    "\n",
    "$\\mathrm{TVD}(P, Q) = \\frac{1}{2} \\sum_x |P(x) - Q(x)|$\n",
    "\n",
    "devqubit computes TVD for you in `diff()` and `verify()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835dac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Drift Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for run_id in production_run_ids:\n",
    "    comp = diff(baseline_id, run_id, registry=registry, store=store)\n",
    "\n",
    "    sc = registry.load(run_id).tags.get(\"scenario\", \"?\")\n",
    "    tvd = comp.tvd\n",
    "\n",
    "    if tvd is None:\n",
    "        print(f\"{sc:>18s}: TVD not available\")\n",
    "        continue\n",
    "\n",
    "    status = \"✓ OK\" if tvd <= CFG.tvd_max else \"! DRIFT\"\n",
    "    print(f\"{sc:>18s}: TVD={tvd:.4f}  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3242d",
   "metadata": {},
   "source": [
    "## 6) CI/CD-style verification (policy)\n",
    "\n",
    "In pipelines you usually want an **automated pass/fail**.\n",
    "\n",
    "We enforce:\n",
    "- program must match (same circuit),\n",
    "- fingerprints can differ (backend snapshot changes are part of the story),\n",
    "- TVD must be under a threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb875f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_policy = VerifyPolicy(\n",
    "    params_must_match=False,  # allow different shot counts\n",
    "    program_must_match=True,  # same circuit is required\n",
    "    fingerprint_must_match=False,  # hardware snapshots can change\n",
    "    tvd_max=CFG.tvd_max,\n",
    ")\n",
    "\n",
    "print(\"CI/CD Verification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_rec = registry.load(baseline_id)\n",
    "\n",
    "for run_id in production_run_ids:\n",
    "    candidate = registry.load(run_id)\n",
    "    sc = candidate.tags.get(\"scenario\", \"?\")\n",
    "\n",
    "    result = verify(\n",
    "        baseline_rec,\n",
    "        candidate,\n",
    "        store_baseline=store,\n",
    "        store_candidate=store,\n",
    "        policy=production_policy,\n",
    "    )\n",
    "\n",
    "    status = \"✓ PASSED\" if result.ok else \"✗ FAILED\"\n",
    "    print(f\"\\n{sc}: {status}\")\n",
    "\n",
    "    if not result.ok:\n",
    "        for failure in result.failures:\n",
    "            print(f\"  - {failure}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0defef74",
   "metadata": {},
   "source": [
    "## 7) Export a JUnit report\n",
    "\n",
    "JUnit XML is a common interchange format for CI systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc995a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a JUnit report for the *last* scenario (as an example).\n",
    "last_candidate = registry.load(production_run_ids[-1])\n",
    "\n",
    "result = verify(\n",
    "    baseline_rec,\n",
    "    last_candidate,\n",
    "    store_baseline=store,\n",
    "    store_candidate=store,\n",
    "    policy=production_policy,\n",
    ")\n",
    "\n",
    "junit_path = WORKSPACE / \"test-results.xml\"\n",
    "write_junit(result, junit_path)\n",
    "\n",
    "print(f\"JUnit report written to: {junit_path}\")\n",
    "print(\"\\n--- test-results.xml ---\")\n",
    "print(junit_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913cfe9",
   "metadata": {},
   "source": [
    "## 8) Debugging: full comparison details\n",
    "\n",
    "When something fails, you usually want a human-readable diff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9127c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = diff(\n",
    "    baseline_id,\n",
    "    production_run_ids[-1],\n",
    "    registry=registry,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f558b12",
   "metadata": {},
   "source": [
    "## 9) Simple monitoring dashboard\n",
    "\n",
    "A tiny text dashboard that pulls all runs from the registry and verifies candidates against the current baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = registry.list_runs(project=CFG.project_name)\n",
    "baseline_info = registry.get_baseline(CFG.project_name)\n",
    "\n",
    "print(\"Production Monitoring Dashboard\")\n",
    "print(\"=\" * 80)\n",
    "print(\n",
    "    f\"Baseline: {baseline_info['run_id'][:16]}... (set: {baseline_info['set_at'][:10]})\\n\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"{'Run ID':<20} {'Role':<10} {'Scenario':<18} {'Conc(topK)':>10} {'Entropy':>10} {'Status':>8}\"\n",
    ")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for run_info in all_runs:\n",
    "    rec = registry.load(run_info[\"run_id\"])\n",
    "    role = rec.tags.get(\"role\", \"N/A\")\n",
    "    scenario = rec.tags.get(\"scenario\", \"-\")\n",
    "\n",
    "    conc = float(rec.metrics.get(\"concentration_topk\", 0.0))\n",
    "    ent = float(rec.metrics.get(\"entropy_bits\", 0.0))\n",
    "\n",
    "    if role == \"candidate\":\n",
    "        v = verify(\n",
    "            baseline_rec,\n",
    "            rec,\n",
    "            store_baseline=store,\n",
    "            store_candidate=store,\n",
    "            policy=production_policy,\n",
    "        )\n",
    "        status = \"✓\" if v.ok else \"✗\"\n",
    "    else:\n",
    "        status = \"-\"\n",
    "\n",
    "    print(\n",
    "        f\"{rec.run_id[:18]}.. {role:<10} {scenario:<18} {conc:>10.2%} {ent:>10.3f} {status:>8}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cleanup (keeps reruns tidy).\n",
    "# If you'd like to inspect the registry/artifacts on disk, comment this out.\n",
    "shutil.rmtree(WORKSPACE)\n",
    "print(f\"Workspace cleaned up: {WORKSPACE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eaa717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
