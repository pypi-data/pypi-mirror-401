{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Quantum Machine Learning with PennyLane + devqubit\n",
    "\n",
    "This notebook is a **small, self-contained demo** of how devqubit can track *quantum machine learning* experiments built with PennyLane.\n",
    "\n",
    "We'll train a tiny **3-qubit variational classifier** (a \"quantum neural network\" style model) and use devqubit to:\n",
    "\n",
    "- log **epoch-by-epoch** metrics (loss, train accuracy, test accuracy),\n",
    "- capture **hyperparameters** and tags,\n",
    "- run an **architecture sweep** (grouped runs),\n",
    "- store **trained parameters** as an artifact,\n",
    "- and compare two runs to see what **changed**.\n",
    "\n",
    "> Why `default.qubit`?  \n",
    "> It's PennyLane's standard **state-vector simulator** on CPU. With `shots=None` (the default), it returns **analytic** expectation values, which keeps this demo fast and deterministic.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from importlib.metadata import entry_points\n",
    "\n",
    "\n",
    "def has_adapter(name: str) -> bool:\n",
    "    eps = entry_points().select(group=\"devqubit.adapters\")\n",
    "    return any(ep.name == name for ep in eps)\n",
    "\n",
    "\n",
    "if not has_adapter(\"pennylane\"):\n",
    "    raise ImportError(\n",
    "        \"devqubit Pennylane adapter is not installed.\\n\"\n",
    "        \"Install with: pip install 'devqubit[pennylane]'\"\n",
    "    )\n",
    "\n",
    "print(\"Pennylane adapter available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "\n",
    "from devqubit import (\n",
    "    create_registry,\n",
    "    create_store,\n",
    "    track,\n",
    "    wrap_backend,\n",
    "    diff,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setup workspace and configuration.\n",
    "\n",
    "We use a local folder as a tiny \"experiment workspace\":\n",
    "- devqubit *store* holds artifacts (e.g., trained parameter arrays)\n",
    "- devqubit *registry* holds run metadata (params, metrics, tags, group IDs)\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "SEED: int = 42\n",
    "\n",
    "# Data\n",
    "N_SAMPLES: int = 500\n",
    "NOISE_STD: float = 0.05\n",
    "TEST_FRACTION: float = 0.20\n",
    "VAL_FRACTION: float = 0.20\n",
    "\n",
    "# Quantum model / simulator\n",
    "DEVICE_NAME: str = \"default.qubit\"\n",
    "N_QUBITS: int = 3\n",
    "SHOTS = None  # None = analytic expectation values (no sampling noise)\n",
    "\n",
    "# Training\n",
    "N_EPOCHS: int = 50\n",
    "LEARNING_RATE: float = 0.3\n",
    "\n",
    "# Numerics / evaluation\n",
    "EPS: float = 1e-7\n",
    "EVAL_CHUNK_SIZE: int = 512  # chunk evaluation to avoid huge tapes\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Reproducibility\n",
    "# ---------------------------------------------------------------------\n",
    "np.random.seed(SEED)\n",
    "pnp.random.seed(SEED)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Fresh workspace (safe to re-run)\n",
    "# ---------------------------------------------------------------------\n",
    "WORKSPACE = Path(\".devqubit_qml_demo\")\n",
    "if WORKSPACE.exists():\n",
    "    shutil.rmtree(WORKSPACE)\n",
    "WORKSPACE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "store = create_store(f\"file://{WORKSPACE}/objects\")\n",
    "registry = create_registry(f\"file://{WORKSPACE}\")\n",
    "\n",
    "print(f\"Workspace: {WORKSPACE.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f7f04",
   "metadata": {},
   "source": [
    "## What gets tracked?\n",
    "\n",
    "devqubit focuses on the pieces you typically want when iterating on QML:\n",
    "\n",
    "- **Run metadata**: parameters (hyperparameters), tags, and a run ID\n",
    "- **Metrics over time**: loss and accuracy logged every epoch\n",
    "- **Backend activity**: when a QNode executes on a device, devqubit can record that execution (via `wrap_backend`)\n",
    "- **Artifacts**: any JSON/arrays you store (e.g., trained weights)\n",
    "\n",
    "In this notebook we keep it intentionally simple: one small dataset, two tiny circuits, and a straightforward training loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Generate a tiny toy dataset (train / validation / test)\n",
    "\n",
    "We create a balanced 2D dataset:\n",
    "\n",
    "- **Class 1**: points *inside* a circle  \n",
    "- **Class 0**: points *outside* the circle\n",
    "\n",
    "Why this dataset?\n",
    "- It is visually intuitive\n",
    "- It is small enough to train quickly\n",
    "- It makes architecture differences easy to notice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0563ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle_data(n_samples: int, noise_std: float, seed: int):\n",
    "    \"\"\"Generate 2D binary data: points inside vs. outside a circle.\"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Balanced classes\n",
    "    n_per_class = n_samples // 2\n",
    "\n",
    "    # Class 1: inside circle (radius < 0.5)\n",
    "    angles_in = rng.uniform(0, 2 * np.pi, n_per_class)\n",
    "    radii_in = rng.uniform(0.0, 0.45, n_per_class)\n",
    "    X_in = np.column_stack(\n",
    "        [\n",
    "            radii_in * np.cos(angles_in),\n",
    "            radii_in * np.sin(angles_in),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Class 0: outside circle (radius > 0.5)\n",
    "    angles_out = rng.uniform(0, 2 * np.pi, n_per_class)\n",
    "    radii_out = rng.uniform(0.6, 1.0, n_per_class)\n",
    "    X_out = np.column_stack(\n",
    "        [\n",
    "            radii_out * np.cos(angles_out),\n",
    "            radii_out * np.sin(angles_out),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X = np.vstack([X_out, X_in])\n",
    "    y = np.hstack(\n",
    "        [\n",
    "            np.zeros(n_per_class, dtype=int),\n",
    "            np.ones(n_per_class, dtype=int),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Shuffle and add noise\n",
    "    perm = rng.permutation(len(y))\n",
    "    X, y = X[perm], y[perm]\n",
    "    X = X + rng.normal(\n",
    "        loc=0.0,\n",
    "        scale=noise_std,\n",
    "        size=X.shape,\n",
    "    )\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_val_test_split(\n",
    "    X: ArrayLike,\n",
    "    y: ArrayLike,\n",
    "    val_frac: float,\n",
    "    test_frac: float,\n",
    "    seed: int = 0,\n",
    ") -> tuple:\n",
    "    \"\"\"Randomly split X, y into train/val/test using NumPy.\"\"\"\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.permutation(len(y))\n",
    "\n",
    "    n_test = int(round(len(y) * test_frac))\n",
    "    n_val = int(round(len(y) * val_frac))\n",
    "\n",
    "    test_idx = idx[:n_test]\n",
    "    val_idx = idx[n_test : n_test + n_val]\n",
    "    train_idx = idx[n_test + n_val :]\n",
    "\n",
    "    return (\n",
    "        X[train_idx],\n",
    "        X[val_idx],\n",
    "        X[test_idx],\n",
    "        y[train_idx],\n",
    "        y[val_idx],\n",
    "        y[test_idx],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create a single dataset, then split cleanly into train/val/test ---\n",
    "X, y = generate_circle_data(\n",
    "    n_samples=N_SAMPLES,\n",
    "    noise_std=NOISE_STD,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    val_frac=VAL_FRACTION,\n",
    "    test_frac=TEST_FRACTION,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "rows = [\n",
    "    (\"Train\", X_train, y_train),\n",
    "    (\"Val\", X_val, y_val),\n",
    "    (\"Test\", X_test, y_test),\n",
    "]\n",
    "\n",
    "print(f\"{'Split':<5} {'N':>5} {'Class0':>7} {'Class1':>7}\")\n",
    "for name, X, y in rows:\n",
    "    y = np.asarray(y)\n",
    "    c0 = int((y == 0).sum())\n",
    "    c1 = int((y == 1).sum())\n",
    "    print(f\"{name:<5} {len(X):>5d} {c0:>7d} {c1:>7d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize the dataset ---\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax.scatter(\n",
    "    X_train[y_train == 0, 0],\n",
    "    X_train[y_train == 0, 1],\n",
    "    c=\"tab:blue\",\n",
    "    alpha=0.5,\n",
    "    s=10,\n",
    "    label=\"Class 0 (outside)\",\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    X_train[y_train == 1, 0],\n",
    "    X_train[y_train == 1, 1],\n",
    "    c=\"tab:orange\",\n",
    "    alpha=0.5,\n",
    "    s=10,\n",
    "    label=\"Class 1 (inside)\",\n",
    ")\n",
    "\n",
    "circle = plt.Circle(\n",
    "    (0, 0),\n",
    "    0.5,\n",
    "    fill=False,\n",
    "    linestyle=\"--\",\n",
    "    color=\"gray\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "\n",
    "ax.add_patch(circle)\n",
    "ax.set_xlim(-1.2, 1.2)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"x0\")\n",
    "ax.set_ylabel(\"x1\")\n",
    "ax.set_title(\"Training Data\")\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Define two tiny quantum classifier architectures\n",
    "\n",
    "Both models use **3 qubits** and output a single number:\n",
    "\n",
    "- we measure <Z> on wire 0 (range `[-1, +1]`)\n",
    "- later we map it into a \"probability-like\" value in `[0, 1]`\n",
    "\n",
    "We compare two feature encodings:\n",
    "\n",
    "1. **Angle encoding**  \n",
    "   Encode each feature with a rotation gate (simple and common).\n",
    "\n",
    "2. **IQP-style encoding**  \n",
    "   Use an entangling feature map (includes a ZZ interaction term).\n",
    "\n",
    "> Note: these circuits are intentionally small so the focus stays on **devqubit tracking** rather than model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectures",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reuploading_radial_classifier(n_layers: int, dev):\n",
    "    \"\"\"Data re-uploading classifier for the circle task.\"\"\"\n",
    "\n",
    "    @qml.qnode(dev, diff_method=\"backprop\")\n",
    "    def circuit(x, params):\n",
    "        # -------------------------\n",
    "        # 0) Unpack features\n",
    "        # -------------------------\n",
    "        x0 = x[..., 0]\n",
    "        x1 = x[..., 1]\n",
    "        r2 = x0**2 + x1**2  # radial feature for circle data\n",
    "\n",
    "        for layer in range(n_layers):\n",
    "            # -------------------------\n",
    "            # 1) Re-upload the features\n",
    "            # -------------------------\n",
    "            qml.RY(pnp.pi * x0, wires=0)\n",
    "            qml.RZ(pnp.pi * x1, wires=0)\n",
    "            qml.RY(pnp.pi * r2, wires=0)\n",
    "\n",
    "            # -------------------------\n",
    "            # 2) Trainable \"processing\" unitary\n",
    "            # -------------------------\n",
    "            qml.Rot(\n",
    "                params[layer, 0],\n",
    "                params[layer, 1],\n",
    "                params[layer, 2],\n",
    "                wires=0,\n",
    "            )\n",
    "\n",
    "        # -------------------------\n",
    "        # 3) Readout\n",
    "        # -------------------------\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "    # Parameter tensor shape: one angle per qubit per layer\n",
    "    return circuit, (n_layers, 3)\n",
    "\n",
    "\n",
    "def create_iqp_encoding_classifier(n_layers: int, dev):\n",
    "    \"\"\"IQP-style feature map with StronglyEntanglingLayers variational classifier.\"\"\"\n",
    "\n",
    "    @qml.qnode(dev, diff_method=\"backprop\")\n",
    "    def circuit(x, params):\n",
    "        # -------------------------\n",
    "        # 0) Unpack features\n",
    "        # -------------------------\n",
    "        x0 = x[..., 0]\n",
    "        x1 = x[..., 1]\n",
    "        r2 = x0**2 + x1**2\n",
    "\n",
    "        # -------------------------\n",
    "        # 1) IQP-style encoding\n",
    "        # -------------------------\n",
    "        for w in [0, 1, 2]:\n",
    "            qml.Hadamard(wires=w)\n",
    "\n",
    "        # Single-qubit feature terms\n",
    "        qml.RZ(pnp.pi * x0, wires=0)\n",
    "        qml.RZ(pnp.pi * x1, wires=1)\n",
    "        qml.RZ(pnp.pi * r2, wires=2)\n",
    "\n",
    "        # Feature interaction terms (ZZ encodes products)\n",
    "        qml.IsingZZ(pnp.pi * (x0 * x1), wires=[0, 1])\n",
    "        qml.IsingZZ(pnp.pi * (x1 * r2), wires=[1, 2])\n",
    "        qml.IsingZZ(pnp.pi * (x0 * r2), wires=[0, 2])\n",
    "\n",
    "        # -------------------------\n",
    "        # 2) Trainable variational layers (richer ansatz)\n",
    "        # -------------------------\n",
    "        qml.StronglyEntanglingLayers(params, wires=[0, 1, 2])\n",
    "\n",
    "        # -------------------------\n",
    "        # 3) Readout\n",
    "        # -------------------------\n",
    "        return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "    # Parameter tensor shape: one trainable angle per qubit per layer\n",
    "    return circuit, (n_layers, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Train the classifier and log every epoch\n",
    "\n",
    "We use a standard \"hybrid\" loop:\n",
    "\n",
    "1. Run the quantum circuit to get a scalar output\n",
    "2. Convert output into a probability-like value in `[0, 1]`\n",
    "3. Compute **binary cross-entropy** loss\n",
    "4. Update parameters with **Adam**\n",
    "5. Log **loss**, **train accuracy**, and **test accuracy** to devqubit each epoch\n",
    "\n",
    "The training loop below is deliberately plain Python so the tracking is easy to follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-fn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(\n",
    "    run,\n",
    "    circuit,\n",
    "    param_shape,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    *,\n",
    "    n_epochs: int,\n",
    "    learning_rate: float,\n",
    "    eps: float,\n",
    "    eval_chunk_size: int,\n",
    "    seed: int,\n",
    "):\n",
    "    \"\"\"Train a quantum classifier and track metrics epoch-by-epoch.\"\"\"\n",
    "\n",
    "    # Convert to PennyLane NumPy arrays to keep math + autograd consistent.\n",
    "    X_train = pnp.asarray(X_train)\n",
    "    y_train = pnp.asarray(y_train)\n",
    "    X_val = pnp.asarray(X_val)\n",
    "    y_val = pnp.asarray(y_val)\n",
    "    X_test = pnp.asarray(X_test)\n",
    "    y_test = pnp.asarray(y_test)\n",
    "\n",
    "    np.random.default_rng(seed)\n",
    "\n",
    "    # Initialize trainable parameters\n",
    "    params = pnp.random.uniform(-np.pi, np.pi, param_shape, requires_grad=True)\n",
    "\n",
    "    # Adam is a good default optimizer for small demos\n",
    "    opt = qml.AdamOptimizer(stepsize=learning_rate)\n",
    "\n",
    "    def predict_batch(X, p):\n",
    "        \"\"\"Return predicted probabilities for a batch of inputs.\"\"\"\n",
    "        return (circuit(X, p) + 1) / 2  # <Z> in [-1,1] -> [0,1]\n",
    "\n",
    "    def loss_fn(p, Xb, yb):\n",
    "        \"\"\"Binary cross-entropy on a mini-batch (vectorized).\"\"\"\n",
    "        preds = pnp.clip(predict_batch(Xb, p), eps, 1 - eps)\n",
    "        return -pnp.mean(yb * pnp.log(preds) + (1 - yb) * pnp.log(1 - preds))\n",
    "\n",
    "    def accuracy(p, X, y):\n",
    "        \"\"\"Chunked accuracy to keep the quantum tape size reasonable.\"\"\"\n",
    "        correct = 0\n",
    "        n = len(X)\n",
    "        for i in range(0, n, eval_chunk_size):\n",
    "            Xc = X[i : i + eval_chunk_size]\n",
    "            yc = y[i : i + eval_chunk_size]\n",
    "            preds = np.asarray(predict_batch(Xc, p))  # detach for fast thresholding\n",
    "            correct += int(np.sum((preds > 0.5) == np.asarray(yc)))\n",
    "        return correct / n\n",
    "\n",
    "    best_val_acc = -1.0\n",
    "    best_test_acc_at_best_val = 0.0\n",
    "    best_params = params\n",
    "\n",
    "    # Store history for plotting\n",
    "    history = {\"loss\": [], \"train_acc\": [], \"val_acc\": [], \"test_acc\": []}\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        params, epoch_loss = opt.step_and_cost(\n",
    "            lambda pp: loss_fn(pp, X_train, y_train), params\n",
    "        )\n",
    "        epoch_loss = float(epoch_loss)\n",
    "\n",
    "        # Evaluate\n",
    "        train_acc = accuracy(params, X_train, y_train)\n",
    "        val_acc = accuracy(params, X_val, y_val)\n",
    "        test_acc = accuracy(params, X_test, y_test)\n",
    "\n",
    "        # Store for plotting\n",
    "        history[\"loss\"].append(epoch_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        # Log epoch metrics\n",
    "        run.log_metric(\"loss\", epoch_loss, step=epoch)\n",
    "        run.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "        run.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "        run.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "        # Track best model *by validation accuracy*\n",
    "        improved = val_acc > best_val_acc\n",
    "        if improved:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc_at_best_val = test_acc\n",
    "            best_params = params\n",
    "\n",
    "        print(\n",
    "            f\"  Epoch {epoch:2d}: loss={epoch_loss:.4f}, \"\n",
    "            f\"train={train_acc:.2%}, val={val_acc:.2%}, test={test_acc:.2%}\"\n",
    "        )\n",
    "\n",
    "    return best_params, best_val_acc, best_test_acc_at_best_val, n_epochs, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a single baseline model with full tracking.\n",
    "\n",
    "devqubit pattern:\n",
    "1) create a run with `track(...)`\n",
    "2) wrap the PennyLane device with `wrap_backend(...)`\n",
    "3) log params/tags\n",
    "4) train while logging metrics (train/val/test)\n",
    "5) store artifacts (e.g., best parameters by validation accuracy)\n",
    "\"\"\"\n",
    "\n",
    "with track(project=\"qml_classifier\", store=store, registry=registry) as run:\n",
    "    # Device (analytic expectation values by default when shots=None)\n",
    "    base_dev = qml.device(DEVICE_NAME, wires=N_QUBITS, shots=SHOTS)\n",
    "    tracked_dev = wrap_backend(run, base_dev)\n",
    "\n",
    "    # Build the circuit/QNode\n",
    "    BASELINE_ARCH = \"angle_encoding\"\n",
    "    BASELINE_LAYERS = 2\n",
    "    circuit, param_shape = create_reuploading_radial_classifier(\n",
    "        n_layers=BASELINE_LAYERS,\n",
    "        dev=tracked_dev,\n",
    "    )\n",
    "\n",
    "    # Log metadata\n",
    "    run.log_params(\n",
    "        {\n",
    "            \"architecture\": BASELINE_ARCH,\n",
    "            \"n_layers\": BASELINE_LAYERS,\n",
    "            \"n_qubits\": N_QUBITS,\n",
    "            \"n_params\": int(np.prod(param_shape)),\n",
    "            \"device\": DEVICE_NAME,\n",
    "            \"shots\": SHOTS,\n",
    "            \"seed\": SEED,\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"n_epochs\": N_EPOCHS,\n",
    "        }\n",
    "    )\n",
    "    run.set_tags({\"task\": \"binary_classification\", \"status\": \"baseline\"})\n",
    "\n",
    "    print(f\"Training baseline {BASELINE_ARCH} classifier ({BASELINE_LAYERS} layers):\")\n",
    "    best_params, best_val_acc, best_test_acc, epochs_trained, baseline_history = (\n",
    "        train_classifier(\n",
    "            run,\n",
    "            circuit,\n",
    "            param_shape,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            n_epochs=N_EPOCHS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            eps=EPS,\n",
    "            eval_chunk_size=EVAL_CHUNK_SIZE,\n",
    "            seed=SEED,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Summary metrics (easy to query later)\n",
    "    run.log_metrics(\n",
    "        {\n",
    "            \"best_val_accuracy\": float(best_val_acc),\n",
    "            \"best_test_accuracy\": float(best_test_acc),\n",
    "            \"epochs_trained\": int(epochs_trained),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Store best parameters (chosen by validation accuracy)\n",
    "    run.log_json(\n",
    "        name=\"best_params\",\n",
    "        obj={\"params\": np.asarray(best_params).tolist()},\n",
    "        role=\"model\",\n",
    "    )\n",
    "\n",
    "    baseline_id = run.run_id\n",
    "\n",
    "print(f\"\\nBaseline run ID:  {baseline_id}\")\n",
    "print(f\"Best val accuracy:  {best_val_acc:.2%}\")\n",
    "print(f\"Test @ best val:    {best_test_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot training curves ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "epochs = range(len(baseline_history[\"loss\"]))\n",
    "\n",
    "axes[0].plot(epochs, baseline_history[\"loss\"], \"o-\", markersize=4)\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training Loss\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(epochs, baseline_history[\"train_acc\"], \"o-\", markersize=4, label=\"Train\")\n",
    "axes[1].plot(epochs, baseline_history[\"val_acc\"], \"s-\", markersize=4, label=\"Val\")\n",
    "axes[1].plot(epochs, baseline_history[\"test_acc\"], \"^-\", markersize=4, label=\"Test\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpret-train-single",
   "metadata": {},
   "source": [
    "### What you should see\n",
    "\n",
    "During training you'll see a small per-epoch printout. In devqubit, those same values are stored as **time series metrics**.\n",
    "\n",
    "Typical behavior on this toy dataset:\n",
    "\n",
    "- loss decreases over epochs,\n",
    "- training accuracy rises quickly,\n",
    "- test accuracy usually improves and then stabilizes.\n",
    "\n",
    "Because we're using `default.qubit` in analytic mode (`shots=None`), results are usually stable across runs with the same seed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Architecture sweep (grouped runs)\n",
    "\n",
    "Now we run a small sweep across:\n",
    "- two architectures (`angle_encoding`, `iqp_encoding`)\n",
    "- two depths (2 vs 3 layers)\n",
    "\n",
    "devqubit groups these runs using a shared `group_id`. This makes it easy to:\n",
    "- retrieve all runs from a sweep,\n",
    "- compare their metrics,\n",
    "- and pick the best-performing configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architecture-sweep",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sweep over architectures (grouped runs).\n",
    "\n",
    "Each loop iteration creates a *new* devqubit run.\n",
    "All runs share the same `group_id`, making it easy to query/compare them later.\n",
    "\"\"\"\n",
    "\n",
    "sweep_id = \"arch_sweep_example\"\n",
    "\n",
    "architectures = [\n",
    "    (\"angle_encoding\", create_reuploading_radial_classifier, 2),\n",
    "    (\"angle_encoding\", create_reuploading_radial_classifier, 3),\n",
    "    (\"iqp_encoding\", create_iqp_encoding_classifier, 2),\n",
    "    (\"iqp_encoding\", create_iqp_encoding_classifier, 3),\n",
    "]\n",
    "\n",
    "sweep_results = []\n",
    "sweep_best_params = {}  # Store best params for decision boundary plotting\n",
    "\n",
    "print(f\"Sweep group_id: {sweep_id}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for arch_name, builder_fn, n_layers in architectures:\n",
    "    with track(\n",
    "        project=\"qml_classifier\",\n",
    "        store=store,\n",
    "        registry=registry,\n",
    "        group_id=sweep_id,\n",
    "    ) as run:\n",
    "        base_dev = qml.device(\n",
    "            DEVICE_NAME,\n",
    "            wires=N_QUBITS,\n",
    "            shots=SHOTS,\n",
    "        )\n",
    "        tracked_dev = wrap_backend(run, base_dev)\n",
    "\n",
    "        circuit, param_shape = builder_fn(n_layers=n_layers, dev=tracked_dev)\n",
    "\n",
    "        run.log_params(\n",
    "            {\n",
    "                \"architecture\": arch_name,\n",
    "                \"n_layers\": n_layers,\n",
    "                \"n_qubits\": N_QUBITS,\n",
    "                \"n_params\": int(np.prod(param_shape)),\n",
    "                \"device\": DEVICE_NAME,\n",
    "                \"shots\": SHOTS,\n",
    "                \"seed\": SEED,\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"n_epochs\": N_EPOCHS,\n",
    "            }\n",
    "        )\n",
    "        run.set_tags({\"task\": \"binary_classification\", \"status\": \"sweep\"})\n",
    "\n",
    "        print(f\"Training {arch_name} (layers={n_layers})\")\n",
    "\n",
    "        best_params, best_val_acc, best_test_acc, epochs_trained, _ = train_classifier(\n",
    "            run,\n",
    "            circuit,\n",
    "            param_shape,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            n_epochs=N_EPOCHS,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            eps=EPS,\n",
    "            eval_chunk_size=EVAL_CHUNK_SIZE,\n",
    "            seed=SEED,\n",
    "        )\n",
    "\n",
    "        run.log_metrics(\n",
    "            {\n",
    "                \"best_val_accuracy\": float(best_val_acc),\n",
    "                \"best_test_accuracy\": float(best_test_acc),\n",
    "                \"epochs_trained\": int(epochs_trained),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        run.log_json(\n",
    "            name=\"best_params\",\n",
    "            obj={\"params\": np.asarray(best_params).tolist()},\n",
    "            role=\"model\",\n",
    "        )\n",
    "\n",
    "        sweep_results.append(\n",
    "            (\n",
    "                arch_name,\n",
    "                n_layers,\n",
    "                float(best_val_acc),\n",
    "                float(best_test_acc),\n",
    "                run.run_id,\n",
    "            )\n",
    "        )\n",
    "        sweep_best_params[(arch_name, n_layers)] = (best_params, builder_fn)\n",
    "        print(f\"  -> best val={best_val_acc:.2%}, test@bestval={best_test_acc:.2%}\\n\")\n",
    "\n",
    "# Pick the best run by validation accuracy (common best practice)\n",
    "best = max(sweep_results, key=lambda x: x[2])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best by val accuracy: {best[0]} (layers={best[1]})\")\n",
    "print(f\"  best val: {best[2]:.2%}\")\n",
    "print(f\"  test@bestval: {best[3]:.2%}\")\n",
    "print(f\"  run_id: {best[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-sweep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot sweep results comparison ---\n",
    "labels = [f\"{r[0]}\\nL={r[1]}\" for r in sweep_results]\n",
    "val_accs = [r[2] for r in sweep_results]\n",
    "test_accs = [r[3] for r in sweep_results]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bars1 = ax.bar(x - width / 2, val_accs, width, label=\"Val Accuracy\")\n",
    "bars2 = ax.bar(x + width / 2, test_accs, width, label=\"Test Accuracy\")\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Architecture Sweep Results\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=9)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-decision-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot decision boundary of the best model ---\n",
    "best_arch, best_layers = best[0], best[1]\n",
    "best_params_final, best_builder_fn = sweep_best_params[(best_arch, best_layers)]\n",
    "\n",
    "# Create a fresh circuit for prediction (untracked)\n",
    "eval_dev = qml.device(\n",
    "    DEVICE_NAME,\n",
    "    wires=N_QUBITS,\n",
    "    shots=SHOTS,\n",
    ")\n",
    "eval_circuit, _ = best_builder_fn(\n",
    "    n_layers=best_layers,\n",
    "    dev=eval_dev,\n",
    ")\n",
    "\n",
    "# Create grid for decision boundary\n",
    "grid_res = 50\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(-1.2, 1.2, grid_res),\n",
    "    np.linspace(-1.2, 1.2, grid_res),\n",
    ")\n",
    "grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Predict on grid\n",
    "grid_preds = (np.array(eval_circuit(grid_points, best_params_final)) + 1) / 2\n",
    "grid_preds = grid_preds.reshape(xx.shape)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "contour = ax.contourf(\n",
    "    xx,\n",
    "    yy,\n",
    "    grid_preds,\n",
    "    levels=20,\n",
    "    cmap=\"RdYlBu\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.contour(\n",
    "    xx,\n",
    "    yy,\n",
    "    grid_preds,\n",
    "    levels=[0.5],\n",
    "    colors=\"k\",\n",
    "    linewidths=2,\n",
    ")\n",
    "ax.scatter(\n",
    "    X_test[y_test == 0, 0],\n",
    "    X_test[y_test == 0, 1],\n",
    "    c=\"tab:blue\",\n",
    "    s=15,\n",
    "    edgecolors=\"k\",\n",
    "    linewidths=0.5,\n",
    "    label=\"Class 0\",\n",
    ")\n",
    "ax.scatter(\n",
    "    X_test[y_test == 1, 0],\n",
    "    X_test[y_test == 1, 1],\n",
    "    c=\"tab:orange\",\n",
    "    s=15,\n",
    "    edgecolors=\"k\",\n",
    "    linewidths=0.5,\n",
    "    label=\"Class 1\",\n",
    ")\n",
    "circle = plt.Circle(\n",
    "    (0, 0),\n",
    "    0.5,\n",
    "    fill=False,\n",
    "    linestyle=\"--\",\n",
    "    color=\"gray\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "ax.add_patch(circle)\n",
    "ax.set_xlim(-1.2, 1.2)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"x0\")\n",
    "ax.set_ylabel(\"x1\")\n",
    "ax.set_title(f\"Decision Boundary: {best_arch} (L={best_layers})\")\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "plt.colorbar(contour, ax=ax, label=\"P(class=1)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpret-architecture-sweep",
   "metadata": {},
   "source": [
    "**How to interpret sweep results**\n",
    "\n",
    "When comparing architectures on small QML problems, focus on:\n",
    "\n",
    "- **best test accuracy** (generalization),\n",
    "- how sensitive results are to **depth** (2 vs 3 layers),\n",
    "- and whether an encoding seems to learn the geometry of the data faster.\n",
    "\n",
    "Because this is a toy dataset and tiny circuits, the \"best\" model can vary a bit.\n",
    "The key takeaway is how devqubit keeps the sweep organized and comparable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Query the registry and compare runs\n",
    "\n",
    "devqubit stores run metadata in the registry, so you can later:\n",
    "\n",
    "- list experiment groups (sweeps),\n",
    "- list runs in a group,\n",
    "- load individual run records,\n",
    "- and compare runs side-by-side.\n",
    "\n",
    "Below we do a tiny \"report\" that prints architecture + layers + best accuracy for each run in every group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Query and analyze QML runs.\n",
    "\n",
    "We print a compact summary: for each group, list runs with their key metrics.\n",
    "\"\"\"\n",
    "\n",
    "groups = registry.list_groups()\n",
    "\n",
    "print(\"QML Experiment Groups\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for group in groups:\n",
    "    print(f\"\\n{group['group_name']}  (group_id={group['group_id']})\")\n",
    "    runs_in_group = registry.list_runs_in_group(group[\"group_id\"])\n",
    "\n",
    "    for run_info in runs_in_group:\n",
    "        rec = registry.load(run_info[\"run_id\"])\n",
    "        arch = rec.params.get(\"architecture\", \"N/A\")\n",
    "        layers = rec.params.get(\"n_layers\", \"N/A\")\n",
    "\n",
    "        best_val = rec.metrics.get(\"best_val_accuracy\", None)\n",
    "        best_test = rec.metrics.get(\"best_test_accuracy\", None)\n",
    "\n",
    "        if best_val is None:\n",
    "            # older/baseline runs might have only test accuracy logged\n",
    "            best_test = rec.metrics.get(\"best_test_accuracy\", 0.0)\n",
    "            print(f\"  {arch} L={layers}: test(best)={best_test:.2%}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"  {arch} L={layers}: val(best)={best_val:.2%} | test@bestval={best_test:.2%}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpret-analyze",
   "metadata": {},
   "source": [
    "**Why grouping matters**\n",
    "\n",
    "Grouped runs make sweeps easy to work with:\n",
    "\n",
    "- you can retrieve *all* runs from a sweep without remembering run IDs,\n",
    "- compare best metrics across candidates,\n",
    "- and keep the baseline run separate from sweep runs.\n",
    "\n",
    "This is a simple organizational feature, but it becomes critical once you run dozens (or hundreds) of experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare baseline to the best sweep result.\n",
    "\n",
    "devqubit can generate a compact \"diff\" report:\n",
    "- parameters and metrics that differ,\n",
    "- and (when available) a summary of program/circuit differences.\n",
    "\n",
    "This helps answer: *what changed between two experiments?*\n",
    "\"\"\"\n",
    "\n",
    "best_run_id = best[4]\n",
    "\n",
    "comparison = diff(\n",
    "    baseline_id,\n",
    "    best_run_id,\n",
    "    registry=registry,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpret-compare",
   "metadata": {},
   "source": [
    "**Reading the comparison output**\n",
    "\n",
    "You'll typically see differences like:\n",
    "\n",
    "- **params**: architecture name, number of layers, number of parameters\n",
    "- **metrics**: best test accuracy\n",
    "- **program/circuit**: gate sequence changes due to different encodings or depths\n",
    "\n",
    "The goal isn't to \"prove\" one model is best here - it's to show a clean, repeatable way\n",
    "to track and compare QML experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In ~20 cells we demonstrated a simple QML workflow with devqubit + PennyLane:\n",
    "\n",
    "| devqubit feature | What we used it for |\n",
    "|---|---|\n",
    "| **Run params + tags** | record architecture, depth, hyperparameters |\n",
    "| **Epoch-wise metrics** | log loss/train acc/test acc each epoch |\n",
    "| **Device wrapping** | track circuit executions via `wrap_backend` |\n",
    "| **Artifacts** | store trained parameters in a JSON-friendly form |\n",
    "| **Grouped runs** | keep an architecture sweep organized under one `group_id` |\n",
    "| **Comparison report** | quickly see what changed between two runs |\n",
    "\n",
    "Clean-up is optional - the `WORKSPACE` folder is where the registry and artifacts live.\n",
    "\n",
    "\n",
    "- We now use a **validation split** for model selection, and report test accuracy only as a final unbiased check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cleanup (keeps reruns tidy).\n",
    "# If you'd like to inspect the registry/artifacts on disk, comment this out.\n",
    "shutil.rmtree(WORKSPACE)\n",
    "print(\"Workspace cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6708c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
