{
  "metadata": {
    "timestamp": "2026-01-11T00:16:22.180806",
    "optimization_method": "bayesian",
    "evaluation_method": "custom",
    "total_trials": 8,
    "pipelines_cached": 5,
    "best_config": {
      "chunk_size": 500,
      "chunk_overlap": 50,
      "embedding_model": "all-MiniLM-L6-v2",
      "top_k": 5,
      "temperature": 1.0,
      "name": "trial_1_c500_k5_t1.0"
    },
    "best_score": 0.2701436692333742
  },
  "results": [
    {
      "config": {
        "chunk_size": 500,
        "chunk_overlap": 50,
        "embedding_model": "all-MiniLM-L6-v2",
        "top_k": 5,
        "temperature": 1.0,
        "name": "trial_1_c500_k5_t1.0"
      },
      "metrics": {
        "accuracy": 0.2701436692333742,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.48057467693349665,
        "context_recall": 0.0
      },
      "weighted_score": 0.2701436692333742
    },
    {
      "config": {
        "chunk_size": 500,
        "chunk_overlap": 100,
        "embedding_model": "all-MiniLM-L6-v2",
        "top_k": 10,
        "temperature": 0.3,
        "name": "trial_7_c500_k10_t0.3"
      },
      "metrics": {
        "accuracy": 0.27007175405168715,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.48028701620674874,
        "context_recall": 0.0
      },
      "weighted_score": 0.27007175405168715
    },
    {
      "config": {
        "chunk_size": 500,
        "chunk_overlap": 50,
        "embedding_model": "all-MiniLM-L6-v2",
        "top_k": 10,
        "temperature": 0.7,
        "name": "trial_8_c500_k10_t0.7"
      },
      "metrics": {
        "accuracy": 0.26685000367453504,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.46740001469814013,
        "context_recall": 0.0
      },
      "weighted_score": 0.26685000367453504
    },
    {
      "config": {
        "chunk_size": 500,
        "chunk_overlap": 100,
        "embedding_model": "all-MiniLM-L6-v2",
        "top_k": 3,
        "temperature": 0.7,
        "name": "trial_3_c500_k3_t0.7"
      },
      "metrics": {
        "accuracy": 0.2627204304346819,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.4508817217387277,
        "context_recall": 0.0
      },
      "weighted_score": 0.2627204304346819
    },
    {
      "config": {
        "chunk_size": 256,
        "chunk_overlap": 100,
        "embedding_model": "paraphrase-MiniLM-L6-v2",
        "top_k": 10,
        "temperature": 1.0,
        "name": "trial_2_c256_k10_t1.0"
      },
      "metrics": {
        "accuracy": 0.2579971516685841,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.4319886066743365,
        "context_recall": 0.0
      },
      "weighted_score": 0.2579971516685841
    },
    {
      "config": {
        "chunk_size": 256,
        "chunk_overlap": 50,
        "embedding_model": "paraphrase-MiniLM-L6-v2",
        "top_k": 5,
        "temperature": 0.3,
        "name": "trial_4_c256_k5_t0.3"
      },
      "metrics": {
        "accuracy": 0.2542531128239645,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.4170124512958581,
        "context_recall": 0.0
      },
      "weighted_score": 0.2542531128239645
    },
    {
      "config": {
        "chunk_size": 256,
        "chunk_overlap": 50,
        "embedding_model": "paraphrase-MiniLM-L6-v2",
        "top_k": 5,
        "temperature": 0.3,
        "name": "trial_6_c256_k5_t0.3"
      },
      "metrics": {
        "accuracy": 0.25369662650734226,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.414786506029369,
        "context_recall": 0.0
      },
      "weighted_score": 0.25369662650734226
    },
    {
      "config": {
        "chunk_size": 256,
        "chunk_overlap": 50,
        "embedding_model": "all-MiniLM-L6-v2",
        "top_k": 5,
        "temperature": 1.0,
        "name": "trial_5_c256_k5_t1.0"
      },
      "metrics": {
        "accuracy": 0.25086839767056995,
        "successful_queries": 15,
        "total_queries": 15,
        "answer_relevancy": 0.5,
        "faithfulness": 0.0,
        "answer_similarity": 0.40347359068227984,
        "context_recall": 0.0
      },
      "weighted_score": 0.25086839767056995
    }
  ]
}