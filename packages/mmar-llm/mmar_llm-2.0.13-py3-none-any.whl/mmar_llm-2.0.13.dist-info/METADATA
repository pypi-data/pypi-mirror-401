Metadata-Version: 2.4
Name: mmar-llm
Version: 2.0.13
Summary: llm wrappers for multimodal architectures team
Keywords: 
Author: Eugene Tagin
Author-email: Eugene Tagin <tagin@airi.net>
License-Expression: MIT
License-File: LICENSE
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Classifier: Topic :: Documentation
Classifier: Topic :: Software Development
Classifier: Topic :: Utilities
Classifier: Typing :: Typed
Requires-Dist: requests~=2.32.5
Requires-Dist: gigachat==0.1.43
Requires-Dist: tiktoken==0.8.0
Requires-Dist: openai>=1.61.0
Requires-Dist: loguru~=0.7.3
Requires-Dist: mmar-mapi~=1.4.2
Requires-Dist: mmar-utils~=1.1.15
Requires-Python: >=3.11
Description-Content-Type: text/markdown

# mmar-llm

Library to access different LLM's via common API:
- GigaChat
- OpenRouter
- ..

## Usage
### Create `llm_config.json` with llm-endpoints:
```js
{
  "default_endpoint_key": "endpoint_key",
  "warmup": true,
  "wait_seconds_on_llm_retry": [1, 2, 4, 4, 4],
  "endpoints": [
    {
      "key": "endpoint_key",
      "caption": "GigaChat MAX 2",
      "descriptor": "gigachat",
      "args": {
		"authorization_key": "MDAwMDAwMDAtMDAwMC0wMDAwLTAwMDAtMDAwMDAwMDAwMDAwOjAwMDAwMDAwLTAwMDAtMDAwMC0wMDAwLTAwMDAwMDAwMDAwMA=="
      }
    },
	...
  ]
}
```
### Create llm-hub:
```python
from pathlib import Path
from types import SimpleNamespace

from mmar_llm import LLMConfig, LLMHub


def create_llm_hub(llm_config_path: str, tmp_path: str | None = None):
    llm_config = LLMConfig.model_validate_json(Path(llm_config_path).read_text())
    llm_hub_config = SimpleNamespace(llm=llm_config, files_dir=tmp_path)
    llm_hub = LLMHub(llm_hub_config)
    return llm_hub

lh = create_llm_hub('/path/to/llm_config.json')
print(lh.get_response(request='What is your name?'))
```
