from runtime.endpoints import predictor_engine as endpoints
from runtime import request_utils
from json import dumps


def get_spending_personality(auth, campaign, channel, customer, headers, params, subcampaign, userid, info=False):
# Provide spending personality scores for customers.
#   auth: Authentication token generated by access.Authenticate()
#   campaign: The name of the campaign. (string)
#   channel: The type of channel. (options: "all", "") 
#   customer: The id of the customer. (string)
#   headers: Added headers. ()
#   params: Addtional parameters added in a dictionary format as a string: ('{"value_1": 300, "value_2": "entry"}')
#   subcampaign: Name of the subcampaigns. (string)
#   userid: The id of the user. (string)
    ep = endpoints.GET_SPENDING_PERSONALITY
    param_dict = {
        "campaign": campaign, 
        "channel": channel,
        "customer": customer,
        "headers": headers,
        "params": params,
        "subcampaign": subcampaign,
        "userid": userid
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def put_spending_personality(auth, document, headers, info=False):
# Update offers taken up by customers
#  document: Documents to be updated. ()
#  headers: Added headers. ()
    ep = endpoints.PUT_SPENDING_PERSONALITY
    param_dict = {
        "document": document, 
        "headers": headers
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def model_detail(auth, model, info=False):
# Model details. 
# model: Model's details to examine. Example parameter: {'mojo':'my_mojo.zip'}
    ep = endpoints.GET_OFFER_RECOMMENDATIONS
    param_dict = {
        "model": model
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def get_offer_recommendations(auth, campaign, channel, customer, headers, numberoffers, params, subcampaign, userid, info=False):
# Provide offers that form part of a campaign for particular customer.
#   auth: Authentication token generated by access.Authenticate()
#   campaign: The name of the campaign. (string)
#   channel: The type of channel. (options: "all", "") 
#   customer: The id of the customer. (string)
#   headers: Added headers. ()
#   numberoffers: Number of offers to get. (int)
#   params: Addtional parameters added in a dictionary format as a string: ('{"value_1": 300, "value_2": "entry"}')
#   subcampaign: Name of the subcampaigns. (string)
#   userid: The id of the user. (string)
    ep = endpoints.GET_OFFER_RECOMMENDATIONS
    param_dict = {
        "campaign": campaign, 
        "channel": channel,
        "customer": customer,
        "headers": headers,
        "numberoffers": numberoffers,
        "params": params,
        "subcampaign": subcampaign,
        "userid": userid
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def put_offer_recommendations(auth, document, headers, info=False):
# Update offers taken up by customers
#  document: Documents to be updated. ()
#  headers: Added headers. ()
    ep = endpoints.PUT_OFFER_RECOMMENDATIONS
    param_dict = {
        "document": document, 
        "headers": headers
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def get_personality_recommender(auth, campaign, channel, customer, headers, numberoffers, params, subcampaign, userid, info=False):
# Provide offers that form part of a campaign for particular customer.
#   auth: Authentication token generated by access.Authenticate()
#   campaign: The name of the campaign. (string)
#   channel: The type of channel. (options: "all", "") 
#   customer: The id of the customer. (string)
#   headers: Added headers. ()
#   numberoffers: Number of offers to get. (int)
#   params: Addtional parameters added in a dictionary format as a string: ('{"value_1": 300, "value_2": "entry"}')
#   subcampaign: Name of the subcampaigns. (string)
#   userid: The id of the user. (string)
    ep = endpoints.GET_PERSONALITY_RECOMMENDER
    param_dict = {
        "campaign": campaign, 
        "channel": channel,
        "customer": customer,
        "headers": headers,
        "numberoffers": numberoffers,
        "params": params,
        "subcampaign": subcampaign,
        "userid": userid
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def put_personality_recommender(auth, document, headers, info=False):
# Update offers taken up by customers
#  document: Documents to be updated. ()
#  headers: Added headers. ()
    ep = endpoints.PUT_PERSONALITY_RECOMMENDER
    param_dict = {
        "document": document, 
        "headers": headers
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def predictor_response_preload(auth, detail, value, info=False):
# Perform prediction on pre-loaded model with detail: none, basic or all. 
# Perform a database lookup if properties file has been set. 
# The predictor parameters are broken into two types namely, 
# requiring all parameters via API or requiring a lookup key via API and extracting parameters from a data source.
# Use this format for input prams only:
# Update offers taken up by customers
#  detail: Documents to be updated. (string: "none", "basic", "all")
#  value: Input parameter. 
#  {
#   'name':'predict1', 
#   'mojo':'model_mojo.zip',
#   'dbparam':false,
#   'input': ['x','y'],
#   'value': ['val_x', 'val_y']
#  }
# Use this approach for inputs from data source: 
#  {
#   'name':'predict1', 
#   'mojo':'model_mojo.zip',
#   'dbparam':true, 
#   'lookup':{key:'customer',value:1234567890}
#  } 
# For post-scoring logic, then use this configuration:
#  {
#   'name':'predict1', 
#   'mojo':'1',
#   'mab':{'class':'mabone', 'epsilon':0.4},
#   'dbparam':true, 
#   'lookup':{key:'customer',value:1234567890}, 
#   'param':{key:'value_field', value:30}
#}
    ep = endpoints.PREDICTOR_RESPONSE_PRELOAD
    param_dict = {
        "detail": detail, 
        "value": value
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def predictor_response_preload_kafka(auth, detail, value, info=False):
# Perform prediction on pre-loaded model with detail and push onto Kafka topic: none, basic or all.
# Perform a database lookup if properties file has been set. 
#  detail: Documents to be updated. (string: "none", "basic", "all")
#  value: Input parameter. 
#  {
#    'name':'predict1', 
#    'kafka':{'TOPIC_NAME':'ecosystem1','log':'true'},
#    'mojo':'1', 'input':['x','y'], 
#    'value':['val_x','val_y']
#  } 
#  OR 
#  {
#    'name':'predict1',
#    'kafka':{'TOPIC_NAME':'ecosystem1','log':'true'},
#    'mojo':'1',
#    'dbparam':true,
#    'lookup':{key:'customer',value:'1234567890'} 
#  }
    ep = endpoints.PREDICTOR_RESPONSE_PRELOAD_KAFKA
    param_dict = {
        "detail": detail, 
        "value": value
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def refresh(auth, headers="", info=False):
# Refresh product matrix and master
#  headers: Added headers. ()
    ep = endpoints.REFRESH
    param_dict = {
        "headers": headers
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def learning(auth, headers="", info=False):
    """
    Manually trigger the learning for a Dynamic Interaction deployment

    :param auth: Token for accessing the ecosystem-runtime. Created using jwt_access.
    """
    ep = endpoints.LEARNING
    param_dict = {
        "headers": headers
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def run_model_mojo(auth, detail, value, info=False):
# Perform basic prediction on model with detail: none, basic or all. 
#  detail: Documents to be updated. (string: "none", "basic", "all")
#  value: Input parameter.
#  {
#    'mojo':'model_mojo.zip',
#    'input': ['x','y'],
#    'value': ['val_x', 'val_y']
#  }
    ep = endpoints.RUN_MODEL_MOJO
    param_dict = {
        "detail": detail, 
        "value": value
    }
    resp = request_utils.create(auth, ep, params=param_dict, info=info)
    meta = resp.json()
    return meta

def invocations(auth, json, info=False):
    """
    Call the invocations endpoint of the ecosystem-runtime. This is the generic endpoint for making predictions using
    the ecosystem-runtime.

    :param auth: Token for accessing the ecosystem-runtime. Created using jwt_access.
    :param json: The parameters to be passed to the invocations api.

    EXAMPLES:

    Call the invocations endpoint for a deployment with the deployment_id of "demo_deployment" and the customer lookup
    of 1234567.

    .. code-block:: python

        offer_response = o.invocations(
                                        auth,
                                        {
                                        "campaign": "demo_deployment",
                                        "subcampaign": "none",
                                        "channel": "notebooks",
                                        "customer": 1234567,
                                        "userid": "ecosystem",
                                        "numberoffers": 4,
                                        "params": "{}"
                                        }
                                      )

    """
    ep = endpoints.INVOCATIONS
    resp = request_utils.create(auth, ep, json=json, info=info)
    meta = resp.json()
    return meta

def response(auth, json, info=False):
    ep = endpoints.RESPONSE
    resp = request_utils.create(auth, ep, json=json, info=info)
    meta = resp.json()
    return meta

def process_batch(auth, json, info=False):
    ep = endpoints.PROCESS_BATCH
    resp = request_utils.create(auth, ep, json=json, info=info)
    meta = resp.json()
    return meta

def generate_key(auth, info=False):
    ep = endpoints.GENERATE_KEY
    resp = request_utils.create(auth, ep, info=info)
    meta = resp.json()
    return meta

def generate_class(auth, code, package_name=None, class_name=None, output_dir=None, info=False):
    """
    Generates a java class file in the runtime from the code in the code parameter.

    :param auth: Token for accessing the ecosystem-runtime. Created using jwt_access.
    :param code: The code to be converted to a java class.
    :param package_name: The package name to be used for the java class.
    :param class_name: The class name to be used for the java class.
    :param output_dir: The directory to which the java class will be written.

    :return: A dictionary containing the details of the generated java class.

    EXAMPLES:

    Getting the post scoring code for a deployment, compiling the java code and pushing the resulting deployment to a runtime endpoint.

    .. code-block:: python

        # Connect to the runtime and server
        auth = jwt_access.Authenticate(server_path, server_user, ecosystem_password)
        auth_runtime = access.Authenticate(runtime_path)
        # Specify the deployment
        deployment_id = "offer_recommend_dynamic"
        version = "001"
        project_id = "Community Edition Recommender"

        # Get the deployment step and extract the post scoring logic
        deployment_step = dm.get_deployment_step(auth, project_id, deployment_id, version)
        post_score_code = deployment_step["plugins"]["post_score_class_code"]
        # Compile the post scoring logic file and add the new file name to the deployment step
        compile_results = o.generate_class(auth_runtime, post_score_code)
        deployment_step["plugins"]["post_score_class_text"] = compile_results["javaFileName"]
        # Save the new deployment step
        dm.update_deployment_step(auth, project_id, deployment_id, version, deployment_step)

        #Push deployment and produce properties file
        push_result = ge.process_push(auth,deployment_step)
        if "ErrorMessage" in push_result:
            print(push_result["ErrorMessage"])
        else:
            print(push_result["properties"])

    An example of the response returned as a result of the class generation.

    .. code-block:: json

        {
          "packagePath": "com/ecosystem/plugin/customer",
          "outputDir": "/app",
          "fullyQualifiedClassName": "com.ecosystem.plugin.customer.PlatformDynamicEngagement_39dhk",
          "methods": [
            {
              "name": "getPostPredict",
              "returnType": "void"
            },
            {
              "name": "getPostPredict",
              "returnType": "class org.json.JSONObject"
            }
          ],
          "javaFileName": "PlatformDynamicEngagement_39dhk.java",
          "className": "PlatformDynamicEngagement",
          "classNameUnique": "PlatformDynamicEngagement_39dhk"
        }

    """
    code_generation_string = code
    if package_name is not None:
        params = {
            "package_name": package_name
            ,"class_name": class_name
            ,"output_dir": output_dir
        }
        code_generation_string = dumps(params)+" CODE: "+code

    ep = endpoints.GENERATE_CLASS
    resp = request_utils.create(auth, ep, data=code_generation_string, info=info)
    meta = resp.json()
    return meta