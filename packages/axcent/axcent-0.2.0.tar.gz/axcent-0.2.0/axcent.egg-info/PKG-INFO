Metadata-Version: 2.4
Name: axcent
Version: 0.2.0
Summary: The easiest way to build AI agents in Python
Home-page: https://github.com/ssshiponu/axcent
Author: Mohin Uddin Shipon
Author-email: sshiponudin22@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai>=1.0.0
Requires-Dist: python-dotenv>=1.0.0
Provides-Extra: gemini
Requires-Dist: google-genai>=1.57.0; extra == "gemini"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Axcent

**The easiest way to build AI agents in Python.**

Axcent is a lightweight framework designed to let you build powerful AI agents with tool calling, context caching, and multi-backend support in just a few lines of code.

## Installation

```bash
pip install axcent
```

To use Gemini models:
```bash
pip install axcent[gemini]
```

## Quick Start (OpenAI)

```python
import os
from axcent import Agent

# Set your API Key
os.environ["OPENAI_API_KEY"] = "sk-..."

# Initialize Agent
agent = Agent(system_prompt="You are a helpful assistant.")

# Register a Tool
@agent.tool
def get_weather(city: str) -> str:
    """Returns weather info for a city."""
    return f"The weather in {city} is sunny!"

# Ask away!
response = agent.ask("What is the weather in Tokyo?")
print(response)
```

## Features

- **Simple Tool Registration**: Just use `@agent.tool`.
- **Automatic Context Caching**: Optimizes token usage by enforcing stable prompt structures.
- **Token Monitoring**: Track prompt, completion, and cached tokens via `agent.get_total_usage()`.
- **Backend Agnostic**:
    - **OpenAI**: First-class support.
    - **Google Gemini**: Support for all of the latest models.
    - **OpenRouter**: Use any model via OpenRouter API compatibility.

## Multi-Backend Usage

### Google Gemini

```python
from axcent import Agent, GeminiBackend
import os

# Set API Key (or GOOGLE_API_KEY)
os.environ["GEMINI_API_KEY"] = "AIza..."

# Use Gemini Backend (uses google-genai V2 SDK)
backend = GeminiBackend(model="gemini-3-flash")
agent = Agent(system_prompt="You are a helper.", backend=backend)
```

### OpenRouter

```python
import os
from axcent import Agent

os.environ["OPENAI_API_KEY"] = "sk-or-..."
os.environ["OPENAI_BASE_URL"] = "https://openrouter.ai/api/v1"

agent = Agent(system_prompt="You are a helper.")
```

## License

MIT
