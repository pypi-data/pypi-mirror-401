import os
import sys
import time
import signal
import yaml
import requests
import subprocess
import typer
from typing import Optional, Dict, Any
from rich.console import Console
from rich.panel import Panel
from rich.live import Live
from rich.markdown import Markdown
from rich.table import Table
from rich.prompt import Prompt, IntPrompt, Confirm

from prompt_toolkit import prompt as pt_prompt
from prompt_toolkit.history import InMemoryHistory
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
from prompt_toolkit.completion import WordCompleter
from prompt_toolkit.key_binding import KeyBindings
from prompt_toolkit.formatted_text import HTML

from .storage import StorageManager
from .ollama_client import OllamaClient

app = typer.Typer()
console = Console()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEFAULT_CONFIG = {
    "default_model": "phi3.5",
    "ollama_url": "http://localhost:11434",
    "summary_threshold": 5,
    "history_dir": "~/.ai-cli",
    "request_timeout": 60,
    "temperature": 0.7,
    "max_output_length": 2048,
    "top_p": 0.9,
    "repeat_penalty": 1.1,
    "prompts": {
        "title_generation": "GÃ©nÃ¨re un titre court (3-5 mots) pour: {content}",
        "summarization": "RÃ©sume les points clÃ©s: {content}",
        "memory_prefix": "Contexte utilisateur: {memory}",
        "welcome_message": "ğŸ¤– Bienvenue dans AI-CLI !",
        "interactive_info": "Mode Interactif â€¢ ModÃ¨le: {model} â€¢ /help pour l'aide",
        "goodbye_message": "ğŸ‘‹ Ã€ bientÃ´t !"
    },
    "user_style": {"border_color": "cyan", "title": "ğŸ‘¤ Vous"},
    "ai_style": {"border_color": "green", "title_template": "ğŸ¤– {model}"}
}


def load_config() -> Dict[str, Any]:
    """Charge la configuration depuis config.yaml ou utilise les valeurs par dÃ©faut."""
    paths = [
        os.path.join(os.getcwd(), "config.yaml"),
        os.path.expanduser("~/.ai-cli/config.yaml")
    ]
    config = DEFAULT_CONFIG.copy()
    
    for p in paths:
        if os.path.exists(p):
            try:
                with open(p, "r", encoding="utf-8") as f:
                    user_config = yaml.safe_load(f) or {}
                    # Merge profond
                    for key, value in user_config.items():
                        if isinstance(value, dict) and key in config:
                            config[key].update(value)
                        else:
                            config[key] = value
                    break
            except (yaml.YAMLError, OSError):
                continue
    
    return config


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              Ã‰TAT DE SESSION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SessionState:
    def __init__(self, model: str, config: Dict[str, Any]):
        self.model = model
        self.messages = []
        self.title = "Nouvelle Discussion"
        self.config = config
        # ParamÃ¨tres modifiables en cours de session
        self.temperature = config.get("temperature", 0.7)
        self.max_output_length = config.get("max_output_length", 2048)
        self.top_p = config.get("top_p", 0.9)
        self.repeat_penalty = config.get("repeat_penalty", 1.1)
        # Gestion interruption
        self.interrupted = False
        self.last_interrupt_time = 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                         SLASH COMMANDS COMPLETION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SLASH_COMMANDS = [
    '/help', '/new', '/old', '/memory', '/resume', 
    '/clear', '/settings', '/exit'
]

def get_slash_completer():
    """Retourne un completer pour les commandes slash."""
    return WordCompleter(
        SLASH_COMMANDS,
        ignore_case=True,
        sentence=True,
        match_middle=False
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              AFFICHAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def display_welcome(storage: StorageManager, config: Dict[str, Any]):
    """Affiche le message de bienvenue et les sessions rÃ©centes."""
    sessions = storage.list_sessions(5)
    welcome_msg = config.get("prompts", {}).get("welcome_message", "Bienvenue")
    
    console.print()
    console.print(Panel(
        f"[bold green]{welcome_msg}[/bold green]",
        border_style="green",
        padding=(0, 2)
    ))
    
    if sessions:
        table = Table(
            title="ğŸ“š Discussions RÃ©centes",
            show_header=True,
            header_style="bold magenta",
            border_style="dim"
        )
        table.add_column("", style="dim", width=3)
        table.add_column("Titre", style="white")
        table.add_column("Date", style="dim")
        
        for i, s in enumerate(sessions):
            table.add_row(str(i+1), s['title'], s['time'])
        
        console.print(table)
        console.print("[dim]ğŸ’¡ Utilisez /old pour charger une ancienne discussion.[/dim]\n")


def display_user_message(content: str, config: Dict[str, Any]):
    """Affiche le message de l'utilisateur (sans panel pour Ã©viter duplication)."""
    # Pas de Panel pour Ã©viter duplication visuelle avec le prompt
    pass  # Le message est dÃ©jÃ  affichÃ© dans le prompt, pas besoin de le rÃ©-afficher


def display_settings_menu(state: SessionState, client: OllamaClient):
    """Affiche et permet de modifier les paramÃ¨tres."""
    console.print()
    console.print(Panel(
        "[bold]âš™ï¸ ParamÃ¨tres de Session[/bold]",
        border_style="yellow"
    ))
    
    # Afficher les paramÃ¨tres actuels
    table = Table(show_header=True, header_style="bold cyan", border_style="dim")
    table.add_column("ParamÃ¨tre", style="white")
    table.add_column("Valeur Actuelle", style="green")
    table.add_column("Description", style="dim")
    
    table.add_row("1. ModÃ¨le", state.model, "LLM utilisÃ©")
    table.add_row("2. TempÃ©rature", str(state.temperature), "0.0=dÃ©terministe, 2.0=crÃ©atif")
    table.add_row("3. Max Output", str(state.max_output_length), "Tokens max en sortie")
    table.add_row("4. Top-P", str(state.top_p), "Nucleus sampling")
    table.add_row("5. Repeat Penalty", str(state.repeat_penalty), "PÃ©nalitÃ© rÃ©pÃ©tition")
    
    console.print(table)
    console.print("\n[dim]Entrez le numÃ©ro du paramÃ¨tre Ã  modifier (0 pour annuler):[/dim]")
    
    try:
        choice = IntPrompt.ask("Choix", default=0)
        
        if choice == 1:
            # Changer de modÃ¨le
            models = client.list_models()
            if not models:
                console.print("[red]Aucun modÃ¨le disponible.[/red]")
                return
            
            console.print("\n[bold]ModÃ¨les disponibles:[/bold]")
            for i, m in enumerate(models):
                size_mb = m.get("size", 0) / (1024 * 1024 * 1024)
                current = "âœ“ " if m["name"].startswith(state.model) else "  "
                console.print(f"  {current}[cyan]{i+1}.[/cyan] {m['name']} [dim]({size_mb:.1f} GB)[/dim]")
            
            idx = IntPrompt.ask("\nNumÃ©ro du modÃ¨le", default=1)
            if 1 <= idx <= len(models):
                state.model = models[idx-1]["name"]
                console.print(f"[green]ModÃ¨le changÃ© en: {state.model}[/green]")
        
        elif choice == 2:
            new_temp = Prompt.ask("Nouvelle tempÃ©rature (0.0-2.0)", default=str(state.temperature))
            state.temperature = max(0.0, min(2.0, float(new_temp)))
            console.print(f"[green]TempÃ©rature: {state.temperature}[/green]")
        
        elif choice == 3:
            new_max = IntPrompt.ask("Max output length (0=illimitÃ©)", default=state.max_output_length)
            state.max_output_length = max(0, new_max)
            console.print(f"[green]Max output: {state.max_output_length}[/green]")
        
        elif choice == 4:
            new_top_p = Prompt.ask("Top-P (0.0-1.0)", default=str(state.top_p))
            state.top_p = max(0.0, min(1.0, float(new_top_p)))
            console.print(f"[green]Top-P: {state.top_p}[/green]")
        
        elif choice == 5:
            new_rp = Prompt.ask("Repeat penalty (1.0=off)", default=str(state.repeat_penalty))
            state.repeat_penalty = max(1.0, float(new_rp))
            console.print(f"[green]Repeat penalty: {state.repeat_penalty}[/green]")
            
    except (ValueError, KeyboardInterrupt):
        console.print("[dim]AnnulÃ©.[/dim]")


def display_help():
    """Affiche l'aide des commandes."""
    help_text = """
[bold cyan]Commandes disponibles:[/bold cyan]

  [green]/help[/green]     ğŸ“š Affiche cette aide
  [green]/new[/green]      ğŸ†• Sauvegarder et dÃ©marrer une nouvelle discussion
  [green]/old[/green]      ğŸ“‚ Charger ou supprimer une discussion
  [green]/memory[/green]   ğŸ§  GÃ©rer la mÃ©moire (voir, ajouter, supprimer)
  [green]/resume[/green]   ğŸ“ RÃ©sumer l'historique pour libÃ©rer du contexte
  [green]/settings[/green] âš™ï¸  Modifier les paramÃ¨tres (modÃ¨le, tempÃ©rature...)
  [green]/clear[/green]    ğŸ§¹ Effacer l'Ã©cran
  [green]/exit[/green]     ğŸ‘‹ Sauvegarder et quitter

[dim]Raccourcis: Ctrl+D = /exit, Ctrl+C (x2 rapide) = exit forcÃ©[/dim]
"""
    console.print(Panel(help_text.strip(), title="Aide", border_style="cyan"))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                         GESTION SAUVEGARDE & EXIT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def handle_save_only(state: SessionState, storage: StorageManager, client: OllamaClient) -> Optional[str]:
    """Sauvegarde la session sans quitter. Retourne le titre si sauvegardÃ©, None sinon."""
    if not state.messages:
        return None
    
    suggested_title = client.generate_title(state.model, state.messages)
    console.print(f"\n[yellow]ğŸ’¾ Sauvegarde de la discussion...[/yellow]")
    console.print(f"Proposition de titre: [dim]{suggested_title}[/dim]")
    
    history = InMemoryHistory()
    history.append_string(suggested_title)
    
    try:
        user_title = pt_prompt(
            "Titre (Tab=accepter, EntrÃ©e=valider): ",
            auto_suggest=AutoSuggestFromHistory(),
            history=history
        )
    except (EOFError, KeyboardInterrupt):
        user_title = suggested_title

    final_title = user_title.strip() or suggested_title
    storage.save_session(state.messages, final_title)
    console.print(f"[green]âœ“ Session enregistrÃ©e: {final_title}[/green]")
    return final_title


def handle_save_and_exit(state: SessionState, storage: StorageManager, client: OllamaClient, config: Dict[str, Any]):
    """Sauvegarde la session et quitte proprement."""
    goodbye_msg = config.get("prompts", {}).get("goodbye_message", "Ã€ bientÃ´t !")
    
    if not state.messages:
        console.print(f"\n[green]{goodbye_msg}[/green]")
        sys.exit(0)
    
    handle_save_only(state, storage, client)
    console.print(f"[green]{goodbye_msg}[/green]")
    sys.exit(0)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              BOUCLE INTERACTIVE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_interactive(state: SessionState, storage: StorageManager, client: OllamaClient, config: Dict[str, Any]):
    """Boucle REPL principale avec gestion Ctrl+C amÃ©liorÃ©e."""
    
    # Afficher info mode interactif
    info_msg = config.get("prompts", {}).get("interactive_info", "Mode Interactif")
    console.print(f"[dim]{info_msg.format(model=state.model)}[/dim]\n")
    
    # Completer pour les commandes slash
    slash_completer = get_slash_completer()
    
    while True:
        try:
            # Reset flag interruption
            state.interrupted = False
            
            # Prompt avec auto-complÃ©tion
            user_input = pt_prompt(
                HTML('<ansigreen><b>Vous</b></ansigreen> <ansicyan>â¯</ansicyan> '),
                completer=slash_completer,
                complete_while_typing=False,
                auto_suggest=AutoSuggestFromHistory()
            ).strip()
            
        except EOFError:
            # Ctrl+D
            handle_save_and_exit(state, storage, client, config)
            break
        except KeyboardInterrupt:
            # Ctrl+C pendant l'input
            now = time.time()
            if now - state.last_interrupt_time < 1.5:
                # Double Ctrl+C rapide = exit forcÃ©
                console.print("\n[yellow]Exit forcÃ©...[/yellow]")
                handle_save_and_exit(state, storage, client, config)
                break
            state.last_interrupt_time = now
            console.print("\n[dim]Ctrl+C dÃ©tectÃ©. Appuyez encore une fois rapidement pour quitter.[/dim]")
            continue

        if not user_input:
            continue

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #                         COMMANDES SLASH
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if user_input.startswith("/"):
            cmd_parts = user_input.split(maxsplit=1)
            cmd = cmd_parts[0].lower()
            args = cmd_parts[1] if len(cmd_parts) > 1 else ""
            
            if cmd == "/exit":
                handle_save_and_exit(state, storage, client, config)
                break
            
            elif cmd == "/clear":
                console.clear()
                continue
            
            elif cmd == "/help":
                display_help()
                continue
            
            elif cmd == "/new":
                if state.messages:
                    handle_save_only(state, storage, client)
                state.messages = []
                state.title = "Nouvelle Discussion"
                console.clear()
                console.print(Panel(
                    "[bold green]ğŸ†• Nouvelle discussion dÃ©marrÃ©e.[/bold green]",
                    border_style="green"
                ))
                continue
            
            elif cmd == "/old":
                sessions = storage.list_sessions(20)
                if not sessions:
                    console.print("[red]Aucun historique trouvÃ©.[/red]")
                    continue
                
                console.print("\n[bold]ğŸ“‚ Sessions disponibles:[/bold]")
                table = Table(show_header=True, header_style="bold cyan", border_style="dim")
                table.add_column("#", style="cyan", width=3)
                table.add_column("Titre", style="white")
                table.add_column("Date", style="dim")
                
                for i, s in enumerate(sessions):
                    table.add_row(str(i+1), s['title'], s['time'])
                
                console.print(table)
                console.print("\n[dim]Actions: [cyan]numÃ©ro[/cyan]=charger, [red]d numÃ©ro[/red]=supprimer, [yellow]0[/yellow]=annuler[/dim]")
                
                try:
                    action = Prompt.ask("Action", default="0")
                    action = action.strip().lower()
                    
                    if action == "0" or not action:
                        console.print("[dim]AnnulÃ©.[/dim]")
                        continue
                    
                    # Supprimer une session
                    if action.startswith("d ") or action.startswith("d"):
                        parts = action.split()
                        if len(parts) >= 2:
                            try:
                                idx = int(parts[1])
                            except ValueError:
                                console.print("[red]NumÃ©ro invalide.[/red]")
                                continue
                        else:
                            idx = IntPrompt.ask("NumÃ©ro de la session Ã  supprimer")
                        
                        if 1 <= idx <= len(sessions):
                            session = sessions[idx-1]
                            if Confirm.ask(f"[red]Supprimer dÃ©finitivement[/red] '{session['title']}' ?", default=False):
                                try:
                                    storage.delete_session(session['file'])
                                    console.print(f"[green]âœ“ Session '{session['title']}' supprimÃ©e.[/green]")
                                except Exception as e:
                                    console.print(f"[red]Erreur: {e}[/red]")
                        else:
                            console.print("[red]NumÃ©ro invalide.[/red]")
                        continue
                    
                    # Charger une session
                    try:
                        idx = int(action)
                    except ValueError:
                        console.print("[red]Action non reconnue.[/red]")
                        continue
                    
                    if 1 <= idx <= len(sessions):
                        data = storage.load_session(sessions[idx-1]['file'])
                        state.messages = data['messages']
                        state.title = data['title']
                        console.clear()
                        console.print(Panel(f"ğŸ“‚ Session chargÃ©e: [bold]{state.title}[/bold]", border_style="green"))
                        
                        # Afficher l'historique
                        for m in state.messages:
                            if m['role'] == 'user':
                                display_user_message(m['content'], config)
                            elif m['role'] == 'assistant':
                                ai_style = config.get("ai_style", {})
                                console.print(Panel(
                                    Markdown(m['content']),
                                    title=ai_style.get("title_template", "ğŸ¤– {model}").format(model=state.model),
                                    border_style=ai_style.get("border_color", "green")
                                ))
                    else:
                        console.print("[red]NumÃ©ro invalide.[/red]")
                except (ValueError, KeyboardInterrupt):
                    console.print("[dim]AnnulÃ©.[/dim]")
                continue
            
            elif cmd == "/memory":
                # Gestion de la mÃ©moire avec sous-commandes
                parts = args.split(maxsplit=1) if args else []
                subcmd = parts[0].lower() if parts else ""
                subargs = parts[1] if len(parts) > 1 else ""
                
                if subcmd == "add" and subargs:
                    storage.save_memory(subargs)
                    console.print(f"[green]ğŸ§  MÃ©morisÃ©: {subargs}[/green]")
                
                elif subcmd == "delete" or subcmd == "del":
                    entries = storage.get_memory_entries()
                    if not entries:
                        console.print("[dim]La mÃ©moire est vide.[/dim]")
                        continue
                    
                    console.print("\n[bold]ğŸ§  EntrÃ©es de mÃ©moire:[/bold]")
                    for i, entry in enumerate(entries):
                        console.print(f"  [cyan]{i+1}.[/cyan] {entry}")
                    
                    try:
                        if subargs:
                            idx = int(subargs)
                        else:
                            idx = IntPrompt.ask("\nNumÃ©ro Ã  supprimer")
                        
                        if 1 <= idx <= len(entries):
                            if storage.delete_memory_entry(idx - 1):
                                console.print(f"[green]âœ“ EntrÃ©e supprimÃ©e.[/green]")
                            else:
                                console.print("[red]Erreur lors de la suppression.[/red]")
                        else:
                            console.print("[red]NumÃ©ro invalide.[/red]")
                    except (ValueError, KeyboardInterrupt):
                        console.print("[dim]AnnulÃ©.[/dim]")
                
                else:
                    # Par dÃ©faut: afficher la mÃ©moire
                    entries = storage.get_memory_entries()
                    if not entries:
                        console.print("[dim]La mÃ©moire est vide. Utilisez [cyan]/memory add <info>[/cyan] pour ajouter.[/dim]")
                    else:
                        console.print("\n[bold]ğŸ§  MÃ©moire de l'utilisateur:[/bold]")
                        for i, entry in enumerate(entries):
                            console.print(f"  [cyan]{i+1}.[/cyan] {entry}")
                        console.print("\n[dim]Actions: [cyan]/memory add <info>[/cyan] | [cyan]/memory delete[/cyan][/dim]")
                continue
            
            elif cmd == "/resume":
                threshold = config.get("summary_threshold", 5)
                if len(state.messages) > threshold:
                    to_summarize = [m for m in state.messages if m['role'] != 'system']
                    summary = client.summarize(state.model, to_summarize)
                    state.messages = [{"role": "system", "content": f"Contexte rÃ©sumÃ©: {summary}"}] + state.messages[-threshold:]
                    console.print("[cyan]ğŸ“ Historique rÃ©sumÃ© avec succÃ¨s.[/cyan]")
                else:
                    console.print("[dim]Pas assez de messages pour rÃ©sumer.[/dim]")
                continue
            
            elif cmd == "/settings":
                display_settings_menu(state, client)
                # Mettre Ã  jour les options du client
                client.set_options(
                    temperature=state.temperature,
                    max_tokens=state.max_output_length,
                    top_p=state.top_p,
                    repeat_penalty=state.repeat_penalty
                )
                continue
            
            else:
                console.print(f"[red]âŒ Commande inconnue: {cmd}[/red]")
                console.print("[dim]Tapez /help pour voir les commandes disponibles.[/dim]")
                continue

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #                         CHAT NORMAL
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # Afficher le message utilisateur avec style
        display_user_message(user_input, config)
        
        # DÃ©tection mÃ©moire naturelle
        lower_input = user_input.lower()
        memory_triggers = ["retiens que ", "souviens-toi que ", "note que ", "enregistre que ", "enregistre dans ta memoire que ", "sache que "]
        
        # VÃ©rifier si l'input contient une commande de mÃ©moire
        trigger_found = next((t for t in memory_triggers if t in lower_input), None)
        
        if trigger_found:
            # Extraire l'information (tout ce qui suit le trigger)
            try:
                start_index = lower_input.find(trigger_found) + len(trigger_found)
                info = user_input[start_index:].strip()
                if info:
                    storage.save_memory(info)
                    console.print(f"[green]ğŸ§  (Auto-Memory) J'ai notÃ©: {info}[/green]")
            except Exception as e:
                logger.error(f"Erreur extraction mÃ©moire: {e}")

        # Mise Ã  jour dynamique du prompt systÃ¨me avec la mÃ©moire
        # On le fait Ã  chaque tour pour inclure la mÃ©moire fraÃ®chement ajoutÃ©e
        memory = storage.get_memory()
        if memory.strip():
            memory_prompt = config.get("prompts", {}).get("memory_prefix", "{memory}").format(memory=memory)
            
            # Si le premier message est un prompt systÃ¨me, on le met Ã  jour
            if state.messages and state.messages[0].get("role") == "system":
                # VÃ©rifier si c'est notre prompt mÃ©moire (simple heuristique)
                if "[CONTEXTE]" in state.messages[0]["content"]:
                     state.messages[0]["content"] = memory_prompt
                else:
                    # Sinon, on ne touche pas au prompt systÃ¨me existant s'il est diffÃ©rent, 
                    # mais on pourrait vouloir concatÃ©ner. Ici on insÃ¨re si pas de contexte mÃ©moire.
                    if "[CONTEXTE]" not in state.messages[0]["content"]:
                         state.messages.insert(0, {"role": "system", "content": memory_prompt})
            
            # Si pas de messages ou pas de systÃ¨me au dÃ©but, on insÃ¨re
            elif not state.messages or state.messages[0].get("role") != "system":
                state.messages.insert(0, {"role": "system", "content": memory_prompt})
        
        
        state.messages.append({"role": "user", "content": user_input})
        
        # Configurer les options avant chaque requÃªte
        client.set_options(
            temperature=state.temperature,
            max_tokens=state.max_output_length,
            top_p=state.top_p,
            repeat_penalty=state.repeat_penalty
        )
        
        # Streaming de la rÃ©ponse avec gestion Ctrl+C
        full_response = ""
        ai_style = config.get("ai_style", {})
        ai_title = ai_style.get("title_template", "ğŸ¤– {model}").format(model=state.model)
        
        try:
            with Live(console=console, refresh_per_second=10, transient=True) as live:
                for chunk in client.chat(state.model, state.messages):
                    if state.interrupted:
                        break
                    full_response += chunk
                    live.update(Panel(
                        Markdown(full_response + "â–Œ"),
                        title=ai_title,
                        border_style=ai_style.get("border_color", "green"),
                        padding=(0, 1)
                    ))
        except KeyboardInterrupt:
            # Ctrl+C pendant le streaming = stop rÃ©ponse
            console.print("\n[dim]GÃ©nÃ©ration interrompue.[/dim]")
            state.interrupted = True
        
        # Afficher la rÃ©ponse finale (sans curseur)
        if full_response:
            console.print(Panel(
                Markdown(full_response),
                title=ai_title,
                border_style=ai_style.get("border_color", "green"),
                padding=(0, 1)
            ))
            state.messages.append({"role": "assistant", "content": full_response})
        
        console.print()  # Ligne vide pour aÃ©rer


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                              POINT D'ENTRÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def update_default_model_in_config(new_model: str, storage: StorageManager) -> bool:
    """Met Ã  jour le modÃ¨le par dÃ©faut dans le fichier config.yaml."""
    config_path = storage.get_config_path()
    if not config_path:
        console.print("[red]Fichier config.yaml non trouvÃ©.[/red]")
        return False
    
    try:
        content = config_path.read_text(encoding="utf-8")
        import re
        # Remplacer default_model: xxx par default_model: new_model
        new_content = re.sub(
            r'^(default_model:\s*).*$',
            f'\\1{new_model}',
            content,
            flags=re.MULTILINE
        )
        config_path.write_text(new_content, encoding="utf-8")
        return True
    except (OSError, Exception) as e:
        console.print(f"[red]Erreur mise Ã  jour config: {e}[/red]")
        return False


def display_models_list(client: OllamaClient, current_default: str):
    """Affiche la liste des modÃ¨les disponibles."""
    models = client.list_models()
    if not models:
        console.print("[yellow]Aucun modÃ¨le trouvÃ©. Est-ce qu'Ollama est en cours d'exÃ©cution?[/yellow]")
        return
    
    console.print()
    table = Table(
        title="ğŸ¦™ ModÃ¨les Ollama Disponibles",
        show_header=True,
        header_style="bold cyan",
        border_style="dim"
    )
    table.add_column("", width=2)
    table.add_column("Nom", style="white")
    table.add_column("Taille", style="dim", justify="right")
    table.add_column("ModifiÃ©", style="dim")
    
    for m in models:
        is_default = "âœ“" if m['name'].startswith(current_default) or m['name'].split(":")[0] == current_default else ""
        size_gb = m.get("size", 0) / (1024 ** 3)
        modified = m.get("modified", "")[:10] if m.get("modified") else ""
        table.add_row(is_default, m['name'], f"{size_gb:.1f} GB", modified)
    
    console.print(table)
    console.print(f"\n[dim]ModÃ¨le par dÃ©faut: [cyan]{current_default}[/cyan][/dim]")
    console.print("[dim]Utilisez [cyan]-d/--default-model <nom>[/cyan] pour changer le dÃ©faut.[/dim]")


@app.command()
def main(
    prompt: Optional[str] = typer.Option(None, "--prompt", "-p", help="Question rapide (one-shot)"),
    interactive: bool = typer.Option(False, "--interactive", "-i", help="Mode interactif"),
    model: Optional[str] = typer.Option(None, "--model", "-m", help="ModÃ¨le Ã  utiliser pour cette session"),
    list_models: bool = typer.Option(False, "--list-models", "-l", help="Lister les modÃ¨les disponibles"),
    default_model: Optional[str] = typer.Option(None, "--default-model", "-d", help="DÃ©finir le modÃ¨le par dÃ©faut")
):
    """AI-CLI - Client CLI intelligent pour Ollama."""
    
    config = load_config()
    storage = StorageManager(config.get("history_dir", "~/.ai-cli"))
    client = OllamaClient(
        config.get("ollama_url", "http://localhost:11434"),
        config.get("prompts", {}),
        timeout=config.get("request_timeout", 60)
    )
    
    # Configurer les options par dÃ©faut
    client.set_options(
        temperature=config.get("temperature", 0.7),
        max_tokens=config.get("max_output_length", 2048),
        top_p=config.get("top_p", 0.9),
        repeat_penalty=config.get("repeat_penalty", 1.1)
    )
    
    current_default = config.get("default_model", "phi3.5")
    
    # Mode: Lister les modÃ¨les
    if list_models:
        # VÃ©rifier qu'Ollama est en cours d'exÃ©cution
        if not client.is_running():
            console.print("[red]âŒ Ollama n'est pas en cours d'exÃ©cution.[/red]")
            return
        display_models_list(client, current_default)
        return
    
    # Mode: Changer le modÃ¨le par dÃ©faut
    if default_model:
        # VÃ©rifier qu'Ollama est en cours d'exÃ©cution pour valider le modÃ¨le
        if not client.is_running():
            console.print("[yellow]âš  Ollama n'est pas en cours d'exÃ©cution. Mise Ã  jour sans validation.[/yellow]")
        elif not client.model_exists(default_model):
            console.print(f"[yellow]âš  ModÃ¨le '{default_model}' non trouvÃ© sur Ollama. Mise Ã  jour quand mÃªme.[/yellow]")
        
        if update_default_model_in_config(default_model, storage):
            console.print(f"[green]âœ“ ModÃ¨le par dÃ©faut changÃ©: [bold]{current_default}[/bold] â†’ [bold]{default_model}[/bold][/green]")
        return
    
    selected_model = model or current_default
    
    # VÃ©rifier qu'Ollama est en cours d'exÃ©cution
    if not client.is_running():
        try:
            subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            console.print("[yellow]â³ DÃ©marrage d'Ollama...[/yellow]")
            for _ in range(10):
                time.sleep(1)
                if client.is_running():
                    console.print("[green]âœ“ Ollama dÃ©marrÃ©.[/green]")
                    break
            else:
                console.print("[red]âŒ Impossible de dÃ©marrer Ollama.[/red]")
                return
        except FileNotFoundError:
            console.print("[red]âŒ Ollama n'est pas installÃ©. Visitez https://ollama.ai[/red]")
            return

    # VÃ©rification du modÃ¨le avec match intelligent
    if not client.model_exists(selected_model):
        console.print(f"[yellow]ğŸ“¥ ModÃ¨le '{selected_model}' non trouvÃ©. TÃ©lÃ©chargement...[/yellow]")
        try:
            with requests.post(
                f"{client.url}/api/pull",
                json={"name": selected_model},
                stream=True,
                timeout=600
            ) as r:
                for line in r.iter_lines():
                    if line:
                        try:
                            data = json.loads(line)
                            status = data.get("status", "")
                            if "pulling" in status or "downloading" in status:
                                console.print(".", end="", style="dim")
                        except json.JSONDecodeError:
                            pass
            console.print(f"\n[green]âœ“ ModÃ¨le '{selected_model}' prÃªt.[/green]")
        except Exception as e:
            console.print(f"\n[red]âŒ Erreur tÃ©lÃ©chargement: {e}[/red]")
            return
    else:
        # Utiliser le nom complet du modÃ¨le
        full_name = client.get_model_full_name(selected_model)
        if full_name:
            selected_model = full_name

    state = SessionState(selected_model, config)
    
    if interactive:
        display_welcome(storage, config)
        run_interactive(state, storage, client, config)
    elif prompt:
        # Mode one-shot
        console.print()
        full_response = ""
        ai_style = config.get("ai_style", {})
        
        try:
            with Live(console=console, refresh_per_second=10, transient=True) as live:
                for chunk in client.chat(selected_model, [{"role": "user", "content": prompt}]):
                    full_response += chunk
                    live.update(Panel(
                        Markdown(full_response + "â–Œ"),
                        title=ai_style.get("title_template", "ğŸ¤– {model}").format(model=selected_model),
                        border_style=ai_style.get("border_color", "green")
                    ))
        except KeyboardInterrupt:
            console.print("\n[dim]Interrompu.[/dim]")
        
        if full_response:
            console.print(Panel(
                Markdown(full_response),
                title=ai_style.get("title_template", "ğŸ¤– {model}").format(model=selected_model),
                border_style=ai_style.get("border_color", "green")
            ))
    else:
        # Afficher l'aide si aucune option
        console.print("[bold cyan]AI-CLI[/bold cyan] - Client CLI intelligent pour Ollama\n")
        console.print("[yellow]Usage:[/yellow]")
        console.print("  ai-cli [cyan]-i[/cyan]              Mode interactif")
        console.print("  ai-cli [cyan]-p[/cyan] \"question\"   Question rapide")
        console.print("  ai-cli [cyan]-l[/cyan]              Lister les modÃ¨les")
        console.print("  ai-cli [cyan]-d[/cyan] <modÃ¨le>     Changer modÃ¨le par dÃ©faut")
        console.print("  ai-cli [cyan]-m[/cyan] <modÃ¨le> -i  Utiliser un modÃ¨le spÃ©cifique")
        console.print("\n[dim]Utilisez --help pour plus d'informations.[/dim]")


# Import json pour le pull
import json

if __name__ == "__main__":
    app()
