{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30cb30dd",
   "metadata": {},
   "source": [
    "# 03 Optimization Goals\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/08_workflow_system/03_optimization_goals.ipynb)\n",
    "\n",
    "Features demonstrated:\n",
    "- OptimizationGoal enum values and their behaviors\n",
    "- Adaptive tolerances based on dataset size\n",
    "- Using workflow presets with fit()\n",
    "- Combining workflow with custom tolerances\n",
    "\n",
    "Run this example:\n",
    "    python examples/scripts/08_workflow_system/03_optimization_goals.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cc6e16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:52.496515Z",
     "iopub.status.busy": "2026-01-06T17:53:52.496127Z",
     "iopub.status.idle": "2026-01-06T17:53:52.502975Z",
     "shell.execute_reply": "2026-01-06T17:53:52.501800Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Install NLSQ (run once in Colab)\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Google Colab - installing NLSQ...\")\n",
    "    !pip install -q nlsq\n",
    "    print(\"NLSQ installed successfully!\")\n",
    "else:\n",
    "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5aabb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:52.506744Z",
     "iopub.status.busy": "2026-01-06T17:53:52.506471Z",
     "iopub.status.idle": "2026-01-06T17:53:53.513091Z",
     "shell.execute_reply": "2026-01-06T17:53:53.512332Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import OptimizationGoal, fit\n",
    "from nlsq.core.workflow import calculate_adaptive_tolerances\n",
    "\n",
    "FIG_DIR = Path.cwd() / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e4a6a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:53.516621Z",
     "iopub.status.busy": "2026-01-06T17:53:53.516182Z",
     "iopub.status.idle": "2026-01-06T17:53:53.530622Z",
     "shell.execute_reply": "2026-01-06T17:53:53.529895Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Optimization Goals and Adaptive Tolerances\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # =========================================================================\n",
    "    # 1. OptimizationGoal Overview\n",
    "    # =========================================================================\n",
    "    print(\"1. OptimizationGoal Values:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for goal in OptimizationGoal:\n",
    "        print(f\"  {goal.name:<20} = {goal.value}\")\n",
    "\n",
    "    goal_info = {\n",
    "        OptimizationGoal.FAST: {\n",
    "            \"description\": \"Prioritize speed with local optimization only\",\n",
    "            \"tolerances\": \"One tier looser\",\n",
    "            \"multistart\": \"Disabled\",\n",
    "            \"use_case\": \"Quick exploration, well-conditioned problems\",\n",
    "        },\n",
    "        OptimizationGoal.ROBUST: {\n",
    "            \"description\": \"Standard tolerances with multi-start\",\n",
    "            \"tolerances\": \"Dataset-appropriate\",\n",
    "            \"multistart\": \"Enabled\",\n",
    "            \"use_case\": \"Production use, unknown problem conditioning\",\n",
    "        },\n",
    "        OptimizationGoal.QUALITY: {\n",
    "            \"description\": \"Highest precision/accuracy as TOP PRIORITY\",\n",
    "            \"tolerances\": \"One tier tighter\",\n",
    "            \"multistart\": \"Enabled + validation passes\",\n",
    "            \"use_case\": \"Publication-quality results\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    print(\"\\nGoal Details:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for goal, info in goal_info.items():\n",
    "        print(f\"\\n  {goal.name}:\")\n",
    "        print(f\"    Description:  {info['description']}\")\n",
    "        print(f\"    Tolerances:   {info['tolerances']}\")\n",
    "        print(f\"    Multi-start:  {info['multistart']}\")\n",
    "        print(f\"    Use case:     {info['use_case']}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 2. Adaptive Tolerances\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"2. Adaptive Tolerances by Dataset Size and Goal:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Dataset Size':<15} {'FAST':<15} {'ROBUST':<15} {'QUALITY':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    dataset_sizes = [500, 5_000, 50_000, 500_000, 5_000_000]\n",
    "    goals_to_compare = [\n",
    "        OptimizationGoal.FAST,\n",
    "        OptimizationGoal.ROBUST,\n",
    "        OptimizationGoal.QUALITY,\n",
    "    ]\n",
    "\n",
    "    for n_points in dataset_sizes:\n",
    "        tols = {}\n",
    "        for goal in goals_to_compare:\n",
    "            tols[goal.name] = calculate_adaptive_tolerances(n_points, goal)[\"gtol\"]\n",
    "\n",
    "        print(\n",
    "            f\"{n_points:>12,}   {tols['FAST']:<15.0e} \"\n",
    "            f\"{tols['ROBUST']:<15.0e} {tols['QUALITY']:<15.0e}\"\n",
    "        )\n",
    "\n",
    "    # =========================================================================\n",
    "    # 3. Practical Comparison\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"3. Testing Workflows on Exponential Decay Problem:\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    n_samples = 1000\n",
    "    x_data = np.linspace(0, 5, n_samples)\n",
    "\n",
    "    true_a, true_b, true_c = 3.0, 1.2, 0.5\n",
    "\n",
    "    y_true = true_a * np.exp(-true_b * x_data) + true_c\n",
    "    noise = 0.1 * np.random.randn(n_samples)\n",
    "    y_data = y_true + noise\n",
    "\n",
    "    p0 = [1.0, 0.5, 0.0]\n",
    "    bounds = ([0.1, 0.1, -1.0], [10.0, 5.0, 2.0])\n",
    "\n",
    "    print(f\"  True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "    print(f\"  Dataset size: {n_samples} points\")\n",
    "\n",
    "    results = {}\n",
    "    workflows_to_test = [\"fast\", \"standard\", \"quality\"]\n",
    "\n",
    "    for workflow_name in workflows_to_test:\n",
    "        start_time = time.time()\n",
    "\n",
    "        popt, pcov = fit(\n",
    "            exponential_decay,\n",
    "            x_data,\n",
    "            y_data,\n",
    "            p0=p0,\n",
    "            bounds=bounds,\n",
    "            workflow=workflow_name,\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        y_pred = exponential_decay(x_data, *popt)\n",
    "        ssr = float(jnp.sum((y_data - y_pred) ** 2))\n",
    "\n",
    "        param_errors = [abs(popt[i] - [true_a, true_b, true_c][i]) for i in range(3)]\n",
    "\n",
    "        results[workflow_name] = {\n",
    "            \"popt\": popt,\n",
    "            \"ssr\": ssr,\n",
    "            \"time\": elapsed,\n",
    "            \"errors\": param_errors,\n",
    "        }\n",
    "\n",
    "        print(f\"\\n  {workflow_name.upper()}:\")\n",
    "        print(f\"    Time:       {elapsed:.4f}s\")\n",
    "        print(f\"    SSR:        {ssr:.6f}\")\n",
    "        print(f\"    Parameters: a={popt[0]:.4f}, b={popt[1]:.4f}, c={popt[2]:.4f}\")\n",
    "        print(\n",
    "            f\"    Errors:     a_err={param_errors[0]:.4f}, \"\n",
    "            f\"b_err={param_errors[1]:.4f}, c_err={param_errors[2]:.4f}\"\n",
    "        )\n",
    "\n",
    "    # =========================================================================\n",
    "    # 4. Custom Tolerances with Workflow\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"4. Custom Tolerances with Workflow:\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    print(\"\\n  Combining workflow='standard' with custom tolerances:\")\n",
    "    popt_custom, _ = fit(\n",
    "        exponential_decay,\n",
    "        x_data,\n",
    "        y_data,\n",
    "        p0=p0,\n",
    "        bounds=bounds,\n",
    "        workflow=\"standard\",\n",
    "        gtol=1e-12,\n",
    "        ftol=1e-12,\n",
    "        xtol=1e-12,\n",
    "    )\n",
    "    print(f\"    Parameters: a={popt_custom[0]:.6f}, b={popt_custom[1]:.6f}, c={popt_custom[2]:.6f}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # 5. Visualization\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"5. Saving visualizations...\")\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    colors = {\"fast\": \"blue\", \"standard\": \"green\", \"quality\": \"red\"}\n",
    "\n",
    "    # Top left: Tolerance comparison across dataset sizes\n",
    "    ax1 = axes[0, 0]\n",
    "    sizes = np.logspace(2, 8, 50).astype(int)\n",
    "\n",
    "    for goal in [\n",
    "        OptimizationGoal.FAST,\n",
    "        OptimizationGoal.ROBUST,\n",
    "        OptimizationGoal.QUALITY,\n",
    "    ]:\n",
    "        tols = [calculate_adaptive_tolerances(n, goal)[\"gtol\"] for n in sizes]\n",
    "        ax1.loglog(sizes, tols, label=goal.name, linewidth=2)\n",
    "\n",
    "    ax1.set_xlabel(\"Dataset Size (points)\")\n",
    "    ax1.set_ylabel(\"gtol\")\n",
    "    ax1.set_title(\"Adaptive Tolerances by Goal\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Top right: SSR comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    workflow_names = list(results.keys())\n",
    "    ssrs = [results[g][\"ssr\"] for g in workflow_names]\n",
    "    bars = ax2.bar(workflow_names, ssrs, color=[colors[g] for g in workflow_names])\n",
    "    ax2.set_xlabel(\"Workflow\")\n",
    "    ax2.set_ylabel(\"Sum of Squared Residuals\")\n",
    "    ax2.set_title(\"Fit Quality by Workflow\")\n",
    "    for bar, ssr in zip(bars, ssrs, strict=False):\n",
    "        ax2.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            f\"{ssr:.4f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    # Bottom left: Time comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    times = [results[g][\"time\"] for g in workflow_names]\n",
    "    bars = ax3.bar(workflow_names, times, color=[colors[g] for g in workflow_names])\n",
    "    ax3.set_xlabel(\"Workflow\")\n",
    "    ax3.set_ylabel(\"Time (seconds)\")\n",
    "    ax3.set_title(\"Computation Time by Workflow\")\n",
    "    for bar, t in zip(bars, times, strict=False):\n",
    "        ax3.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height(),\n",
    "            f\"{t:.3f}s\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "        )\n",
    "\n",
    "    # Bottom right: Parameter errors\n",
    "    ax4 = axes[1, 1]\n",
    "    x_pos = np.arange(len(workflow_names))\n",
    "    width = 0.25\n",
    "\n",
    "    for i, param in enumerate([\"a\", \"b\", \"c\"]):\n",
    "        errors = [results[g][\"errors\"][i] for g in workflow_names]\n",
    "        ax4.bar(x_pos + i * width, errors, width, label=f\"{param} error\")\n",
    "\n",
    "    ax4.set_xlabel(\"Workflow\")\n",
    "    ax4.set_ylabel(\"Absolute Error\")\n",
    "    ax4.set_title(\"Parameter Errors by Workflow\")\n",
    "    ax4.set_xticks(x_pos + width)\n",
    "    ax4.set_xticklabels(workflow_names)\n",
    "    ax4.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"03_goal_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"  Saved: {FIG_DIR / '03_goal_comparison.png'}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # Summary\n",
    "    # =========================================================================\n",
    "    print()\n",
    "    print(\"=\" * 70)\n",
    "    print(\"Summary\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"True parameters: a={true_a}, b={true_b}, c={true_c}\")\n",
    "    print()\n",
    "    print(\"Workflow recommendations:\")\n",
    "    print(\"  - Exploratory analysis:    workflow='fast'\")\n",
    "    print(\"  - Production fitting:      workflow='standard'\")\n",
    "    print(\"  - Publication quality:     workflow='quality'\")\n",
    "    print()\n",
    "    print(\"Key behaviors:\")\n",
    "    print(\"  - fast: Looser tolerances, no multi-start\")\n",
    "    print(\"  - standard: Balanced tolerances, optional multi-start\")\n",
    "    print(\"  - quality: Tighter tolerances, multi-start enabled\")\n",
    "    print()\n",
    "    print(\"Usage:\")\n",
    "    print(\"  popt, pcov = fit(model, x, y, workflow='quality')\")\n",
    "    print(\"  popt, pcov = fit(model, x, y, workflow='standard', gtol=1e-12)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abaa456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:53:53.532354Z",
     "iopub.status.busy": "2026-01-06T17:53:53.532242Z",
     "iopub.status.idle": "2026-01-06T17:54:00.771068Z",
     "shell.execute_reply": "2026-01-06T17:54:00.770279Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
