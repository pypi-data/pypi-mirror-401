{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263477b7",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605af0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:59:31.837836Z",
     "iopub.status.busy": "2026-01-06T16:59:31.837696Z",
     "iopub.status.idle": "2026-01-06T16:59:43.202894Z",
     "shell.execute_reply": "2026-01-06T16:59:43.202087Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converted from time_series_analysis.ipynb\n",
    "\n",
    "This script was automatically generated from a Jupyter notebook.\n",
    "Plots are saved to the figures/ directory instead of displayed inline.\n",
    "\"\"\"\n",
    "\n",
    "# ======================================================================\n",
    "# # Time Series Analysis with NLSQ\n",
    "#\n",
    "# **Level**: Intermediate to Advanced\n",
    "# **Time**: 35-45 minutes\n",
    "# **Prerequisites**: NLSQ Quickstart\n",
    "#\n",
    "# ## Overview\n",
    "#\n",
    "# Time series analysis involves fitting models to sequential data with temporal dependencies. While traditional approaches use ARIMA or state-space models, **NLSQ excels at fitting parametric trend and seasonal components** with physical interpretations.\n",
    "#\n",
    "# ### What You'll Learn\n",
    "#\n",
    "# 1. **Trend Fitting**: Polynomial, exponential, and logistic growth models\n",
    "# 2. **Seasonal Decomposition**: Fourier series for periodic components\n",
    "# 3. **Combined Models**: Trend + seasonality + noise\n",
    "# 4. **Forecasting**: Extrapolation with uncertainty quantification\n",
    "# 5. **Autocorrelation**: Checking residual independence\n",
    "#\n",
    "# ### When to Use NLSQ for Time Series\n",
    "#\n",
    "# **NLSQ is ideal when:**\n",
    "# - You have a **physical or mechanistic model** for the process (e.g., exponential growth, damped oscillations)\n",
    "# - You need **interpretable parameters** (e.g., growth rate, decay constant, period)\n",
    "# - Data exhibits **strong deterministic trends** or **periodic patterns**\n",
    "# - You want to **leverage JAX's speed** for large datasets or batch fitting\n",
    "#\n",
    "# **Use traditional time series methods (ARIMA, Prophet) when:**\n",
    "# - Data is dominated by **stochastic processes** without clear parametric form\n",
    "# - You need **complex autoregressive structures**\n",
    "# - **Missing data** or **irregular sampling** is common\n",
    "#\n",
    "# ### Applications\n",
    "#\n",
    "# - **Scientific**: Radioactive decay, population dynamics, chemical kinetics\n",
    "# - **Engineering**: Sensor drift, system response, degradation models\n",
    "# - **Environmental**: Temperature cycles, tidal patterns, climate trends\n",
    "# - **Business**: Product lifecycle, seasonal sales (with physical constraints)\n",
    "# ======================================================================\n",
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import CurveFit\n",
    "\n",
    "# Plotting configuration\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ## Part 1: Trend Fitting\n",
    "#\n",
    "# We'll explore different growth models commonly found in time series data.\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "# Generate synthetic growth data (logistic curve)\n",
    "\n",
    "# Time points (days)\n",
    "t_data = np.linspace(0, 100, 150)\n",
    "\n",
    "# True logistic growth parameters\n",
    "L_true = 1000.0  # Carrying capacity\n",
    "k_true = 0.08  # Growth rate\n",
    "t0_true = 40.0  # Inflection point\n",
    "\n",
    "\n",
    "def logistic_growth(t, L, k, t0):\n",
    "    \"\"\"Logistic growth model (S-curve).\n",
    "\n",
    "    Common in population dynamics, product adoption, epidemic spread.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : array_like\n",
    "        Time\n",
    "    L : float\n",
    "        Carrying capacity (asymptotic maximum)\n",
    "    k : float\n",
    "        Growth rate\n",
    "    t0 : float\n",
    "        Inflection point (time of maximum growth rate)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array_like\n",
    "        Population/quantity at time t\n",
    "    \"\"\"\n",
    "    return L / (1.0 + jnp.exp(-k * (t - t0)))\n",
    "\n",
    "\n",
    "# Generate clean signal\n",
    "y_true = logistic_growth(t_data, L_true, k_true, t0_true)\n",
    "\n",
    "# Add noise (proportional to signal level)\n",
    "np.random.seed(42)\n",
    "noise = np.random.normal(0, 30, len(t_data))\n",
    "y_observed = y_true + noise\n",
    "\n",
    "print(\"✓ Generated logistic growth data\")\n",
    "print(f\"  Time range: {t_data.min():.0f} - {t_data.max():.0f} days\")\n",
    "print(f\"  True parameters: L={L_true}, k={k_true}, t0={t0_true}\")\n",
    "\n",
    "\n",
    "# Fit logistic growth model\n",
    "\n",
    "cf = CurveFit()\n",
    "\n",
    "# Initial guess (from visual inspection)\n",
    "p0 = [900.0, 0.1, 45.0]  # L, k, t0\n",
    "\n",
    "# Bounds (physical constraints)\n",
    "bounds = ([0, 0, 0], [2000, 1.0, 100])  # L, k, t0 must be positive\n",
    "\n",
    "# Fit\n",
    "popt, pcov = cf.curve_fit(\n",
    "    logistic_growth, jnp.array(t_data), jnp.array(y_observed), p0=p0, bounds=bounds\n",
    ")\n",
    "\n",
    "L_fit, k_fit, t0_fit = popt\n",
    "L_err, k_err, t0_err = np.sqrt(np.diag(pcov))\n",
    "\n",
    "print(\"Fitted Parameters:\")\n",
    "print(f\"  Carrying capacity (L): {L_fit:.1f} ± {L_err:.1f} (true: {L_true})\")\n",
    "print(f\"  Growth rate (k): {k_fit:.3f} ± {k_err:.3f} (true: {k_true})\")\n",
    "print(f\"  Inflection point (t0): {t0_fit:.1f} ± {t0_err:.1f} days (true: {t0_true})\")\n",
    "\n",
    "# Calculate derived quantities\n",
    "max_growth_rate = k_fit * L_fit / 4  # dN/dt at t0\n",
    "print(\"\\nDerived:\")\n",
    "print(f\"  Maximum growth rate: {max_growth_rate:.1f} units/day\")\n",
    "print(f\"  Doubling time (early phase): {np.log(2) / k_fit:.1f} days\")\n",
    "\n",
    "\n",
    "# Visualize growth fit with forecast\n",
    "\n",
    "# Extended time for forecasting\n",
    "t_extended = np.linspace(0, 150, 300)\n",
    "y_fit = logistic_growth(jnp.array(t_extended), L_fit, k_fit, t0_fit)\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Main plot: data + fit + forecast\n",
    "ax1.plot(t_data, y_observed, \"o\", alpha=0.5, label=\"Observed data\", ms=4)\n",
    "ax1.plot(t_extended, y_fit, \"r-\", lw=2, label=\"Fitted logistic model\")\n",
    "ax1.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1, label=\"Forecast boundary\")\n",
    "ax1.axhline(\n",
    "    L_fit, color=\"green\", ls=\":\", lw=1.5, label=f\"Carrying capacity: {L_fit:.0f}\"\n",
    ")\n",
    "ax1.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=f\"Inflection: {t0_fit:.0f} d\")\n",
    "\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Population / Quantity\")\n",
    "ax1.set_title(\"Logistic Growth Fitting and Forecasting\")\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Growth rate plot\n",
    "growth_rate = k_fit * y_fit * (1 - y_fit / L_fit)  # dN/dt\n",
    "ax2.plot(t_extended, growth_rate, \"b-\", lw=2)\n",
    "ax2.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=\"Maximum growth rate\")\n",
    "ax2.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1)\n",
    "ax2.set_xlabel(\"Time (days)\")\n",
    "ax2.set_ylabel(\"Growth Rate (dN/dt)\")\n",
    "ax2.set_title(\"Instantaneous Growth Rate\")\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_01.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Growth trend analysis complete\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ## Part 2: Seasonal Decomposition with Fourier Series\n",
    "#\n",
    "# Many time series exhibit periodic patterns (daily, weekly, annual cycles). We can model these using Fourier series.\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "# Generate seasonal data (temperature with annual cycle)\n",
    "\n",
    "# Daily temperature over 3 years\n",
    "days = np.linspace(0, 3 * 365, 3 * 365)\n",
    "\n",
    "# True components\n",
    "annual_mean = 15.0  # °C\n",
    "annual_amplitude = 10.0  # °C\n",
    "annual_period = 365.25  # days\n",
    "trend_slope = 0.01  # °C/day (climate warming)\n",
    "\n",
    "# Generate signal: trend + annual cycle + noise\n",
    "trend_component = annual_mean + trend_slope * days\n",
    "seasonal_component = annual_amplitude * np.sin(2 * np.pi * days / annual_period)\n",
    "temp_true = trend_component + seasonal_component\n",
    "\n",
    "# Add weather noise\n",
    "np.random.seed(123)\n",
    "temp_observed = temp_true + np.random.normal(0, 2.0, len(days))\n",
    "\n",
    "print(\"✓ Generated seasonal temperature data\")\n",
    "print(f\"  Duration: {len(days)} days ({len(days) / 365:.1f} years)\")\n",
    "print(f\"  True parameters: mean={annual_mean}°C, amplitude={annual_amplitude}°C\")\n",
    "print(f\"  Warming trend: {trend_slope * 365:.2f}°C/year\")\n",
    "\n",
    "\n",
    "# Fit trend + seasonal model\n",
    "\n",
    "\n",
    "def trend_seasonal_model(t, mean, trend, amplitude, period, phase):\n",
    "    \"\"\"Combined linear trend and sinusoidal seasonal component.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : array_like\n",
    "        Time (days)\n",
    "    mean : float\n",
    "        Baseline level\n",
    "    trend : float\n",
    "        Linear trend (units per day)\n",
    "    amplitude : float\n",
    "        Seasonal amplitude\n",
    "    period : float\n",
    "        Seasonal period (days)\n",
    "    phase : float\n",
    "        Phase shift (radians)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array_like\n",
    "        Modeled values\n",
    "    \"\"\"\n",
    "    trend_part = mean + trend * t\n",
    "    seasonal_part = amplitude * jnp.sin(2 * jnp.pi * t / period + phase)\n",
    "    return trend_part + seasonal_part\n",
    "\n",
    "\n",
    "# Initial guess\n",
    "p0_seasonal = [15.0, 0.0, 8.0, 365.0, 0.0]  # mean, trend, amplitude, period, phase\n",
    "\n",
    "# Bounds (constrain period to be near annual)\n",
    "bounds_seasonal = (\n",
    "    [-50, -0.1, 0, 300, -2 * np.pi],  # Lower\n",
    "    [50, 0.1, 20, 400, 2 * np.pi],  # Upper\n",
    ")\n",
    "\n",
    "# Fit\n",
    "popt_seasonal, pcov_seasonal = cf.curve_fit(\n",
    "    trend_seasonal_model,\n",
    "    jnp.array(days),\n",
    "    jnp.array(temp_observed),\n",
    "    p0=p0_seasonal,\n",
    "    bounds=bounds_seasonal,\n",
    ")\n",
    "\n",
    "mean_fit, trend_fit, amp_fit, period_fit, phase_fit = popt_seasonal\n",
    "errors = np.sqrt(np.diag(pcov_seasonal))\n",
    "\n",
    "print(\"Fitted Seasonal Parameters:\")\n",
    "print(f\"  Baseline: {mean_fit:.2f} ± {errors[0]:.2f} °C\")\n",
    "print(\n",
    "    f\"  Trend: {trend_fit:.4f} ± {errors[1]:.4f} °C/day = {trend_fit * 365:.2f} °C/year\"\n",
    ")\n",
    "print(f\"  Amplitude: {amp_fit:.2f} ± {errors[2]:.2f} °C\")\n",
    "print(f\"  Period: {period_fit:.1f} ± {errors[3]:.1f} days\")\n",
    "print(f\"  Phase: {phase_fit:.3f} ± {errors[4]:.3f} rad\")\n",
    "\n",
    "\n",
    "# Decompose time series into components\n",
    "\n",
    "# Fitted components\n",
    "trend_fitted = mean_fit + trend_fit * days\n",
    "seasonal_fitted = amp_fit * np.sin(2 * np.pi * days / period_fit + phase_fit)\n",
    "total_fitted = trend_fitted + seasonal_fitted\n",
    "residuals = temp_observed - total_fitted\n",
    "\n",
    "# Plot decomposition\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "# Original data\n",
    "axes[0].plot(days / 365, temp_observed, \"o\", alpha=0.3, ms=2, label=\"Observed\")\n",
    "axes[0].plot(days / 365, total_fitted, \"r-\", lw=1.5, label=\"Fitted model\")\n",
    "axes[0].set_ylabel(\"Temperature (°C)\")\n",
    "axes[0].set_title(\"Original Time Series\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Trend component\n",
    "axes[1].plot(days / 365, trend_fitted, \"b-\", lw=2)\n",
    "axes[1].set_ylabel(\"Trend (°C)\")\n",
    "axes[1].set_title(f\"Trend Component (slope: {trend_fit * 365:.3f} °C/year)\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Seasonal component\n",
    "axes[2].plot(days / 365, seasonal_fitted, \"g-\", lw=1.5)\n",
    "axes[2].set_ylabel(\"Seasonal (°C)\")\n",
    "axes[2].set_title(\n",
    "    f\"Seasonal Component (period: {period_fit:.1f} days, amplitude: {amp_fit:.1f} °C)\"\n",
    ")\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "axes[3].plot(days / 365, residuals, \"o\", alpha=0.4, ms=2, color=\"gray\")\n",
    "axes[3].axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "axes[3].set_ylabel(\"Residual (°C)\")\n",
    "axes[3].set_xlabel(\"Time (years)\")\n",
    "axes[3].set_title(f\"Residuals (std: {np.std(residuals):.2f} °C, should be white noise)\")\n",
    "axes[3].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_02.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Seasonal decomposition complete\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ## Part 3: Forecasting with Uncertainty\n",
    "#\n",
    "# Extrapolate the fitted model into the future with prediction intervals.\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "# Generate forecast with uncertainty bands\n",
    "\n",
    "# Forecast horizon: 1 additional year\n",
    "days_forecast = np.linspace(0, 4 * 365, 4 * 365)\n",
    "forecast_boundary = 3 * 365\n",
    "\n",
    "# Point forecast\n",
    "temp_forecast = trend_seasonal_model(jnp.array(days_forecast), *popt_seasonal)\n",
    "\n",
    "# Uncertainty from parameter covariance (simplified)\n",
    "# Full approach: Monte Carlo sampling from parameter distribution\n",
    "n_samples = 200\n",
    "param_samples = np.random.multivariate_normal(\n",
    "    popt_seasonal, pcov_seasonal, size=n_samples\n",
    ")\n",
    "\n",
    "forecast_samples = np.array(\n",
    "    [\n",
    "        trend_seasonal_model(jnp.array(days_forecast), *params)\n",
    "        for params in param_samples\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate prediction intervals\n",
    "forecast_mean = np.mean(forecast_samples, axis=0)\n",
    "forecast_std = np.std(forecast_samples, axis=0)\n",
    "forecast_lower = np.percentile(forecast_samples, 2.5, axis=0)  # 95% PI\n",
    "forecast_upper = np.percentile(forecast_samples, 97.5, axis=0)\n",
    "\n",
    "# Add residual uncertainty\n",
    "residual_std = np.std(residuals)\n",
    "forecast_lower_total = forecast_lower - 2 * residual_std\n",
    "forecast_upper_total = forecast_upper + 2 * residual_std\n",
    "\n",
    "print(f\"✓ Generated {len(days_forecast) - len(days)} day forecast\")\n",
    "print(\n",
    "    f\"  Forecast period: {len(days) / 365:.1f} - {len(days_forecast) / 365:.1f} years\"\n",
    ")\n",
    "print(f\"  Prediction interval width: {2 * residual_std:.1f} °C (±1σ residuals)\")\n",
    "\n",
    "\n",
    "# Visualize forecast with prediction intervals\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Historical data\n",
    "ax.plot(\n",
    "    days / 365, temp_observed, \"o\", alpha=0.3, ms=2, color=\"steelblue\", label=\"Observed\"\n",
    ")\n",
    "\n",
    "# Fitted model (historical)\n",
    "ax.plot(\n",
    "    days / 365,\n",
    "    total_fitted,\n",
    "    \"r-\",\n",
    "    lw=2,\n",
    "    label=\"Fitted model\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# Forecast (future)\n",
    "forecast_mask = days_forecast > forecast_boundary\n",
    "ax.plot(\n",
    "    days_forecast[forecast_mask] / 365,\n",
    "    forecast_mean[forecast_mask],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"Forecast\",\n",
    ")\n",
    "\n",
    "# Prediction intervals (parameter uncertainty only)\n",
    "ax.fill_between(\n",
    "    days_forecast[forecast_mask] / 365,\n",
    "    forecast_lower[forecast_mask],\n",
    "    forecast_upper[forecast_mask],\n",
    "    alpha=0.3,\n",
    "    color=\"red\",\n",
    "    label=\"95% PI (parameter)\",\n",
    ")\n",
    "\n",
    "# Total prediction intervals (parameter + residual uncertainty)\n",
    "ax.fill_between(\n",
    "    days_forecast[forecast_mask] / 365,\n",
    "    forecast_lower_total[forecast_mask],\n",
    "    forecast_upper_total[forecast_mask],\n",
    "    alpha=0.15,\n",
    "    color=\"orange\",\n",
    "    label=\"95% PI (total)\",\n",
    ")\n",
    "\n",
    "# Forecast boundary\n",
    "ax.axvline(forecast_boundary / 365, color=\"gray\", ls=\"--\", lw=2, label=\"Forecast start\")\n",
    "\n",
    "ax.set_xlabel(\"Time (years)\", fontsize=12)\n",
    "ax.set_ylabel(\"Temperature (°C)\", fontsize=12)\n",
    "ax.set_title(\"Time Series Forecast with Uncertainty Quantification\", fontsize=14)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_03.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"✓ Forecast visualization complete\")\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ## Part 4: Residual Diagnostics (Autocorrelation)\n",
    "#\n",
    "# For valid inference, residuals should be uncorrelated (white noise). We check this with autocorrelation analysis.\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "# Calculate and plot autocorrelation of residuals\n",
    "\n",
    "\n",
    "def autocorrelation(x, max_lag=50):\n",
    "    \"\"\"Calculate autocorrelation function (ACF).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Time series (residuals)\n",
    "    max_lag : int\n",
    "        Maximum lag to compute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lags : array\n",
    "        Lag values\n",
    "    acf : array\n",
    "        Autocorrelation values\n",
    "    \"\"\"\n",
    "    x_centered = x - np.mean(x)\n",
    "    c0 = np.dot(x_centered, x_centered) / len(x)\n",
    "\n",
    "    lags = np.arange(0, max_lag + 1)\n",
    "    acf = np.zeros(len(lags))\n",
    "\n",
    "    for i, lag in enumerate(lags):\n",
    "        if lag == 0:\n",
    "            acf[i] = 1.0\n",
    "        else:\n",
    "            c_lag = np.dot(x_centered[:-lag], x_centered[lag:]) / len(x)\n",
    "            acf[i] = c_lag / c0\n",
    "\n",
    "    return lags, acf\n",
    "\n",
    "\n",
    "# Calculate ACF\n",
    "lags, acf_values = autocorrelation(residuals, max_lag=60)\n",
    "\n",
    "# Significance bounds (95% confidence for white noise)\n",
    "conf_bound = 1.96 / np.sqrt(len(residuals))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.stem(lags, acf_values, basefmt=\" \", linefmt=\"C0-\", markerfmt=\"C0o\")\n",
    "ax.axhline(0, color=\"k\", lw=1)\n",
    "ax.axhline(conf_bound, color=\"r\", ls=\"--\", lw=1.5, label=\"95% confidence\")\n",
    "ax.axhline(-conf_bound, color=\"r\", ls=\"--\", lw=1.5)\n",
    "ax.fill_between(\n",
    "    lags, -conf_bound, conf_bound, alpha=0.2, color=\"red\", label=\"White noise region\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Lag (days)\")\n",
    "ax.set_ylabel(\"Autocorrelation\")\n",
    "ax.set_title(\"Autocorrelation Function (ACF) of Residuals\")\n",
    "ax.set_xlim(-1, max(lags) + 1)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig_dir = Path.cwd() / \"figures\" / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_04.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# Check for significant autocorrelation\n",
    "significant_lags = np.sum(np.abs(acf_values[1:]) > conf_bound)  # Exclude lag 0\n",
    "print(\"✓ Autocorrelation analysis complete\")\n",
    "print(\n",
    "    f\"  Significant lags (95% level): {significant_lags} / {len(lags) - 1} ({significant_lags / (len(lags) - 1) * 100:.1f}%)\"\n",
    ")\n",
    "if significant_lags / (len(lags) - 1) < 0.05:\n",
    "    print(\"  ✓ Residuals consistent with white noise (good fit)\")\n",
    "else:\n",
    "    print(\n",
    "        \"  ⚠ Significant autocorrelation detected: consider more complex model or autoregressive errors\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# ## Summary and Best Practices\n",
    "#\n",
    "# ### When to Use NLSQ for Time Series\n",
    "#\n",
    "# | **Use Case** | **NLSQ Strength** | **Alternative** |\n",
    "# |--------------|-------------------|------------------|\n",
    "# | Physical growth models (exponential, logistic) | ✅ Excellent (interpretable parameters) | ARIMA (less interpretable) |\n",
    "# | Periodic data with known/unknown period | ✅ Good (Fourier series) | Seasonal decomposition (STL, Prophet) |\n",
    "# | Trend + seasonality | ✅ Good (combined parametric model) | Prophet, TBATS |\n",
    "# | Autoregressive processes (ARMA) | ❌ Poor (not designed for this) | ARIMA, SARIMA |\n",
    "# | Irregular sampling | ✅ Excellent (handles any time grid) | Interpolation + ARIMA |\n",
    "# | Large datasets (millions of points) | ✅ Excellent (JAX GPU acceleration) | Dask + statsmodels |\n",
    "#\n",
    "# ### Key Takeaways\n",
    "#\n",
    "# 1. **Model Selection**: Choose parametric forms based on domain knowledge\n",
    "#    - Growth: Exponential, logistic, Gompertz\n",
    "#    - Decay: Exponential, power-law\n",
    "#    - Periodic: Fourier series (sum of sines/cosines)\n",
    "#\n",
    "# 2. **Forecasting Uncertainty**\n",
    "#    - **Parameter uncertainty**: From covariance matrix (Monte Carlo sampling)\n",
    "#    - **Model uncertainty**: Residual standard deviation\n",
    "#    - **Total**: Combine both sources for realistic prediction intervals\n",
    "#\n",
    "# 3. **Diagnostics**\n",
    "#    - **Residuals**: Should be centered at zero, no trend\n",
    "#    - **Autocorrelation**: Should be within confidence bounds (white noise)\n",
    "#    - **Heteroscedasticity**: Check if residual variance changes over time\n",
    "#\n",
    "# 4. **Multi-Seasonal Data**\n",
    "#    - Use multiple sinusoids: `amp1 * sin(2π t / P1) + amp2 * sin(2π t / P2)`\n",
    "#    - Example: Daily + weekly cycles in energy consumption\n",
    "#\n",
    "# ### Production Code Template\n",
    "#\n",
    "# ```python\n",
    "# from nlsq import CurveFit\n",
    "# import jax.numpy as jnp\n",
    "#\n",
    "# def forecast_time_series(t, y, forecast_days=30):\n",
    "#     \"\"\"Fit trend+seasonal model and forecast.\"\"\"\n",
    "#\n",
    "#     # Model\n",
    "#     def model(t, mean, trend, amp, period, phase):\n",
    "#         return mean + trend * t + amp * jnp.sin(2 * jnp.pi * t / period + phase)\n",
    "#\n",
    "#     # Fit\n",
    "#     cf = CurveFit()\n",
    "#     p0 = [jnp.mean(y), 0.0, jnp.std(y) / 2, 365.0, 0.0]\n",
    "#     popt, pcov = cf.curve_fit(model, jnp.array(t), jnp.array(y), p0=p0)\n",
    "#\n",
    "#     # Forecast\n",
    "#     t_future = jnp.arange(t[-1] + 1, t[-1] + 1 + forecast_days)\n",
    "#     y_forecast = model(t_future, *popt)\n",
    "#\n",
    "#     # Uncertainty (simplified)\n",
    "#     residual_std = jnp.std(y - model(jnp.array(t), *popt))\n",
    "#     forecast_uncertainty = residual_std\n",
    "#\n",
    "#     return t_future, y_forecast, forecast_uncertainty\n",
    "# ```\n",
    "#\n",
    "# ### Next Steps\n",
    "#\n",
    "# - **Advanced Seasonality**: Multi-frequency Fourier series for complex cycles\n",
    "# - **State-Space Models**: Kalman filtering with NLSQ parameter estimation\n",
    "# - **Batch Processing**: Fit thousands of time series in parallel with `jax.vmap`\n",
    "# - **Hybrid Models**: Combine NLSQ (trend/seasonal) with ARIMA (residual modeling)\n",
    "#\n",
    "# ### References\n",
    "#\n",
    "# 1. **Time Series Analysis**: Chatfield, *The Analysis of Time Series* (2004)\n",
    "# 2. **Forecasting**: Hyndman & Athanasopoulos, *Forecasting: Principles and Practice* (2021)\n",
    "# 3. **Related Examples**:\n",
    "#    - `gallery/biology/growth_curves.py` - Bacterial growth fitting\n",
    "#    - `gallery/physics/damped_oscillation.py` - Oscillatory time series\n",
    "#    - `advanced_features_demo.ipynb` - Robustness for outliers in time series\n",
    "# ======================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
