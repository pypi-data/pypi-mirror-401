{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# 4-Layer Defense Strategy for L-BFGS Warmup Divergence Prevention\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/05_feature_demos/defense_layers_demo.ipynb)\n",
    "\n",
    "**Level**: Intermediate | **Time**: 25-30 minutes | **Version**: 0.3.6+\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates NLSQ's **4-layer defense strategy** that prevents Adam optimizer divergence during the warmup phase when initial parameters are already near optimal.\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- Understanding each defense layer and when it activates\n",
    "- Using telemetry to monitor defense layer behavior\n",
    "- Configuring defense sensitivity for different scenarios\n",
    "- Using preset configurations (strict, relaxed, scientific)\n",
    "- Troubleshooting common defense layer issues\n",
    "\n",
    "### Why Defense Layers?\n",
    "\n",
    "The hybrid streaming optimizer uses Adam for initial warmup before switching to Gauss-Newton. However, if initial parameters are already close to optimal, Adam's aggressive updates can push parameters **away** from the optimum, causing divergence.\n",
    "\n",
    "The 4-layer defense strategy prevents this by:\n",
    "1. **Layer 1**: Detecting warm starts and skipping warmup\n",
    "2. **Layer 2**: Adapting learning rate based on initial fit quality\n",
    "3. **Layer 3**: Aborting if loss increases beyond tolerance\n",
    "4. **Layer 4**: Clipping update magnitude to prevent large jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-install",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:12:34.795292Z",
     "iopub.status.busy": "2026-01-06T17:12:34.795125Z",
     "iopub.status.idle": "2026-01-06T17:12:34.798960Z",
     "shell.execute_reply": "2026-01-06T17:12:34.798353Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Install NLSQ (run once in Colab)\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Google Colab - installing NLSQ...\")\n",
    "    !pip install -q nlsq\n",
    "    print(\"NLSQ installed successfully!\")\n",
    "else:\n",
    "    print(\"Not running in Colab - assuming NLSQ is already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matplotlib-config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:12:34.800384Z",
     "iopub.status.busy": "2026-01-06T17:12:34.800243Z",
     "iopub.status.idle": "2026-01-06T17:12:35.187789Z",
     "shell.execute_reply": "2026-01-06T17:12:35.187079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:12:35.189942Z",
     "iopub.status.busy": "2026-01-06T17:12:35.189653Z",
     "iopub.status.idle": "2026-01-06T17:12:36.205676Z",
     "shell.execute_reply": "2026-01-06T17:12:36.204955Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import (\n",
    "    HybridStreamingConfig,\n",
    "    curve_fit,\n",
    "    get_defense_telemetry,\n",
    "    reset_defense_telemetry,\n",
    ")\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Understanding the 4 Defense Layers\n",
    "\n",
    "Let's set up a test model and explore each defense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:12:36.208562Z",
     "iopub.status.busy": "2026-01-06T17:12:36.208302Z",
     "iopub.status.idle": "2026-01-06T17:12:36.460095Z",
     "shell.execute_reply": "2026-01-06T17:12:36.458977Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Three-parameter exponential decay: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "# Generate synthetic data\n",
    "true_params = np.array([5.0, 0.5, 1.0])\n",
    "x = np.linspace(0, 10, 500)  # Reduced for faster execution\n",
    "y_true = exponential_decay(x, *true_params)\n",
    "y = y_true + np.random.normal(0, 0.1, len(x))\n",
    "\n",
    "print(f\"Dataset: {len(x)} samples\")\n",
    "print(f\"True parameters: a={true_params[0]}, b={true_params[1]}, c={true_params[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer1-header",
   "metadata": {},
   "source": [
    "### Layer 1: Warm Start Detection\n",
    "\n",
    "**Purpose**: Skip L-BFGS warmup entirely when initial parameters are already near optimal.\n",
    "\n",
    "**How it works**: Computes `relative_loss = initial_loss / y_variance`. If `relative_loss < warm_start_threshold` (default 1%), warmup is skipped.\n",
    "\n",
    "**When it helps**: Refinement workflows, iterative fitting, warm starts from previous fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "layer1-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:12:36.464452Z",
     "iopub.status.busy": "2026-01-06T17:12:36.464036Z",
     "iopub.status.idle": "2026-01-06T17:12:41.612370Z",
     "shell.execute_reply": "2026-01-06T17:12:41.611408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate Layer 1: Near-optimal initial guess\n",
    "print(\"=\" * 60)\n",
    "print(\"Layer 1: Warm Start Detection Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reset telemetry to track this specific fit\n",
    "reset_defense_telemetry()\n",
    "\n",
    "# Use parameters very close to true values (simulating a refinement scenario)\n",
    "near_optimal_p0 = true_params + np.random.normal(0, 0.01, 3)\n",
    "print(f\"\\nNear-optimal p0: {near_optimal_p0}\")\n",
    "print(f\"True params:     {true_params}\")\n",
    "\n",
    "# Fit with hybrid_streaming\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay,\n",
    "    x, y,\n",
    "    p0=near_optimal_p0,\n",
    "    method='hybrid_streaming',\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Check telemetry\n",
    "telemetry = get_defense_telemetry()\n",
    "summary = telemetry.get_summary()\n",
    "layer1_triggers = summary['layer1']['triggers']\n",
    "\n",
    "print(f\"\\nFitted params: {popt}\")\n",
    "print(\"\\n--- Telemetry ---\")\n",
    "print(f\"Layer 1 triggers: {layer1_triggers}\")\n",
    "print(f\"Total warmup calls: {summary['total_warmup_calls']}\")\n",
    "\n",
    "if layer1_triggers > 0:\n",
    "    print(\"\\n-> Layer 1 detected warm start and skipped L-BFGS warmup!\")\n",
    "else:\n",
    "    print(\"\\n-> Initial guess not close enough for warm start detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer2-header",
   "metadata": {},
   "source": [
    "### Layer 2: Adaptive Step Size\n",
    "\n",
    "**Purpose**: Automatically select learning rate based on initial loss quality.\n",
    "\n",
    "**Learning rate tiers**:\n",
    "- **Refinement** (1e-6): `relative_loss < 0.1` - ultra-conservative for excellent fits\n",
    "- **Careful** (1e-5): `0.1 <= relative_loss < 1.0` - conservative for good fits\n",
    "- **Exploration** (0.001): `relative_loss >= 1.0` - standard rate for poor fits\n",
    "\n",
    "**When it helps**: Multi-scale parameter problems, mixed starting point quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "layer2-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:12:41.615119Z",
     "iopub.status.busy": "2026-01-06T17:12:41.614846Z",
     "iopub.status.idle": "2026-01-06T17:14:06.819066Z",
     "shell.execute_reply": "2026-01-06T17:14:06.817990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate Layer 2: Different LR modes\n",
    "print(\"=\" * 60)\n",
    "print(\"Layer 2: Adaptive Step Size Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test with different initial guess qualities\n",
    "test_cases = [\n",
    "    (\"Excellent fit (refinement LR)\", true_params * np.array([1.02, 1.01, 0.99])),\n",
    "    (\"Good fit (careful LR)\", true_params * np.array([1.2, 0.8, 1.3])),\n",
    "    (\"Poor fit (exploration LR)\", np.array([1.0, 0.1, 5.0])),\n",
    "]\n",
    "\n",
    "for name, p0 in test_cases:\n",
    "    reset_defense_telemetry()\n",
    "\n",
    "    # Disable Layer 1 to see Layer 2 in action\n",
    "    config = HybridStreamingConfig(\n",
    "        enable_warm_start_detection=False,  # Force warmup to run\n",
    "        warmup_iterations=50,  # Short warmup for demo\n",
    "    )\n",
    "\n",
    "    popt, _ = curve_fit(\n",
    "        exponential_decay, x, y, p0=p0,\n",
    "        method='hybrid_streaming',\n",
    "        config=config,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    telemetry = get_defense_telemetry()\n",
    "    lr_counts = telemetry.layer2_lr_mode_counts\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  p0: {p0}\")\n",
    "    print(f\"  LR mode counts: {lr_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer3-header",
   "metadata": {},
   "source": [
    "### Layer 3: Cost-Increase Guard\n",
    "\n",
    "**Purpose**: Abort warmup immediately if loss increases beyond tolerance.\n",
    "\n",
    "**How it works**: After each Adam step, checks if `current_loss > initial_loss * (1 + cost_increase_tolerance)`. If triggered, returns the **best parameters found** (not the diverged ones).\n",
    "\n",
    "**Default tolerance**: 5% (configurable)\n",
    "\n",
    "**When it helps**: Preventing divergence from near-optimal starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "layer3-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:14:06.825030Z",
     "iopub.status.busy": "2026-01-06T17:14:06.824548Z",
     "iopub.status.idle": "2026-01-06T17:14:07.999100Z",
     "shell.execute_reply": "2026-01-06T17:14:07.998329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate Layer 3: Cost Guard Protection\n",
    "print(\"=\" * 60)\n",
    "print(\"Layer 3: Cost-Increase Guard Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Scenario: Aggressive LR that would cause divergence\n",
    "# Layer 3 should catch this and return best params\n",
    "reset_defense_telemetry()\n",
    "\n",
    "# Use a config that might cause divergence (high LR, disabled other defenses)\n",
    "config = HybridStreamingConfig(\n",
    "    enable_warm_start_detection=False,\n",
    "    enable_adaptive_warmup_lr=False,  # Use fixed (high) LR\n",
    "    warmup_learning_rate=0.1,  # Very aggressive LR\n",
    "    enable_cost_guard=True,  # But cost guard is ON\n",
    "    cost_increase_tolerance=0.05,  # Abort if loss increases >5%\n",
    "    enable_step_clipping=False,\n",
    "    warmup_iterations=100,\n",
    ")\n",
    "\n",
    "# Start from excellent initial guess\n",
    "excellent_p0 = true_params * np.array([1.01, 0.99, 1.005])\n",
    "print(f\"Starting from near-optimal p0: {excellent_p0}\")\n",
    "print(f\"With aggressive LR={config.warmup_learning_rate}\")\n",
    "\n",
    "popt, _ = curve_fit(\n",
    "    exponential_decay, x, y, p0=excellent_p0,\n",
    "    method='hybrid_streaming',\n",
    "    config=config,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "telemetry = get_defense_telemetry()\n",
    "summary = telemetry.get_summary()\n",
    "layer3_triggers = summary['layer3']['triggers']\n",
    "\n",
    "print(f\"\\nFinal params: {popt}\")\n",
    "print(\"\\n--- Telemetry ---\")\n",
    "print(f\"Layer 3 (cost guard) triggers: {layer3_triggers}\")\n",
    "\n",
    "if layer3_triggers > 0:\n",
    "    print(\"\\n-> Layer 3 detected loss increase and aborted warmup!\")\n",
    "    print(\"   Returned best parameters found, not diverged values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer4-header",
   "metadata": {},
   "source": [
    "### Layer 4: Trust Region Constraint (Step Clipping)\n",
    "\n",
    "**Purpose**: Limit parameter update magnitude to prevent large destabilizing jumps.\n",
    "\n",
    "**How it works**: Clips Adam parameter updates to max L2 norm of `max_warmup_step_size` (default 0.1).\n",
    "\n",
    "**When it helps**: Multi-scale parameters, ill-conditioned problems, preventing overshooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "layer4-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:14:08.002885Z",
     "iopub.status.busy": "2026-01-06T17:14:08.002575Z",
     "iopub.status.idle": "2026-01-06T17:15:22.070122Z",
     "shell.execute_reply": "2026-01-06T17:15:22.069422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstrate Layer 4: Step Clipping\n",
    "print(\"=\" * 60)\n",
    "print(\"Layer 4: Trust Region Constraint Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reset_defense_telemetry()\n",
    "\n",
    "# Config with step clipping\n",
    "config = HybridStreamingConfig(\n",
    "    enable_warm_start_detection=False,\n",
    "    enable_adaptive_warmup_lr=False,\n",
    "    warmup_learning_rate=0.01,  # High LR that would produce large steps\n",
    "    enable_cost_guard=False,\n",
    "    enable_step_clipping=True,  # Step clipping ON\n",
    "    max_warmup_step_size=0.1,  # Max L2 norm of update\n",
    "    warmup_iterations=100,\n",
    ")\n",
    "\n",
    "# Poor initial guess that needs exploration\n",
    "poor_p0 = np.array([10.0, 0.1, 5.0])\n",
    "print(f\"Starting from poor p0: {poor_p0}\")\n",
    "\n",
    "popt, _ = curve_fit(\n",
    "    exponential_decay, x, y, p0=poor_p0,\n",
    "    method='hybrid_streaming',\n",
    "    config=config,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "telemetry = get_defense_telemetry()\n",
    "summary = telemetry.get_summary()\n",
    "layer4_triggers = summary['layer4']['triggers']\n",
    "\n",
    "print(f\"\\nFinal params: {popt}\")\n",
    "print(f\"True params:  {true_params}\")\n",
    "print(\"\\n--- Telemetry ---\")\n",
    "print(f\"Layer 4 (step clipping) triggers: {layer4_triggers}\")\n",
    "\n",
    "if layer4_triggers > 0:\n",
    "    print(f\"\\n-> Layer 4 clipped {layer4_triggers} large parameter updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Using Defense Layer Telemetry\n",
    "\n",
    "Telemetry helps monitor defense layer behavior in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "telemetry-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:15:22.071907Z",
     "iopub.status.busy": "2026-01-06T17:15:22.071791Z",
     "iopub.status.idle": "2026-01-06T17:22:00.141509Z",
     "shell.execute_reply": "2026-01-06T17:22:00.140167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run multiple fits and collect telemetry\n",
    "print(\"=\" * 60)\n",
    "print(\"Defense Layer Telemetry Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reset_defense_telemetry()\n",
    "\n",
    "# Simulate a batch of fits with varying starting points\n",
    "n_fits = 5  # Reduced for faster execution\n",
    "for i in range(n_fits):\n",
    "    # Vary initial guess quality\n",
    "    noise_scale = 0.01 if i < 2 else (0.3 if i < 4 else 1.0)\n",
    "    p0 = true_params * (1 + np.random.uniform(-noise_scale, noise_scale, 3))\n",
    "\n",
    "    popt, _ = curve_fit(\n",
    "        exponential_decay, x, y, p0=p0,\n",
    "        method='hybrid_streaming',\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "# Get comprehensive telemetry report\n",
    "telemetry = get_defense_telemetry()\n",
    "\n",
    "print(f\"\\n--- Summary after {n_fits} fits ---\")\n",
    "summary = telemetry.get_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n--- Trigger Rates ---\")\n",
    "rates = telemetry.get_trigger_rates()\n",
    "for key, value in rates.items():\n",
    "    print(f\"  {key}: {value:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "telemetry-events",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:22:00.143941Z",
     "iopub.status.busy": "2026-01-06T17:22:00.143743Z",
     "iopub.status.idle": "2026-01-06T17:22:00.148152Z",
     "shell.execute_reply": "2026-01-06T17:22:00.146924Z"
    }
   },
   "outputs": [],
   "source": [
    "# View recent events\n",
    "print(\"\\n--- Recent Events (last 5) ---\")\n",
    "events = telemetry.get_recent_events(5)\n",
    "for event in events:\n",
    "    print(f\"  {event['timestamp']}: {event['type']} - {event.get('data', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "telemetry-export",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:22:00.150780Z",
     "iopub.status.busy": "2026-01-06T17:22:00.150495Z",
     "iopub.status.idle": "2026-01-06T17:22:00.155620Z",
     "shell.execute_reply": "2026-01-06T17:22:00.154618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export metrics (Prometheus/Grafana compatible)\n",
    "print(\"\\n--- Prometheus-Compatible Metrics ---\")\n",
    "metrics = telemetry.export_metrics()\n",
    "for metric_name, value in metrics.items():\n",
    "    print(f\"  {metric_name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Configuration Presets\n",
    "\n",
    "NLSQ provides preset configurations for common scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presets-demo",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:22:00.157950Z",
     "iopub.status.busy": "2026-01-06T17:22:00.157679Z",
     "iopub.status.idle": "2026-01-06T17:22:00.164805Z",
     "shell.execute_reply": "2026-01-06T17:22:00.163365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Available presets\n",
    "print(\"=\" * 60)\n",
    "print(\"Configuration Presets\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "presets = [\n",
    "    (\"Default\", HybridStreamingConfig()),\n",
    "    (\"defense_strict()\", HybridStreamingConfig.defense_strict()),\n",
    "    (\"defense_relaxed()\", HybridStreamingConfig.defense_relaxed()),\n",
    "    (\"defense_disabled()\", HybridStreamingConfig.defense_disabled()),\n",
    "    (\"scientific_default()\", HybridStreamingConfig.scientific_default()),\n",
    "]\n",
    "\n",
    "print(\"\\n{:<22} {:>8} {:>10} {:>12} {:>8}\".format(\n",
    "    \"Preset\", \"Layer1\", \"Layer2\", \"Layer3\", \"Layer4\"\n",
    "))\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, config in presets:\n",
    "    print(\"{:<22} {:>8} {:>10} {:>12} {:>8}\".format(\n",
    "        name,\n",
    "        \"ON\" if config.enable_warm_start_detection else \"OFF\",\n",
    "        \"ON\" if config.enable_adaptive_warmup_lr else \"OFF\",\n",
    "        \"ON\" if config.enable_cost_guard else \"OFF\",\n",
    "        \"ON\" if config.enable_step_clipping else \"OFF\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preset-comparison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:22:00.168512Z",
     "iopub.status.busy": "2026-01-06T17:22:00.167974Z",
     "iopub.status.idle": "2026-01-06T17:22:05.026336Z",
     "shell.execute_reply": "2026-01-06T17:22:05.025246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compare preset behavior\n",
    "print(\"\\n--- Preset Comparison: Near-Optimal Start ---\")\n",
    "\n",
    "near_optimal_p0 = true_params * np.array([1.005, 0.995, 1.002])\n",
    "\n",
    "for name, config in presets[:4]:  # Skip scientific_default for brevity\n",
    "    reset_defense_telemetry()\n",
    "\n",
    "    popt, _ = curve_fit(\n",
    "        exponential_decay, x, y, p0=near_optimal_p0,\n",
    "        method='hybrid_streaming',\n",
    "        config=config,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    telemetry = get_defense_telemetry()\n",
    "    rates = telemetry.get_trigger_rates()\n",
    "\n",
    "    error = np.linalg.norm(popt - true_params)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Parameter error: {error:.6f}\")\n",
    "    print(f\"  Layer 1 rate: {rates.get('layer1_warm_start_rate', 0):.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Custom Configuration\n",
    "\n",
    "Fine-tune defense layers for your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:22:05.031382Z",
     "iopub.status.busy": "2026-01-06T17:22:05.031192Z",
     "iopub.status.idle": "2026-01-06T17:24:14.130627Z",
     "shell.execute_reply": "2026-01-06T17:24:14.129423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom configuration example\n",
    "print(\"=\" * 60)\n",
    "print(\"Custom Configuration Example\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Scenario: Scientific computing with multi-scale parameters\n",
    "custom_config = HybridStreamingConfig(\n",
    "    # Layer 1: Stricter warm start detection\n",
    "    enable_warm_start_detection=True,\n",
    "    warm_start_threshold=0.005,  # 0.5% instead of 1%\n",
    "\n",
    "    # Layer 2: Conservative learning rates\n",
    "    enable_adaptive_warmup_lr=True,\n",
    "    warmup_lr_refinement=1e-7,  # Ultra-conservative\n",
    "    warmup_lr_careful=1e-6,\n",
    "    warmup_learning_rate=1e-4,  # Lower than default 0.001\n",
    "\n",
    "    # Layer 3: Tighter cost tolerance\n",
    "    enable_cost_guard=True,\n",
    "    cost_increase_tolerance=0.02,  # 2% instead of 5%\n",
    "\n",
    "    # Layer 4: Smaller step limit\n",
    "    enable_step_clipping=True,\n",
    "    max_warmup_step_size=0.05,  # Half the default\n",
    "\n",
    "    # Other settings\n",
    "    precision='float64',  # Full precision for scientific work\n",
    "    warmup_iterations=300,\n",
    ")\n",
    "\n",
    "print(\"Custom config created with:\")\n",
    "print(f\"  warm_start_threshold: {custom_config.warm_start_threshold}\")\n",
    "print(f\"  warmup_lr_refinement: {custom_config.warmup_lr_refinement}\")\n",
    "print(f\"  cost_increase_tolerance: {custom_config.cost_increase_tolerance}\")\n",
    "print(f\"  max_warmup_step_size: {custom_config.max_warmup_step_size}\")\n",
    "\n",
    "# Use the custom config\n",
    "reset_defense_telemetry()\n",
    "popt, pcov = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=np.array([4.5, 0.45, 1.1]),\n",
    "    method='hybrid_streaming',\n",
    "    config=custom_config,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "print(f\"\\nFitted params: {popt}\")\n",
    "print(f\"Std errors: {np.sqrt(np.diag(pcov))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Practical Scenarios\n",
    "\n",
    "### Scenario A: Warm Start Refinement\n",
    "\n",
    "Refining parameters from a previous fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenario-a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:24:14.133616Z",
     "iopub.status.busy": "2026-01-06T17:24:14.133314Z",
     "iopub.status.idle": "2026-01-06T17:25:16.838242Z",
     "shell.execute_reply": "2026-01-06T17:25:16.837560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Warm Start Refinement Scenario\n",
    "print(\"=\" * 60)\n",
    "print(\"Scenario A: Warm Start Refinement\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Initial fit on first batch of data\n",
    "x1 = x[:500]\n",
    "y1 = y[:500]\n",
    "\n",
    "popt_v1, _ = curve_fit(\n",
    "    exponential_decay, x1, y1,\n",
    "    p0=np.array([3.0, 0.3, 0.5]),\n",
    "    method='hybrid_streaming',\n",
    "    verbose=0,\n",
    ")\n",
    "print(f\"Initial fit (v1): {popt_v1}\")\n",
    "\n",
    "# Step 2: Refinement with full data (using v1 as starting point)\n",
    "reset_defense_telemetry()\n",
    "\n",
    "popt_v2, pcov_v2 = curve_fit(\n",
    "    exponential_decay, x, y,\n",
    "    p0=popt_v1,  # Use previous result as initial guess\n",
    "    method='hybrid_streaming',\n",
    "    config=HybridStreamingConfig.defense_strict(),  # Use strict for refinement\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "telemetry = get_defense_telemetry()\n",
    "rates = telemetry.get_trigger_rates()\n",
    "\n",
    "print(f\"Refined fit (v2): {popt_v2}\")\n",
    "print(f\"True params:      {true_params}\")\n",
    "print(f\"\\nLayer 1 (warm start) triggered: {rates.get('layer1_warm_start_rate', 0):.0f}%\")\n",
    "print(\"-> Defense layers protected against divergence from good initial guess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenario-b-header",
   "metadata": {},
   "source": [
    "### Scenario B: Production Monitoring\n",
    "\n",
    "Monitoring defense layer activations in a batch processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenario-b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:25:16.840912Z",
     "iopub.status.busy": "2026-01-06T17:25:16.840747Z",
     "iopub.status.idle": "2026-01-06T17:29:04.410795Z",
     "shell.execute_reply": "2026-01-06T17:29:04.409947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Production Monitoring Scenario\n",
    "print(\"=\" * 60)\n",
    "print(\"Scenario B: Production Monitoring\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reset_defense_telemetry()\n",
    "\n",
    "# Simulate production batch with varying data quality\n",
    "results = []\n",
    "for i in range(3):  # Reduced from 20 for faster execution\n",
    "    # Simulate different starting point qualities\n",
    "    if i < 2:\n",
    "        p0 = true_params * (1 + np.random.uniform(-0.01, 0.01, 3))  # Excellent\n",
    "    elif i < 7:\n",
    "        p0 = true_params * (1 + np.random.uniform(-0.2, 0.2, 3))  # Good\n",
    "    else:\n",
    "        p0 = np.array([1.0, 0.1, 5.0]) + np.random.uniform(-0.5, 0.5, 3)  # Poor\n",
    "\n",
    "    # Add some noise to data\n",
    "    y_noisy = y + np.random.normal(0, 0.05 * (i % 3 + 1), len(y))\n",
    "\n",
    "    popt, _ = curve_fit(\n",
    "        exponential_decay, x, y_noisy, p0=p0,\n",
    "        method='hybrid_streaming',\n",
    "        verbose=0,\n",
    "    )\n",
    "    results.append(popt)\n",
    "\n",
    "# Production monitoring report\n",
    "telemetry = get_defense_telemetry()\n",
    "rates = telemetry.get_trigger_rates()\n",
    "\n",
    "print(f\"\\n--- Production Report ({len(results)} fits) ---\")\n",
    "print(\"\\nDefense Layer Activation Rates:\")\n",
    "print(f\"  Layer 1 (Warm Start):     {rates.get('layer1_warm_start_rate', 0):.1f}%\")\n",
    "print(f\"  Layer 2 (Refinement LR):  {rates.get('layer2_refinement_rate', 0):.1f}%\")\n",
    "print(f\"  Layer 2 (Careful LR):     {rates.get('layer2_careful_rate', 0):.1f}%\")\n",
    "print(f\"  Layer 2 (Exploration LR): {rates.get('layer2_exploration_rate', 0):.1f}%\")\n",
    "print(f\"  Layer 3 (Cost Guard):     {rates.get('layer3_cost_guard_rate', 0):.1f}%\")\n",
    "print(f\"  Layer 4 (Step Clipping):  {rates.get('layer4_clip_rate', 0):.1f}%\")\n",
    "\n",
    "# Alerts based on rates\n",
    "print(\"\\n--- Alerts ---\")\n",
    "if rates.get('layer1_warm_start_rate', 0) > 50:\n",
    "    print(\"INFO: >50% warm starts - consider using defense_strict()\")\n",
    "if rates.get('layer3_cost_guard_rate', 0) > 20:\n",
    "    print(\"WARNING: >20% cost guard triggers - review initial guess quality\")\n",
    "if rates.get('layer3_cost_guard_rate', 0) == 0 and rates.get('layer1_warm_start_rate', 0) == 0:\n",
    "    print(\"OK: Defense layers active but not frequently triggered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "troubleshooting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T17:29:04.414257Z",
     "iopub.status.busy": "2026-01-06T17:29:04.413942Z",
     "iopub.status.idle": "2026-01-06T17:29:04.419601Z",
     "shell.execute_reply": "2026-01-06T17:29:04.419011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Troubleshooting guide\n",
    "print(\"=\" * 60)\n",
    "print(\"Troubleshooting Guide\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "issues = [\n",
    "    {\n",
    "        \"problem\": \"Warmup always skipped (Layer 1 always triggers)\",\n",
    "        \"cause\": \"warm_start_threshold too high for your use case\",\n",
    "        \"solution\": \"config = HybridStreamingConfig(warm_start_threshold=0.001)\",\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Convergence too slow after upgrading to 0.3.6\",\n",
    "        \"cause\": \"Layer 2 using ultra-conservative LR\",\n",
    "        \"solution\": \"config = HybridStreamingConfig.defense_relaxed()\",\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Cost guard aborts warmup too early\",\n",
    "        \"cause\": \"cost_increase_tolerance too strict\",\n",
    "        \"solution\": \"config = HybridStreamingConfig(cost_increase_tolerance=0.2)\",\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Results different from pre-0.3.6\",\n",
    "        \"cause\": \"Defense layers preventing previous divergence\",\n",
    "        \"solution\": \"config = HybridStreamingConfig.defense_disabled() # For testing only\",\n",
    "    },\n",
    "    {\n",
    "        \"problem\": \"Need pre-0.3.6 behavior for regression tests\",\n",
    "        \"cause\": \"Defense layers change optimization path\",\n",
    "        \"solution\": \"config = HybridStreamingConfig.defense_disabled()\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, issue in enumerate(issues, 1):\n",
    "    print(f\"\\n{i}. Problem: {issue['problem']}\")\n",
    "    print(f\"   Cause: {issue['cause']}\")\n",
    "    print(f\"   Solution: {issue['solution']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **4 Defense Layers** protect against L-BFGS warmup divergence:\n",
    "   - Layer 1: Warm start detection (skip warmup if near optimal)\n",
    "   - Layer 2: Adaptive step size (scale step size by fit quality)\n",
    "   - Layer 3: Cost-increase guard (abort on loss increase)\n",
    "   - Layer 4: Step clipping (limit update magnitude)\n",
    "\n",
    "2. **Enabled by default** - no code changes required for most users\n",
    "\n",
    "3. **Telemetry** helps monitor defense behavior in production:\n",
    "   - `get_defense_telemetry()` - access telemetry singleton\n",
    "   - `reset_defense_telemetry()` - reset counters\n",
    "   - `.get_summary()` - comprehensive report\n",
    "   - `.get_trigger_rates()` - percentage rates\n",
    "   - `.export_metrics()` - Prometheus-compatible format\n",
    "\n",
    "4. **Presets** for common scenarios:\n",
    "   - `defense_strict()` - for refinement/warm starts\n",
    "   - `defense_relaxed()` - for exploration\n",
    "   - `defense_disabled()` - pre-0.3.6 behavior\n",
    "   - `scientific_default()` - optimized for physics/scientific computing\n",
    "\n",
    "### When to Customize\n",
    "\n",
    "| Scenario | Recommendation |\n",
    "|----------|----------------|\n",
    "| Default usage | Use defaults (all layers ON) |\n",
    "| Warm start refinement | `defense_strict()` |\n",
    "| Exploration from poor guess | `defense_relaxed()` |\n",
    "| Regression testing | `defense_disabled()` |\n",
    "| Scientific computing | `scientific_default()` |\n",
    "| Custom requirements | Create `HybridStreamingConfig(...)` |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- [Hybrid Streaming API](../06_streaming/05_hybrid_streaming_api.ipynb) - Complete hybrid streaming guide\n",
    "- [Troubleshooting Guide](../03_advanced/troubleshooting_guide.ipynb) - General troubleshooting\n",
    "- [Migration Guide](https://nlsq.readthedocs.io/en/latest/migration/v0.3.6_defense_layers.html) - v0.3.6 migration details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
