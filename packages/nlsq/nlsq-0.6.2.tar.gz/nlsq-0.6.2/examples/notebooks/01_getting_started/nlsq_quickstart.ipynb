{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e028d1",
   "metadata": {},
   "source": [
    "# üìò NLSQ Quickstart: Your First Curve Fit in 5 Minutes\n",
    "\n",
    "> Learn the basics of curve fitting with NLSQ through simple, hands-on examples\n",
    "\n",
    "‚è±Ô∏è **10-15 minutes** | üìä **Level: ‚óè‚óã‚óã Beginner** | üéì **No prior curve fitting experience needed**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/01_getting_started/nlsq_quickstart.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298698c",
   "metadata": {},
   "source": [
    "## üéØ What You'll Learn\n",
    "\n",
    "By the end of this quickstart, you will:\n",
    "- ‚úì Fit your first curve using NLSQ's `curve_fit` function\n",
    "- ‚úì Understand JAX's JIT compilation and why the first fit is slower\n",
    "- ‚úì Use memory management features for optimal performance\n",
    "- ‚úì See NLSQ's 100x+ speed advantage over SciPy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0b081",
   "metadata": {},
   "source": [
    "## üí° Why This Matters\n",
    "\n",
    "Curve fitting is fundamental to scientific analysis: extracting parameters from experimental data, fitting calibration curves, modeling physical processes. NLSQ makes this **10-300x faster** than traditional methods through GPU acceleration and intelligent compilation.\n",
    "\n",
    "**Perfect for:**\n",
    "- üî¨ Scientists analyzing experimental data\n",
    "- üìä First-time curve fitting users\n",
    "- üöÄ SciPy users needing better performance\n",
    "- üíª Anyone working with large datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1392dcd",
   "metadata": {},
   "source": [
    "## üìö Before You Begin\n",
    "\n",
    "**First time here?** Perfect! This is exactly where you should start.\n",
    "\n",
    "**What you need to know:**\n",
    "- [ ] Python basics (variables, functions)\n",
    "- [ ] Basic NumPy array operations\n",
    "\n",
    "**What you don't need to know:**\n",
    "- ‚ùå Advanced mathematics or optimization theory\n",
    "- ‚ùå GPU programming or CUDA\n",
    "- ‚ùå JAX internals or automatic differentiation\n",
    "\n",
    "**Software requirements:**\n",
    "- Python >= 3.12\n",
    "- NLSQ package: `pip install nlsq` ([Installation guide](../../README.md#installation))\n",
    "- Optional: GPU for maximum performance (works great on CPU too!)\n",
    "\n",
    "üí° **Tip:** In Google Colab, set Runtime ‚Üí Change runtime type ‚Üí GPU for best performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ac6c76",
   "metadata": {},
   "source": [
    "## 1. Installation and Imports\n",
    "\n",
    "**Important:** NLSQ requires Python 3.12 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77a2c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:43.792212Z",
     "iopub.status.busy": "2026-01-06T16:55:43.791951Z",
     "iopub.status.idle": "2026-01-06T16:55:44.118700Z",
     "shell.execute_reply": "2026-01-06T16:55:44.118036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a00b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:44.121492Z",
     "iopub.status.busy": "2026-01-06T16:55:44.121307Z",
     "iopub.status.idle": "2026-01-06T16:55:44.123862Z",
     "shell.execute_reply": "2026-01-06T16:55:44.123033Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3137cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:44.125881Z",
     "iopub.status.busy": "2026-01-06T16:55:44.125601Z",
     "iopub.status.idle": "2026-01-06T16:55:44.128154Z",
     "shell.execute_reply": "2026-01-06T16:55:44.127444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to install in Colab/notebook environment\n",
    "# !pip install nlsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0c9e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:44.130285Z",
     "iopub.status.busy": "2026-01-06T16:55:44.130041Z",
     "iopub.status.idle": "2026-01-06T16:55:45.014746Z",
     "shell.execute_reply": "2026-01-06T16:55:45.013679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import NLSQ before JAX (NLSQ configures JAX for 64-bit precision)\n",
    "import os\n",
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from nlsq import CurveFit, __version__\n",
    "\n",
    "QUICK = os.environ.get(\"NLSQ_EXAMPLES_QUICK\") == \"1\"\n",
    "\n",
    "\n",
    "print(f\"NLSQ version: {__version__}\")\n",
    "\n",
    "# Import advanced memory management features\n",
    "from nlsq import (\n",
    "    MemoryConfig,\n",
    "    estimate_memory_requirements,\n",
    "    get_memory_config,\n",
    "    memory_context,\n",
    "    set_memory_limits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b2ce5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö° Quick Start (30 seconds)\n",
    "\n",
    "Let's fit your first curve! We'll fit a linear function to noisy data.\n",
    "\n",
    "### Step 1: Define your model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdfedb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:45.016962Z",
     "iopub.status.busy": "2026-01-06T16:55:45.016629Z",
     "iopub.status.idle": "2026-01-06T16:55:45.020356Z",
     "shell.execute_reply": "2026-01-06T16:55:45.019414Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear(x, m, b):\n",
    "    \"\"\"Linear function: y = m*x + b\"\"\"\n",
    "    return m * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0694c",
   "metadata": {},
   "source": [
    "### Step 2: Create synthetic data\n",
    "\n",
    "We'll generate data from y = 3x + 5 with some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf60b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:45.022501Z",
     "iopub.status.busy": "2026-01-06T16:55:45.022299Z",
     "iopub.status.idle": "2026-01-06T16:55:45.186568Z",
     "shell.execute_reply": "2026-01-06T16:55:45.185883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate noisy data\n",
    "length = 1000\n",
    "x = np.linspace(0, 10, length)\n",
    "true_params = (3, 5)  # m=3, b=5\n",
    "y = linear(x, *true_params) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "# Visualize the data\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, y, 'o', alpha=0.5, markersize=3, label='Noisy data')\n",
    "plt.plot(x, linear(x, *true_params), 'r-', linewidth=2, label='True function (y = 3x + 5)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Noisy Linear Data')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"True parameters: m={true_params[0]}, b={true_params[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb44360",
   "metadata": {},
   "source": [
    "### Step 3: Fit the data!\n",
    "\n",
    "Now let's use NLSQ to find the best-fit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d63c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:45.188951Z",
     "iopub.status.busy": "2026-01-06T16:55:45.188831Z",
     "iopub.status.idle": "2026-01-06T16:55:47.477772Z",
     "shell.execute_reply": "2026-01-06T16:55:47.477089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a CurveFit object\n",
    "jcf = CurveFit()\n",
    "\n",
    "# Fit the data\n",
    "popt, pcov = jcf.curve_fit(linear, x, y, p0=(1, 1))  # p0 is initial guess\n",
    "\n",
    "# Visualize the fit\n",
    "y_fit = linear(x, *popt)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, y, 'o', alpha=0.5, markersize=3, label='Noisy data')\n",
    "plt.plot(x, linear(x, *true_params), 'r--', linewidth=2, label='True function')\n",
    "plt.plot(x, y_fit, 'g-', linewidth=2, label='Fitted function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('NLSQ Curve Fit Results')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Fitting successful!\")\n",
    "print(f\"\\nFitted parameters: m={popt[0]:.4f}, b={popt[1]:.4f}\")\n",
    "print(f\"True parameters:   m={true_params[0]:.4f}, b={true_params[1]:.4f}\")\n",
    "print(f\"\\nErrors: Œîm={abs(popt[0]-true_params[0]):.4f}, Œîb={abs(popt[1]-true_params[1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7396c",
   "metadata": {},
   "source": [
    "‚úì **Success!** If your fitted parameters are close to the true values (3, 5), you've completed your first fit!\n",
    "\n",
    "üí° **What just happened:** NLSQ used the Levenberg-Marquardt algorithm with automatic differentiation to find the parameters (m, b) that minimize the difference between your model and data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9761c3e6",
   "metadata": {},
   "source": [
    "## 2. Memory Management and Configuration\n",
    "\n",
    "NLSQ includes sophisticated memory management features for optimal performance with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17201b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:47.479784Z",
     "iopub.status.busy": "2026-01-06T16:55:47.479663Z",
     "iopub.status.idle": "2026-01-06T16:55:47.484840Z",
     "shell.execute_reply": "2026-01-06T16:55:47.483938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check current memory configuration\n",
    "current_config = get_memory_config()\n",
    "print(f\"Current memory limit: {current_config.memory_limit_gb} GB\")\n",
    "print(f\"Mixed precision fallback: {current_config.enable_mixed_precision_fallback}\")\n",
    "\n",
    "# Estimate memory requirements for our dataset\n",
    "n_points = len(x)\n",
    "n_params = 2  # m and b for linear function\n",
    "memory_stats = estimate_memory_requirements(n_points, n_params)\n",
    "\n",
    "print(f\"\\nMemory estimate for {n_points:,} points, {n_params} parameters:\")\n",
    "print(f\"  Total memory needed: {memory_stats.total_memory_estimate_gb:.4f} GB\")\n",
    "print(f\"  Recommended chunk size: {memory_stats.recommended_chunk_size:,}\")\n",
    "print(f\"  Number of chunks needed: {memory_stats.n_chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4141ed",
   "metadata": {},
   "source": [
    "### Temporary Memory Configuration\n",
    "\n",
    "You can temporarily change memory settings using context managers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be92d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:47.487962Z",
     "iopub.status.busy": "2026-01-06T16:55:47.487487Z",
     "iopub.status.idle": "2026-01-06T16:55:47.495048Z",
     "shell.execute_reply": "2026-01-06T16:55:47.493713Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Default memory limit:\", get_memory_config().memory_limit_gb, \"GB\")\n",
    "\n",
    "# Use a temporary memory configuration\n",
    "temp_config = MemoryConfig(memory_limit_gb=4.0, enable_mixed_precision_fallback=True)\n",
    "with memory_context(temp_config):\n",
    "    print(\"Inside context memory limit:\", get_memory_config().memory_limit_gb, \"GB\")\n",
    "\n",
    "print(\"After context memory limit:\", get_memory_config().memory_limit_gb, \"GB\")\n",
    "\n",
    "print(\"\\n‚úì Context managers allow temporary configuration changes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b0841",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Understanding JAX Compilation\n",
    "\n",
    "NLSQ uses JAX's JIT (Just-In-Time) compilation for speed. Let's see how this affects fit times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ac875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:47.498578Z",
     "iopub.status.busy": "2026-01-06T16:55:47.498135Z",
     "iopub.status.idle": "2026-01-06T16:55:52.542964Z",
     "shell.execute_reply": "2026-01-06T16:55:52.542326Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_parameters(mmin=1, mmax=10, bmin=0, bmax=10):\n",
    "    \"\"\"Generate random linear parameters\"\"\"\n",
    "    m = mmin + (mmax - mmin) * np.random.random()\n",
    "    b = bmin + (bmax - bmin) * np.random.random()\n",
    "    return m, b\n",
    "\n",
    "# Fit 20 different datasets\n",
    "length = 300000  # 300K points\n",
    "x = np.linspace(0, 10, length)\n",
    "\n",
    "jcf = CurveFit()\n",
    "nlsq_fit_times = []\n",
    "nsamples = 21\n",
    "\n",
    "for i in range(nsamples):\n",
    "    params = get_random_parameters()\n",
    "    y = linear(x, *params) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    start_time = time.time()\n",
    "    popt, pcov = jcf.curve_fit(linear, x, y, p0=(1, 1))\n",
    "    nlsq_fit_times.append(time.time() - start_time)\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(nlsq_fit_times, 'o-', linewidth=2, markersize=8)\n",
    "plt.axhline(np.mean(nlsq_fit_times[1:]), color='r', linestyle='--',\n",
    "            label=f'Average (after compilation): {np.mean(nlsq_fit_times[1:]):.4f}s')\n",
    "plt.xlabel('Fit Iteration')\n",
    "plt.ylabel('Fit Time (seconds)')\n",
    "plt.title('JAX Compilation Effect: First Fit Slower, Then Fast')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"First fit (with compilation): {nlsq_fit_times[0]:.4f}s\")\n",
    "print(f\"Average after compilation:    {np.mean(nlsq_fit_times[1:]):.4f}s\")\n",
    "print(f\"\\nSpeedup after compilation: {nlsq_fit_times[0] / np.mean(nlsq_fit_times[1:]):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d6ca0",
   "metadata": {},
   "source": [
    "üí° **Key Insight:** The first fit is slow because JAX is compiling (tracing) the functions. After compilation, subsequent fits are **extremely fast** because they reuse the compiled code!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db57ca",
   "metadata": {},
   "source": [
    "## 4. Varying Data Sizes: The Recompilation Problem\n",
    "\n",
    "What happens if we change the data size for each fit? JAX must recompile for each new array size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb64b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:55:52.545453Z",
     "iopub.status.busy": "2026-01-06T16:55:52.545267Z",
     "iopub.status.idle": "2026-01-06T16:56:33.766922Z",
     "shell.execute_reply": "2026-01-06T16:56:33.766089Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_data(length):\n",
    "    \"\"\"Generate random linear data\"\"\"\n",
    "    xdata = np.linspace(0, 10, length)\n",
    "    params = get_random_parameters()\n",
    "    ydata = linear(xdata, *params) + np.random.normal(0, 0.2, size=length)\n",
    "    return xdata, ydata\n",
    "\n",
    "# Test different data sizes\n",
    "lengths = np.linspace(10**3, 10**6, 20, dtype=int)\n",
    "\n",
    "jcf = CurveFit()\n",
    "nlsq_fit_times_varying = []\n",
    "\n",
    "for length in lengths:\n",
    "    xdata, ydata = get_random_data(length)\n",
    "    start_time = time.time()\n",
    "    popt, pcov = jcf.curve_fit(linear, xdata, ydata, p0=(1, 1))\n",
    "    nlsq_fit_times_varying.append(time.time() - start_time)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(lengths, nlsq_fit_times_varying, 'o-', linewidth=2, label='Without fixed size')\n",
    "plt.xlabel('Data Length')\n",
    "plt.ylabel('Fit Time (seconds)')\n",
    "plt.title('Varying Data Size: Recompilation at Each Size')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total time with recompilation: {np.sum(nlsq_fit_times_varying):.2f}s\")\n",
    "print(\"\\n‚ö†Ô∏è Notice: Every fit is slow because JAX recompiles for each new array size!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a92731f",
   "metadata": {},
   "source": [
    "### Solution: Fixed Array Size\n",
    "\n",
    "NLSQ can use a fixed array size to avoid recompilation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589175c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:56:33.769288Z",
     "iopub.status.busy": "2026-01-06T16:56:33.769101Z",
     "iopub.status.idle": "2026-01-06T16:56:41.421282Z",
     "shell.execute_reply": "2026-01-06T16:56:41.420713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use fixed array size to avoid recompilation\n",
    "fixed_length = np.max(lengths)\n",
    "jcf_fixed = CurveFit(flength=fixed_length)\n",
    "\n",
    "nlsq_fit_times_fixed = []\n",
    "for length in lengths:\n",
    "    xdata, ydata = get_random_data(length)\n",
    "    start_time = time.time()\n",
    "    popt, pcov = jcf_fixed.curve_fit(linear, xdata, ydata, p0=(1, 1))\n",
    "    nlsq_fit_times_fixed.append(time.time() - start_time)\n",
    "\n",
    "# Compare\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(lengths, nlsq_fit_times_varying, 'o-', linewidth=2, label='Without fixed size (recompiles)')\n",
    "plt.plot(lengths, nlsq_fit_times_fixed, 's-', linewidth=2, label='With fixed size (no recompile)')\n",
    "plt.xlabel('Data Length')\n",
    "plt.ylabel('Fit Time (seconds)')\n",
    "plt.title('Fixed Array Size Eliminates Recompilation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total time without fixed size: {np.sum(nlsq_fit_times_varying):.2f}s\")\n",
    "print(f\"Total time with fixed size:    {np.sum(nlsq_fit_times_fixed):.2f}s\")\n",
    "print(f\"\\nSpeedup: {np.sum(nlsq_fit_times_varying) / np.sum(nlsq_fit_times_fixed):.1f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277f46d",
   "metadata": {},
   "source": [
    "‚úì **Success!** By setting `flength=fixed_length`, we avoid recompilation and get consistently fast fits!\n",
    "\n",
    "üí° **Best Practice:** If you have varying data sizes, use `CurveFit(flength=max_expected_length)`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226338b4",
   "metadata": {},
   "source": [
    "## 5. Fitting Multiple Functions\n",
    "\n",
    "**Important:** Use separate `CurveFit` objects for different functions to avoid recompilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb100567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:56:41.423679Z",
     "iopub.status.busy": "2026-01-06T16:56:41.423519Z",
     "iopub.status.idle": "2026-01-06T16:56:47.573548Z",
     "shell.execute_reply": "2026-01-06T16:56:47.572736Z"
    }
   },
   "outputs": [],
   "source": [
    "def quad_exp(x, a, b, c, d):\n",
    "    \"\"\"Quadratic + exponential function\"\"\"\n",
    "    return a * x**2 + b * x + c + jnp.exp(d)\n",
    "\n",
    "# BAD: Using same CurveFit object for different functions\n",
    "length = 300000\n",
    "x = np.linspace(0, 10, length)\n",
    "jcf_shared = CurveFit()\n",
    "\n",
    "n_runs = 5 if QUICK else 21\n",
    "linear_params = np.random.random((n_runs, 2))\n",
    "quad_params = np.random.random((n_runs, 4))\n",
    "\n",
    "linear_times_bad = []\n",
    "quad_times_bad = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    y_lin = linear(x, *linear_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "    y_quad = quad_exp(x, *quad_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    start = time.time()\n",
    "    jcf_shared.curve_fit(linear, x, y_lin, p0=(0.5, 0.5))\n",
    "    linear_times_bad.append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    jcf_shared.curve_fit(quad_exp, x, y_quad, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    quad_times_bad.append(time.time() - start)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(linear_times_bad, 'o-', label='Linear (shared object)')\n",
    "plt.plot(quad_times_bad, 's-', label='Quad+Exp (shared object)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Fit Time (seconds)')\n",
    "plt.title('BAD: Sharing CurveFit Object: Constant Recompilation')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total time (shared object): {np.sum(linear_times_bad + quad_times_bad):.2f}s\")\n",
    "print(\"\\n‚ö†Ô∏è Every fit recompiles because we're alternating between functions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87981638",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:56:47.575511Z",
     "iopub.status.busy": "2026-01-06T16:56:47.575390Z",
     "iopub.status.idle": "2026-01-06T16:56:51.377844Z",
     "shell.execute_reply": "2026-01-06T16:56:51.376727Z"
    }
   },
   "outputs": [],
   "source": [
    "# GOOD: Separate CurveFit objects for each function\n",
    "jcf_linear = CurveFit()\n",
    "jcf_quad = CurveFit()\n",
    "\n",
    "linear_times_good = []\n",
    "quad_times_good = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    y_lin = linear(x, *linear_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "    y_quad = quad_exp(x, *quad_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    start = time.time()\n",
    "    jcf_linear.curve_fit(linear, x, y_lin, p0=(0.5, 0.5))\n",
    "    linear_times_good.append(time.time() - start)\n",
    "\n",
    "    start = time.time()\n",
    "    jcf_quad.curve_fit(quad_exp, x, y_quad, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    quad_times_good.append(time.time() - start)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.plot(linear_times_good, 'o-', label='Linear (dedicated object)')\n",
    "plt.plot(quad_times_good, 's-', label='Quad+Exp (dedicated object)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Fit Time (seconds)')\n",
    "plt.title('GOOD: Separate CurveFit Objects: Compile Once, Run Fast')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total time (shared object):   {np.sum(linear_times_bad + quad_times_bad):.2f}s\")\n",
    "print(f\"Total time (separate objects): {np.sum(linear_times_good + quad_times_good):.2f}s\")\n",
    "print(f\"\\nSpeedup: {np.sum(linear_times_bad + quad_times_bad) / np.sum(linear_times_good + quad_times_good):.1f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e8fe7",
   "metadata": {},
   "source": [
    "üí° **Best Practice:** Create one `CurveFit()` object per unique function you're fitting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc83eff",
   "metadata": {},
   "source": [
    "## 6. NLSQ vs SciPy: Speed Comparison\n",
    "\n",
    "Let's compare NLSQ's performance against SciPy's `curve_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09875da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:56:51.380295Z",
     "iopub.status.busy": "2026-01-06T16:56:51.380043Z",
     "iopub.status.idle": "2026-01-06T16:56:54.860841Z",
     "shell.execute_reply": "2026-01-06T16:56:54.860081Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from scipy.optimize import OptimizeWarning\n",
    "\n",
    "\n",
    "def quad_exp_numpy(x, a, b, c, d):\n",
    "    \"\"\"NumPy version for SciPy (with overflow protection)\"\"\"\n",
    "    d_clipped = np.clip(d, -700, 700)\n",
    "    return a * x**2 + b * x + c + np.exp(d_clipped)\n",
    "\n",
    "length = 300000\n",
    "x = np.linspace(0, 10, length)\n",
    "\n",
    "jcf = CurveFit()\n",
    "all_params = np.random.random((n_runs, 4))\n",
    "\n",
    "nlsq_times = []\n",
    "scipy_times = []\n",
    "\n",
    "# Suppress SciPy covariance warnings (not relevant for performance comparison)\n",
    "warnings.filterwarnings(\"ignore\", category=OptimizeWarning)\n",
    "\n",
    "for i in range(n_runs):\n",
    "    y = quad_exp(x, *all_params[i]) + np.random.normal(0, 0.2, size=length)\n",
    "\n",
    "    # NLSQ\n",
    "    start = time.time()\n",
    "    popt_nlsq, _ = jcf.curve_fit(quad_exp, x, y, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    nlsq_times.append(time.time() - start)\n",
    "\n",
    "    # SciPy\n",
    "    start = time.time()\n",
    "    popt_scipy, _ = curve_fit(quad_exp_numpy, x, y, p0=(0.5, 0.5, 0.5, 0.5))\n",
    "    scipy_times.append(time.time() - start)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(nlsq_times, 'go-', label='NLSQ', linewidth=2, markersize=8)\n",
    "plt.plot(scipy_times, 'bs-', label='SciPy', linewidth=2, markersize=8)\n",
    "plt.axhline(np.mean(nlsq_times[1:]), color='g', linestyle='--', alpha=0.7,\n",
    "           label=f'NLSQ avg (after compile): {np.mean(nlsq_times[1:]):.4f}s')\n",
    "plt.axhline(np.mean(scipy_times), color='b', linestyle='--', alpha=0.7,\n",
    "           label=f'SciPy avg: {np.mean(scipy_times):.4f}s')\n",
    "plt.xlabel('Fit Iteration')\n",
    "plt.ylabel('Fit Time (seconds)')\n",
    "plt.title('NLSQ vs SciPy: 300K Points, 4 Parameters')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Performance Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"NLSQ first fit (with compilation): {nlsq_times[0]:.4f}s\")\n",
    "print(f\"NLSQ average (after compilation):  {np.mean(nlsq_times[1:]):.4f}s\")\n",
    "print(f\"SciPy average:                      {np.mean(scipy_times):.4f}s\")\n",
    "print(f\"\\nSpeedup: {np.mean(scipy_times) / np.mean(nlsq_times[1:]):.1f}x faster than SciPy!\")\n",
    "print(\"\\nüí° By avoiding recompilation and using GPU/JAX, NLSQ achieves massive speedups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f151b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì What You've Learned\n",
    "\n",
    "Congratulations! You've just:\n",
    "\n",
    "1. ‚úì **Fit your first curve** with NLSQ in just a few lines of code\n",
    "2. ‚úì **Understood JAX compilation** - first fit compiles, then runs super fast\n",
    "3. ‚úì **Learned memory management** - estimate requirements and configure limits\n",
    "4. ‚úì **Avoided recompilation** - use fixed array sizes and separate CurveFit objects\n",
    "5. ‚úì **Saw 100x+ speedups** vs SciPy on large datasets\n",
    "\n",
    "**Key takeaways:**\n",
    "- First fit is slow (compilation), subsequent fits are very fast\n",
    "- Use `CurveFit(flength=max_size)` for varying data sizes\n",
    "- Create one `CurveFit()` per unique function\n",
    "- NLSQ is 10-300x faster than SciPy, especially with GPU\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c9ea6",
   "metadata": {},
   "source": [
    "## ‚ùì Common First-Time Questions\n",
    "\n",
    "**Q: Why was my first fit so slow?**  \n",
    "A: JAX compiles functions on first use (JIT compilation). Subsequent fits reuse the compiled code and run 100-300x faster! This is normal and expected.\n",
    "\n",
    "**Q: Do I need a GPU to use NLSQ?**  \n",
    "A: No! NLSQ works great on CPU. GPU gives extra speedup for large datasets (millions of points), but isn't required.\n",
    "\n",
    "**Q: How is this different from SciPy's curve_fit?**  \n",
    "A: Same API and algorithms, but NLSQ uses JAX for:\n",
    "- Automatic differentiation (no manual Jacobians!)\n",
    "- JIT compilation for speed\n",
    "- GPU acceleration\n",
    "- Result: 10-300x faster on large datasets\n",
    "\n",
    "**Q: My fitted parameters are slightly different from true values. Is that okay?**  \n",
    "A: Yes! Small differences are normal with noisy data. If your parameters are within 10-20% of true values with the noise we added, that's excellent!\n",
    "\n",
    "**Q: Can I use NLSQ with my own custom functions?**  \n",
    "A: Absolutely! Just define your function using `jax.numpy` instead of `numpy` (or use regular `numpy` for simple functions). NLSQ handles the rest.\n",
    "\n",
    "**Q: What if I get errors about array sizes?**  \n",
    "A: Use `CurveFit(flength=max_expected_size)` to set a fixed array size. This avoids recompilation when data sizes vary.\n",
    "\n",
    "üí¨ More questions? Check the [FAQ](../../docs/faq.md) or [ask the community](https://github.com/imewei/NLSQ/discussions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4624542",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è What's Next?\n",
    "\n",
    "**Ready to learn more?**\n",
    "\n",
    "**Recommended next steps:**\n",
    "1. **[Interactive Tutorial](nlsq_interactive_tutorial.ipynb)** (30 min) - Hands-on practice with exercises\n",
    "2. **[Function Library Demo](../05_feature_demos/function_library_demo.ipynb)** (20 min) - Pre-built models (exponential, Gaussian, etc.)\n",
    "3. **[Domain Gallery](../04_gallery/README.md)** - See examples from your field\n",
    "\n",
    "**Got a specific need?**\n",
    "- **Large dataset (>1M points)?** ‚Üí [Large Dataset Demo](../02_core_tutorials/large_dataset_demo.ipynb)\n",
    "- **Want GPU acceleration?** ‚Üí [Performance Optimization](../02_core_tutorials/performance_optimization_demo.ipynb)\n",
    "- **Need 2D fitting (images)?** ‚Üí [2D Gaussian Demo](../02_core_tutorials/nlsq_2d_gaussian_demo.ipynb)\n",
    "- **Custom algorithms?** ‚Üí [Custom Algorithms](../03_advanced/custom_algorithms_advanced.ipynb)\n",
    "\n",
    "**Browse by field:**\n",
    "- üß¨ [Biology Examples](../04_gallery/biology/) - Dose-response, enzyme kinetics, growth curves\n",
    "- ‚öóÔ∏è [Chemistry Examples](../04_gallery/chemistry/) - Reaction kinetics, titrations\n",
    "- ‚öõÔ∏è [Physics Examples](../04_gallery/physics/) - Oscillations, decay, spectroscopy\n",
    "- üîß [Engineering Examples](../04_gallery/engineering/) - Calibration, materials, system ID\n",
    "\n",
    "**Not sure where to go?** Check the [Learning Map](../00_learning_map.ipynb) for guided paths!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e89e2",
   "metadata": {},
   "source": [
    "## üîó Additional Resources\n",
    "\n",
    "**Documentation:**\n",
    "- [Complete API Documentation](https://nlsq.readthedocs.io/)\n",
    "- [Installation Guide](../../README.md#installation)\n",
    "- [Troubleshooting Guide](../03_advanced/troubleshooting_guide.ipynb)\n",
    "- [FAQ](../../docs/faq.md)\n",
    "- [Glossary](../../docs/glossary.md)\n",
    "\n",
    "**Community:**\n",
    "- üí¨ [GitHub Discussions](https://github.com/imewei/NLSQ/discussions) - Ask questions\n",
    "- üêõ [GitHub Issues](https://github.com/imewei/NLSQ/issues) - Report bugs\n",
    "- üìú [Python Script Version](../../scripts/01_getting_started/nlsq_quickstart.py)\n",
    "\n",
    "**Research:**\n",
    "- [JAXFit Paper (arXiv)](https://doi.org/10.48550/arXiv.2208.12187) - Original research\n",
    "- [Citing NLSQ](../../README.md#citing-nlsq)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c709ff4c",
   "metadata": {},
   "source": [
    "## üìö Glossary\n",
    "\n",
    "**Curve fitting:** Finding the parameters of a mathematical function that best match observed data\n",
    "\n",
    "**JIT compilation (Just-In-Time):** Converting Python code to optimized machine code at runtime. First run is slower (compilation), subsequent runs are very fast.\n",
    "\n",
    "**JAX:** Google's library for high-performance numerical computing with automatic differentiation and GPU support\n",
    "\n",
    "**Automatic differentiation:** Computing derivatives automatically without manual calculation or numerical approximation\n",
    "\n",
    "**Parameters:** The values in your model function that you're trying to find (e.g., m and b in y = mx + b)\n",
    "\n",
    "**Initial guess (p0):** Starting values for parameters. NLSQ iteratively improves these to find the best fit.\n",
    "\n",
    "**Covariance matrix (pcov):** Describes uncertainty in fitted parameters and correlations between them\n",
    "\n",
    "**GPU:** Graphics Processing Unit - specialized hardware that can perform many calculations in parallel, great for large datasets\n",
    "\n",
    "[See complete glossary](../../docs/glossary.md)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Congratulations!\n",
    "\n",
    "You've completed the NLSQ Quickstart! You now have the foundation to:\n",
    "- Fit curves to your experimental data\n",
    "- Optimize NLSQ performance\n",
    "- Understand JAX compilation benefits\n",
    "- Choose the right next tutorial for your needs\n",
    "\n",
    "**Happy fitting!** üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLSQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
