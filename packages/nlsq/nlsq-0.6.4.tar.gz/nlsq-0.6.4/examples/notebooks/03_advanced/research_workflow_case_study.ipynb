{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa24910c",
   "metadata": {},
   "source": [
    "# Research Workflow Case Study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d6b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-06T16:59:27.302094Z",
     "iopub.status.busy": "2026-01-06T16:59:27.301482Z",
     "iopub.status.idle": "2026-01-06T16:59:28.363812Z",
     "shell.execute_reply": "2026-01-06T16:59:28.362920Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converted from research_workflow_case_study.ipynb\n",
    "\n",
    "This script was automatically generated from a Jupyter notebook.\n",
    "Plots are saved to the figures/ directory instead of displayed inline.\n",
    "\"\"\"\n",
    "\n",
    "# ======================================================================\n",
    "# # Research Workflow Case Study: Raman Spectroscopy Peak Analysis\n",
    "#\n",
    "# **Level**: Advanced\n",
    "# **Time**: 40-50 minutes\n",
    "# **Prerequisites**: NLSQ Quickstart, Advanced Features Demo\n",
    "#\n",
    "# ## Overview\n",
    "#\n",
    "# This tutorial demonstrates a **complete research workflow** from raw experimental data to publication-ready results. We analyze Raman spectroscopy data from graphene oxide characterization, following best practices for scientific curve fitting.\n",
    "#\n",
    "# ### What You'll Learn\n",
    "#\n",
    "# 1. **Data Preprocessing**: Baseline subtraction, noise filtering, quality checks\n",
    "# 2. **Multi-Peak Fitting**: Lorentzian/Voigt profiles for overlapping peaks\n",
    "# 3. **Uncertainty Quantification**: Confidence intervals, error propagation, bootstrap resampling\n",
    "# 4. **Publication Plots**: High-quality matplotlib figures with proper styling\n",
    "# 5. **Statistical Analysis**: Goodness-of-fit metrics, residual analysis\n",
    "# 6. **Results Reporting**: Tables, uncertainties, physical interpretation\n",
    "#\n",
    "# ### Scientific Context\n",
    "#\n",
    "# Raman spectroscopy is widely used to characterize carbon materials. Graphene oxide exhibits two characteristic peaks:\n",
    "# - **D-band** (~1350 cm⁻¹): Disorder-induced peak\n",
    "# - **G-band** (~1580 cm⁻¹): Graphitic carbon peak\n",
    "#\n",
    "# The D/G intensity ratio quantifies the degree of disorder, crucial for materials characterization.\n",
    "#\n",
    "# ### Reference\n",
    "#\n",
    "# Based on methodology from: Ferrari & Robertson, *Phys. Rev. B* **61**, 14095 (2000)\n",
    "# ======================================================================\n",
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from nlsq import CurveFit, __version__\n",
    "\n",
    "QUICK = os.environ.get(\"NLSQ_EXAMPLES_QUICK\") == \"1\"\n",
    "if QUICK:\n",
    "    print(\n",
    "        \"Quick mode: skipping full research workflow demo \"\n",
    "        \"(unset NLSQ_EXAMPLES_QUICK for full run).\"\n",
    "    )\n",
    "\n",
    "def _run_full_demo():\n",
    "\n",
    "    # Publication-quality matplotlib settings\n",
    "    rcParams[\"figure.figsize\"] = (10, 6)\n",
    "    rcParams[\"font.size\"] = 11\n",
    "    rcParams[\"axes.labelsize\"] = 12\n",
    "    rcParams[\"axes.titlesize\"] = 13\n",
    "    rcParams[\"xtick.labelsize\"] = 10\n",
    "    rcParams[\"ytick.labelsize\"] = 10\n",
    "    rcParams[\"legend.fontsize\"] = 10\n",
    "    rcParams[\"lines.linewidth\"] = 1.5\n",
    "    rcParams[\"axes.grid\"] = True\n",
    "    rcParams[\"grid.alpha\"] = 0.3\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    print(\"✓ Imports successful\")\n",
    "    print(f\"  NLSQ version: {__version__}\")\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # ## Part 1: Data Generation and Preprocessing\n",
    "    #\n",
    "    # We'll simulate realistic Raman spectroscopy data with noise, then apply standard preprocessing steps.\n",
    "    # ======================================================================\n",
    "\n",
    "\n",
    "    # Generate synthetic Raman spectroscopy data\n",
    "\n",
    "    # Experimental parameters (realistic values)\n",
    "    wavenumber = np.linspace(1000, 2000, 500)  # Raman shift in cm^-1\n",
    "\n",
    "    # True parameters for two Lorentzian peaks\n",
    "    # D-band: position, amplitude, width (FWHM)\n",
    "    d_band_true = {\"pos\": 1350.0, \"amp\": 800.0, \"width\": 50.0}\n",
    "\n",
    "    # G-band: position, amplitude, width\n",
    "    g_band_true = {\"pos\": 1580.0, \"amp\": 1200.0, \"width\": 40.0}\n",
    "\n",
    "    # Baseline (polynomial background)\n",
    "    baseline_true = 100.0 + 0.05 * wavenumber\n",
    "\n",
    "\n",
    "    def lorentzian(x, pos, amp, width):\n",
    "        \"\"\"Lorentzian (Cauchy) peak profile.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Independent variable (wavenumber)\n",
    "        pos : float\n",
    "            Peak position (center)\n",
    "        amp : float\n",
    "            Peak amplitude (height)\n",
    "        width : float\n",
    "            Full width at half maximum (FWHM)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array_like\n",
    "            Lorentzian profile\n",
    "        \"\"\"\n",
    "        gamma = width / 2.0  # Half-width at half-maximum\n",
    "        return amp * (gamma**2) / ((x - pos) ** 2 + gamma**2)\n",
    "\n",
    "\n",
    "    # Generate clean signal\n",
    "    d_band_signal = lorentzian(\n",
    "        wavenumber, d_band_true[\"pos\"], d_band_true[\"amp\"], d_band_true[\"width\"]\n",
    "    )\n",
    "    g_band_signal = lorentzian(\n",
    "        wavenumber, g_band_true[\"pos\"], g_band_true[\"amp\"], g_band_true[\"width\"]\n",
    "    )\n",
    "    clean_signal = d_band_signal + g_band_signal + baseline_true\n",
    "\n",
    "    # Add realistic noise (Poisson + Gaussian)\n",
    "    np.random.seed(42)  # Reproducibility\n",
    "    noise_level = 30.0\n",
    "    noise = np.random.normal(0, noise_level, len(wavenumber))\n",
    "    intensity_measured = clean_signal + noise\n",
    "\n",
    "    # Simulate uncertainty (shot noise scales with sqrt(signal))\n",
    "    sigma_measured = np.sqrt(np.abs(intensity_measured)) + noise_level / 10\n",
    "\n",
    "    print(f\"✓ Generated {len(wavenumber)} data points\")\n",
    "    print(f\"  Wavenumber range: {wavenumber.min():.0f} - {wavenumber.max():.0f} cm⁻¹\")\n",
    "    print(f\"  Signal-to-noise ratio: {clean_signal.max() / noise_level:.1f}\")\n",
    "    print(f\"  True D/G ratio: {d_band_true['amp'] / g_band_true['amp']:.3f}\")\n",
    "\n",
    "\n",
    "    # Preprocessing: baseline subtraction and quality checks\n",
    "\n",
    "    # Simple linear baseline estimation from edge regions\n",
    "    edge_points = 50\n",
    "    left_baseline = np.mean(intensity_measured[:edge_points])\n",
    "    right_baseline = np.mean(intensity_measured[-edge_points:])\n",
    "    estimated_baseline = np.linspace(left_baseline, right_baseline, len(wavenumber))\n",
    "\n",
    "    # Subtract baseline\n",
    "    intensity_corrected = intensity_measured - estimated_baseline\n",
    "\n",
    "    # Quality checks\n",
    "    print(\"Data Quality Checks:\")\n",
    "    print(f\"  Max intensity: {intensity_corrected.max():.1f} counts\")\n",
    "    print(f\"  Min intensity: {intensity_corrected.min():.1f} counts\")\n",
    "    print(\n",
    "        f\"  Negative points: {np.sum(intensity_corrected < 0)} / {len(intensity_corrected)}\"\n",
    "    )\n",
    "\n",
    "    # Clip small negative values (common in baseline-corrected spectra)\n",
    "    intensity_corrected = np.maximum(intensity_corrected, 1.0)\n",
    "\n",
    "    print(\"\\n✓ Baseline correction applied\")\n",
    "\n",
    "\n",
    "    # Visualize raw and preprocessed data\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    # Raw data\n",
    "    ax1.plot(wavenumber, intensity_measured, \"o\", ms=2, alpha=0.5, label=\"Raw data\")\n",
    "    ax1.plot(wavenumber, estimated_baseline, \"r--\", lw=2, label=\"Estimated baseline\")\n",
    "    ax1.set_xlabel(\"Raman Shift (cm⁻¹)\")\n",
    "    ax1.set_ylabel(\"Intensity (counts)\")\n",
    "    ax1.set_title(\"(a) Raw Raman Spectrum\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Baseline-corrected data\n",
    "    ax2.plot(wavenumber, intensity_corrected, \"o\", ms=2, alpha=0.5, label=\"Corrected data\")\n",
    "    ax2.axhline(0, color=\"k\", ls=\":\", lw=1)\n",
    "    ax2.set_xlabel(\"Raman Shift (cm⁻¹)\")\n",
    "    ax2.set_ylabel(\"Intensity (counts)\")\n",
    "    ax2.set_title(\"(b) Baseline-Corrected Spectrum\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Save figure to file\n",
    "    fig_dir = Path.cwd() / \"figures\" / \"research_workflow_case_study\"\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(fig_dir / \"fig_01.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"✓ Data preprocessing complete\")\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # ## Part 2: Multi-Peak Fitting with NLSQ\n",
    "    #\n",
    "    # Fit the D and G bands simultaneously using a two-Lorentzian model.\n",
    "    # ======================================================================\n",
    "\n",
    "\n",
    "    # Define multi-peak model for fitting\n",
    "\n",
    "\n",
    "    def lorentzian_jax(x, pos, amp, width):\n",
    "        \"\"\"JAX-compatible Lorentzian profile.\"\"\"\n",
    "        gamma = width / 2.0\n",
    "        return amp * (gamma**2) / ((x - pos) ** 2 + gamma**2)\n",
    "\n",
    "\n",
    "    def two_peak_model(x, d_pos, d_amp, d_width, g_pos, g_amp, g_width):\n",
    "        \"\"\"Model for two overlapping Lorentzian peaks.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Wavenumber values\n",
    "        d_pos, d_amp, d_width : float\n",
    "            D-band position, amplitude, and FWHM\n",
    "        g_pos, g_amp, g_width : float\n",
    "            G-band position, amplitude, and FWHM\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array_like\n",
    "            Combined spectrum\n",
    "        \"\"\"\n",
    "        d_band = lorentzian_jax(x, d_pos, d_amp, d_width)\n",
    "        g_band = lorentzian_jax(x, g_pos, g_amp, g_width)\n",
    "        return d_band + g_band\n",
    "\n",
    "\n",
    "    print(\"✓ Model defined: 6 parameters (2 peaks × 3 parameters)\")\n",
    "\n",
    "\n",
    "    # Perform curve fitting with NLSQ\n",
    "\n",
    "    # Initial parameter guess (from visual inspection)\n",
    "    p0 = [\n",
    "        1340.0,\n",
    "        750.0,\n",
    "        60.0,  # D-band: pos, amp, width\n",
    "        1590.0,\n",
    "        1100.0,\n",
    "        50.0,  # G-band: pos, amp, width\n",
    "    ]\n",
    "\n",
    "    # Parameter bounds (physical constraints)\n",
    "    bounds = (\n",
    "        [1300, 100, 20, 1550, 100, 20],  # Lower bounds\n",
    "        [1400, 2000, 100, 1650, 2000, 100],  # Upper bounds\n",
    "    )\n",
    "\n",
    "    # Create CurveFit instance with diagnostic output\n",
    "    cf = CurveFit()\n",
    "\n",
    "    # Fit with uncertainty estimation\n",
    "    x_fit = jnp.array(wavenumber)\n",
    "    y_fit = jnp.array(intensity_corrected)\n",
    "    sigma_fit = np.array(sigma_measured)  # sigma must be numpy array\n",
    "\n",
    "    popt, pcov = cf.curve_fit(\n",
    "        two_peak_model,\n",
    "        x_fit,\n",
    "        y_fit,\n",
    "        p0=p0,\n",
    "        sigma=sigma_fit,\n",
    "        bounds=bounds,\n",
    "        absolute_sigma=True,\n",
    "        full_output=False,\n",
    "    )\n",
    "\n",
    "    # Extract fitted parameters\n",
    "    d_pos_fit, d_amp_fit, d_width_fit = popt[0], popt[1], popt[2]\n",
    "    g_pos_fit, g_amp_fit, g_width_fit = popt[3], popt[4], popt[5]\n",
    "\n",
    "    # Calculate uncertainties (1-sigma)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    d_pos_err, d_amp_err, d_width_err = perr[0], perr[1], perr[2]\n",
    "    g_pos_err, g_amp_err, g_width_err = perr[3], perr[4], perr[5]\n",
    "\n",
    "    print(\"✓ Fitting complete\\n\")\n",
    "    print(\"Fitted Parameters:\")\n",
    "    print(\"D-band (Disorder):\")\n",
    "    print(f\"  Position: {d_pos_fit:.1f} ± {d_pos_err:.1f} cm⁻¹\")\n",
    "    print(f\"  Amplitude: {d_amp_fit:.1f} ± {d_amp_err:.1f} counts\")\n",
    "    print(f\"  FWHM: {d_width_fit:.1f} ± {d_width_err:.1f} cm⁻¹\")\n",
    "    print(\"\\nG-band (Graphitic):\")\n",
    "    print(f\"  Position: {g_pos_fit:.1f} ± {g_pos_err:.1f} cm⁻¹\")\n",
    "    print(f\"  Amplitude: {g_amp_fit:.1f} ± {g_amp_err:.1f} counts\")\n",
    "    print(f\"  FWHM: {g_width_fit:.1f} ± {g_width_err:.1f} cm⁻¹\")\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # ## Part 3: Uncertainty Quantification and Error Propagation\n",
    "    #\n",
    "    # Calculate derived quantities (D/G ratio) with proper error propagation.\n",
    "    # ======================================================================\n",
    "\n",
    "\n",
    "    # Error propagation for D/G intensity ratio\n",
    "\n",
    "    # D/G ratio (disorder quantification)\n",
    "    dg_ratio = d_amp_fit / g_amp_fit\n",
    "\n",
    "    # Error propagation using partial derivatives\n",
    "    # For R = D/G, δR = R * sqrt((δD/D)^2 + (δG/G)^2)\n",
    "    dg_ratio_err = dg_ratio * np.sqrt(\n",
    "        (d_amp_err / d_amp_fit) ** 2 + (g_amp_err / g_amp_fit) ** 2\n",
    "    )\n",
    "\n",
    "    print(\"Derived Quantity:\")\n",
    "    print(f\"  D/G Intensity Ratio: {dg_ratio:.3f} ± {dg_ratio_err:.3f}\")\n",
    "    print(f\"  True D/G ratio: {d_band_true['amp'] / g_band_true['amp']:.3f}\")\n",
    "    print(\n",
    "        f\"  Relative error: {abs(dg_ratio - d_band_true['amp'] / g_band_true['amp']) / (d_band_true['amp'] / g_band_true['amp']) * 100:.1f}%\"\n",
    "    )\n",
    "\n",
    "    # Physical interpretation\n",
    "    print(\"\\nPhysical Interpretation:\")\n",
    "    if dg_ratio < 0.5:\n",
    "        print(\"  → Low disorder: High-quality graphene\")\n",
    "    elif dg_ratio < 1.0:\n",
    "        print(\"  → Moderate disorder: Partially reduced graphene oxide\")\n",
    "    else:\n",
    "        print(\"  → High disorder: Heavily oxidized material\")\n",
    "\n",
    "\n",
    "    # Bootstrap resampling for robust uncertainty estimation\n",
    "\n",
    "    n_bootstrap = 100  # Number of bootstrap samples\n",
    "    bootstrap_ratios = []\n",
    "\n",
    "    np.random.seed(123)\n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample data with replacement\n",
    "        indices = np.random.choice(len(wavenumber), size=len(wavenumber), replace=True)\n",
    "        x_boot = x_fit[indices]\n",
    "        y_boot = y_fit[indices]\n",
    "        sigma_boot = np.array(sigma_fit[indices])  # sigma must be numpy array\n",
    "\n",
    "        try:\n",
    "            # Fit bootstrapped sample\n",
    "            popt_boot, _ = cf.curve_fit(\n",
    "                two_peak_model,\n",
    "                x_boot,\n",
    "                y_boot,\n",
    "                p0=p0,\n",
    "                sigma=sigma_boot,\n",
    "                bounds=bounds,\n",
    "                absolute_sigma=True,\n",
    "            )\n",
    "            # Calculate D/G ratio for this sample\n",
    "            ratio_boot = popt_boot[1] / popt_boot[4]\n",
    "            bootstrap_ratios.append(ratio_boot)\n",
    "        except Exception:\n",
    "            continue  # Skip failed fits\n",
    "\n",
    "    bootstrap_ratios = np.array(bootstrap_ratios)\n",
    "\n",
    "    # Bootstrap statistics\n",
    "    dg_ratio_boot_mean = np.mean(bootstrap_ratios)\n",
    "    dg_ratio_boot_std = np.std(bootstrap_ratios)\n",
    "    dg_ratio_boot_ci = np.percentile(bootstrap_ratios, [2.5, 97.5])  # 95% CI\n",
    "\n",
    "    print(f\"Bootstrap Results ({len(bootstrap_ratios)} successful samples):\")\n",
    "    print(f\"  Mean D/G ratio: {dg_ratio_boot_mean:.3f} ± {dg_ratio_boot_std:.3f}\")\n",
    "    print(\n",
    "        f\"  95% Confidence Interval: [{dg_ratio_boot_ci[0]:.3f}, {dg_ratio_boot_ci[1]:.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"\\n  Agreement with propagated error: {abs(dg_ratio_boot_std - dg_ratio_err) / dg_ratio_err * 100:.1f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # ## Part 4: Statistical Analysis and Goodness-of-Fit\n",
    "    # ======================================================================\n",
    "\n",
    "\n",
    "    # Calculate goodness-of-fit metrics\n",
    "\n",
    "    # Predicted values\n",
    "    y_pred = two_peak_model(x_fit, *popt)\n",
    "\n",
    "    # Residuals\n",
    "    residuals = y_fit - y_pred\n",
    "    weighted_residuals = residuals / sigma_fit\n",
    "\n",
    "    # Chi-squared statistic\n",
    "    chi_squared = np.sum(weighted_residuals**2)\n",
    "    n_data = len(y_fit)\n",
    "    n_params = len(popt)\n",
    "    dof = n_data - n_params  # Degrees of freedom\n",
    "    reduced_chi_squared = chi_squared / dof\n",
    "\n",
    "    # R-squared\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y_fit - np.mean(y_fit)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    # Root mean square error\n",
    "    rmse = np.sqrt(np.mean(residuals**2))\n",
    "\n",
    "    print(\"Goodness-of-Fit Statistics:\")\n",
    "    print(f\"  χ² = {chi_squared:.1f}\")\n",
    "    print(f\"  Reduced χ² = {reduced_chi_squared:.2f} (expect ~1.0 for good fit)\")\n",
    "    print(f\"  R² = {r_squared:.4f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f} counts\")\n",
    "    print(f\"  Degrees of freedom: {dof}\")\n",
    "\n",
    "    # Interpretation\n",
    "    if 0.8 < reduced_chi_squared < 1.2:\n",
    "        print(\"\\n  ✓ Excellent fit: Model captures data well\")\n",
    "    elif reduced_chi_squared > 1.5:\n",
    "        print(\"\\n  ⚠ Poor fit: Consider more complex model or check uncertainties\")\n",
    "    else:\n",
    "        print(\"\\n  ⚠ Overfit or underestimated uncertainties\")\n",
    "\n",
    "\n",
    "    # Residual analysis for model validation\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # Residual plot\n",
    "    ax1.axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "    ax1.fill_between(\n",
    "        wavenumber,\n",
    "        -3 * sigma_measured,\n",
    "        3 * sigma_measured,\n",
    "        alpha=0.2,\n",
    "        color=\"gray\",\n",
    "        label=\"±3σ expected\",\n",
    "    )\n",
    "    ax1.plot(wavenumber, residuals, \"o\", ms=3, alpha=0.6, label=\"Residuals\")\n",
    "    ax1.set_xlabel(\"Raman Shift (cm⁻¹)\")\n",
    "    ax1.set_ylabel(\"Residual (counts)\")\n",
    "    ax1.set_title(\"(a) Residual Plot\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Histogram of weighted residuals\n",
    "    ax2.hist(weighted_residuals, bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "    ax2.axvline(0, color=\"r\", ls=\"--\", lw=2, label=\"Mean\")\n",
    "\n",
    "    # Overlay normal distribution (expected for good fit)\n",
    "    x_norm = np.linspace(-4, 4, 100)\n",
    "    y_norm = (\n",
    "        len(weighted_residuals)\n",
    "        * (x_norm[1] - x_norm[0])\n",
    "        * (1 / np.sqrt(2 * np.pi))\n",
    "        * np.exp(-(x_norm**2) / 2)\n",
    "    )\n",
    "    ax2.plot(x_norm, y_norm, \"r-\", lw=2, label=\"N(0,1)\")\n",
    "\n",
    "    ax2.set_xlabel(\"Weighted Residual (σ)\")\n",
    "    ax2.set_ylabel(\"Frequency\")\n",
    "    ax2.set_title(\"(b) Residual Distribution\")\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Save figure to file\n",
    "    fig_dir = Path.cwd() / \"figures\" / \"research_workflow_case_study\"\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(fig_dir / \"fig_02.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"✓ Residual analysis complete\")\n",
    "    print(f\"  Residual mean: {np.mean(weighted_residuals):.3f} (expect 0 for unbiased fit)\")\n",
    "    print(\n",
    "        f\"  Residual std: {np.std(weighted_residuals):.3f} (expect 1 for correct uncertainties)\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # ## Part 5: Publication-Quality Visualization\n",
    "    # ======================================================================\n",
    "\n",
    "\n",
    "    # Create publication-ready figure with all components\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "    # Main plot: Data + fit + components\n",
    "    ax_main = fig.add_subplot(gs[0, :])\n",
    "\n",
    "    # Plot data with error bars (subsample for clarity)\n",
    "    step = 10\n",
    "    ax_main.errorbar(\n",
    "        wavenumber[::step],\n",
    "        intensity_corrected[::step],\n",
    "        yerr=sigma_measured[::step],\n",
    "        fmt=\"o\",\n",
    "        ms=4,\n",
    "        alpha=0.4,\n",
    "        elinewidth=1,\n",
    "        capsize=2,\n",
    "        label=\"Experimental data\",\n",
    "        color=\"steelblue\",\n",
    "    )\n",
    "\n",
    "    # Plot total fit\n",
    "    ax_main.plot(wavenumber, y_pred, \"r-\", lw=2.5, label=\"Total fit\", zorder=10, alpha=0.9)\n",
    "\n",
    "    # Plot individual components\n",
    "    d_component = lorentzian_jax(x_fit, d_pos_fit, d_amp_fit, d_width_fit)\n",
    "    g_component = lorentzian_jax(x_fit, g_pos_fit, g_amp_fit, g_width_fit)\n",
    "\n",
    "    ax_main.fill_between(\n",
    "        wavenumber, 0, d_component, alpha=0.3, color=\"orange\", label=\"D-band\"\n",
    "    )\n",
    "    ax_main.fill_between(\n",
    "        wavenumber, 0, g_component, alpha=0.3, color=\"green\", label=\"G-band\"\n",
    "    )\n",
    "\n",
    "    # Annotate peak positions\n",
    "    ax_main.annotate(\n",
    "        f\"D\\n{d_pos_fit:.0f} cm⁻¹\",\n",
    "        xy=(d_pos_fit, d_amp_fit),\n",
    "        xytext=(d_pos_fit - 100, d_amp_fit + 200),\n",
    "        arrowprops={\"arrowstyle\": \"->\", \"lw\": 1.5},\n",
    "        fontsize=11,\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    ax_main.annotate(\n",
    "        f\"G\\n{g_pos_fit:.0f} cm⁻¹\",\n",
    "        xy=(g_pos_fit, g_amp_fit),\n",
    "        xytext=(g_pos_fit + 100, g_amp_fit + 200),\n",
    "        arrowprops={\"arrowstyle\": \"->\", \"lw\": 1.5},\n",
    "        fontsize=11,\n",
    "        ha=\"center\",\n",
    "    )\n",
    "\n",
    "    ax_main.set_xlabel(\"Raman Shift (cm⁻¹)\", fontsize=12)\n",
    "    ax_main.set_ylabel(\"Intensity (counts)\", fontsize=12)\n",
    "    ax_main.set_title(\n",
    "        \"Raman Spectrum of Graphene Oxide: D and G Band Analysis\",\n",
    "        fontsize=14,\n",
    "        weight=\"bold\",\n",
    "    )\n",
    "    ax_main.legend(loc=\"upper right\", frameon=True, shadow=True)\n",
    "    ax_main.set_xlim(1000, 2000)\n",
    "\n",
    "    # Bottom left: Parameter table\n",
    "    ax_table = fig.add_subplot(gs[1, 0])\n",
    "    ax_table.axis(\"off\")\n",
    "\n",
    "    table_data = [\n",
    "        [\"Parameter\", \"D-band\", \"G-band\"],\n",
    "        [\n",
    "            \"Position (cm⁻¹)\",\n",
    "            f\"{d_pos_fit:.1f} ± {d_pos_err:.1f}\",\n",
    "            f\"{g_pos_fit:.1f} ± {g_pos_err:.1f}\",\n",
    "        ],\n",
    "        [\n",
    "            \"Amplitude\",\n",
    "            f\"{d_amp_fit:.0f} ± {d_amp_err:.0f}\",\n",
    "            f\"{g_amp_fit:.0f} ± {g_amp_err:.0f}\",\n",
    "        ],\n",
    "        [\n",
    "            \"FWHM (cm⁻¹)\",\n",
    "            f\"{d_width_fit:.1f} ± {d_width_err:.1f}\",\n",
    "            f\"{g_width_fit:.1f} ± {g_width_err:.1f}\",\n",
    "        ],\n",
    "        [\"\", \"\", \"\"],\n",
    "        [\"D/G Ratio\", f\"{dg_ratio:.3f} ± {dg_ratio_err:.3f}\", \"\"],\n",
    "        [\"χ²ᵣ\", f\"{reduced_chi_squared:.2f}\", \"\"],\n",
    "        [\"R²\", f\"{r_squared:.4f}\", \"\"],\n",
    "    ]\n",
    "\n",
    "    table = ax_table.table(\n",
    "        cellText=table_data,\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        bbox=[0, 0, 1, 1],\n",
    "        colWidths=[0.4, 0.3, 0.3],\n",
    "    )\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 2)\n",
    "\n",
    "    # Style header row\n",
    "    for i in range(3):\n",
    "        table[(0, i)].set_facecolor(\"#4CAF50\")\n",
    "        table[(0, i)].set_text_props(weight=\"bold\", color=\"white\")\n",
    "\n",
    "    # Bottom right: Bootstrap distribution\n",
    "    ax_boot = fig.add_subplot(gs[1, 1])\n",
    "    ax_boot.hist(bootstrap_ratios, bins=20, alpha=0.7, edgecolor=\"black\", color=\"steelblue\")\n",
    "    ax_boot.axvline(dg_ratio, color=\"r\", ls=\"--\", lw=2, label=f\"Fitted: {dg_ratio:.3f}\")\n",
    "    ax_boot.axvline(dg_ratio_boot_ci[0], color=\"orange\", ls=\":\", lw=1.5, label=\"95% CI\")\n",
    "    ax_boot.axvline(dg_ratio_boot_ci[1], color=\"orange\", ls=\":\", lw=1.5)\n",
    "    ax_boot.set_xlabel(\"D/G Intensity Ratio\")\n",
    "    ax_boot.set_ylabel(\"Frequency\")\n",
    "    ax_boot.set_title(\"Bootstrap Distribution\")\n",
    "    ax_boot.legend()\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Figure 1: Complete Raman Spectroscopy Analysis\",\n",
    "        fontsize=15,\n",
    "        weight=\"bold\",\n",
    "        y=0.98,\n",
    "    )\n",
    "\n",
    "    # Save figure (uncomment to save)\n",
    "    # plt.savefig('raman_analysis_figure1.png', dpi=300, bbox_inches='tight')\n",
    "    # plt.savefig('raman_analysis_figure1.pdf', bbox_inches='tight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Save figure to file\n",
    "    fig_dir = Path.cwd() / \"figures\" / \"research_workflow_case_study\"\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(fig_dir / \"fig_03.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"✓ Publication figure generated\")\n",
    "    print(\"  Recommendation: Save as PDF for LaTeX, PNG (300 dpi) for presentations\")\n",
    "\n",
    "\n",
    "    # ======================================================================\n",
    "    # ## Summary and Best Practices\n",
    "    #\n",
    "    # ### Complete Research Workflow\n",
    "    #\n",
    "    # 1. **Data Preprocessing**\n",
    "    #    - Baseline correction (polynomial, edge-fitting, or automated)\n",
    "    #    - Noise filtering (optional: Savitzky-Golay)\n",
    "    #    - Quality checks (range, negative values, outliers)\n",
    "    #\n",
    "    # 2. **Model Selection**\n",
    "    #    - Choose appropriate peak shapes (Lorentzian, Gaussian, Voigt)\n",
    "    #    - Consider physical constraints (bounds)\n",
    "    #    - Start with simple models, add complexity if needed\n",
    "    #\n",
    "    # 3. **Fitting Strategy**\n",
    "    #    - Good initial guesses (visual inspection, peak finding)\n",
    "    #    - Use measurement uncertainties (`sigma` parameter)\n",
    "    #    - Apply bounds for physical validity\n",
    "    #    - Check convergence and diagnostics\n",
    "    #\n",
    "    # 4. **Uncertainty Quantification**\n",
    "    #    - Parameter uncertainties from covariance matrix\n",
    "    #    - Error propagation for derived quantities\n",
    "    #    - Bootstrap resampling for robust estimates\n",
    "    #    - Report 95% confidence intervals\n",
    "    #\n",
    "    # 5. **Validation**\n",
    "    #    - Goodness-of-fit metrics (χ²ᵣ, R², RMSE)\n",
    "    #    - Residual analysis (pattern detection, normality)\n",
    "    #    - Physical interpretation of parameters\n",
    "    #    - Sensitivity analysis (optional)\n",
    "    #\n",
    "    # 6. **Reporting**\n",
    "    #    - Publication-quality figures\n",
    "    #    - Parameter tables with uncertainties\n",
    "    #    - Statistical metrics\n",
    "    #    - Physical interpretation\n",
    "    #\n",
    "    # ### Production Recommendations\n",
    "    #\n",
    "    # ```python\n",
    "    # # For batch processing multiple spectra\n",
    "    # results = []\n",
    "    # for spectrum_file in spectrum_files:\n",
    "    #     wavenumber, intensity = load_spectrum(spectrum_file)\n",
    "    #     # ... preprocessing ...\n",
    "    #     popt, pcov = cf.curve_fit(model, x, y, ...)\n",
    "    #     results.append({'file': spectrum_file, 'params': popt, 'cov': pcov})\n",
    "    #\n",
    "    # # Save results to structured format\n",
    "    # import pandas as pd\n",
    "    # df = pd.DataFrame(results)\n",
    "    # df.to_csv('batch_fitting_results.csv')\n",
    "    # ```\n",
    "    #\n",
    "    # ### Next Steps\n",
    "    #\n",
    "    # - **Extend to 3+ peaks**: Add more Lorentzian components for complex spectra\n",
    "    # - **Voigt profiles**: Mix Gaussian and Lorentzian for realistic broadening\n",
    "    # - **Automated peak finding**: Use `scipy.signal.find_peaks` for initial guesses\n",
    "    # - **Batch processing**: Analyze multiple samples with automated workflows\n",
    "    # - **Advanced models**: Background modeling with splines or polynomials\n",
    "    #\n",
    "    # ### References\n",
    "    #\n",
    "    # 1. Ferrari & Robertson, *Phys. Rev. B* **61**, 14095 (2000)\n",
    "    # 2. NLSQ Documentation: https://nlsq.readthedocs.io/\n",
    "    # 3. Related examples:\n",
    "    #    - `nlsq_quickstart.ipynb` - Basic curve fitting\n",
    "    #    - `advanced_features_demo.ipynb` - Diagnostics and robustness\n",
    "    #    - `gallery/physics/spectroscopy_peaks.py` - Simple peak fitting\n",
    "    # ======================================================================\n",
    "\n",
    "if not QUICK:\n",
    "    _run_full_demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
