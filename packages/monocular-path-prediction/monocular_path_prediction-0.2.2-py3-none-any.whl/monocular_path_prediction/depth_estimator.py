"""Monocular depth and normal estimation algorithms."""

import cv2
import torch
from depth_anything_v2.dpt import DepthAnythingV2
from loguru import logger
from numpy.typing import NDArray

from monocular_path_prediction.config.definitions import (
    EPSILON,
    MODEL_EXTENSION,
    PRETRAINED_MODEL_DIR,
    DepthModelConfig,
)


class MonocularDepthEstimator:
    """Class for estimating inverse depth maps from images."""

    def __init__(self, model_config: DepthModelConfig, device: str | None = None):
        if device is None:
            self.device = (
                "cuda"
                if torch.cuda.is_available()
                else "mps"
                if torch.backends.mps.is_available()
                else "cpu"
            )
        else:
            self.device = device
        logger.info(f"Using device: {self.device}")

        self.model = self.load_model(model_config=model_config)

    def load_model(self, model_config: DepthModelConfig):
        """Load the model for the specified encoder."""
        checkpoint_path = (
            PRETRAINED_MODEL_DIR
            / f"depth_anything_v2_{model_config.encoder}{MODEL_EXTENSION}"
        )
        logger.info(f"Loading model for encoder: {model_config.encoder}")

        if not checkpoint_path.exists():
            msg = f"Checkpoint {checkpoint_path} not found."
            logger.error(msg)
            raise FileNotFoundError(msg)

        model = DepthAnythingV2(
            encoder=model_config.encoder,
            features=model_config.features,
            out_channels=model_config.out_channels,
        )
        model.load_state_dict(torch.load(checkpoint_path, map_location="cpu"))
        return model.to(self.device).eval()

    @staticmethod
    def _convert_to_bgr(image: NDArray) -> NDArray:
        """Convert RGB to BGR if needed (OpenCV uses BGR)."""
        if len(image.shape) == 3 and image.shape[2] == 3:
            # Check if an image is in RGB format (this is a heuristic)
            if image[0, 0, 0] > image[0, 0, 2]:  # If R > B, likely RGB
                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        return image

    def infer_inverse_depth(self, image: NDArray) -> NDArray:
        """Infer an inverse depth map from an image.

        Args:
            image: a preloaded image as a numpy array

        Returns:
            Inverse depth map as a numpy array

        """
        # Convert RGB to BGR if needed (OpenCV uses BGR)
        image = self._convert_to_bgr(image)
        return self.model.infer_image(image)

    def infer_depth(self, image: NDArray) -> NDArray:
        """Infer an inverse depth map from an image."""
        inv_depth_map = self.infer_inverse_depth(image)
        depth = 1.0 / (inv_depth_map + EPSILON)
        return depth
