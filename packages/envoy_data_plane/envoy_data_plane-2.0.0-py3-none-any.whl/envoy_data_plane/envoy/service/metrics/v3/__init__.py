# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: envoy/service/metrics/v3/metrics_service.proto
# plugin: python-betterproto2
# This file has been @generated

__all__ = (
    "MetricsServiceAsyncStub",
    "MetricsServiceBase",
    "MetricsServiceSyncStub",
    "StreamMetricsMessage",
    "StreamMetricsMessageIdentifier",
    "StreamMetricsResponse",
)

from collections.abc import AsyncIterable, AsyncIterator, Iterable
from typing import TYPE_CHECKING

import betterproto2
import grpc
import grpclib
from betterproto2 import grpclib as betterproto2_grpclib
from pydantic.dataclasses import dataclass

from .....message_pool import default_message_pool

if TYPE_CHECKING:
    import grpclib.server
    from betterproto2.grpclib.grpclib_client import MetadataLike
    from grpclib.metadata import Deadline

_COMPILER_VERSION = "0.9.0"
betterproto2.check_compiler_version(_COMPILER_VERSION)


@dataclass(eq=False, repr=False, config={"extra": "forbid"})
class StreamMetricsMessage(betterproto2.Message):
    identifier: "StreamMetricsMessageIdentifier | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    Identifier data effectively is a structured metadata. As a performance optimization this will
    only be sent in the first message on the stream.
    """

    envoy_metrics: "list[____io__prometheus__client__.MetricFamily]" = (
        betterproto2.field(2, betterproto2.TYPE_MESSAGE, repeated=True)
    )
    """
    A list of metric entries
    """


default_message_pool.register_message(
    "envoy.service.metrics.v3", "StreamMetricsMessage", StreamMetricsMessage
)


@dataclass(eq=False, repr=False, config={"extra": "forbid"})
class StreamMetricsMessageIdentifier(betterproto2.Message):
    node: "___config__core__v3__.Node | None" = betterproto2.field(
        1, betterproto2.TYPE_MESSAGE, optional=True
    )
    """
    The node sending metrics over the stream.
    """


default_message_pool.register_message(
    "envoy.service.metrics.v3",
    "StreamMetricsMessage.Identifier",
    StreamMetricsMessageIdentifier,
)


@dataclass(eq=False, repr=False, config={"extra": "forbid"})
class StreamMetricsResponse(betterproto2.Message):
    pass


default_message_pool.register_message(
    "envoy.service.metrics.v3", "StreamMetricsResponse", StreamMetricsResponse
)


class MetricsServiceSyncStub:
    """
    [#protodoc-title: Metrics service]

    Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
    data model as a standard to represent metrics information.
    """

    def __init__(self, channel: grpc.Channel):
        self._channel = channel

    def stream_metrics(
        self, messages: "Iterable[StreamMetricsMessage]"
    ) -> "StreamMetricsResponse":
        """
        Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
        response to be sent as nothing would be done in the case of failure.
        """

        return self._channel.stream_unary(
            "/envoy.service.metrics.v3.MetricsService/StreamMetrics",
            StreamMetricsMessage.SerializeToString,
            StreamMetricsResponse.FromString,
        )(iter(messages))


class MetricsServiceAsyncStub(betterproto2_grpclib.ServiceStub):
    """
    [#protodoc-title: Metrics service]

    Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
    data model as a standard to represent metrics information.
    """

    async def stream_metrics(
        self,
        messages: "AsyncIterable[StreamMetricsMessage] | Iterable[StreamMetricsMessage]",
        *,
        timeout: "float | None" = None,
        deadline: "Deadline | None" = None,
        metadata: "MetadataLike | None" = None,
    ) -> "StreamMetricsResponse":
        """
        Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
        response to be sent as nothing would be done in the case of failure.
        """

        return await self._stream_unary(
            "/envoy.service.metrics.v3.MetricsService/StreamMetrics",
            messages,
            StreamMetricsMessage,
            StreamMetricsResponse,
            timeout=timeout,
            deadline=deadline,
            metadata=metadata,
        )


from .....io.prometheus import client as ____io__prometheus__client__
from ....config.core import v3 as ___config__core__v3__


class MetricsServiceBase(betterproto2_grpclib.ServiceBase):
    """
    [#protodoc-title: Metrics service]

    Service for streaming metrics to server that consumes the metrics data. It uses Prometheus metric
    data model as a standard to represent metrics information.
    """

    async def stream_metrics(
        self, messages: "AsyncIterator[StreamMetricsMessage]"
    ) -> "StreamMetricsResponse":
        """
        Envoy will connect and send StreamMetricsMessage messages forever. It does not expect any
        response to be sent as nothing would be done in the case of failure.
        """

        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_stream_metrics(
        self,
        stream: "grpclib.server.Stream[StreamMetricsMessage, StreamMetricsResponse]",
    ) -> None:
        request = stream.__aiter__()
        response = await self.stream_metrics(request)
        await stream.send_message(response)

    def __mapping__(self) -> "dict[str, grpclib.const.Handler]":
        return {
            "/envoy.service.metrics.v3.MetricsService/StreamMetrics": grpclib.const.Handler(
                self.__rpc_stream_metrics,
                grpclib.const.Cardinality.STREAM_UNARY,
                StreamMetricsMessage,
                StreamMetricsResponse,
            ),
        }
