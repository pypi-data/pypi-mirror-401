{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a958351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nextrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3c1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "\n",
    "logger = logging.getLogger() \n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))\n",
    "logger.handlers = [handler] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43500b8",
   "metadata": {},
   "source": [
    "In this example, we'll walk through using the NextRec framework to train an RQ-VAE model and generate semantic IDs. Under `dataset/` we provide a sample e-commerce dataset that contains user id, item id, product text description, event time, and a few common features. We'll use the text feature for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb52e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_bucket</th>\n",
       "      <th>city</th>\n",
       "      <th>device</th>\n",
       "      <th>channel</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>impression_position</th>\n",
       "      <th>user_active_days_7</th>\n",
       "      <th>user_ctr</th>\n",
       "      <th>text_desc</th>\n",
       "      <th>click</th>\n",
       "      <th>conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-14 09:16:00</td>\n",
       "      <td>10001</td>\n",
       "      <td>item_BEAU_01399</td>\n",
       "      <td>F</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Web</td>\n",
       "      <td>search</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>PureSkin</td>\n",
       "      <td>277.62</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Sunscreen cruelty-free brightening</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-15 17:18:00</td>\n",
       "      <td>10001</td>\n",
       "      <td>item_BEAU_01530</td>\n",
       "      <td>F</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Web</td>\n",
       "      <td>push</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>BrandN</td>\n",
       "      <td>814.57</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Essence for sensitive skin with niacinamide hy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-18 09:51:00</td>\n",
       "      <td>10001</td>\n",
       "      <td>item_HOME_01211</td>\n",
       "      <td>F</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Web</td>\n",
       "      <td>organic</td>\n",
       "      <td>Home</td>\n",
       "      <td>BrandB</td>\n",
       "      <td>904.47</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Office chair with lumbar support handcrafted</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-23 09:59:00</td>\n",
       "      <td>10001</td>\n",
       "      <td>item_CLOT_00426</td>\n",
       "      <td>F</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Web</td>\n",
       "      <td>search</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>BrandD</td>\n",
       "      <td>358.71</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Cotton t-shirt short sleeve athletic fit with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-12-08 19:39:00</td>\n",
       "      <td>10001</td>\n",
       "      <td>item_HOME_01178</td>\n",
       "      <td>F</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Web</td>\n",
       "      <td>search</td>\n",
       "      <td>Home</td>\n",
       "      <td>ModernLiving</td>\n",
       "      <td>315.23</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Plant pot space-saving durable material easy a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              log_time  user_id          item_id gender age_bucket     city  \\\n",
       "0  2025-11-14 09:16:00    10001  item_BEAU_01399      F      35-44  Beijing   \n",
       "1  2025-11-15 17:18:00    10001  item_BEAU_01530      F      35-44  Beijing   \n",
       "2  2025-11-18 09:51:00    10001  item_HOME_01211      F      35-44  Beijing   \n",
       "3  2025-11-23 09:59:00    10001  item_CLOT_00426      F      35-44  Beijing   \n",
       "4  2025-12-08 19:39:00    10001  item_HOME_01178      F      35-44  Beijing   \n",
       "\n",
       "  device  channel  category         brand   price  impression_position  \\\n",
       "0    Web   search    Beauty      PureSkin  277.62                   10   \n",
       "1    Web     push    Beauty        BrandN  814.57                    9   \n",
       "2    Web  organic      Home        BrandB  904.47                    5   \n",
       "3    Web   search  Clothing        BrandD  358.71                   10   \n",
       "4    Web   search      Home  ModernLiving  315.23                   10   \n",
       "\n",
       "   user_active_days_7  user_ctr  \\\n",
       "0                   7      0.29   \n",
       "1                   7      0.29   \n",
       "2                   7      0.29   \n",
       "3                   7      0.29   \n",
       "4                   7      0.29   \n",
       "\n",
       "                                           text_desc  click  conversion  \n",
       "0                 Sunscreen cruelty-free brightening      0           0  \n",
       "1  Essence for sensitive skin with niacinamide hy...      0           0  \n",
       "2       Office chair with lumbar support handcrafted      0           0  \n",
       "3  Cotton t-shirt short sleeve athletic fit with ...      1           1  \n",
       "4  Plant pot space-saving durable material easy a...      0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/ecommerce_task.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6094f8",
   "metadata": {},
   "source": [
    "# RQ-VAE\n",
    "\n",
    "Before getting started, here is a quick introduction to RQ-VAE. RQ-VAE is an improvement over VAE (Variational Autoencoder), a generative model that learns the distribution of the input data and outputs a similar distribution using KL divergence as the metric. Simply put, a VAE works like an embedding layer: for text data, it maps text into a low-dimensional space. Because a VAE expects a vector input, we need to tokenize and embed/one-hot the text so each token becomes a high-dimensional vector, then feed the high-dimensional sequence into an encoder (RNN/GRN/CNN/Transformer) to compress the sequence into a low-dimensional vector—that is the final representation we want.\n",
    "\n",
    "A VAE already reduces the high-dimensional embedding to something lower, but saving that vector for every item can still be heavy in production. We would like to compress the output once more and turn continuous vectors into discrete low-dimensional vectors—that is the problem RQ-VAE tries to solve. RQ stands for Vector Quantization (VQ) and Residual Encoding. RQ-VAE aims to store each item as an index ID and perform retrieval with ID → lookup → dot-product.\n",
    "\n",
    "RQ-VAE represents the original VAE embedding using a combination of discrete codebook indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8f4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nextrec.basic.features import DenseFeature\n",
    "from nextrec.data.dataloader import RecDataLoader\n",
    "from nextrec.models.representation import RQVAE\n",
    "\n",
    "from nextrec.data.data_processing import split_dict_random\n",
    "from nextrec.utils.embedding import encode_multimodel_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f9b19",
   "metadata": {},
   "source": [
    "To generate semantic IDs with RQ-VAE, we first need multimodal inputs. In this example we use text as the raw signal and embed it with a BERT model into high-dimensional dense vectors. The NextRec utility `encode_multimodel_content` handles this step for you, invoking the transformers library under the hood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42137bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 10000 samples\n",
      "Encoded text_desc into embeddings with shape torch.Size([10000, 768])\n",
      "tensor([-6.9366e-02, -2.5368e-01, -4.2544e-01,  2.4386e-01, -2.3643e-01,\n",
      "        -2.3092e-02, -7.0698e-02,  2.4566e-01, -4.0289e-02, -1.3284e-01,\n",
      "         9.2764e-02,  4.7631e-01, -2.7675e-02,  1.6549e-01, -2.5294e-01,\n",
      "         1.0878e-01, -2.4900e-01,  4.8581e-01,  3.5214e-02,  1.4288e-01,\n",
      "        -8.4659e-02, -8.7917e-02, -6.5080e-01,  1.9214e-01,  9.4129e-02,\n",
      "        -1.0084e-01,  3.9686e-01,  2.1918e-01,  1.7440e-01,  1.8361e-01,\n",
      "         2.5563e-01,  1.7434e-01, -5.5120e-02, -5.0393e-02,  5.2894e-01,\n",
      "        -5.3674e-01,  2.0702e-02, -8.3346e-01, -2.1497e-01, -9.4487e-02,\n",
      "        -1.1800e-02,  1.2713e-01,  6.3430e-01, -1.8029e-01,  5.2011e-02,\n",
      "        -3.1240e-01, -2.5302e+00,  2.3571e-01, -1.6146e-01, -1.8182e-01,\n",
      "         6.8951e-01, -4.4509e-01,  6.4377e-02,  1.4384e-01,  6.2194e-01,\n",
      "         8.5790e-01, -2.3083e-02,  5.3937e-01,  3.3104e-01,  1.1583e-01,\n",
      "         8.1912e-02, -3.3135e-01, -2.5769e-01,  3.6626e-02,  1.5965e-01,\n",
      "         3.3988e-02, -1.3385e-01,  3.4125e-01, -2.2593e-01,  2.2698e-01,\n",
      "        -4.8414e-01,  3.7880e-02, -7.9133e-02, -4.3425e-02, -9.6151e-02,\n",
      "        -1.5596e-01,  1.2116e-01,  7.5390e-02, -5.4109e-02, -1.1437e-01,\n",
      "         2.0788e-02,  5.3831e-01,  1.2107e-01,  4.4698e-01,  1.8357e-01,\n",
      "         4.0756e-01, -2.0482e-01, -2.2030e-01,  5.8290e-01,  8.9612e-01,\n",
      "        -8.8884e-02,  1.7875e-01,  5.7594e-01,  2.7254e-01,  5.9928e-01,\n",
      "        -1.7287e-01,  3.7728e-02,  2.1079e-01,  3.4164e-01, -8.3466e-02,\n",
      "        -2.5629e-02, -3.8143e-02, -1.0855e-01, -4.1824e-01,  2.4296e-01,\n",
      "        -6.6965e-02, -6.6354e-03, -1.0347e-01,  1.9249e-01, -2.3163e+00,\n",
      "         3.8747e-01,  1.5098e-01,  1.4482e-01,  2.3235e-01, -5.8179e-01,\n",
      "         3.8337e-01, -6.4055e-02,  1.2763e-01,  8.3698e-02,  9.9421e-02,\n",
      "        -9.9673e-02,  2.8180e-01,  2.1983e-01, -1.3839e-02, -8.4813e-02,\n",
      "         5.0904e-01, -3.0666e-01,  4.5403e-01,  2.8270e-02, -9.8717e-02,\n",
      "         3.8649e-02,  4.0795e-01,  9.8648e-02, -6.8703e-01, -3.3533e-01,\n",
      "         8.3121e-02,  3.5431e-01,  1.0801e-01,  1.6950e-01, -5.0428e-01,\n",
      "        -7.8143e-01, -4.0190e-01, -3.1062e+00, -2.3790e-01,  1.0108e+00,\n",
      "        -1.4190e-01,  2.7980e-01,  6.9310e-01,  1.4091e-01,  7.5458e-02,\n",
      "         5.6058e-01,  2.9992e-01, -3.6911e-01,  9.7665e-02,  2.9242e-01,\n",
      "        -8.1825e-02,  5.2271e-02, -2.2228e-01,  2.1968e-01, -6.5691e-02,\n",
      "         1.5747e-01, -2.0537e-01,  7.9325e-02,  1.0311e-01, -2.0537e-01,\n",
      "         1.7432e-01,  7.2282e-02,  2.2525e-01,  6.2064e-01,  3.7530e-01,\n",
      "         1.5799e-01,  5.6158e-02,  3.6148e-01, -4.2427e-02,  7.8699e-01,\n",
      "        -1.2320e-02, -3.4269e-01,  5.1480e-01,  1.3052e-01,  1.3414e-01,\n",
      "        -2.2502e-01,  6.0436e-01,  5.9342e-01,  9.2160e-02,  5.5220e-01,\n",
      "        -1.7860e-01,  1.8045e-01, -1.7164e-01,  2.9960e-01,  3.9801e-01,\n",
      "        -6.2805e-01, -3.2539e-01,  2.2267e-01,  1.8860e-01, -2.6236e-01,\n",
      "        -2.0792e-03,  1.7970e-01,  9.6719e-02,  1.3834e-01,  1.6465e-01,\n",
      "         4.3941e-01,  4.0408e-01, -1.1593e-01,  5.0312e-01, -7.9638e-01,\n",
      "         3.8036e+00, -2.5938e-02, -2.9573e-01, -5.5707e-01,  2.0672e-01,\n",
      "        -1.6628e-02,  7.6502e-02,  5.0318e-02, -3.7029e-01, -9.4420e-02,\n",
      "         2.1649e-02,  3.6363e-01,  3.4216e-01, -4.4548e-01, -3.1554e-01,\n",
      "        -1.4671e-01,  2.2865e-01, -4.0624e-01,  1.7409e-01,  1.9627e-01,\n",
      "        -2.5682e-02, -5.0682e-01,  4.1476e-02, -3.7071e-02, -1.1322e+00,\n",
      "         1.5225e-01, -3.9729e-01, -3.8710e-01,  1.8852e-01, -1.3645e-01,\n",
      "        -5.0950e-02, -6.5730e-02, -3.6738e-01,  4.2436e-01, -1.7697e-01,\n",
      "        -2.4992e-02, -1.9092e-01,  4.3674e-01,  1.7234e-01, -5.2417e-01,\n",
      "         4.1063e-01,  4.1986e-01,  2.7603e-01,  3.6187e-01, -2.1469e-01,\n",
      "         9.1558e-01, -4.1393e-01,  2.2331e-01, -2.8814e-01, -2.2860e-01,\n",
      "         7.0311e-02,  1.9104e-02,  2.3647e-01, -1.2071e-01, -1.4964e-01,\n",
      "        -2.4925e-01,  8.5475e-02,  3.6431e-01, -3.7920e-01, -3.1736e-01,\n",
      "        -3.2072e-01, -1.2138e-01, -4.0661e-01, -6.8701e-02, -2.4337e-01,\n",
      "         1.2148e-01, -2.2233e-01, -4.3085e-01, -3.5164e+00, -4.7643e-01,\n",
      "         4.9333e-02,  8.0546e-01,  6.6038e-01, -6.2852e-02, -5.0351e-02,\n",
      "         2.7127e-01, -7.3066e-02, -3.8528e-01,  6.4198e-01, -1.1995e-01,\n",
      "        -2.9475e-01, -5.3356e-02, -6.7284e-01,  2.7137e-01,  2.2273e-01,\n",
      "         2.2851e-01,  1.5039e-01, -2.8687e-03,  1.6053e-01, -6.0219e-02,\n",
      "        -2.2570e-01, -1.7218e-01,  3.7920e-01,  1.3907e-01, -7.7125e-01,\n",
      "        -9.4169e-03, -6.2083e-03, -3.9824e-01,  4.5904e-01, -4.2053e-01,\n",
      "         1.4814e-01, -1.8934e-01, -5.1180e-01, -3.0337e+00,  6.3251e-01,\n",
      "        -3.4695e-01, -3.6198e-01, -1.3974e-01, -2.3074e-01,  5.3864e-01,\n",
      "         1.8220e-01, -4.0131e-01,  2.5629e-01,  2.0530e-01,  5.6823e-02,\n",
      "         5.6716e-02,  9.6733e-02,  1.5985e-01,  5.3779e-01,  2.8825e-01,\n",
      "        -1.5445e-01,  4.8056e-01,  7.9940e-02,  1.6704e-01, -2.5466e-01,\n",
      "        -2.5154e-01, -1.2814e-01, -4.3058e-01,  4.5326e-01, -3.8428e-01,\n",
      "         2.2742e-01, -2.6829e-01, -4.8025e-02, -1.1971e-01,  7.1794e-02,\n",
      "         3.0362e-01, -4.6630e-02,  1.4646e-01, -2.6315e-01, -9.1856e-04,\n",
      "         1.4888e-01,  3.8987e-01,  2.2798e-01, -8.3920e-02,  1.0038e+00,\n",
      "         5.8821e-02,  6.1741e-01,  8.2228e-01,  1.0828e-01,  5.2113e-01,\n",
      "        -6.3850e-02,  4.3798e-01,  8.2911e-02, -5.8361e-02,  1.5287e-01,\n",
      "         6.3643e-01, -3.0526e-01, -4.8996e-01,  8.3750e-02,  3.0410e-01,\n",
      "        -4.6447e-02,  1.9311e-01, -1.4793e-01,  6.5270e-01, -6.8207e-01,\n",
      "         2.3250e-01,  2.2581e-01,  1.0160e-01, -1.7039e-01,  4.5763e-01,\n",
      "        -6.6117e-01, -1.0915e-01,  3.1759e-01, -5.6742e-01,  3.6369e-01,\n",
      "         1.1118e-01, -9.2273e-01, -1.8318e-01,  1.9630e-01, -3.5768e-01,\n",
      "        -1.1572e-01,  6.1387e-01, -1.7925e-01, -3.7512e-01,  2.9159e-02,\n",
      "        -3.4944e-01,  6.7496e-01, -4.1452e-01,  1.4668e-01, -2.1319e-01,\n",
      "        -1.2230e-01, -6.6191e-01, -5.7266e-02, -1.5278e-01,  7.0484e-01,\n",
      "        -6.3267e-03,  1.2094e-01, -1.3995e-01,  2.9667e-01,  4.2080e-01,\n",
      "        -1.1279e+00,  4.6778e-01, -2.3268e-01, -3.4625e-01, -2.7924e-01,\n",
      "         1.6204e-01, -3.6720e-01, -3.4509e-01, -1.3106e-01, -2.0637e-02,\n",
      "        -2.9770e-01,  3.5473e-01, -1.0500e-02, -6.8337e-02, -1.8009e-01,\n",
      "         8.4196e-02,  4.3347e-01,  9.9328e-01, -7.0923e-02,  9.2673e-02,\n",
      "         6.6957e-01,  3.4144e-01,  5.4814e-01,  6.2526e-01,  3.7684e-01,\n",
      "        -8.4530e-02, -4.1268e-01, -2.8410e-01, -1.9068e-01,  2.6755e-02,\n",
      "        -6.8923e-01, -7.0618e-01,  1.5478e-01,  1.2836e-01, -3.5345e-01,\n",
      "        -1.7234e-01, -5.8153e-01, -4.6847e-01, -4.1033e-01, -4.6941e-01,\n",
      "        -1.0821e-01, -1.0341e-01, -6.4984e-02, -2.9586e-01, -1.7551e-01,\n",
      "        -6.6527e-02,  1.1980e-01, -7.1435e-03,  5.9394e-01,  1.7895e-02,\n",
      "        -1.7739e-01, -1.2278e-01,  7.0724e-01, -1.2774e-01, -1.9259e-01,\n",
      "        -4.2095e-01, -4.5515e-01, -2.8818e-01, -1.5670e-01,  4.3510e-01,\n",
      "        -1.9231e-02,  3.5389e-01, -4.7203e-01, -2.2583e-01, -1.3106e-01,\n",
      "        -1.7989e+00,  2.3723e-01,  3.4040e-01,  2.2196e-01,  2.7090e-01,\n",
      "        -6.2533e-01, -7.6352e-01,  6.4266e-01,  1.7336e-01,  1.4678e-01,\n",
      "        -5.6795e-01, -1.2158e-01,  1.1580e-02, -1.3967e-02, -8.1238e-02,\n",
      "         1.1433e-02,  1.2196e-02, -9.5423e-02,  2.2765e-01, -5.1093e-01,\n",
      "        -1.2084e-01,  2.8321e-01,  5.6126e-01, -3.9942e-01, -5.8153e-01,\n",
      "         3.8004e-03,  1.1020e-01,  9.6521e-02,  5.3683e-02,  3.0277e-01,\n",
      "        -5.5503e-01, -5.4410e-01, -5.9991e-01, -2.0292e-01,  2.5257e-02,\n",
      "         1.4013e-01,  4.8088e-01, -3.4687e-02, -3.3648e-01,  2.2430e-01,\n",
      "        -5.4277e-01,  5.2681e-01,  2.1319e-02, -9.8654e-02,  5.3981e-01,\n",
      "         3.1239e-01, -7.1116e-01,  6.4740e-02, -8.6942e-02, -6.1064e-01,\n",
      "        -2.8150e-01,  1.4165e-01, -2.4054e-01,  1.4434e-01,  7.1285e-02,\n",
      "        -3.3866e-01, -6.1422e-01,  2.1060e-01, -2.0925e-01, -3.1046e-01,\n",
      "         3.9100e-01, -1.9506e-01, -2.8720e-01,  2.8261e-04,  6.0405e-02,\n",
      "        -5.6653e-01, -6.1056e-02, -7.9092e-02, -4.7727e-01, -2.1269e-02,\n",
      "         5.3112e-01,  4.8477e-01, -1.4412e-01,  8.8439e-01, -2.7032e-01,\n",
      "         7.8288e-02,  2.2952e-01, -7.7833e-04,  3.5408e-01, -2.3626e-01,\n",
      "        -2.1180e-01, -3.2179e-01, -4.3833e-01,  2.3894e-01, -6.7503e-01,\n",
      "         8.1350e-01, -1.0447e-01, -1.8474e-01, -2.5916e-01, -2.0528e-02,\n",
      "        -5.8164e-01, -4.4628e-01,  2.0156e-01,  1.5272e-02, -8.0457e-02,\n",
      "         1.4970e-01, -2.8312e-01,  3.4177e-01, -3.4481e-01,  4.2938e-01,\n",
      "        -1.6818e-01,  4.3744e-01,  6.1219e-01,  1.1482e-01,  1.0051e-01,\n",
      "         4.6275e-02,  4.9423e-01,  2.9493e-01, -2.0491e-01, -4.8518e-01,\n",
      "         8.6826e-02, -1.6348e-01, -5.1374e-01,  2.9356e-03,  1.9949e-01,\n",
      "        -3.2420e-01,  1.6379e-01, -3.4601e-01,  2.0076e+00,  3.2521e-01,\n",
      "         2.6308e-01, -1.6533e-01,  4.2788e-02, -2.7729e-01, -4.2491e-01,\n",
      "         1.2408e-01, -6.0217e-01,  4.4291e-01,  5.7114e-01,  3.1247e-01,\n",
      "         2.8356e-01,  6.4406e-02,  2.3504e-01,  6.9948e-01, -3.0132e-01,\n",
      "        -4.7122e-01, -7.5120e-01, -1.9443e-01, -2.0153e-01,  8.6684e-02,\n",
      "         3.6493e-01,  3.7720e-02,  2.8007e-02, -1.3535e-01,  1.1384e-01,\n",
      "        -2.2620e-01, -1.4043e-01,  1.6133e-01, -1.7186e-01,  4.0180e-02,\n",
      "        -3.1330e-02,  4.8217e-01, -1.5895e-01,  3.3973e-01,  1.1754e-01,\n",
      "        -2.3574e-02,  2.3798e-01, -5.6425e-03,  3.8240e-01, -4.0302e-01,\n",
      "         7.4354e-01,  1.6381e-02,  1.8022e-01,  1.0966e+00, -1.4816e-01,\n",
      "        -2.7472e-01,  4.0889e-01,  5.5912e-01, -3.8880e-01,  5.6891e-02,\n",
      "         1.2181e-02, -2.3278e-01, -1.2547e-01, -2.2284e-01, -6.6471e-02,\n",
      "        -3.3570e-01, -7.4227e-01,  5.1837e-01,  9.1139e-02,  2.4492e-01,\n",
      "         2.6933e-01, -4.8274e-01,  3.1287e-01,  3.9045e-02, -1.3839e-01,\n",
      "         1.9426e-01,  8.3204e-01, -1.8849e-01,  7.3139e-02, -6.3581e-02,\n",
      "         2.9828e-01, -1.8007e-01,  3.6696e-01,  5.1320e-02,  4.9431e-01,\n",
      "        -3.7047e-02, -2.8472e-01, -2.9826e+00, -2.8985e-01,  3.1972e-01,\n",
      "        -8.1519e-02,  6.4848e-03,  5.5849e-01,  1.1519e-01, -2.0170e-01,\n",
      "         3.4829e-02, -1.4676e-01,  3.0870e-01,  2.4527e-01,  1.0434e-01,\n",
      "         2.0022e-01,  1.5045e-01,  1.0219e-01,  2.2780e-02, -4.5604e-01,\n",
      "        -1.3816e-02,  3.2144e-01,  9.0319e-01, -5.9987e-02, -6.2334e-01,\n",
      "        -3.3442e-01, -4.5039e-01,  4.1877e-01,  6.0070e-01, -3.7741e-01,\n",
      "        -1.7775e-01,  3.2265e-01, -5.6936e-02,  1.9614e-01, -1.1707e-01,\n",
      "        -2.3342e-01,  4.0205e-01, -6.8591e-01,  1.6166e-01,  3.3266e-02,\n",
      "         2.3545e-02, -6.9738e-03, -3.6437e-01,  4.1949e-01,  1.7129e-01,\n",
      "         2.6154e-01,  2.4273e-01,  1.1987e-01,  4.6432e-01, -6.8651e-02,\n",
      "         7.3708e-01, -8.8414e-01, -1.3060e-01,  1.4399e-01,  3.0227e-01,\n",
      "        -2.4266e-01,  8.9823e-02,  1.6494e-01,  4.3161e-01, -5.8104e-02,\n",
      "         1.9733e-01, -8.3772e-01,  4.2085e-01,  6.2676e-01, -1.0064e-01,\n",
      "         1.0587e-01,  7.1138e-02, -2.2048e-02,  1.2831e-01, -4.3649e-02,\n",
      "         2.3304e-02,  3.4029e-02,  1.0609e-01, -5.9020e-01,  6.4011e-01,\n",
      "        -8.3592e-02,  1.4647e-01, -2.9901e-01,  3.1314e-01,  2.9735e-01,\n",
      "         2.0583e-01, -3.2639e-01,  1.0104e-01, -1.8237e-01, -7.3217e-01,\n",
      "         2.3650e-01,  7.4988e-02, -7.0153e+00, -4.9691e-01, -4.0131e-01,\n",
      "         2.7561e-01,  2.8285e-01, -5.9808e-01,  6.0939e-02, -2.0890e-01,\n",
      "         1.2492e-02,  7.5696e-02,  1.9983e-01, -1.1688e-01, -4.0965e-02,\n",
      "        -1.8963e-01, -1.9239e-01,  4.6898e-01])\n"
     ]
    }
   ],
   "source": [
    "texts = df[\"text_desc\"].fillna(\"\").tolist()\n",
    "print(f\"Dataset loaded: {len(df)} samples\")\n",
    "\n",
    "embeddings = encode_multimodel_content(texts, model_name=\"bert-base-uncased\", device=\"cpu\", batch_size=32)\n",
    "print(f\"Encoded text_desc into embeddings with shape {embeddings.shape}\")\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1df0e",
   "metadata": {},
   "source": [
    "Now that we have the raw inputs, we want RQ-VAE to learn and reconstruct their distribution. We therefore split the data into training and validation sets and build dataloaders. NextRec provides `RecDataLoader` to help with this.\n",
    "\n",
    "Because we have converted the text feature into a dense feature (`DenseFeature`), we only need to define the feature and pass it to `RecDataLoader`. In the future, NextRec will support multimodal feature definitions and automatic transforms; before that, please use the utility functions to perform the transforms manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268663cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build loaders for RQ-VAE\n",
    "text_feature = DenseFeature(name=\"text_embedding\", input_dim=embeddings.shape[1])\n",
    "loader_builder = RecDataLoader(dense_features=[text_feature])\n",
    "emb_np = embeddings.cpu().numpy()\n",
    "rqvae_train_dict, rqvae_valid_dict = split_dict_random(\n",
    "    {\"text_embedding\": emb_np}, test_size=0.1, random_state=2025\n",
    ")\n",
    "rqvae_train_loader = loader_builder.create_dataloader(\n",
    "    rqvae_train_dict, batch_size=256, shuffle=True\n",
    ")\n",
    "rqvae_valid_loader = loader_builder.create_dataloader(\n",
    "    rqvae_valid_dict, batch_size=256, shuffle=False\n",
    ")\n",
    "rqvae_full_loader = loader_builder.create_dataloader(\n",
    "    {\"text_embedding\": emb_np}, batch_size=256, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faef7c1b",
   "metadata": {},
   "source": [
    "Now we can instantiate RQ-VAE. It exposes several parameters:\n",
    "\n",
    "- input_dim: dimension of the input embedding (e.g., 768 for BERT); this is what the encoder receives and what the decoder outputs back to.\n",
    "- hidden_dims: list of hidden layer sizes for the encoder/decoder.\n",
    "- latent_dim: dimension of the latent space and codebook vectors after encoding; smaller values compress more, larger values give more capacity.\n",
    "- num_codebooks: number of residual quantization layers (stack depth); more layers yield finer-grained semantic IDs but make training/inference slightly slower.\n",
    "- codebook_size: list of vocabulary sizes for each codebook layer; its length should equal `num_codebooks`. For example, `[256, 256, 256]` means 3 layers with 256 codewords each, for 256^3 combinations.\n",
    "- shared_codebook: whether all layers share a single codebook; sharing reduces parameters while not sharing gives each layer more expressiveness. Default is not sharing.\n",
    "- kmeans_method: codebook initialization method; `\"kmeans\"` is standard KMeans, `\"bkmeans\"` is balanced KMeans (recommended), and any other value uses random initialization.\n",
    "- kmeans_iters: maximum iterations for KMeans initialization.\n",
    "- distances_method: distance metric for quantization; `\"l2\"` is Euclidean (default for VAE usage) and `\"cosine\"` is also supported.\n",
    "- loss_beta: commitment loss weight beta (the second term in the quantization loss); larger values force the encoder closer to the codebook, typically around 0.25.\n",
    "- dense_features: RQ-VAE expects the raw embedding distribution as dense vectors; we need to tell the model which vectors should be learned and compressed.\n",
    "\n",
    "After configuration, call `fit` to start training. Unlike the `fit` methods for ranking models, RQ-VAE requires an `init_batches` parameter to specify how many batches to use for codebook initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de26531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m================================================================================\u001b[0m\n",
      "\u001b[1m\u001b[94mModel Summary: RQVAE\u001b[0m\n",
      "\u001b[1m\u001b[94m================================================================================\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[36m[1] Feature Configuration\u001b[0m\n",
      "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
      "Dense Features (1):\n",
      "  1. text_embedding      \n",
      "\n",
      "\u001b[1m\u001b[36m[2] Model Parameters\u001b[0m\n",
      "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
      "Model Architecture:\n",
      "RQVAE(\n",
      "  (encoder): RQEncoder(\n",
      "    (stages): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): RQDecoder(\n",
      "    (stages): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (2): Linear(in_features=128, out_features=768, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (rq): RQ(\n",
      "    (vqmodules): ModuleList(\n",
      "      (0-1): 2 x VQEmbedding(128, 128)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Total Parameters:        363,648\n",
      "Trainable Parameters:    363,648\n",
      "Non-trainable Parameters: 0\n",
      "Layer-wise Parameters:\n",
      "  encoder                       : 165,120\n",
      "  decoder                       : 165,760\n",
      "  rq                            : 32,768\n",
      "\n",
      "\u001b[1m\u001b[36m[3] Training Configuration\u001b[0m\n",
      "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
      "Task Type:               regression\n",
      "Number of Tasks:         1\n",
      "Metrics:                 ['loss']\n",
      "Target Columns:          []\n",
      "Device:                  cpu\n",
      "Regularization:\n",
      "  Embedding L1:          0.0\n",
      "  Embedding L2:          0.0\n",
      "  Dense L1:              0.0\n",
      "  Dense L2:              0.0\n",
      "Other Settings:\n",
      "  Early Stop Patience:   20\n",
      "  Max Gradient Norm:     1.0\n",
      "  Session ID:            rqvae_tutorial\n",
      "  Features Config Path:  /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/rqvae_tutorial/features_config.pkl\n",
      "  Latest Checkpoint:     /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/rqvae_tutorial/RQVAE_checkpoint.pt\n",
      "\n",
      "\u001b[1m================================================================================\u001b[0m\n",
      "\u001b[1mStart training\u001b[0m\n",
      "\u001b[1m================================================================================\u001b[0m\n",
      "\n",
      "\u001b[1mModel device: cpu\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 36/36 [00:00<00:00, 106.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 0.3862\n",
      "\u001b[36m  Epoch 1/5 - Valid Loss: 0.1776\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/5: 100%|██████████| 36/36 [00:00<00:00, 131.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 0.1252\n",
      "\u001b[36m  Epoch 2/5 - Valid Loss: 0.0908\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/5: 100%|██████████| 36/36 [00:00<00:00, 142.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.0788\n",
      "\u001b[36m  Epoch 3/5 - Valid Loss: 0.0696\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/5: 100%|██████████| 36/36 [00:00<00:00, 136.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.0654\n",
      "\u001b[36m  Epoch 4/5 - Valid Loss: 0.0622\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5: 100%|██████████| 36/36 [00:00<00:00, 131.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.0623\n",
      "\u001b[36m  Epoch 5/5 - Valid Loss: 0.0614\u001b[0m\n",
      " \n",
      "\u001b[1mTraining finished.\u001b[0m\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RQVAE(\n",
       "  (encoder): RQEncoder(\n",
       "    (stages): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): RQDecoder(\n",
       "    (stages): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Linear(in_features=128, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (rq): RQ(\n",
       "    (vqmodules): ModuleList(\n",
       "      (0-1): 2 x VQEmbedding(128, 128)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rqvae = RQVAE(\n",
    "    input_dim=embeddings.shape[1],\n",
    "    hidden_dims=[128, 256],\n",
    "    latent_dim=128,\n",
    "    num_codebooks=2,\n",
    "    codebook_size=[128, 128],\n",
    "    shared_codebook=False,\n",
    "    kmeans_method=\"bkmeans\",\n",
    "    kmeans_iters=50,\n",
    "    distances_method=\"cosine\",\n",
    "    loss_beta=0.25,\n",
    "    device=\"cpu\",\n",
    "    dense_features=[DenseFeature(name=\"text_embedding\", input_dim=embeddings.shape[1])],\n",
    "    session_id=\"rqvae_tutorial\",\n",
    ")\n",
    "rqvae.fit(\n",
    "    train_data=rqvae_train_loader,\n",
    "    valid_data=rqvae_valid_loader,\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    lr=1e-3,\n",
    "    init_batches=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44762411",
   "metadata": {},
   "source": [
    "Training is finished; let's inspect the output. Each sample's original 768-dimensional continuous embedding is now represented by a 2-dimensional discrete vector, greatly reducing computation and storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcb5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic IDs shape: torch.Size([10000, 2])\n",
      "Semantic IDs sample (first 5 items):\n",
      "tensor([[119,  27],\n",
      "        [119,  69],\n",
      "        [ 52,  33],\n",
      "        [ 98,  80],\n",
      "        [ 14,   3]])\n"
     ]
    }
   ],
   "source": [
    "semantic_ids = rqvae.predict(\n",
    "    rqvae_full_loader, batch_size=256, return_reconstruction=False, as_numpy=False\n",
    ")\n",
    "semantic_ids = semantic_ids.to(\"cpu\")\n",
    "print(f\"Semantic IDs shape: {semantic_ids.shape}\")\n",
    "print(f\"Semantic IDs sample (first 5 items):\\n{semantic_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be14c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nextrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
