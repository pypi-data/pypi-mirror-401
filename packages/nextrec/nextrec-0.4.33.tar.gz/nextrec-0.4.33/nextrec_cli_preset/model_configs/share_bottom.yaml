model: share_bottom

params:
  bottom_mlp_params:
    hidden_dims: [256, 128]
    activation: relu
    dropout: 0.2

  tower_mlp_params_list:
    - hidden_dims: [96, 48]
      activation: relu
      dropout: 0.2
    - hidden_dims: [128, 64]
      activation: relu
      dropout: 0.2

  embedding_l1_reg: 1.e-6
  embedding_l2_reg: 1.e-5     
  dense_l1_reg: 1.e-6
  dense_l2_reg: 1.e-4
