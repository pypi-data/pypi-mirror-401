{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "aab95b2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "#pip install nextrec\n",
                "\n",
                "import logging\n",
                "import sys\n",
                "\n",
                "logger = logging.getLogger() \n",
                "logger.setLevel(logging.INFO)\n",
                "handler = logging.StreamHandler(sys.stdout)\n",
                "handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s %(message)s'))\n",
                "logger.handlers = [handler] "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d4b56c96",
            "metadata": {},
            "source": [
                "# 5-Minute Quick Start\n",
                "\n",
                "This notebook introduces NextRec, a unified, efficient, and scalable recommender-system framework, and walks you through training and building a production-ready model from scratch. The example uses internal feature definitions and online samples from E-commerce scenario.\n",
                "\n",
                "Before getting started, install nextrec from the command line:\n",
                "\n",
                "```bash\n",
                "# Release\n",
                "pip install nextrec\n",
                "\n",
                "# Test\n",
                "pip install -i https://test.pypi.org/simple/ nextrec\n",
                "```\n",
                "\n",
                "Here is a quick primer on the signals we usually process in recommendation. We handle several input types, transform them, and then feed vectors into the network:\n",
                "\n",
                "- Dense features (numeric): continuous or ordered values such as age, price, duration, or scores; typically standardized/normalized or log-transformed.\n",
                "- Sparse features (categorical/ID): high-cardinality discrete fields such as user ID, item ID, gender, occupation, or device type; typically indexed and embedded via an embedding lookup matrix.\n",
                "- Sequence features (behavior history): variable-length histories such as browse/click/purchase lists. They capture user behavior and interest drift; we usually truncate/pad, embed, and then aggregate (mean/sum/attention) to get a fixed-length vector.\n",
                "- Context features: environment information such as time, geography, or slot position; can be dense or sparse and often interacts with the main features.\n",
                "- Multi-modal features: vectors from pre-trained models on text, images, or video; they can be used directly as dense inputs or interact with IDs.\n",
                "\n",
                "A typical training data format looks like this:\n",
                "\n",
                "```text\n",
                "user_id,item_id,gender,age,occupation,history_seq,label\n",
                "1024,501,1,28,3,\"[12,45,18,77]\",1\n",
                "2048,777,0,35,5,\"[8,99]\",0\n",
                "```\n",
                "\n",
                "We provide a desensitized e-commerce dataset with user IDs, item IDs, dense features, sparse features, and sequence features. The labels include both click and conversion.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "33e27fee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Name: nextrec\n",
                        "Version: 0.4.21\n",
                        "Summary: A comprehensive recommendation library with match, ranking, and multi-task learning models\n",
                        "Home-page: https://github.com/zerolovesea/NextRec\n",
                        "Author: Yang Zhou\n",
                        "Author-email: zyaztec@gmail.com\n",
                        "License: \n",
                        "Location: /opt/anaconda3/envs/nextrec/lib/python3.10/site-packages\n",
                        "Editable project location: /Users/zyaztec/DailyWork/建模代码整理/NextRec\n",
                        "Requires: numpy, pandas, pyarrow, pyyaml, rich, scikit-learn, scipy, swanlab, torch, torchvision, transformers, wandb\n",
                        "Required-by: \n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip show nextrec"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "97cae0dd",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>user_id</th>\n",
                            "      <th>item_id</th>\n",
                            "      <th>dense_0</th>\n",
                            "      <th>dense_1</th>\n",
                            "      <th>dense_2</th>\n",
                            "      <th>dense_3</th>\n",
                            "      <th>dense_4</th>\n",
                            "      <th>dense_5</th>\n",
                            "      <th>dense_6</th>\n",
                            "      <th>dense_7</th>\n",
                            "      <th>...</th>\n",
                            "      <th>sparse_5</th>\n",
                            "      <th>sparse_6</th>\n",
                            "      <th>sparse_7</th>\n",
                            "      <th>sparse_8</th>\n",
                            "      <th>sparse_9</th>\n",
                            "      <th>sparse_10</th>\n",
                            "      <th>sparse_11</th>\n",
                            "      <th>sequence_0</th>\n",
                            "      <th>click</th>\n",
                            "      <th>conversion</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>7817</td>\n",
                            "      <td>0.147041</td>\n",
                            "      <td>0.310204</td>\n",
                            "      <td>0.777809</td>\n",
                            "      <td>0.944897</td>\n",
                            "      <td>0.623154</td>\n",
                            "      <td>0.571242</td>\n",
                            "      <td>0.770095</td>\n",
                            "      <td>0.321103</td>\n",
                            "      <td>...</td>\n",
                            "      <td>161</td>\n",
                            "      <td>138</td>\n",
                            "      <td>88</td>\n",
                            "      <td>5</td>\n",
                            "      <td>312</td>\n",
                            "      <td>416</td>\n",
                            "      <td>188</td>\n",
                            "      <td>[90, 54, 86, 5, 121, 138, 45, 100, 0, 0, 0, 0,...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>3579</td>\n",
                            "      <td>0.778112</td>\n",
                            "      <td>0.803593</td>\n",
                            "      <td>0.518520</td>\n",
                            "      <td>0.910912</td>\n",
                            "      <td>0.043562</td>\n",
                            "      <td>0.821427</td>\n",
                            "      <td>0.880369</td>\n",
                            "      <td>0.337482</td>\n",
                            "      <td>...</td>\n",
                            "      <td>252</td>\n",
                            "      <td>25</td>\n",
                            "      <td>402</td>\n",
                            "      <td>7</td>\n",
                            "      <td>168</td>\n",
                            "      <td>155</td>\n",
                            "      <td>154</td>\n",
                            "      <td>[3, 95, 31, 124, 56, 79, 109, 0, 0, 0, 0, 0, 0...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "      <td>2657</td>\n",
                            "      <td>0.586647</td>\n",
                            "      <td>0.123208</td>\n",
                            "      <td>0.203636</td>\n",
                            "      <td>0.116398</td>\n",
                            "      <td>0.240645</td>\n",
                            "      <td>0.882588</td>\n",
                            "      <td>0.062836</td>\n",
                            "      <td>0.629869</td>\n",
                            "      <td>...</td>\n",
                            "      <td>27</td>\n",
                            "      <td>62</td>\n",
                            "      <td>145</td>\n",
                            "      <td>109</td>\n",
                            "      <td>432</td>\n",
                            "      <td>170</td>\n",
                            "      <td>133</td>\n",
                            "      <td>[139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "      <td>2689</td>\n",
                            "      <td>0.337401</td>\n",
                            "      <td>0.705511</td>\n",
                            "      <td>0.138758</td>\n",
                            "      <td>0.945233</td>\n",
                            "      <td>0.330333</td>\n",
                            "      <td>0.377462</td>\n",
                            "      <td>0.121577</td>\n",
                            "      <td>0.427124</td>\n",
                            "      <td>...</td>\n",
                            "      <td>241</td>\n",
                            "      <td>144</td>\n",
                            "      <td>40</td>\n",
                            "      <td>6</td>\n",
                            "      <td>333</td>\n",
                            "      <td>175</td>\n",
                            "      <td>210</td>\n",
                            "      <td>[59, 29, 34, 106, 4, 103, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1</td>\n",
                            "      <td>2495</td>\n",
                            "      <td>0.669473</td>\n",
                            "      <td>0.564266</td>\n",
                            "      <td>0.006319</td>\n",
                            "      <td>0.255851</td>\n",
                            "      <td>0.698055</td>\n",
                            "      <td>0.052065</td>\n",
                            "      <td>0.583597</td>\n",
                            "      <td>0.590456</td>\n",
                            "      <td>...</td>\n",
                            "      <td>152</td>\n",
                            "      <td>27</td>\n",
                            "      <td>204</td>\n",
                            "      <td>129</td>\n",
                            "      <td>319</td>\n",
                            "      <td>97</td>\n",
                            "      <td>168</td>\n",
                            "      <td>[52, 122, 104, 116, 5, 138, 37, 30, 59, 10, 19...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 25 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   user_id  item_id   dense_0   dense_1   dense_2   dense_3   dense_4  \\\n",
                            "0        1     7817  0.147041  0.310204  0.777809  0.944897  0.623154   \n",
                            "1        1     3579  0.778112  0.803593  0.518520  0.910912  0.043562   \n",
                            "2        1     2657  0.586647  0.123208  0.203636  0.116398  0.240645   \n",
                            "3        1     2689  0.337401  0.705511  0.138758  0.945233  0.330333   \n",
                            "4        1     2495  0.669473  0.564266  0.006319  0.255851  0.698055   \n",
                            "\n",
                            "    dense_5   dense_6   dense_7  ...  sparse_5  sparse_6  sparse_7  sparse_8  \\\n",
                            "0  0.571242  0.770095  0.321103  ...       161       138        88         5   \n",
                            "1  0.821427  0.880369  0.337482  ...       252        25       402         7   \n",
                            "2  0.882588  0.062836  0.629869  ...        27        62       145       109   \n",
                            "3  0.377462  0.121577  0.427124  ...       241       144        40         6   \n",
                            "4  0.052065  0.583597  0.590456  ...       152        27       204       129   \n",
                            "\n",
                            "   sparse_9  sparse_10  sparse_11  \\\n",
                            "0       312        416        188   \n",
                            "1       168        155        154   \n",
                            "2       432        170        133   \n",
                            "3       333        175        210   \n",
                            "4       319         97        168   \n",
                            "\n",
                            "                                          sequence_0  click  conversion  \n",
                            "0  [90, 54, 86, 5, 121, 138, 45, 100, 0, 0, 0, 0,...      1           0  \n",
                            "1  [3, 95, 31, 124, 56, 79, 109, 0, 0, 0, 0, 0, 0...      1           1  \n",
                            "2    [139, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]      1           0  \n",
                            "3  [59, 29, 34, 106, 4, 103, 0, 0, 0, 0, 0, 0, 0,...      1           0  \n",
                            "4  [52, 122, 104, 116, 5, 138, 37, 30, 59, 10, 19...      1           0  \n",
                            "\n",
                            "[5 rows x 25 columns]"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from nextrec.data.preprocessor import DataProcessor\n",
                "\n",
                "df = pd.read_csv('/Users/zyaztec/DailyWork/建模代码整理/NextRec/dataset/multitask_task.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "353c8eb2",
            "metadata": {},
            "outputs": [],
            "source": [
                "task_labels = ['click', 'conversion']\n",
                "dense_features_list = [col for col in df.columns if 'dense' in col]\n",
                "sparse_features_list = [col for col in df.columns if 'sparse' in col] + ['user_id', 'item_id']\n",
                "sequence_features_list = [col for col in df.columns if 'sequence' in col]\n",
                "\n",
                "# we need to convert the sequence features stored as string representations of lists in the CSV to actual list objects\n",
                "for col in df.columns:\n",
                "    if 'sequence' in col:\n",
                "        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "833b3dc5",
            "metadata": {},
            "source": [
                "After processing the data into the required format, split out training and inference sets so the model can be evaluated on metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "886906e4",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=2025)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34e07b6c",
            "metadata": {},
            "source": [
                "Next we prepare the model by defining the different feature types it needs and passing them into the model. Here we use the built-in DenseFeature, SequenceFeature, and SparseFeature classes from nextrec."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "82c38f7f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from nextrec.basic.features import DenseFeature, SequenceFeature, SparseFeature\n",
                "\n",
                "# we treat all dense features as DenseFeature, proj_dim=1 means no projection is performed. When proj_dim is greater than 1, \n",
                "# it indicates that a linear transformation is performed on the dense features, similar to the effect of embedding\n",
                "dense_features = [DenseFeature(name=feat, proj_dim=1) for feat in dense_features_list] \n",
                "\n",
                "# Sparse features and sequence features are generally embedded, and the embedding_dim can be adjusted according to actual needs\n",
                "sparse_features = []\n",
                "for feat in sparse_features_list:\n",
                "    vocab_size = 20001 # assuming the vocabulary size for each sparse feature is 20001\n",
                "    # SparseFeature can also set some other parameters, such as initializer, regularization, and embedding_name, etc. \n",
                "    # When two features share embedding, the same embedding_name can be set       \n",
                "    sparse_features.append(SparseFeature(name=feat, vocab_size=vocab_size, embedding_dim=4, embedding_name=feat)) \n",
                "\n",
                "# Sequence features are handled similarly to sparse features, but you also need to set the maximum length max_len and padding_idx parameters\n",
                "sequence_features = []\n",
                "for feat in sequence_features_list:\n",
                "    vocab_size = 500 # assuming the vocabulary size for each sequence feature is 500\n",
                "    sequence_features.append(\n",
                "        SequenceFeature(\n",
                "            name=feat,\n",
                "            vocab_size=vocab_size,\n",
                "            max_len=20,\n",
                "            embedding_dim=8,\n",
                "            padding_idx=0\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5c71a374",
            "metadata": {},
            "source": [
                "Time to use the DataLoader. A DataLoader prepares iterative batches for the model. To keep things simple, we provide RecDataLoader.\n",
                "\n",
                "RecDataLoader is a powerful utility that accepts a dict, DataFrame, DataLoader, or a path. It can also stream data by setting streaming=True. This instance fits every training scenario in the NextRec framework, and we strongly recommend giving it a try to avoid unnecessary hassle.\n",
                "\n",
                "You can skip it if you prefer—NextRec also supports training directly with a dict or DataFrame, as shown later.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "14b6d004",
            "metadata": {},
            "outputs": [],
            "source": [
                "from nextrec.data.dataloader import RecDataLoader\n",
                "\n",
                "task_labels = ['click', 'conversion']\n",
                "\n",
                "dataloader = RecDataLoader(\n",
                "    dense_features=dense_features,\n",
                "    sparse_features=sparse_features,\n",
                "    sequence_features=sequence_features,\n",
                "    target=task_labels,\n",
                ")\n",
                "\n",
                "# We need to create dataloaders for the training set and validation set separately\n",
                "train_loader = dataloader.create_dataloader(\n",
                "    data=train_df,\n",
                "    batch_size=512,\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "valid_loader = dataloader.create_dataloader(\n",
                "    data=valid_df,\n",
                "    batch_size=512,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "\n",
                "# you can also pass in a path to configure a streaming data loader\n",
                "# train_loader = dataloader.create_dataloader(\n",
                "#     data='/path/to/train/data',\n",
                "#     batch_size=512,\n",
                "#     shuffle=True,\n",
                "#     streaming=True\n",
                "# )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f0e6cd8e",
            "metadata": {},
            "source": [
                "Now let's choose a model to train. NextRec offers more than 20 industry-standard models for retrieval, ranking, and multi-task learning. Here we start with a classic MMOE model. Before training, we need to instantiate the model and assign parameters.\n",
                "\n",
                "After instantiation we compile the model, assigning the optimizer, scheduler, and loss functions to the trainer. NextRec supports more than 8 optimizers, 10 schedulers, 20 loss functions, and imbalance-aware losses.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "a31cce1f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\u001b[1m\u001b[94mModel Summary: MMOE\u001b[0m\n",
                        "\n",
                        "\n",
                        "\u001b[1m\u001b[36mFeature Configuration\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Dense Features (8):\n",
                        "  1. dense_0             \n",
                        "  2. dense_1             \n",
                        "  3. dense_2             \n",
                        "  4. dense_3             \n",
                        "  5. dense_4             \n",
                        "  6. dense_5             \n",
                        "  7. dense_6             \n",
                        "  8. dense_7             \n",
                        "\n",
                        "Sparse Features (14):\n",
                        "  #    Name           Vocab Size        Embed Name  Embed Dim\n",
                        "  ---- ------------ ------------ ----------------- ----------\n",
                        "  1    sparse_0           200002          sparse_0          4\n",
                        "  2    sparse_1           200002          sparse_1          4\n",
                        "  3    sparse_2           200002          sparse_2          4\n",
                        "  4    sparse_3           200002          sparse_3          4\n",
                        "  5    sparse_4           200002          sparse_4          4\n",
                        "  6    sparse_5           200002          sparse_5          4\n",
                        "  7    sparse_6           200002          sparse_6          4\n",
                        "  8    sparse_7           200002          sparse_7          4\n",
                        "  9    sparse_8           200002          sparse_8          4\n",
                        "  10   sparse_9           200002          sparse_9          4\n",
                        "  11   sparse_10          200002         sparse_10          4\n",
                        "  12   sparse_11          200002         sparse_11          4\n",
                        "  13   user_id            200002           user_id          4\n",
                        "  14   item_id            200002           item_id          4\n",
                        "\n",
                        "Sequence Features (1):\n",
                        "  #    Name           Vocab Size        Embed Name  Embed Dim    Max Len\n",
                        "  ---- ------------ ------------ ----------------- ---------- ----------\n",
                        "  1    sequence_0            200        sequence_0          8         20\n",
                        "\n",
                        "\u001b[1m\u001b[36mModel Parameters\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Model Architecture:\n",
                        "MMOE(\n",
                        "  (embedding): EmbeddingLayer(\n",
                        "    (embed_dict): ModuleDict(\n",
                        "      (sparse_0): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_1): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_2): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_3): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_4): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_5): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_6): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_7): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_8): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_9): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_10): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_11): Embedding(200002, 4, padding_idx=0)\n",
                        "      (user_id): Embedding(200002, 4, padding_idx=0)\n",
                        "      (item_id): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sequence_0): Embedding(200, 8, padding_idx=0)\n",
                        "    )\n",
                        "    (dense_transforms): ModuleDict()\n",
                        "    (sequence_poolings): ModuleDict(\n",
                        "      (sequence_0): AveragePooling()\n",
                        "    )\n",
                        "  )\n",
                        "  (experts): ModuleList(\n",
                        "    (0-3): 4 x MLP(\n",
                        "      (mlp): Sequential(\n",
                        "        (0): Linear(in_features=72, out_features=128, bias=True)\n",
                        "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
                        "        (2): LeakyReLU(negative_slope=0.01)\n",
                        "        (3): Dropout(p=0.3, inplace=False)\n",
                        "        (4): Linear(in_features=128, out_features=64, bias=True)\n",
                        "        (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
                        "        (6): LeakyReLU(negative_slope=0.01)\n",
                        "        (7): Dropout(p=0.3, inplace=False)\n",
                        "      )\n",
                        "    )\n",
                        "  )\n",
                        "  (gates): ModuleList(\n",
                        "    (0-1): 2 x Sequential(\n",
                        "      (0): Linear(in_features=72, out_features=4, bias=True)\n",
                        "      (1): Softmax(dim=1)\n",
                        "    )\n",
                        "  )\n",
                        "  (towers): ModuleList(\n",
                        "    (0-1): 2 x MLP(\n",
                        "      (mlp): Sequential(\n",
                        "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
                        "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
                        "        (2): LeakyReLU(negative_slope=0.01)\n",
                        "        (3): Dropout(p=0.2, inplace=False)\n",
                        "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
                        "        (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
                        "        (6): LeakyReLU(negative_slope=0.01)\n",
                        "        (7): Dropout(p=0.2, inplace=False)\n",
                        "        (8): Linear(in_features=32, out_features=1, bias=True)\n",
                        "      )\n",
                        "    )\n",
                        "  )\n",
                        "  (prediction_layer): TaskHead(\n",
                        "    (prediction): PredictionLayer()\n",
                        "  )\n",
                        ")\n",
                        "\n",
                        "Total Parameters:        11,287,164\n",
                        "Trainable Parameters:    11,287,164\n",
                        "Non-trainable Parameters: 0\n",
                        "Layer-wise Parameters:\n",
                        "  embedding                     : 11,201,712\n",
                        "  experts                       : 71,936\n",
                        "  gates                         : 584\n",
                        "  towers                        : 12,930\n",
                        "  prediction_layer              : 2\n",
                        "\n",
                        "\u001b[1m\u001b[36mTraining Configuration\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Task Type:               ['binary', 'binary']\n",
                        "Number of Tasks:         2\n",
                        "Metrics:                 ['auc', 'recall', 'precision']\n",
                        "Target Columns:          ['click', 'conversion']\n",
                        "Device:                  cpu\n",
                        "Optimizer:               adam\n",
                        "  lr                       : 0.001\n",
                        "  weight_decay             : 1e-05\n",
                        "Loss Function:           ['bce', 'bce']\n",
                        "Loss Weights:            None\n",
                        "GradNorm Enabled:        True\n",
                        "  GradNorm alpha:        1.5\n",
                        "  GradNorm lr:           0.025\n",
                        "Regularization:\n",
                        "  Embedding L1:          1e-06\n",
                        "  Embedding L2:          1e-05\n",
                        "  Dense L1:              1e-05\n",
                        "  Dense L2:              0.0001\n",
                        "Other Settings:\n",
                        "  Early Stop Patience:   20\n",
                        "  Max Gradient Norm:     1.0\n",
                        "  Max Metrics Samples:   200000\n",
                        "  Session ID:            mmoe_task\n",
                        "  Features Config Path:  /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/features_config.pkl\n",
                        "  Latest Checkpoint:     /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/MMOE_checkpoint.pt\n",
                        "\n",
                        "\u001b[1m\u001b[36mData Summary\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Train Samples:                     80,000\n",
                        "click:\n",
                        "0:                                 27232 (34.04%)\n",
                        "1:                                 52768 (65.96%)\n",
                        "conversion:\n",
                        "0:                                 52937 (66.17%)\n",
                        "1:                                 27063 (33.83%)\n",
                        "\n",
                        "Valid Samples:                     20,000\n",
                        "click:\n",
                        "0:                                 6798 (33.99%)\n",
                        "1:                                 13202 (66.01%)\n",
                        "conversion:\n",
                        "0:                                 13197 (65.98%)\n",
                        "1:                                 6803 (34.02%)\n",
                        "\n",
                        "\u001b[36mTensorBoard logs saved to: /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/tensorboard\u001b[0m\n",
                        "\u001b[36mTo view logs, run:\u001b[0m\n",
                        "\u001b[36m    tensorboard --logdir /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/tensorboard --port 6006\u001b[0m\n",
                        "\u001b[36mThen SSH port forward:\u001b[0m\n",
                        "\u001b[36m    ssh -L 6006:localhost:6006 zyaztec@madelixiyubawangdeMacBook-Pro.local\u001b[0m\n",
                        "\n",
                        "\u001b[1m\u001b[94m[Training]\u001b[0m\n",
                        "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Start training:                    1 epochs\n",
                        "Model device:                      cpu\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1: 84/157 elapsed=0:00:10 speed=8.38/s ETA=0:00:08\n",
                        "Epoch 1: 157/157 elapsed=0:00:19 speed=8.20/s ETA=0:00:00\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">      Epoch 1/1 - Train (loss=1.1518)       </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> click      </span>│ 0.7917 │ 0.8363 │    0.7907 │\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.6594 │ 0.2514 │    0.5408 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m      Epoch 1/1 - Train (loss=1.1518)       \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mclick     \u001b[0m\u001b[1m \u001b[0m│ 0.7917 │ 0.8363 │    0.7907 │\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.6594 │ 0.2514 │    0.5408 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">      Epoch 1/1 - Train (loss=1.1518)       </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> click      </span>│ 0.7917 │ 0.8363 │    0.7907 │\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.6594 │ 0.2514 │    0.5408 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m      Epoch 1/1 - Train (loss=1.1518)       \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mclick     \u001b[0m\u001b[1m \u001b[0m│ 0.7917 │ 0.8363 │    0.7907 │\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.6594 │ 0.2514 │    0.5408 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">             Epoch 1/1 - Valid              </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> click      </span>│ 0.8557 │ 0.8453 │    0.8310 │\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.7197 │ 0.4113 │    0.5828 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m             Epoch 1/1 - Valid              \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mclick     \u001b[0m\u001b[1m \u001b[0m│ 0.8557 │ 0.8453 │    0.8310 │\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.7197 │ 0.4113 │    0.5828 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">             Epoch 1/1 - Valid              </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> click      </span>│ 0.8557 │ 0.8453 │    0.8310 │\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.7197 │ 0.4113 │    0.5828 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m             Epoch 1/1 - Valid              \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mclick     \u001b[0m\u001b[1m \u001b[0m│ 0.8557 │ 0.8453 │    0.8310 │\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.7197 │ 0.4113 │    0.5828 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved checkpoint to /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/MMOE_checkpoint.pt\n",
                        "Saved checkpoint to /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/MMOE_best.pt\n",
                        "\u001b[94mSaved best model to:               /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/MMOE_best.pt with val_auc_click: 0.855681\u001b[0m\n",
                        "\u001b[94mRestoring model weights from epoch: 1 with best val_auc_click: 0.855681\u001b[0m\n",
                        "\n",
                        "\u001b[1m\u001b[94mTraining finished.\u001b[0m\n",
                        "\n",
                        "Load best model from:              /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/mmoe_task/MMOE_best.pt\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "MMOE(\n",
                            "  (embedding): EmbeddingLayer(\n",
                            "    (embed_dict): ModuleDict(\n",
                            "      (sparse_0): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_1): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_2): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_3): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_4): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_5): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_6): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_7): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_8): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_9): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_10): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_11): Embedding(200002, 4, padding_idx=0)\n",
                            "      (user_id): Embedding(200002, 4, padding_idx=0)\n",
                            "      (item_id): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sequence_0): Embedding(200, 8, padding_idx=0)\n",
                            "    )\n",
                            "    (dense_transforms): ModuleDict()\n",
                            "    (sequence_poolings): ModuleDict(\n",
                            "      (sequence_0): AveragePooling()\n",
                            "    )\n",
                            "  )\n",
                            "  (experts): ModuleList(\n",
                            "    (0-3): 4 x MLP(\n",
                            "      (mlp): Sequential(\n",
                            "        (0): Linear(in_features=72, out_features=128, bias=True)\n",
                            "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
                            "        (2): LeakyReLU(negative_slope=0.01)\n",
                            "        (3): Dropout(p=0.3, inplace=False)\n",
                            "        (4): Linear(in_features=128, out_features=64, bias=True)\n",
                            "        (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
                            "        (6): LeakyReLU(negative_slope=0.01)\n",
                            "        (7): Dropout(p=0.3, inplace=False)\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (gates): ModuleList(\n",
                            "    (0-1): 2 x Sequential(\n",
                            "      (0): Linear(in_features=72, out_features=4, bias=True)\n",
                            "      (1): Softmax(dim=1)\n",
                            "    )\n",
                            "  )\n",
                            "  (towers): ModuleList(\n",
                            "    (0-1): 2 x MLP(\n",
                            "      (mlp): Sequential(\n",
                            "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
                            "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
                            "        (2): LeakyReLU(negative_slope=0.01)\n",
                            "        (3): Dropout(p=0.2, inplace=False)\n",
                            "        (4): Linear(in_features=64, out_features=32, bias=True)\n",
                            "        (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
                            "        (6): LeakyReLU(negative_slope=0.01)\n",
                            "        (7): Dropout(p=0.2, inplace=False)\n",
                            "        (8): Linear(in_features=32, out_features=1, bias=True)\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (prediction_layer): TaskHead(\n",
                            "    (prediction): PredictionLayer()\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 30,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from nextrec.models.multi_task.mmoe import MMOE\n",
                "\n",
                "# we need to set the parameters of the expert network and task tower for mmoe. Here we set 4 expert networks, each containing two layers,\n",
                "# and the task tower also contains two layers. We have two tasks, click and conversion, \n",
                "# each of which is a binary classification task, so the task parameter is set to ['binary', 'binary']\n",
                "model = MMOE(\n",
                "    dense_features=dense_features,\n",
                "    sparse_features=sparse_features,\n",
                "    sequence_features=sequence_features,\n",
                "    expert_params= {\"dims\": [128, 64],  \"activation\": \"leaky_relu\", \"dropout\": 0.3},\n",
                "    num_experts=4,  # 4 expert networks\n",
                "    tower_params_list=[{\"dims\": [64, 32], \"activation\": \"leaky_relu\", \"dropout\": 0.2},  # click task\n",
                "                       {\"dims\": [64, 32], \"activation\": \"leaky_relu\", \"dropout\": 0.2},  # conversion task\n",
                "                        ],\n",
                "    target=task_labels,  # multiple task labels\n",
                "    task=['binary', 'binary'],  # each task type\n",
                "    device='cpu',  \n",
                "    embedding_l1_reg=1e-6,\n",
                "    embedding_l2_reg=1e-5,\n",
                "    dense_l1_reg=1e-5,\n",
                "    dense_l2_reg=1e-4,\n",
                "    session_id=\"mmoe_task\"    # session id is used to distinguish different training tasks, and will save training logs, checkpoints, model parameters, etc. in a folder named after the session_id\n",
                "    \n",
                ")\n",
                "\n",
                "# Compile the model to set the optimizer and loss function. Configure them via compile().\n",
                "# but we recommend passing them in compile for clarity.\n",
                "# Here we use the Adam optimizer with a learning rate of 1e-3 and weight decay of 1e-5\n",
                "# Each task uses binary cross-entropy loss\n",
                "model.compile(\n",
                "    optimizer=\"adam\",\n",
                "    optimizer_params={\"lr\": 1e-3, \"weight_decay\": 1e-5},\n",
                "    loss=['bce', 'bce'],  # loss for each task\n",
                "    loss_weights=\"grad_norm\" # use grad_norm to automatically adjust the weights of each task's loss during training. you can also set it to a list of fixed weights, e.g., [1.0, 0.5]\n",
                ")\n",
                "\n",
                "# Now we can start training the model. Here we set the training to 3 epochs, but you can adjust it according to your actual situation.\n",
                "# At the same time, we can also set evaluation metrics for each task. Here we set AUC, Recall, and Precision metrics for each task.\n",
                "# Note you can check the training logs and model checkpoints in the nextrec_logs/mmoe_iflytek folder\n",
                "# pass use_tensorboard，use_wandb，use_swanlab and wandb_kwargs, swanlab_kwargs to enable logging to TensorBoard, Weights & Biases, and SwanLab respectively.\n",
                "# for exameple, use_swanlab=True, swanlab_kwargs={\"project\": \"NextRec\", \"name\": \"MMOE_experiment\"}\n",
                "model.fit(\n",
                "    train_data=train_loader, \n",
                "    valid_data=valid_loader,\n",
                "    metrics={\n",
                "        'click': ['auc', 'recall', 'precision'],\n",
                "        'conversion': ['auc', 'recall', 'precision']\n",
                "    },\n",
                "    epochs=1,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2f817212",
            "metadata": {},
            "source": [
                "Next we train a ranking model using AutoINT as the example, switching the task from multi-task to single-task. This model comes from a Peking University paper published at CIKM 2019; you can read an explainer [here](https://guyuecanhui.github.io/2020/05/09/paper-2019-pku-autoint/).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "fd350faa",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\u001b[1m\u001b[94mModel Summary: AUTOINT\u001b[0m\n",
                        "\n",
                        "\n",
                        "\u001b[1m\u001b[36mFeature Configuration\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Dense Features (8):\n",
                        "  1. dense_0             \n",
                        "  2. dense_1             \n",
                        "  3. dense_2             \n",
                        "  4. dense_3             \n",
                        "  5. dense_4             \n",
                        "  6. dense_5             \n",
                        "  7. dense_6             \n",
                        "  8. dense_7             \n",
                        "\n",
                        "Sparse Features (14):\n",
                        "  #    Name           Vocab Size        Embed Name  Embed Dim\n",
                        "  ---- ------------ ------------ ----------------- ----------\n",
                        "  1    sparse_0           200002          sparse_0          4\n",
                        "  2    sparse_1           200002          sparse_1          4\n",
                        "  3    sparse_2           200002          sparse_2          4\n",
                        "  4    sparse_3           200002          sparse_3          4\n",
                        "  5    sparse_4           200002          sparse_4          4\n",
                        "  6    sparse_5           200002          sparse_5          4\n",
                        "  7    sparse_6           200002          sparse_6          4\n",
                        "  8    sparse_7           200002          sparse_7          4\n",
                        "  9    sparse_8           200002          sparse_8          4\n",
                        "  10   sparse_9           200002          sparse_9          4\n",
                        "  11   sparse_10          200002         sparse_10          4\n",
                        "  12   sparse_11          200002         sparse_11          4\n",
                        "  13   user_id            200002           user_id          4\n",
                        "  14   item_id            200002           item_id          4\n",
                        "\n",
                        "Sequence Features (1):\n",
                        "  #    Name           Vocab Size        Embed Name  Embed Dim    Max Len\n",
                        "  ---- ------------ ------------ ----------------- ---------- ----------\n",
                        "  1    sequence_0            200        sequence_0          8         20\n",
                        "\n",
                        "\u001b[1m\u001b[36mModel Parameters\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Model Architecture:\n",
                        "AutoInt(\n",
                        "  (embedding): EmbeddingLayer(\n",
                        "    (embed_dict): ModuleDict(\n",
                        "      (sparse_0): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_1): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_2): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_3): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_4): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_5): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_6): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_7): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_8): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_9): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_10): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_11): Embedding(200002, 4, padding_idx=0)\n",
                        "      (user_id): Embedding(200002, 4, padding_idx=0)\n",
                        "      (item_id): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sequence_0): Embedding(200, 8, padding_idx=0)\n",
                        "    )\n",
                        "    (dense_transforms): ModuleDict()\n",
                        "    (sequence_poolings): ModuleDict(\n",
                        "      (sequence_0): AveragePooling()\n",
                        "    )\n",
                        "  )\n",
                        "  (projection_layers): ModuleList(\n",
                        "    (0-7): 8 x Linear(in_features=1, out_features=8, bias=False)\n",
                        "    (8-21): 14 x Linear(in_features=4, out_features=8, bias=False)\n",
                        "    (22): Linear(in_features=8, out_features=8, bias=False)\n",
                        "  )\n",
                        "  (attention_layers): ModuleList(\n",
                        "    (0-2): 3 x MultiHeadSelfAttention(\n",
                        "      (q_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (k_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (v_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (out_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (dropout): Dropout(p=0.0, inplace=False)\n",
                        "    )\n",
                        "  )\n",
                        "  (fc): Linear(in_features=184, out_features=1, bias=True)\n",
                        "  (prediction_layer): TaskHead(\n",
                        "    (prediction): PredictionLayer()\n",
                        "  )\n",
                        ")\n",
                        "\n",
                        "Total Parameters:        11,203,242\n",
                        "Trainable Parameters:    11,203,242\n",
                        "Non-trainable Parameters: 0\n",
                        "Layer-wise Parameters:\n",
                        "  embedding                     : 11,201,712\n",
                        "  projection_layers             : 576\n",
                        "  attention_layers              : 768\n",
                        "  fc                            : 185\n",
                        "  prediction_layer              : 1\n",
                        "\n",
                        "\u001b[1m\u001b[36mTraining Configuration\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Task Type:               binary\n",
                        "Number of Tasks:         1\n",
                        "Metrics:                 ['auc', 'recall', 'precision']\n",
                        "Target Columns:          ['conversion']\n",
                        "Device:                  cpu\n",
                        "Optimizer:               adam\n",
                        "  lr                       : 0.001\n",
                        "  weight_decay             : 1e-05\n",
                        "Loss Function:           bce\n",
                        "Loss Weights:            None\n",
                        "GradNorm Enabled:        False\n",
                        "Regularization:\n",
                        "  Embedding L1:          1e-06\n",
                        "  Embedding L2:          1e-05\n",
                        "  Dense L1:              1e-05\n",
                        "  Dense L2:              0.0001\n",
                        "Other Settings:\n",
                        "  Early Stop Patience:   20\n",
                        "  Max Gradient Norm:     1.0\n",
                        "  Max Metrics Samples:   200000\n",
                        "  Session ID:            autoint_iflytek\n",
                        "  Features Config Path:  /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/features_config.pkl\n",
                        "  Latest Checkpoint:     /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/AUTOINT_checkpoint.pt\n",
                        "\n",
                        "\u001b[1m\u001b[36mData Summary\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Train Samples:                     80,000\n",
                        "conversion:\n",
                        "0:                                 52937 (66.17%)\n",
                        "1:                                 27063 (33.83%)\n",
                        "\n",
                        "Valid Samples:                     80,000\n",
                        "conversion:\n",
                        "0:                                 52937 (66.17%)\n",
                        "1:                                 27063 (33.83%)\n",
                        "\n",
                        "\u001b[36mTensorBoard logs saved to: /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/tensorboard\u001b[0m\n",
                        "\u001b[36mTo view logs, run:\u001b[0m\n",
                        "\u001b[36m    tensorboard --logdir /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/tensorboard --port 6006\u001b[0m\n",
                        "\u001b[36mThen SSH port forward:\u001b[0m\n",
                        "\u001b[36m    ssh -L 6006:localhost:6006 zyaztec@madelixiyubawangdeMacBook-Pro.local\u001b[0m\n",
                        "\n",
                        "\u001b[1m\u001b[94m[Training]\u001b[0m\n",
                        "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Start training:                    1 epochs\n",
                        "Model device:                      cpu\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1: 157/157 elapsed=0:00:07 speed=20.65/s ETA=0:00:00\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">      Epoch 1/1 - Train (loss=0.6315)       </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.5792 │ 0.0873 │    0.4605 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m      Epoch 1/1 - Train (loss=0.6315)       \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.5792 │ 0.0873 │    0.4605 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">      Epoch 1/1 - Train (loss=0.6315)       </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.5792 │ 0.0873 │    0.4605 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m      Epoch 1/1 - Train (loss=0.6315)       \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.5792 │ 0.0873 │    0.4605 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">             Epoch 1/1 - Valid              </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.6799 │ 0.2296 │    0.5840 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m             Epoch 1/1 - Valid              \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.6799 │ 0.2296 │    0.5840 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">             Epoch 1/1 - Valid              </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.6799 │ 0.2296 │    0.5840 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m             Epoch 1/1 - Valid              \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.6799 │ 0.2296 │    0.5840 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved checkpoint to /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/AUTOINT_checkpoint.pt\n",
                        "Saved checkpoint to /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/AUTOINT_best.pt\n",
                        "\u001b[94mSaved best model to:               /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/AUTOINT_best.pt with val_auc: 0.679912\u001b[0m\n",
                        "\u001b[94mRestoring model weights from epoch: 1 with best val_auc: 0.679912\u001b[0m\n",
                        "\n",
                        "\u001b[1m\u001b[94mTraining finished.\u001b[0m\n",
                        "\n",
                        "Load best model from:              /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/AUTOINT_best.pt\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "AutoInt(\n",
                            "  (embedding): EmbeddingLayer(\n",
                            "    (embed_dict): ModuleDict(\n",
                            "      (sparse_0): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_1): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_2): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_3): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_4): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_5): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_6): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_7): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_8): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_9): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_10): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_11): Embedding(200002, 4, padding_idx=0)\n",
                            "      (user_id): Embedding(200002, 4, padding_idx=0)\n",
                            "      (item_id): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sequence_0): Embedding(200, 8, padding_idx=0)\n",
                            "    )\n",
                            "    (dense_transforms): ModuleDict()\n",
                            "    (sequence_poolings): ModuleDict(\n",
                            "      (sequence_0): AveragePooling()\n",
                            "    )\n",
                            "  )\n",
                            "  (projection_layers): ModuleList(\n",
                            "    (0-7): 8 x Linear(in_features=1, out_features=8, bias=False)\n",
                            "    (8-21): 14 x Linear(in_features=4, out_features=8, bias=False)\n",
                            "    (22): Linear(in_features=8, out_features=8, bias=False)\n",
                            "  )\n",
                            "  (attention_layers): ModuleList(\n",
                            "    (0-2): 3 x MultiHeadSelfAttention(\n",
                            "      (q_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (k_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (v_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (out_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (dropout): Dropout(p=0.0, inplace=False)\n",
                            "    )\n",
                            "  )\n",
                            "  (fc): Linear(in_features=184, out_features=1, bias=True)\n",
                            "  (prediction_layer): TaskHead(\n",
                            "    (prediction): PredictionLayer()\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from nextrec.models.ranking.autoint import AutoInt\n",
                "\n",
                "target = 'conversion'\n",
                "\n",
                "# Since the target has changed, we recreate the dataloader\n",
                "dataloader = RecDataLoader(\n",
                "    dense_features=dense_features,\n",
                "    sparse_features=sparse_features,\n",
                "    sequence_features=sequence_features,\n",
                "    target=target,\n",
                ")\n",
                "\n",
                "train_loader = dataloader.create_dataloader(\n",
                "    data=train_df,\n",
                "    batch_size=512,\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "valid_loader = dataloader.create_dataloader(\n",
                "    data=train_df,\n",
                "    batch_size=512,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "model = AutoInt(\n",
                "    dense_features=dense_features,\n",
                "    sparse_features=sparse_features,\n",
                "    sequence_features=sequence_features,\n",
                "    att_layer_num=3,\n",
                "    att_embedding_dim=8,\n",
                "    att_head_num=2,\n",
                "    att_dropout=0.0,\n",
                "    att_use_residual=True,\n",
                "    target=target,\n",
                "    device='cpu',\n",
                "    embedding_l1_reg=1e-6,\n",
                "    dense_l1_reg=1e-5,\n",
                "    embedding_l2_reg=1e-5,\n",
                "    dense_l2_reg=1e-4,\n",
                "    session_id=\"autoint_iflytek\"\n",
                ")\n",
                "\n",
                "# compile the model to set the optimizer and loss function\n",
                "model.compile(\n",
                "    optimizer=\"adam\",\n",
                "    optimizer_params={\n",
                "        \"lr\": 1e-3,\n",
                "        \"weight_decay\": 1e-5\n",
                "    },\n",
                "    loss=\"bce\",\n",
                ")\n",
                "\n",
                "# training the model\n",
                "model.fit(\n",
                "    train_data=train_loader,\n",
                "    valid_data=valid_loader,\n",
                "    metrics=['auc',\n",
                "             'recall',\n",
                "             'precision'],\n",
                "    epochs=1,\n",
                "    batch_size=512,\n",
                "    shuffle=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "534113f0",
            "metadata": {},
            "source": [
                "Prefer not to build the dataloader manually? NextRec also supports passing a DataFrame or dict directly—as long as you have enough memory. (That said, RecDataLoader remains the better choice.)\n",
                "\n",
                "You can also omit valid_data, in which case the model trains on the full dataset.\n",
                "\n",
                "Or set valid_split to let the model automatically carve out a validation set from the training data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "73d7ad57",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\u001b[1m\u001b[94mModel Summary: AUTOINT\u001b[0m\n",
                        "\n",
                        "\n",
                        "\u001b[1m\u001b[36mFeature Configuration\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Dense Features (8):\n",
                        "  1. dense_0             \n",
                        "  2. dense_1             \n",
                        "  3. dense_2             \n",
                        "  4. dense_3             \n",
                        "  5. dense_4             \n",
                        "  6. dense_5             \n",
                        "  7. dense_6             \n",
                        "  8. dense_7             \n",
                        "\n",
                        "Sparse Features (14):\n",
                        "  #    Name           Vocab Size        Embed Name  Embed Dim\n",
                        "  ---- ------------ ------------ ----------------- ----------\n",
                        "  1    sparse_0              100          sparse_0          4\n",
                        "  2    sparse_1              100          sparse_1          4\n",
                        "  3    sparse_2              100          sparse_2          4\n",
                        "  4    sparse_3              100          sparse_3          4\n",
                        "  5    sparse_4              100          sparse_4          4\n",
                        "  6    sparse_5              100          sparse_5          4\n",
                        "  7    sparse_6              100          sparse_6          4\n",
                        "  8    sparse_7              100          sparse_7          4\n",
                        "  9    sparse_8              100          sparse_8          4\n",
                        "  10   sparse_9              100          sparse_9          4\n",
                        "  11   sparse_10             100         sparse_10          4\n",
                        "  12   sparse_11             100         sparse_11          4\n",
                        "  13   user_id               100           user_id          4\n",
                        "  14   item_id               100           item_id          4\n",
                        "\n",
                        "Sequence Features (1):\n",
                        "  #    Name           Vocab Size        Embed Name  Embed Dim    Max Len\n",
                        "  ---- ------------ ------------ ----------------- ---------- ----------\n",
                        "  1    sequence_0           5000        sequence_0          8         20\n",
                        "\n",
                        "\u001b[1m\u001b[36mModel Parameters\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Model Architecture:\n",
                        "AutoInt(\n",
                        "  (embedding): EmbeddingLayer(\n",
                        "    (embed_dict): ModuleDict(\n",
                        "      (sparse_0): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_1): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_2): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_3): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_4): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_5): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_6): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_7): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_8): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_9): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_10): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sparse_11): Embedding(200002, 4, padding_idx=0)\n",
                        "      (user_id): Embedding(200002, 4, padding_idx=0)\n",
                        "      (item_id): Embedding(200002, 4, padding_idx=0)\n",
                        "      (sequence_0): Embedding(200, 8, padding_idx=0)\n",
                        "    )\n",
                        "    (dense_transforms): ModuleDict()\n",
                        "    (sequence_poolings): ModuleDict(\n",
                        "      (sequence_0): AveragePooling()\n",
                        "    )\n",
                        "  )\n",
                        "  (projection_layers): ModuleList(\n",
                        "    (0-7): 8 x Linear(in_features=1, out_features=8, bias=False)\n",
                        "    (8-21): 14 x Linear(in_features=4, out_features=8, bias=False)\n",
                        "    (22): Linear(in_features=8, out_features=8, bias=False)\n",
                        "  )\n",
                        "  (attention_layers): ModuleList(\n",
                        "    (0-2): 3 x MultiHeadSelfAttention(\n",
                        "      (q_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (k_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (v_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (out_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                        "      (dropout): Dropout(p=0.0, inplace=False)\n",
                        "    )\n",
                        "  )\n",
                        "  (fc): Linear(in_features=184, out_features=1, bias=True)\n",
                        "  (prediction_layer): TaskHead(\n",
                        "    (prediction): PredictionLayer()\n",
                        "  )\n",
                        ")\n",
                        "\n",
                        "Total Parameters:        11,203,242\n",
                        "Trainable Parameters:    11,203,242\n",
                        "Non-trainable Parameters: 0\n",
                        "Layer-wise Parameters:\n",
                        "  embedding                     : 11,201,712\n",
                        "  projection_layers             : 576\n",
                        "  attention_layers              : 768\n",
                        "  fc                            : 185\n",
                        "  prediction_layer              : 1\n",
                        "\n",
                        "\u001b[1m\u001b[36mTraining Configuration\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Task Type:               binary\n",
                        "Number of Tasks:         1\n",
                        "Metrics:                 ['auc', 'recall', 'precision']\n",
                        "Target Columns:          ['conversion']\n",
                        "Device:                  cpu\n",
                        "Optimizer:               adam\n",
                        "  lr                       : 0.001\n",
                        "  weight_decay             : 1e-05\n",
                        "Loss Function:           bce\n",
                        "Loss Weights:            None\n",
                        "GradNorm Enabled:        False\n",
                        "Regularization:\n",
                        "  Embedding L1:          1e-06\n",
                        "  Embedding L2:          1e-05\n",
                        "  Dense L1:              1e-05\n",
                        "  Dense L2:              0.0001\n",
                        "Other Settings:\n",
                        "  Early Stop Patience:   20\n",
                        "  Max Gradient Norm:     1.0\n",
                        "  Max Metrics Samples:   200000\n",
                        "  Session ID:            autoint_iflytek\n",
                        "  Features Config Path:  /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/features_config.pkl\n",
                        "  Latest Checkpoint:     /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/AUTOINT_checkpoint.pt\n",
                        "\n",
                        "\u001b[1m\u001b[36mData Summary\u001b[0m\n",
                        "\u001b[36m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Train Samples:                     80,000\n",
                        "conversion:\n",
                        "0:                                 52937 (66.17%)\n",
                        "1:                                 27063 (33.83%)\n",
                        "\n",
                        "\u001b[36mTensorBoard logs saved to: /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/tensorboard\u001b[0m\n",
                        "\u001b[36mTo view logs, run:\u001b[0m\n",
                        "\u001b[36m    tensorboard --logdir /Users/zyaztec/DailyWork/建模代码整理/NextRec/tutorials/notebooks/en/nextrec_logs/autoint_iflytek/tensorboard --port 6006\u001b[0m\n",
                        "\u001b[36mThen SSH port forward:\u001b[0m\n",
                        "\u001b[36m    ssh -L 6006:localhost:6006 zyaztec@madelixiyubawangdeMacBook-Pro.local\u001b[0m\n",
                        "\n",
                        "\u001b[1m\u001b[94m[Training]\u001b[0m\n",
                        "\u001b[94m--------------------------------------------------------------------------------\u001b[0m\n",
                        "Start training:                    1 epochs\n",
                        "Model device:                      cpu\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1: 157/157 elapsed=0:00:07 speed=20.68/s ETA=0:00:00\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">      Epoch 1/1 - Train (loss=0.5722)       </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.7160 │ 0.3566 │    0.5947 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m      Epoch 1/1 - Train (loss=0.5722)       \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.7160 │ 0.3566 │    0.5947 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">      Epoch 1/1 - Train (loss=0.5722)       </span>\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│<span style=\"font-weight: bold\"> Task       </span>│<span style=\"font-weight: bold\">    auc </span>│<span style=\"font-weight: bold\"> recall </span>│<span style=\"font-weight: bold\"> precision </span>│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│<span style=\"font-weight: bold\"> conversion </span>│ 0.7160 │ 0.3566 │    0.5947 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m      Epoch 1/1 - Train (loss=0.5722)       \u001b[0m\n",
                            "╭────────────┬────────┬────────┬───────────╮\n",
                            "│\u001b[1m \u001b[0m\u001b[1mTask      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m   auc\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mrecall\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1mprecision\u001b[0m\u001b[1m \u001b[0m│\n",
                            "├────────────┼────────┼────────┼───────────┤\n",
                            "│\u001b[1m \u001b[0m\u001b[1mconversion\u001b[0m\u001b[1m \u001b[0m│ 0.7160 │ 0.3566 │    0.5947 │\n",
                            "╰────────────┴────────┴────────┴───────────╯\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[33mEarly stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,auc,recall,precision\u001b[0m\n",
                        "\n",
                        "\u001b[1m\u001b[94mTraining finished.\u001b[0m\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "AutoInt(\n",
                            "  (embedding): EmbeddingLayer(\n",
                            "    (embed_dict): ModuleDict(\n",
                            "      (sparse_0): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_1): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_2): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_3): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_4): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_5): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_6): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_7): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_8): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_9): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_10): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sparse_11): Embedding(200002, 4, padding_idx=0)\n",
                            "      (user_id): Embedding(200002, 4, padding_idx=0)\n",
                            "      (item_id): Embedding(200002, 4, padding_idx=0)\n",
                            "      (sequence_0): Embedding(200, 8, padding_idx=0)\n",
                            "    )\n",
                            "    (dense_transforms): ModuleDict()\n",
                            "    (sequence_poolings): ModuleDict(\n",
                            "      (sequence_0): AveragePooling()\n",
                            "    )\n",
                            "  )\n",
                            "  (projection_layers): ModuleList(\n",
                            "    (0-7): 8 x Linear(in_features=1, out_features=8, bias=False)\n",
                            "    (8-21): 14 x Linear(in_features=4, out_features=8, bias=False)\n",
                            "    (22): Linear(in_features=8, out_features=8, bias=False)\n",
                            "  )\n",
                            "  (attention_layers): ModuleList(\n",
                            "    (0-2): 3 x MultiHeadSelfAttention(\n",
                            "      (q_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (k_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (v_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (out_proj): Linear(in_features=8, out_features=8, bias=False)\n",
                            "      (dropout): Dropout(p=0.0, inplace=False)\n",
                            "    )\n",
                            "  )\n",
                            "  (fc): Linear(in_features=184, out_features=1, bias=True)\n",
                            "  (prediction_layer): TaskHead(\n",
                            "    (prediction): PredictionLayer()\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.fit(\n",
                "    train_data=train_df,\n",
                "    metrics=['auc',\n",
                "             'recall',\n",
                "             'precision'],\n",
                "    epochs=1,\n",
                "    batch_size=512,\n",
                "    shuffle=True,\n",
                "    # valid_split=0.2\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "82000a76",
            "metadata": {},
            "source": [
                "Below are the models currently supported—feel free to try them out.\n",
                "\n",
                "### Ranking models\n",
                "\n",
                "| Model | Paper | Year | Status |\n",
                "|------|------|------|------|\n",
                "| **FM** | Factorization Machines | ICDM 2010 | Supported |\n",
                "| **AFM** | Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks | IJCAI 2017 | Supported |\n",
                "| **DeepFM** | DeepFM: A Factorization-Machine based Neural Network for CTR Prediction | IJCAI 2017 | Supported |\n",
                "| **Wide&Deep** | Wide & Deep Learning for Recommender Systems | DLRS 2016 | Supported |\n",
                "| **xDeepFM** | xDeepFM: Combining Explicit and Implicit Feature Interactions | KDD 2018 | Supported |\n",
                "| **FiBiNET** | FiBiNET: Combining Feature Importance and Bilinear Feature Interaction for CTR Prediction | RecSys 2019 | Supported |\n",
                "| **PNN** | Product-based Neural Networks for User Response Prediction | ICDM 2016 | Supported |\n",
                "| **AutoInt** | AutoInt: Automatic Feature Interaction Learning | CIKM 2019 | Supported |\n",
                "| **DCN** | Deep & Cross Network for Ad Click Predictions | ADKDD 2017 | Supported |\n",
                "| **DIN** | Deep Interest Network for Click-Through Rate Prediction | KDD 2018 | Supported |\n",
                "| **DIEN** | Deep Interest Evolution Network for Click-Through Rate Prediction | AAAI 2019 | Supported |\n",
                "| **MaskNet** | MaskNet: Introducing Feature-wise Gating Blocks for High-dimensional Sparse Recommendation Data | 2020 | Supported |\n",
                "\n",
                "### Retrieval models\n",
                "\n",
                "| Model | Paper | Year | Status |\n",
                "|------|------|------|------|\n",
                "| **DSSM** | Learning Deep Structured Semantic Models | CIKM 2013 | Supported |\n",
                "| **DSSM v2** | DSSM with pairwise BPR-style optimization | - | Supported |\n",
                "| **YouTube DNN** | Deep Neural Networks for YouTube Recommendations | RecSys 2016 | Supported |\n",
                "| **MIND** | Multi-Interest Network with Dynamic Routing | CIKM 2019 | Supported |\n",
                "| **SDM** | Sequential Deep Matching Model | - | Supported |\n",
                "\n",
                "### Multi-task models\n",
                "\n",
                "| Model | Paper | Year | Status |\n",
                "|------|------|------|------|\n",
                "| **MMOE** | Modeling Task Relationships in Multi-task Learning | KDD 2018 | Supported |\n",
                "| **PLE** | Progressive Layered Extraction | RecSys 2020 | Supported |\n",
                "| **ESMM** | Entire Space Multi-Task Model | SIGIR 2018 | Supported |\n",
                "| **ShareBottom** | Multitask Learning | - | Supported |\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a64e8c99",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nextrec",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}