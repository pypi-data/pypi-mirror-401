"""Setup helpers for ODIBI - Phase 2C performance utilities."""

import concurrent.futures
import warnings
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple


@dataclass
class KeyVaultFetchResult:
    """Result of a Key Vault secret fetch operation."""

    connection_name: str
    account: str
    success: bool
    secret_value: Optional[str] = None
    error: Optional[Exception] = None
    duration_ms: Optional[float] = None


def fetch_keyvault_secret(
    connection_name: str,
    key_vault_name: str,
    secret_name: str,
    timeout: float = 30.0,
) -> KeyVaultFetchResult:
    """Fetch a single Key Vault secret with timeout protection.

    Args:
        connection_name: Name of the connection (for error reporting)
        key_vault_name: Azure Key Vault name
        secret_name: Secret name in Key Vault
        timeout: Timeout in seconds (default: 30.0)

    Returns:
        KeyVaultFetchResult with success status and secret value or error
    """
    import time

    start_time = time.time()

    try:
        from azure.identity import DefaultAzureCredential
        from azure.keyvault.secrets import SecretClient
    except ImportError:
        duration_ms = (time.time() - start_time) * 1000
        return KeyVaultFetchResult(
            connection_name=connection_name,
            account=key_vault_name,
            success=False,
            error=ImportError(
                "Key Vault authentication requires 'azure-identity' and 'azure-keyvault-secrets'. "
                "Install with: pip install odibi[azure]"
            ),
            duration_ms=duration_ms,
        )

    try:
        credential = DefaultAzureCredential()
        kv_uri = f"https://{key_vault_name}.vault.azure.net"
        client = SecretClient(vault_url=kv_uri, credential=credential)

        secret = client.get_secret(secret_name)
        duration_ms = (time.time() - start_time) * 1000

        return KeyVaultFetchResult(
            connection_name=connection_name,
            account=key_vault_name,
            success=True,
            secret_value=secret.value,
            duration_ms=duration_ms,
        )

    except Exception as e:
        duration_ms = (time.time() - start_time) * 1000
        return KeyVaultFetchResult(
            connection_name=connection_name,
            account=key_vault_name,
            success=False,
            error=e,
            duration_ms=duration_ms,
        )


def fetch_keyvault_secrets_parallel(
    connections: Dict[str, Any],
    max_workers: int = 5,
    timeout: float = 30.0,
    verbose: bool = True,
) -> Dict[str, KeyVaultFetchResult]:
    """Fetch Key Vault secrets in parallel for multiple connections.

    This provides 3x+ performance improvement over sequential fetching
    when multiple ADLS connections use Key Vault authentication.

    Args:
        connections: Dictionary of connection objects (name -> connection instance)
        max_workers: Maximum number of parallel workers (default: 5)
        timeout: Timeout per secret fetch in seconds (default: 30.0)
        verbose: Print progress messages

    Returns:
        Dictionary mapping connection name to KeyVaultFetchResult

    Example:
        >>> from odibi.connections import AzureADLS
        >>> connections = {
        ...     "bronze": AzureADLS(account="storage1", container="bronze", auth_mode="key_vault",
        ...                         key_vault_name="kv1", secret_name="secret1", validate=False),
        ...     "silver": AzureADLS(account="storage2", container="silver", auth_mode="key_vault",
        ...                         key_vault_name="kv2", secret_name="secret2", validate=False),
        ... }
        >>> results = fetch_keyvault_secrets_parallel(connections)
        >>> all(r.success for r in results.values())
        True
    """
    import time

    kv_connections = []
    results = {}

    for name, conn in connections.items():
        # Check if connection is configured to use Key Vault (has vault name and secret name)
        # This supports ANY auth mode (key_vault, sas_token, service_principal, sql, etc.)
        # as long as they want to fetch a credential from KV.
        if (
            hasattr(conn, "key_vault_name")
            and conn.key_vault_name
            and hasattr(conn, "secret_name")
            and conn.secret_name
        ):
            kv_connections.append((name, conn))
        else:
            results[name] = KeyVaultFetchResult(
                connection_name=name,
                account=getattr(conn, "account", "unknown"),
                success=True,
                secret_value=None,
                duration_ms=0.0,
            )

    if not kv_connections:
        if verbose:
            print("- No Key Vault connections to fetch")
        return results

    if verbose:
        print(f"âš¡ Fetching {len(kv_connections)} Key Vault secrets in parallel...")

    start_time = time.time()

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_conn = {
            executor.submit(
                fetch_keyvault_secret,
                name,
                conn.key_vault_name,
                conn.secret_name,
                timeout,
            ): (name, conn)
            for name, conn in kv_connections
        }

        for future in concurrent.futures.as_completed(future_to_conn):
            name, conn = future_to_conn[future]
            result = future.result()
            results[name] = result

            if verbose:
                if result.success:
                    print(f"  - {name}: {result.duration_ms:.0f}ms")
                else:
                    print(f"  [X] {name}: {type(result.error).__name__}")

    total_duration = (time.time() - start_time) * 1000

    if verbose:
        success_count = sum(1 for r in results.values() if r.success)
        print(
            f"- Completed in {total_duration:.0f}ms ({success_count}/{len(kv_connections)} successful)"
        )

    return results


def configure_connections_parallel(
    connections: Dict[str, Any],
    prefetch_secrets: bool = True,
    max_workers: int = 5,
    timeout: float = 30.0,
    verbose: bool = True,
) -> Tuple[Dict[str, Any], List[str]]:
    """Configure connections with parallel Key Vault fetching.

    Args:
        connections: Dictionary of connection objects
        prefetch_secrets: Whether to prefetch Key Vault secrets in parallel
        max_workers: Maximum parallel workers
        timeout: Timeout per operation
        verbose: Print progress messages

    Returns:
        Tuple of (configured_connections, errors)
            - configured_connections: Dict with cached secrets
            - errors: List of error messages

    Example:
        >>> connections, errors = configure_connections_parallel(my_connections)
        >>> if errors:
        ...     print("Errors:", errors)
    """
    errors = []

    if not prefetch_secrets:
        return connections, errors

    results = fetch_keyvault_secrets_parallel(
        connections, max_workers=max_workers, timeout=timeout, verbose=verbose
    )

    for name, result in results.items():
        if not result.success:
            error_msg = f"Failed to fetch secret for '{name}': {result.error}"
            errors.append(error_msg)
            if verbose:
                warnings.warn(error_msg, UserWarning)
        elif result.secret_value:
            conn = connections[name]
            if hasattr(conn, "_cached_key"):
                conn._cached_key = result.secret_value

    return connections, errors


def validate_databricks_environment(verbose: bool = True) -> Dict[str, Any]:
    """Validate that we're running in a Databricks environment.

    Args:
        verbose: Print validation results

    Returns:
        Dictionary with validation results:
            - is_databricks: bool
            - spark_available: bool
            - dbutils_available: bool
            - runtime_version: Optional[str]
            - errors: List[str]

    Example:
        >>> info = validate_databricks_environment()
        >>> if info["is_databricks"]:
        ...     print("Running in Databricks")
    """
    results = {
        "is_databricks": False,
        "spark_available": False,
        "dbutils_available": False,
        "runtime_version": None,
        "errors": [],
    }

    try:
        import os

        runtime = os.getenv("DATABRICKS_RUNTIME_VERSION")
        if runtime:
            results["is_databricks"] = True
            results["runtime_version"] = runtime
    except Exception as e:
        results["errors"].append(f"Environment check failed: {e}")

    try:
        from pyspark.sql import SparkSession

        spark = SparkSession.getActiveSession()
        if spark:
            results["spark_available"] = True
    except Exception as e:
        results["errors"].append(f"Spark check failed: {e}")

    try:
        import IPython

        ipython = IPython.get_ipython()
        if ipython and hasattr(ipython, "user_ns") and "dbutils" in ipython.user_ns:
            results["dbutils_available"] = True
    except Exception as e:
        results["errors"].append(f"dbutils check failed: {e}")

    if verbose:
        print(f"  Databricks Runtime: {'[X]' if results['is_databricks'] else '[ ]'}")
        if results["runtime_version"]:
            print(f"  Runtime Version: {results['runtime_version']}")
        print(f"  Spark Available: {'[X]' if results['spark_available'] else '[ ]'}")
        print(f"  dbutils Available: {'[X]' if results['dbutils_available'] else '[ ]'}")

        if results["errors"]:
            print("\n  Errors:")
            for error in results["errors"]:
                print(f"    - {error}")

    return results
