[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "CoT_Optimized_QKV"
version = "0.1.0"
description = "Chain-of-Thought Optimized QKV Attention - Infini-Attention transformers with DeepSeek reasoner CoT optimization"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.9"
authors = [
    {name = "Bo Shang", email = "bo@shang.software"}
]
keywords = [
    "transformer",
    "attention",
    "infini-attention",
    "linear-attention",
    "long-context",
    "language-model",
    "pytorch",
    "machine-learning",
    "deep-learning",
    "cloud-run",
    "angular",
    "chain-of-thought",
    "cot-optimization",
    "deepseek"
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Operating System :: OS Independent",
]
dependencies = [
    "torch>=2.0.0",
    "numpy>=1.24.0",
    "pyyaml>=6.0",
    "aiohttp>=3.8.0",
    "tqdm>=4.64.0",
]

[project.optional-dependencies]
full = [
    "openai>=1.0.0",
    "transformers>=4.36.0",
    "datasets>=2.14.0",
    "accelerate>=0.25.0",
    "wandb>=0.16.0",
    "huggingface_hub>=0.19.0",
]
bench = [
    "lm-eval>=0.4.2",
]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "build>=1.0.0",
    "twine>=4.0.0",
]
cloud = [
    "google-cloud-run>=0.10.0",
    "google-auth>=2.0.0",
]
huawei = [
    "torch_npu",  # Huawei Ascend NPU support
]

[project.urls]
Homepage = "https://github.com/boshangclean/DeepSeeker-LLM"
Documentation = "https://github.com/boshangclean/DeepSeeker-LLM#readme"
Repository = "https://github.com/boshangclean/DeepSeeker-LLM.git"
Issues = "https://github.com/boshangclean/DeepSeeker-LLM/issues"

[project.scripts]
# Primary entry point - Mini AI Manager
mini-ai-manager = "__main__:main"
# Alternative entry points
erosolar = "mini_the_agentic_cli:main"
erosolar-train = "train_v001:main"
erosolar-generate = "generate:main"
erosolar-cloud = "cloud_run:main"
erosolar-cot = "mini_cot_optimizer:main"
erosolar-data = "generate_all_training_data:main"

[tool.setuptools]
py-modules = [
    # Core model
    "model",
    "infini_attention",
    "config",
    "tokenizer",

    # Training
    "train_v001",
    "data",
    "auto_attention",
    "mini_cot_optimizer",
    "master_scalar",

    # Data generation
    "generate_all_training_data",
    "generate_coding_only",
    "generate",

    # CLI and orchestration
    "mini_the_agentic_cli",

    # Cloud and deployment
    "cloud_run",

    # Device support
    "huawei_npu",

    # Utilities
    "atomic_save",
    "registry",
    "concepts",
    "training_upgrade_pipeline",
]

[tool.setuptools.package-data]
"*" = ["*.yaml", "*.json"]

[tool.black]
line-length = 100
target-version = ['py39', 'py310', 'py311', 'py312']

[tool.ruff]
line-length = 100
select = ["E", "F", "W", "I", "N", "UP", "B", "C4"]
ignore = ["E501"]

[tool.pytest.ini_options]
testpaths = ["tests", "."]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = "-v --tb=short"
