# PowerRAG SDK

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

PowerRAG SDK æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ Python SDKï¼Œä¸º PowerRAG API æä¾›äº†ç®€å•æ˜“ç”¨çš„æŽ¥å£ï¼Œæ”¯æŒçŸ¥è¯†åº“ç®¡ç†ã€æ–‡æ¡£å¤„ç†ã€Markdown è§£æžã€æ–‡æœ¬åˆ‡ç‰‡ã€ä¿¡æ¯æŠ½å–ã€RAPTOR æž„å»ºã€çŸ¥è¯†å›¾è°±å’Œæ£€ç´¢ç­‰åŠŸèƒ½ã€‚

## ç‰¹æ€§

- ðŸš€ **ç®€å•æ˜“ç”¨**: é¢å‘å¯¹è±¡çš„ API è®¾è®¡ï¼Œç›´è§‚çš„æ–¹æ³•è°ƒç”¨
- ðŸ“š **å®Œæ•´åŠŸèƒ½**: æ”¯æŒ PowerRAG æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ï¼ŒåŒ…æ‹¬æ–‡æ¡£ä¸Šä¼ /è§£æž/åˆ‡ç‰‡/æå–/Raptoræž„å»º/çŸ¥è¯†åº“graphæž„å»º
- ðŸ”„ **å¼‚æ­¥æ”¯æŒ**: æ”¯æŒå¼‚æ­¥ä»»åŠ¡çš„çŠ¶æ€æŸ¥è¯¢å’Œè½®è¯¢ç­‰å¾…
- ðŸ“¦ **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡ä¸Šä¼ ã€åˆ é™¤ã€æŠ½å–ç­‰æ“ä½œ
- ðŸ“ **Markdown è§£æž**: æ”¯æŒæ–‡æ¡£è§£æžä¸º Markdown æ ¼å¼ï¼ˆåŒæ­¥/å¼‚æ­¥ï¼‰

## å®‰è£…

### ä½¿ç”¨ pip

```bash
pip install powerrag-sdk
```

### ä¾èµ–è¦æ±‚

- Python 3.10+
- requests >= 2.28.0
- typing-extensions (Python < 3.11)

### éªŒè¯å®‰è£…

```python
from powerrag.sdk import PowerRAGClient

print(f"PowerRAG SDK installed successfully!")
```

## å¿«é€Ÿå¼€å§‹

### åˆå§‹åŒ–å®¢æˆ·ç«¯

```python
from powerrag.sdk import PowerRAGClient

# åˆ›å»ºå®¢æˆ·ç«¯
client = PowerRAGClient(
    api_key="your-api-key",
    base_url="http://localhost:9380"
)
```

### åˆ›å»ºçŸ¥è¯†åº“

```python
# åˆ›å»ºçŸ¥è¯†åº“
kb = client.knowledge_base.create(
    name="my_knowledge_base",
    description="My first knowledge base",
    chunk_method="naive"
)
print(f"Knowledge Base ID: {kb['id']}")
```

### ä¸Šä¼ æ–‡æ¡£

```python
# ä¸Šä¼ å•ä¸ªæ–‡æ¡£
docs = client.document.upload(kb['id'], "document.pdf")

# ä¸Šä¼ å¤šä¸ªæ–‡æ¡£
docs = client.document.upload(kb['id'], ["doc1.pdf", "doc2.pdf", "doc3.pdf"])
```

### è§£æžæ–‡æ¡£ä¸ºåˆ‡ç‰‡

```python
# å¼‚æ­¥è§£æžæ–‡æ¡£ä¸ºåˆ‡ç‰‡
task_id = client.document.parse_to_chunk(
    kb['id'], 
    [docs[0]['id']], 
    wait=False
)

# åŒæ­¥è§£æžå¹¶ç­‰å¾…å®Œæˆ
results = client.document.parse_to_chunk(
    kb['id'], 
    [docs[0]['id']], 
    wait=True,
    delete_existing=False
)
```

### è§£æžæ–‡æ¡£ä¸º Markdown

```python
# åŒæ­¥è§£æžä¸º Markdownï¼ˆä¸åˆ‡åˆ†ï¼‰
result = client.document.parse_to_md(
    doc_id=docs[0]['id'],
    config={
        "layout_recognize": "mineru",  # æˆ– "dots_ocr"
        "enable_ocr": False,
        "enable_formula": False,
        "enable_table": True
    }
)
print(f"Markdown: {result['markdown']}")
print(f"Total images: {result['total_images']}")

# å¼‚æ­¥è§£æžä¸º Markdown
task_id = client.document.parse_to_md_async(
    doc_id=docs[0]['id'],
    config={"layout_recognize": "mineru"}
)

# æŸ¥è¯¢å¼‚æ­¥ä»»åŠ¡çŠ¶æ€
status = client.document.get_parse_to_md_status(task_id)
print(f"Status: {status['status']}")

# ç­‰å¾…ä»»åŠ¡å®Œæˆ
result = client.document.wait_for_parse_to_md(task_id, timeout=300)

# ç›´æŽ¥ä¸Šä¼ æ–‡ä»¶å¹¶è§£æžä¸º Markdown
result = client.document.parse_to_md_upload(
    "document.pdf",
    config={"layout_recognize": "mineru"}
)
```

### æ£€ç´¢

```python
# æ‰§è¡Œæ£€ç´¢
result = client.retrieval.search(
    kb_ids=[kb['id']],
    question="ä»€ä¹ˆæ˜¯ PowerRAG?",
    page_size=10,
    similarity_threshold=0.2
)

# æ‰“å°ç»“æžœ
for chunk in result['chunks']:
    print(f"Content: {chunk['content']}")
    print(f"Score: {chunk['similarity']}")
    print(f"Document: {chunk['document_name']}")
```

## æ ¸å¿ƒåŠŸèƒ½äº®ç‚¹

### æ–‡æ¡£è§£æžä¸º Markdown

PowerRAG SDK æä¾›äº†å¼ºå¤§çš„æ–‡æ¡£è§£æžä¸º Markdown çš„åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼š

**æ”¯æŒçš„æ ¼å¼ï¼š**
- PDF (.pdf)
- Office æ–‡æ¡£ (.doc, .docx, .ppt, .pptx)
- å›¾ç‰‡ (.jpg, .png)
- HTML (.html, .htm)

**ä¸‰ç§ä½¿ç”¨æ–¹å¼ï¼š**

1. **åŒæ­¥è§£æž**ï¼ˆé€‚åˆå°æ–‡æ¡£ï¼‰ï¼š
```python
result = client.document.parse_to_md(doc_id, config={...})
```

2. **å¼‚æ­¥è§£æž**ï¼ˆé€‚åˆå¤§æ–‡æ¡£ï¼‰ï¼š
```python
task_id = client.document.parse_to_md_async(doc_id, config={...})
status = client.document.get_parse_to_md_status(task_id)
# æˆ–ç­‰å¾…å®Œæˆ
result = client.document.wait_for_parse_to_md(task_id, timeout=300)
```

3. **ç›´æŽ¥ä¸Šä¼ è§£æž**ï¼ˆæ— éœ€çŸ¥è¯†åº“ï¼‰ï¼š
```python
result = client.document.parse_to_md_upload("file.pdf", config={...})
```

**é…ç½®é€‰é¡¹ï¼š**
- `layout_recognize`: å¸ƒå±€è¯†åˆ«å¼•æ“Ž (`"mineru"` æˆ– `"dots_ocr"`)
- `enable_ocr`: æ˜¯å¦å¯ç”¨ OCR
- `enable_formula`: æ˜¯å¦è¯†åˆ«å…¬å¼
- `enable_table`: æ˜¯å¦è¯†åˆ«è¡¨æ ¼
- `from_page`/`to_page`: PDF é¡µé¢èŒƒå›´

### ç»“æž„åŒ–ä¿¡æ¯æŠ½å–

æ”¯æŒä½¿ç”¨ LangExtract è¿›è¡Œç»“æž„åŒ–ä¿¡æ¯æŠ½å–ï¼š

```python
task = client.extraction.struct_extract(
    text_or_documents="...",
    prompt_description="Extract person information",
    examples=[...],
    temperature=0.0
)
status = client.extraction.get_struct_extract_status(task['task_id'])
```

### æ–‡æœ¬åˆ‡ç‰‡

æ— éœ€ä¸Šä¼ æ–‡æ¡£å³å¯å¯¹æ–‡æœ¬è¿›è¡Œåˆ‡ç‰‡ï¼š

```python
result = client.chunk.split_text(
    text="# Title\n\nContent...",
    parser_id="title",
    config={"chunk_token_num": 512}
)
```

## æ ¸å¿ƒæ¨¡å—

PowerRAG SDK åŒ…å«ä»¥ä¸‹ 7 ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

### 1. çŸ¥è¯†åº“ç®¡ç† (Knowledge Base)

ç®¡ç†çŸ¥è¯†åº“çš„åˆ›å»ºã€æŸ¥è¯¢ã€æ›´æ–°å’Œåˆ é™¤ã€‚

```python
# åˆ›å»ºçŸ¥è¯†åº“
kb = client.knowledge_base.create(
    name="test_kb",
    description="Test knowledge base",
    embedding_model="BAAI/bge-small-en-v1.5@Builtin",
    permission="me",
    chunk_method="naive"
)

# èŽ·å–çŸ¥è¯†åº“
kb_info = client.knowledge_base.get(kb['id'])

# åˆ—å‡ºçŸ¥è¯†åº“
kbs, total = client.knowledge_base.list(
    name="test",
    page=1,
    page_size=10
)

# æ›´æ–°çŸ¥è¯†åº“
updated_kb = client.knowledge_base.update(
    kb['id'],
    description="Updated description",
    pagerank=True
)

# åˆ é™¤çŸ¥è¯†åº“
client.knowledge_base.delete([kb['id']])
```

### 2. æ–‡æ¡£ç®¡ç† (Document)

å¤„ç†æ–‡æ¡£çš„ä¸Šä¼ ã€åˆ—è¡¨ã€æŸ¥è¯¢ã€æ›´æ–°ã€åˆ é™¤ã€ä¸‹è½½å’Œè§£æžã€‚

```python
# ä¸Šä¼ æ–‡æ¡£
docs = client.document.upload(kb_id, ["file1.pdf", "file2.docx"])

# ä»ŽURLä¸Šä¼ æ–‡æ¡£
success = client.document.upload_from_url(
    kb_id,
    url="https://example.com/doc.pdf",
    name="document.pdf"
)

# åˆ—å‡ºæ–‡æ¡£
docs, total = client.document.list(
    kb_id,
    name="report",
    page=1,
    page_size=20,
    keywords="æœºå™¨å­¦ä¹ ",  # å…³é”®è¯æœç´¢
    suffix=["pdf", "docx"],  # æŒ‰åŽç¼€è¿‡æ»¤
    run=["DONE", "FAIL"]  # æŒ‰çŠ¶æ€è¿‡æ»¤
)

# èŽ·å–æ–‡æ¡£è¯¦æƒ…
doc = client.document.get(kb_id, doc_id)

# æ›´æ–°æ–‡æ¡£
updated_doc = client.document.update(
    kb_id,
    doc_id,
    name="new_name.pdf",
    meta_fields={"author": "John", "category": "AI"},
    enabled=True
)

# å¿«æ·æ–¹æ³•ï¼šé‡å‘½åæ–‡æ¡£
client.document.rename(kb_id, doc_id, "renamed.pdf")

# å¿«æ·æ–¹æ³•ï¼šè®¾ç½®å…ƒæ•°æ®
client.document.set_meta(kb_id, doc_id, {"version": "1.0"})

# ä¸‹è½½æ–‡æ¡£
# ä¸‹è½½ä¸ºå­—èŠ‚æµ
file_bytes = client.document.download(kb_id, doc_id)

# ä¸‹è½½åˆ°æ–‡ä»¶
saved_path = client.document.download(kb_id, doc_id, save_path="downloaded.pdf")

# è§£æžæ–‡æ¡£ä¸ºåˆ‡ç‰‡ï¼ˆå¼‚æ­¥ï¼‰
task_id = client.document.parse_to_chunk(kb_id, [doc_id], wait=False)

# è§£æžæ–‡æ¡£ä¸ºåˆ‡ç‰‡ï¼ˆåŒæ­¥ç­‰å¾…ï¼‰
results = client.document.parse_to_chunk(
    kb_id, 
    [doc_id], 
    wait=True,
    delete_existing=False,  # æ˜¯å¦åˆ é™¤å·²æœ‰åˆ‡ç‰‡
    config={"max_token": 512}  # è‡ªå®šä¹‰é…ç½®
)

# è§£æžæ–‡æ¡£ä¸º Markdownï¼ˆåŒæ­¥ï¼‰
result = client.document.parse_to_md(
    doc_id,
    config={
        "layout_recognize": "mineru",  # mineru æˆ– dots_ocr
        "enable_ocr": False,
        "enable_formula": False,
        "enable_table": True,
        "from_page": 0,  # PDFèµ·å§‹é¡µ
        "to_page": 100   # PDFç»“æŸé¡µ
    }
)
print(result['markdown'])

# è§£æžæ–‡æ¡£ä¸º Markdownï¼ˆå¼‚æ­¥ï¼‰
task_id = client.document.parse_to_md_async(doc_id, config={...})

# æŸ¥è¯¢ parse_to_md ä»»åŠ¡çŠ¶æ€
status = client.document.get_parse_to_md_status(task_id)
if status["status"] == "success":
    print(status["result"]["markdown"])

# ç­‰å¾… parse_to_md ä»»åŠ¡å®Œæˆ
result = client.document.wait_for_parse_to_md(task_id, timeout=300)

# ä¸Šä¼ å¹¶è§£æžä¸º Markdownï¼ˆæ— éœ€çŸ¥è¯†åº“ï¼‰
result = client.document.parse_to_md_upload("file.pdf", config={...})

# è§£æžURLæ–‡æ¡£ï¼ˆåŒæ­¥ç­‰å¾…ï¼‰
doc = client.document.parse_url(
    kb_id,
    url="https://example.com/doc.pdf",
    name="web_doc.pdf",
    wait=True
)

# å–æ¶ˆè§£æžä»»åŠ¡
client.document.cancel_parse(kb_id, [doc_id])

# åˆ é™¤æ–‡æ¡£
client.document.delete(kb_id, [doc_id])
```

### 3. åˆ‡ç‰‡ç®¡ç† (Chunk)

ç®¡ç†æ–‡æ¡£åˆ‡ç‰‡çš„æŸ¥è¯¢ã€åˆ›å»ºã€æ›´æ–°ã€åˆ é™¤å’Œæ–‡æœ¬åˆ‡ç‰‡ã€‚

```python
# åˆ—å‡ºæ–‡æ¡£çš„åˆ‡ç‰‡
chunks, total, doc_info = client.chunk.list(
    kb_id,
    doc_id,
    keywords="æœºå™¨å­¦ä¹ ",
    page=1,
    page_size=30
)

# èŽ·å–åˆ‡ç‰‡è¯¦æƒ…
chunk = client.chunk.get(kb_id, doc_id, chunk_id)

# åˆ›å»ºåˆ‡ç‰‡
chunk = client.chunk.create(
    kb_id,
    doc_id,
    content="This is a chunk content",
    important_keywords=["keyword1", "keyword2"],
    questions=["What is this about?"]
)

# æ›´æ–°åˆ‡ç‰‡
updated_chunk = client.chunk.update(
    kb_id,
    doc_id,
    chunk_id,
    content="Updated content",
    important_keywords=["new_keyword"],
    questions=["Updated question?"],
    available=True,
    positions=[[0, 100]]
)

# åˆ é™¤åˆ‡ç‰‡
client.chunk.delete(kb_id, doc_id, [chunk_id])

# åˆ é™¤æ–‡æ¡£çš„æ‰€æœ‰åˆ‡ç‰‡
client.chunk.delete(kb_id, doc_id, None)

# æ–‡æœ¬åˆ‡ç‰‡ï¼ˆæ— éœ€ä¸Šä¼ æ–‡æ¡£ï¼‰
result = client.chunk.split_text(
    text="# Title\n\nLong text to be chunked...",
    parser_id="title",  # è§£æžå™¨ID
    config={"chunk_token_num": 512}  # è‡ªå®šä¹‰é…ç½®
)
print(f"Total chunks: {result['total_chunks']}")
for chunk in result['chunks']:
    print(chunk['content'])
```

### 4. ä¿¡æ¯æŠ½å– (Extraction)

ä»Žæ–‡æ¡£æˆ–æ–‡æœ¬ä¸­æŠ½å–å®žä½“ã€å…³é”®è¯ã€æ‘˜è¦ç­‰ä¿¡æ¯ã€‚

```python
# ä»Žæ–‡æ¡£æŠ½å–
result = client.extraction.extract_from_document(
    doc_id=doc_id,
    extractor_type="entity",  # entity, keyword, summary
    config={
        "entity_types": ["PERSON", "ORG", "LOC"],
        "use_regex": True,
        "use_llm": False
    }
)
print(result['entities'])

# ä»Žæ–‡æœ¬æŠ½å–
result = client.extraction.extract_from_text(
    text="PowerRAG is an advanced RAG framework developed by OceanBase",
    extractor_type="entity",
    config={"entity_types": ["ORG", "PRODUCT"]}
)

# æŠ½å–å…³é”®è¯
result = client.extraction.extract_from_document(
    doc_id=doc_id,
    extractor_type="keyword",
    config={
        "max_keywords": 20,
        "min_word_length": 3
    }
)

# æŠ½å–æ‘˜è¦
result = client.extraction.extract_from_document(
    doc_id=doc_id,
    extractor_type="summary",
    config={
        "max_length": 200,
        "min_length": 50
    }
)

# æ‰¹é‡æŠ½å–
results = client.extraction.extract_batch(
    doc_ids=[doc_id1, doc_id2, doc_id3],
    extractor_type="keyword",
    config={"max_keywords": 15}
)
for result in results:
    if result['success']:
        print(f"Doc {result['doc_id']}: {result['data']}")

# ç»“æž„åŒ–æŠ½å– (LangExtract)
task = client.extraction.struct_extract(
    text_or_documents="John Doe is 30 years old. His email is john@example.com",
    prompt_description="Extract person information including name, age, and email",
    examples=[
        {
            "text": "Jane Smith is 25 years old. Email: jane@example.com",
            "extractions": [
                {"name": "Jane Smith", "age": 25, "email": "jane@example.com"}
            ]
        }
    ],
    fetch_urls=False,
    max_char_buffer=1000,
    temperature=0.0,
    extraction_passes=1
)
print(f"Task ID: {task['task_id']}")

# èŽ·å–ç»“æž„åŒ–æŠ½å–çŠ¶æ€
status = client.extraction.get_struct_extract_status(task['task_id'])
print(f"Status: {status['status']}")
if status['status'] == 'completed':
    print(f"Result: {status['result']}")
```

### 5. RAPTOR

æž„å»ºå’Œç®¡ç† RAPTORï¼ˆRecursive Abstractive Processing for Tree-Organized Retrievalï¼‰ã€‚

**æ³¨æ„**: RAPTOR çš„é…ç½®å‚æ•°éœ€è¦åœ¨åˆ›å»ºæˆ–æ›´æ–°çŸ¥è¯†åº“æ—¶é€šè¿‡ `parser_config.raptor` è®¾ç½®ã€‚

```python
# åˆ›å»ºçŸ¥è¯†åº“æ—¶é…ç½® RAPTOR å‚æ•°
kb = client.knowledge_base.create(
    name="raptor_kb",
    chunk_method="naive",
    parser_config={
        "raptor": {
            "max_cluster": 64,
            "random_seed": 224,
            "llm_model": "deepseek-chat"
        }
    }
)

# æž„å»º RAPTORï¼ˆå¼‚æ­¥ï¼‰
task = client.raptor.build(kb_id)
print(f"RAPTOR Task ID: {task['raptor_task_id']}")

# èŽ·å– RAPTOR æž„å»ºçŠ¶æ€
status = client.raptor.get_status(kb_id)
if status:
    print(f"Status: {status['status']}")
    print(f"Progress: {status['progress']}")
else:
    print("No RAPTOR task found")
```

### 6. çŸ¥è¯†å›¾è°± (Knowledge Graph)

æž„å»ºå’Œç®¡ç†çŸ¥è¯†å›¾è°±ã€‚

**æ³¨æ„**: çŸ¥è¯†å›¾è°±çš„é…ç½®å‚æ•°éœ€è¦åœ¨åˆ›å»ºæˆ–æ›´æ–°çŸ¥è¯†åº“æ—¶é€šè¿‡ `parser_config.graphrag` è®¾ç½®ã€‚

```python
# åˆ›å»ºçŸ¥è¯†åº“æ—¶é…ç½®çŸ¥è¯†å›¾è°±å‚æ•°
kb = client.knowledge_base.create(
    name="kg_kb",
    chunk_method="naive",
    parser_config={
        "graphrag": {
            "entity_types": ["PERSON", "ORG", "LOC", "EVENT"],
            "llm_model": "deepseek-chat"
        }
    }
)

# æž„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå¼‚æ­¥ï¼‰
task = client.knowledge_graph.build(kb_id)
print(f"Knowledge Graph Task ID: {task['graphrag_task_id']}")

# èŽ·å–çŸ¥è¯†å›¾è°±æ•°æ®
kg = client.knowledge_graph.get(kb_id)
print(f"Graph nodes: {len(kg['graph'].get('nodes', []))}")
print(f"Graph edges: {len(kg['graph'].get('edges', []))}")
print(f"Mind map: {kg['mind_map']}")

# èŽ·å–æž„å»ºçŠ¶æ€
status = client.knowledge_graph.get_status(kb_id)
if status:
    print(f"Status: {status['status']}")
    print(f"Progress: {status['progress']}")
else:
    print("No knowledge graph task found")
```

### 7. æ£€ç´¢ (Retrieval)

æ‰§è¡Œè¯­ä¹‰æ£€ç´¢å’Œæ··åˆæ£€ç´¢ã€‚

```python
# åŸºæœ¬æ£€ç´¢
result = client.retrieval.search(
    kb_ids=[kb_id],
    question="What is PowerRAG?",
    page=1,
    page_size=10
)

# æ‰“å°ç»“æžœ
print(f"Total results: {result['total']}")
for chunk in result['chunks']:
    print(f"Content: {chunk['content']}")
    print(f"Similarity: {chunk['similarity']}")
    print(f"Document: {chunk['document_name']}")

# é«˜çº§æ£€ç´¢
result = client.retrieval.search(
    kb_ids=[kb_id1, kb_id2],
    question="æœºå™¨å­¦ä¹ çš„åº”ç”¨",
    document_ids=[doc_id],  # é™å®šæ–‡æ¡£èŒƒå›´
    page=1,
    page_size=30,
    similarity_threshold=0.3,  # ç›¸ä¼¼åº¦é˜ˆå€¼
    vector_similarity_weight=0.3,  # å‘é‡ç›¸ä¼¼åº¦æƒé‡ï¼ˆæ··åˆæ£€ç´¢ï¼‰
    top_k=1024,  # æœ€å¤§è¿”å›žæ•°é‡
    keyword=True,  # å¯ç”¨å…³é”®è¯å¢žå¼º
    use_kg=True,  # ä½¿ç”¨çŸ¥è¯†å›¾è°±æ£€ç´¢
    rerank_id="bge-reranker-v2-m3",  # é‡æŽ’åºæ¨¡åž‹
    highlight=True,  # é«˜äº®åŒ¹é…å†…å®¹
    cross_languages=["en", "zh"],  # è·¨è¯­è¨€æ£€ç´¢
    metadata_condition={"status": "published", "year": 2024}  # å…ƒæ•°æ®è¿‡æ»¤
)

# æ£€ç´¢æµ‹è¯•ï¼ˆä¸Ž search åŠŸèƒ½ç›¸åŒï¼Œç”¨äºŽæµ‹è¯•åœºæ™¯ï¼‰
test_result = client.retrieval.test(
    kb_ids=[kb_id],
    question="æµ‹è¯•æŸ¥è¯¢",
    page=1,
    page_size=50,
    similarity_threshold=0.2,
    keyword=True,
    use_kg=False
)
```

## å®Œæ•´ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„å·¥ä½œæµç¨‹ç¤ºä¾‹ï¼š

```python
from powerrag.sdk import PowerRAGClient
import time

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = PowerRAGClient(
    api_key="your-api-key",
    base_url="http://localhost:9380"
)

# 1. åˆ›å»ºçŸ¥è¯†åº“
kb = client.knowledge_base.create(
    name="research_papers",
    description="Collection of AI research papers",
    chunk_method="naive"
)
print(f"Created knowledge base: {kb['id']}")

# 2. ä¸Šä¼ æ–‡æ¡£
docs = client.document.upload(
    kb['id'],
    ["paper1.pdf", "paper2.pdf", "paper3.pdf"]
)
print(f"Uploaded {len(docs)} documents")

# 3. è§£æžæ–‡æ¡£ä¸ºåˆ‡ç‰‡ï¼ˆåŒæ­¥ç­‰å¾…ï¼‰
doc_ids = [doc['id'] for doc in docs]
results = client.document.parse_to_chunk(kb['id'], doc_ids, wait=True)
print(f"Parsed {len(results)} documents")
for result in results:
    print(f"Doc {result['doc_id']}: {result['status']}, {result['chunk_count']} chunks")

# 4. æž„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå¯é€‰ï¼‰
kg_task = client.knowledge_graph.build(kb['id'])
print(f"Building knowledge graph: {kg_task['graphrag_task_id']}")

# ç­‰å¾…çŸ¥è¯†å›¾è°±æž„å»ºå®Œæˆ
while True:
    status = client.knowledge_graph.get_status(kb['id'])
    if not status:
        break
    print(f"KG status: {status['status']}, progress: {status.get('progress', 0)}")
    if status['status'] in ['DONE', 'FAIL']:
        break
    time.sleep(5)

# 5. æ‰§è¡Œæ£€ç´¢
result = client.retrieval.search(
    kb_ids=[kb['id']],
    question="What are the latest advances in transformer models?",
    page_size=5,
    similarity_threshold=0.2,
    use_kg=True,
    highlight=True
)

# æ‰“å°æ£€ç´¢ç»“æžœ
print(f"\nFound {result['total']} results:")
for i, chunk in enumerate(result['chunks'], 1):
    print(f"\n{i}. Score: {chunk['similarity']:.3f}")
    print(f"   Content: {chunk['content'][:200]}...")
    print(f"   Document: {chunk['document_name']}")

# 6. ä»Žæ–‡æ¡£æŠ½å–å…³é”®ä¿¡æ¯
for doc_id in doc_ids[:3]:  # æŠ½å–å‰3ä¸ªæ–‡æ¡£
    extraction = client.extraction.extract_from_document(
        doc_id=doc_id,
        extractor_type="keyword",
        config={"max_keywords": 10}
    )
    print(f"\nExtracted keywords from {doc_id}: {extraction.get('keywords', [])}")

# 7. è§£æžæ–‡æ¡£ä¸º Markdownï¼ˆå¯é€‰ï¼‰
md_result = client.document.parse_to_md(
    doc_id=doc_ids[0],
    config={"layout_recognize": "mineru"}
)
print(f"\nMarkdown length: {md_result['markdown_length']}")
print(f"Total images: {md_result['total_images']}")

# 8. æ¸…ç†ï¼ˆå¦‚éœ€è¦ï¼‰
# åˆ é™¤ç‰¹å®šæ–‡æ¡£
# client.document.delete(kb['id'], [doc_ids[0]])

# åˆ é™¤æ•´ä¸ªçŸ¥è¯†åº“ï¼ˆåŒ…æ‹¬æ‰€æœ‰æ–‡æ¡£ï¼‰
# client.knowledge_base.delete([kb['id']])
```

## çŽ¯å¢ƒé…ç½®

ä½¿ç”¨ SDK å‰éœ€è¦é…ç½®ä»¥ä¸‹çŽ¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰ï¼š

```bash
# PowerRAG æœåŠ¡åœ°å€
export HOST_ADDRESS="http://127.0.0.1:9380"

# API å¯†é’¥
export POWERRAG_API_KEY="your-api-key"
```

æˆ–åœ¨ä»£ç ä¸­ç›´æŽ¥æŒ‡å®šï¼š

```python
client = PowerRAGClient(
    api_key="your-api-key",
    base_url="http://127.0.0.1:9380",
    version="v1"  # API ç‰ˆæœ¬ï¼Œé»˜è®¤ä¸º v1
)
```

## æµ‹è¯•

SDK åŒ…å«å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼Œè¦†ç›–æ‰€æœ‰åŠŸèƒ½æ¨¡å—ã€‚

### è¿è¡Œæ‰€æœ‰æµ‹è¯•

```bash
# è®¾ç½®çŽ¯å¢ƒå˜é‡
export HOST_ADDRESS="http://127.0.0.1:9380"
export POWERRAG_API_KEY="your-api-key"

# è¿è¡Œæµ‹è¯•
pytest powerrag/sdk/tests/
```

### è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•

```bash
# æµ‹è¯•çŸ¥è¯†åº“æ¨¡å—
pytest powerrag/sdk/tests/test_knowledge_base.py

# æµ‹è¯•æ–‡æ¡£æ¨¡å—
pytest powerrag/sdk/tests/test_document.py

# æµ‹è¯•æ£€ç´¢æ¨¡å—
pytest powerrag/sdk/tests/test_retrieval.py
```

æ›´å¤šæµ‹è¯•è¯´æ˜Žè¯·å‚è€ƒ [tests/README.md](tests/README.md)ã€‚

## é¡¹ç›®ç»“æž„

```
powerrag/sdk/
â”œâ”€â”€ __init__.py                      # SDK å…¥å£ï¼Œå¯¼å‡º PowerRAGClient
â”œâ”€â”€ client.py                        # ä¸»å®¢æˆ·ç«¯ç±»ï¼Œæä¾› HTTP è¯·æ±‚æ–¹æ³•
â”œâ”€â”€ README.md                        # SDK æ–‡æ¡£ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ modules/                         # åŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ knowledge_base.py            # çŸ¥è¯†åº“æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â”œâ”€â”€ knowledge_base_manager.py    # çŸ¥è¯†åº“ç®¡ç†å™¨
â”‚   â”œâ”€â”€ document.py                  # æ–‡æ¡£æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â”œâ”€â”€ document_manager.py          # æ–‡æ¡£ç®¡ç†å™¨
â”‚   â”œâ”€â”€ chunk.py                     # åˆ‡ç‰‡æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â”œâ”€â”€ chunk_manager.py             # åˆ‡ç‰‡ç®¡ç†å™¨
â”‚   â”œâ”€â”€ extraction.py                # æŠ½å–æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â”œâ”€â”€ extraction_manager.py        # æŠ½å–ç®¡ç†å™¨
â”‚   â”œâ”€â”€ raptor.py                    # RAPTOR æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â”œâ”€â”€ raptor_manager.py            # RAPTOR ç®¡ç†å™¨
â”‚   â”œâ”€â”€ knowledge_graph.py           # çŸ¥è¯†å›¾è°±æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â”œâ”€â”€ knowledge_graph_manager.py   # çŸ¥è¯†å›¾è°±ç®¡ç†å™¨
â”‚   â”œâ”€â”€ retrieval.py                 # æ£€ç´¢æ•°æ®æ¨¡åž‹ (TypedDict)
â”‚   â””â”€â”€ retrieval_manager.py         # æ£€ç´¢ç®¡ç†å™¨
â””â”€â”€ tests/                           # å®Œæ•´çš„æµ‹è¯•å¥—ä»¶
    â”œâ”€â”€ README.md                    # æµ‹è¯•æ–‡æ¡£
    â”œâ”€â”€ conftest.py                  # pytest é…ç½®å’Œ fixtures
    â”œâ”€â”€ pytest.ini                   # pytest é…ç½®æ–‡ä»¶
    â”œâ”€â”€ test_knowledge_base.py       # çŸ¥è¯†åº“æµ‹è¯•
    â”œâ”€â”€ test_document.py             # æ–‡æ¡£æµ‹è¯•
    â”œâ”€â”€ test_chunk.py                # åˆ‡ç‰‡æµ‹è¯•
    â”œâ”€â”€ test_extraction.py           # æŠ½å–æµ‹è¯•
    â”œâ”€â”€ test_raptor.py               # RAPTOR æµ‹è¯•
    â”œâ”€â”€ test_knowledge_graph.py      # çŸ¥è¯†å›¾è°±æµ‹è¯•
    â””â”€â”€ test_retrieval.py            # æ£€ç´¢æµ‹è¯•
```

## API å‚è€ƒ

### PowerRAGClient

ä¸»å®¢æˆ·ç«¯ç±»ï¼Œæä¾›å¯¹æ‰€æœ‰åŠŸèƒ½æ¨¡å—çš„è®¿é—®ã€‚

**åˆå§‹åŒ–å‚æ•°ï¼š**
- `api_key` (str): API å¯†é’¥ï¼Œå¿…å¡«
- `base_url` (str): æœåŠ¡åœ°å€ï¼Œé»˜è®¤ `"http://localhost:9380"`
- `version` (str): API ç‰ˆæœ¬ï¼Œé»˜è®¤ `"v1"`

**å±žæ€§ï¼š**
- `knowledge_base` (KnowledgeBaseManager): çŸ¥è¯†åº“ç®¡ç†å™¨
- `document` (DocumentManager): æ–‡æ¡£ç®¡ç†å™¨
- `chunk` (ChunkManager): åˆ‡ç‰‡ç®¡ç†å™¨
- `extraction` (ExtractionManager): æŠ½å–ç®¡ç†å™¨
- `raptor` (RAPTORManager): RAPTOR ç®¡ç†å™¨
- `knowledge_graph` (KnowledgeGraphManager): çŸ¥è¯†å›¾è°±ç®¡ç†å™¨
- `retrieval` (RetrievalManager): æ£€ç´¢ç®¡ç†å™¨

**å†…éƒ¨æ–¹æ³•ï¼š**
- `post(url, json=None, files=None, data=None, stream=False)`: POST è¯·æ±‚
- `get(url, params=None, stream=False)`: GET è¯·æ±‚
- `put(url, json=None)`: PUT è¯·æ±‚
- `delete(url, json=None, params=None)`: DELETE è¯·æ±‚

### æ•°æ®æ¨¡åž‹

æ‰€æœ‰æ•°æ®æ¨¡åž‹éƒ½ä½¿ç”¨ `TypedDict` å®šä¹‰ï¼Œæä¾›å®Œæ•´çš„ç±»åž‹æç¤ºï¼š

**çŸ¥è¯†åº“ç›¸å…³ï¼š**
- `KnowledgeBaseInfo`: çŸ¥è¯†åº“ä¿¡æ¯

**æ–‡æ¡£ç›¸å…³ï¼š**
- `DocumentInfo`: æ–‡æ¡£ä¿¡æ¯

**åˆ‡ç‰‡ç›¸å…³ï¼š**
- `ChunkInfo`: åˆ‡ç‰‡ä¿¡æ¯

**æŠ½å–ç›¸å…³ï¼š**
- `ExtractionResult`: æŠ½å–ç»“æžœ
- `StructExtractTaskInfo`: ç»“æž„åŒ–æŠ½å–ä»»åŠ¡ä¿¡æ¯

**RAPTOR ç›¸å…³ï¼š**
- `RAPTORTaskInfo`: RAPTOR ä»»åŠ¡ä¿¡æ¯

**çŸ¥è¯†å›¾è°±ç›¸å…³ï¼š**
- `KnowledgeGraphData`: çŸ¥è¯†å›¾è°±æ•°æ®
- `KnowledgeGraphTaskInfo`: çŸ¥è¯†å›¾è°±ä»»åŠ¡ä¿¡æ¯

**æ£€ç´¢ç›¸å…³ï¼š**
- `RetrievalResult`: æ£€ç´¢ç»“æžœ

## æœ€ä½³å®žè·µ

### 1. é”™è¯¯å¤„ç†

SDK ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œå»ºè®®åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­è¿›è¡Œé€‚å½“çš„é”™è¯¯å¤„ç†ï¼š

```python
from requests.exceptions import RequestException, HTTPError

try:
    result = client.retrieval.search(
        kb_ids=[kb_id],
        question="test query"
    )
except RequestException as e:
    print(f"Network error: {e}")
except Exception as e:
    print(f"API error: {e}")
```

### 2. å¼‚æ­¥ä»»åŠ¡å¤„ç†

å¯¹äºŽé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Œå»ºè®®ä½¿ç”¨å¼‚æ­¥æ–¹å¼ï¼š

```python
# æäº¤ä»»åŠ¡
task_id = client.document.parse_to_chunk(kb_id, doc_ids, wait=False)

# è½®è¯¢çŠ¶æ€
import time
for doc_id in doc_ids:
    while True:
        doc = client.document.get(kb_id, doc_id)
        if doc['run'] in ['DONE', 'FAIL']:
            break
        time.sleep(2)
```

### 3. æ‰¹é‡æ“ä½œ

å……åˆ†åˆ©ç”¨æ‰¹é‡æ“ä½œæé«˜æ•ˆçŽ‡ï¼š

```python
# æ‰¹é‡ä¸Šä¼ 
docs = client.document.upload(kb_id, ["doc1.pdf", "doc2.pdf", "doc3.pdf"])

# æ‰¹é‡è§£æž
doc_ids = [doc['id'] for doc in docs]
results = client.document.parse_to_chunk(kb_id, doc_ids, wait=True)

# æ‰¹é‡æŠ½å–
results = client.extraction.extract_batch(doc_ids, extractor_type="keyword")
```

### 4. çŸ¥è¯†åº“é…ç½®

åœ¨åˆ›å»ºçŸ¥è¯†åº“æ—¶å°±é…ç½®å¥½æ‰€éœ€çš„å‚æ•°ï¼š

```python
kb = client.knowledge_base.create(
    name="my_kb",
    chunk_method="naive",
    embedding_model="BAAI/bge-large-zh-v1.5@Builtin",
    parser_config={
        "chunk_token_num": 512,
        "raptor": {
            "max_cluster": 64,
            "llm_model": "deepseek-chat"
        },
        "graphrag": {
            "entity_types": ["PERSON", "ORG", "LOC"],
            "llm_model": "deepseek-chat"
        }
    }
)
```

### 5. æ£€ç´¢ä¼˜åŒ–

æ ¹æ®åœºæ™¯è°ƒæ•´æ£€ç´¢å‚æ•°ï¼š

```python
# ç²¾ç¡®æ£€ç´¢ï¼ˆé«˜é˜ˆå€¼ï¼‰
result = client.retrieval.search(
    kb_ids=[kb_id],
    question="query",
    similarity_threshold=0.5,  # æ›´é«˜çš„é˜ˆå€¼
    page_size=10
)

# å¬å›žä¼˜åŒ–ï¼ˆä½Žé˜ˆå€¼ + å¤§top_k + é‡æŽ’åºï¼‰
result = client.retrieval.search(
    kb_ids=[kb_id],
    question="query",
    similarity_threshold=0.1,  # æ›´ä½Žçš„é˜ˆå€¼
    top_k=2048,  # æ›´å¤§çš„å€™é€‰é›†
    rerank_id="bge-reranker-v2-m3",  # ä½¿ç”¨é‡æŽ’åº
    keyword=True,  # å¯ç”¨å…³é”®è¯
    use_kg=True  # ä½¿ç”¨çŸ¥è¯†å›¾è°±
)
```

## é”™è¯¯å¤„ç†

SDK ä¼šæŠ›å‡ºä»¥ä¸‹ç±»åž‹çš„å¼‚å¸¸ï¼š

**å¸¸è§å¼‚å¸¸ï¼š**
- `FileNotFoundError`: æ–‡ä»¶ä¸å­˜åœ¨
- `Exception`: API è°ƒç”¨å¤±è´¥ï¼ˆåŒ…å«é”™è¯¯æ¶ˆæ¯ï¼‰
- `TimeoutError`: ä»»åŠ¡è¶…æ—¶ï¼ˆä»…åœ¨ä½¿ç”¨ `wait_for_*` æ–¹æ³•æ—¶ï¼‰
- `RequestException`: ç½‘ç»œè¯·æ±‚é”™è¯¯

**ç¤ºä¾‹ï¼š**

```python
try:
    kb = client.knowledge_base.get("nonexistent-id")
except Exception as e:
    print(f"Error: {e}")
```

```python
from requests.exceptions import RequestException

try:
    result = client.retrieval.search(
        kb_ids=[kb_id],
        question="test query"
    )
except RequestException as e:
    print(f"Network error: {e}")
except Exception as e:
    print(f"API error: {e}")
```

## å¸¸è§é—®é¢˜ (FAQ)

### Q: å¦‚ä½•å¤„ç†å¤§æ–‡æ¡£çš„è§£æžï¼Ÿ

A: å¯¹äºŽå¤§æ–‡æ¡£ï¼Œå»ºè®®ä½¿ç”¨å¼‚æ­¥è§£æžï¼š
```python
# ä½¿ç”¨å¼‚æ­¥è§£æž
task_id = client.document.parse_to_md_async(doc_id)
result = client.document.wait_for_parse_to_md(task_id, timeout=600)
```

### Q: RAPTOR å’ŒçŸ¥è¯†å›¾è°±çš„é…ç½®åœ¨å“ªé‡Œè®¾ç½®ï¼Ÿ

A: éœ€è¦åœ¨åˆ›å»ºæˆ–æ›´æ–°çŸ¥è¯†åº“æ—¶é€šè¿‡ `parser_config` è®¾ç½®ï¼š
```python
kb = client.knowledge_base.create(
    name="my_kb",
    parser_config={
        "raptor": {"max_cluster": 64},
        "graphrag": {"entity_types": ["PERSON", "ORG"]}
    }
)
```

### Q: å¦‚ä½•æŸ¥çœ‹çŸ¥è¯†åº“çš„ RAPTOR å’ŒçŸ¥è¯†å›¾è°±çŠ¶æ€ï¼Ÿ

A: ä½¿ç”¨å¯¹åº”çš„ `get_status` æ–¹æ³•ï¼š
```python
raptor_status = client.raptor.get_status(kb_id)
kg_status = client.knowledge_graph.get_status(kb_id)
```
è¿”å›ž `None` è¡¨ç¤ºæ²¡æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡ã€‚

### Q: å¦‚ä½•å®žçŽ°æ··åˆæ£€ç´¢ï¼Ÿ

A: è°ƒæ•´ `vector_similarity_weight` å‚æ•°å’Œå¯ç”¨ `keyword`ï¼š
```python
result = client.retrieval.search(
    kb_ids=[kb_id],
    question="query",
    vector_similarity_weight=0.3,  # å‘é‡æƒé‡
    keyword=True,  # å¯ç”¨å…³é”®è¯
    use_kg=True  # ä½¿ç”¨çŸ¥è¯†å›¾è°±
)
```

### Q: æ”¯æŒå“ªäº›æŠ½å–ç±»åž‹ï¼Ÿ

A: æ”¯æŒä¸‰ç§æŠ½å–ç±»åž‹ï¼š
- `entity`: å®žä½“æŠ½å–ï¼ˆäººåã€åœ°åã€ç»„ç»‡ç­‰ï¼‰
- `keyword`: å…³é”®è¯æŠ½å–
- `summary`: æ‘˜è¦ç”Ÿæˆ

è¿˜æ”¯æŒç»“æž„åŒ–æŠ½å– (`struct_extract`)ï¼Œå¯ä»¥è‡ªå®šä¹‰æŠ½å–æ¨¡å¼ã€‚

### Q: å¦‚ä½•å¤„ç†è§£æžå¤±è´¥çš„æ–‡æ¡£ï¼Ÿ

A: æ£€æŸ¥æ–‡æ¡£çŠ¶æ€å¹¶æ ¹æ®é”™è¯¯ä¿¡æ¯å¤„ç†ï¼š
```python
results = client.document.parse_to_chunk(kb_id, doc_ids, wait=True)
for result in results:
    if result['status'] == 'FAIL':
        print(f"Document {result['doc_id']} failed to parse")
        # é‡æ–°è§£æžæˆ–åˆ é™¤
```

### Q: SDK æ˜¯å¦æ”¯æŒæµå¼è¿”å›žï¼Ÿ

A: å½“å‰ç‰ˆæœ¬ä¸»è¦æ”¯æŒæ ‡å‡† REST API è°ƒç”¨ã€‚å¯¹äºŽä¸‹è½½ç­‰æ“ä½œï¼ŒSDK å†…éƒ¨ä½¿ç”¨äº†æµå¼ä¼ è¾“ã€‚

### Q: å¦‚ä½•è®¾ç½®è¯·æ±‚è¶…æ—¶ï¼Ÿ

A: å½“å‰ SDK ä½¿ç”¨ `requests` åº“çš„é»˜è®¤è¶…æ—¶ã€‚å¦‚éœ€è‡ªå®šä¹‰ï¼Œå¯ä»¥åœ¨è°ƒç”¨å‰è®¾ç½®ï¼š
```python
import requests
requests.adapters.DEFAULT_RETRIES = 5
```

## è´¡çŒ®

æ¬¢è¿Žè´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add amazing feature'`)
4. æŽ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. åˆ›å»º Pull Request

**è´¡çŒ®æŒ‡å—ï¼š**
- éµå¾ª PEP 8 ä»£ç è§„èŒƒ
- æ·»åŠ é€‚å½“çš„ç±»åž‹æ³¨è§£
- ä¸ºæ–°åŠŸèƒ½æ·»åŠ æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## è®¸å¯è¯

Copyright 2025 The OceanBase Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

## é“¾æŽ¥

- [PowerRAG é¡¹ç›®ä¸»é¡µ](https://github.com/oceanbase/powerrag)
- [API æ–‡æ¡£](https://github.com/oceanbase/powerrag/docs)
- [é—®é¢˜åé¦ˆ](https://github.com/oceanbase/powerrag/issues)
- [æ›´æ–°æ—¥å¿—](https://github.com/oceanbase/powerrag/CHANGELOG.md)

## æ”¯æŒ

### èŽ·å–å¸®åŠ©

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š

1. ðŸ“– æŸ¥çœ‹ [å®Œæ•´æ–‡æ¡£](https://github.com/oceanbase/powerrag/docs)
2. ðŸ” æœç´¢ [å·²æœ‰é—®é¢˜](https://github.com/oceanbase/powerrag/issues)
3. ðŸ’¬ åˆ›å»º [æ–°é—®é¢˜](https://github.com/oceanbase/powerrag/issues/new)
4. ðŸ“§ è”ç³» OceanBase å›¢é˜Ÿ

### ç¤¾åŒº

- GitHub: [oceanbase/powerrag](https://github.com/oceanbase/powerrag)
- æ–‡æ¡£: [PowerRAG Documentation](https://github.com/oceanbase/powerrag/docs)
- é—®é¢˜è·Ÿè¸ª: [GitHub Issues](https://github.com/oceanbase/powerrag/issues)

### åé¦ˆ

æˆ‘ä»¬éžå¸¸é‡è§†æ‚¨çš„åé¦ˆï¼å¦‚æžœæ‚¨ï¼š
- å‘çŽ°äº† bug
- æœ‰åŠŸèƒ½å»ºè®®
- éœ€è¦å¸®åŠ©
- æƒ³è¦è´¡çŒ®ä»£ç 

è¯·é€šè¿‡ GitHub Issues è”ç³»æˆ‘ä»¬ã€‚

---

**Made with â¤ï¸ by OceanBase Team**


