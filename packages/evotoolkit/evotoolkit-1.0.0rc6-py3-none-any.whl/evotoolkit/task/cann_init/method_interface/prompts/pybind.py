# Copyright (c) 2025 Ping Guo
# Licensed under the MIT License

"""Pybind code generation prompt for Ascend C operator."""

from typing import Any


def _dtype_to_cpp_type(dtype: str) -> str:
    """Convert dtype string to C++ type."""
    mapping = {
        "float": "float",
        "float32": "float",
        "double": "double",
        "float64": "double",
        "int": "int64_t",
        "int32": "int32_t",
        "int64": "int64_t",
        "bool": "bool",
    }
    return mapping.get(dtype.lower(), "float")


def _generate_fixed_parts(signature: Any) -> dict:
    """
    Generate fixed parts of pybind code from signature.

    Returns dict with:
        - params: function parameter string
        - first_tensor: first tensor name for options()
        - exec_args: arguments for EXEC_NPU_CMD
        - input_info: formatted input info for LLM reference
    """
    if isinstance(signature, dict):
        sig = signature
    elif hasattr(signature, "to_dict"):
        sig = signature.to_dict()
    else:
        sig = {"op_name": "Unknown", "inputs": [], "outputs": [], "init_params": []}

    inputs = sig.get("inputs", [])
    init_params = sig.get("init_params", [])

    param_parts = []
    first_tensor = None
    input_info_lines = []

    # Process inputs
    for inp in inputs:
        name = inp["name"]
        dtype = inp.get("dtype", "float")
        is_tensor = inp.get("is_tensor", True)

        if is_tensor:
            param_parts.append(f"const at::Tensor& {name}")
            input_info_lines.append(f"  - {name}: Tensor")
            if first_tensor is None:
                first_tensor = name
        else:
            cpp_type = _dtype_to_cpp_type(dtype)
            param_parts.append(f"{cpp_type} {name}")
            input_info_lines.append(f"  - {name}: {cpp_type} (scalar)")

    # Process init_params
    for param in init_params:
        name = param["name"]
        dtype = param.get("dtype", "float")
        is_tensor = param.get("is_tensor", False)

        if is_tensor:
            param_parts.append(f"const at::Tensor& {name}")
            input_info_lines.append(f"  - {name}: Tensor (init param)")
            if first_tensor is None:
                first_tensor = name
        else:
            cpp_type = _dtype_to_cpp_type(dtype)
            param_parts.append(f"{cpp_type} {name}")
            input_info_lines.append(f"  - {name}: {cpp_type} (init param)")

    # Generate exec args
    all_args = [inp["name"] for inp in inputs] + [p["name"] for p in init_params]
    exec_args = ", ".join(all_args + ["result"])

    if first_tensor is None:
        first_tensor = "x"

    return {
        "params": ", ".join(param_parts),
        "first_tensor": first_tensor,
        "exec_args": exec_args,
        "input_info": "\n".join(input_info_lines) if input_info_lines else "  (none)",
    }


class PybindPromptMixin:
    """Pybind code generation prompt mixin."""

    def assemble_pybind_code(self, signature: Any, shape_inference_code: str) -> str:
        """
        Assemble complete pybind source code from signature and shape inference code.

        Args:
            signature: Operator signature from Phase 0
            shape_inference_code: Shape inference code generated by LLM (e.g., "auto output_shape = x.sizes();")

        Returns:
            Complete pybind C++ source code ready for compilation
        """
        fixed = _generate_fixed_parts(signature)
        params = fixed["params"]
        first_tensor = fixed["first_tensor"]
        exec_args = fixed["exec_args"]

        op_name = signature.get("op_name", "Unknown") if isinstance(signature, dict) else "Unknown"
        op_lower = op_name.lower()
        op_capital = op_name[0].upper() + op_name[1:] if op_name else "Unknown"

        return f"""#include <torch/library.h>
#include <torch/csrc/autograd/custom_function.h>
#include "pytorch_npu_helper.hpp"
#include <torch/extension.h>

at::Tensor {op_lower}_custom_impl_npu({params}) {{
    {shape_inference_code}

    at::Tensor result = at::empty(output_shape, {first_tensor}.options());
    EXEC_NPU_CMD(aclnn{op_capital}Custom, {exec_args});
    return result;
}}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {{
    m.def("{op_lower}_custom", &{op_lower}_custom_impl_npu, "{op_name} operator");
}}
"""

    def get_pybind_prompt(
        self,
        signature: Any,
        functionality: str,
        compute_pattern: str,
        shape_inference: dict,
    ) -> str:
        """
        Generate prompt for pybind code generation.

        Args:
            signature: Operator signature from Phase 0
            functionality: Operator functionality description from Phase 0
            compute_pattern: Compute pattern (reduction/matmul/broadcast/other)
            shape_inference: Shape inference info from Phase 0 (input, output, formula)
        """
        # Get input info for LLM reference
        fixed = _generate_fixed_parts(signature)
        input_info = fixed["input_info"]

        # Shape inference from Phase 0
        shape_input = shape_inference.get("input", "unknown")
        shape_output = shape_inference.get("output", "unknown")
        shape_formula = shape_inference.get("formula", "auto output_shape = x.sizes();")

        # Generate template code with placeholder
        template_code = self.assemble_pybind_code(signature, "// === YOUR CODE HERE ===")

        return f"""## Your Role

You are the **pybind agent** in a multi-agent Ascend C code generation pipeline.

Your task: Verify and refine the **output shape inference code** for the Python binding.

## Input

### Available Parameters
{input_info}

### Functionality
{functionality}

### Compute Pattern
{compute_pattern}

### Shape Analysis (from upstream agent)
- Input shape: {shape_input}
- Output shape: {shape_output}
- Suggested formula: `{shape_formula}`

## Fixed Code (you cannot modify)

```cpp
{template_code}```

## Your Task

Review the suggested shape formula and output the final shape inference code.
If the formula is correct, use it directly. If not, fix it.

## Response Format

<response>
<your shape inference code that defines output_shape>
</response>

## Examples

<response>
auto output_shape = x.sizes();
</response>

<response>
auto output_shape = {{a.size(0), b.size(1)}};
</response>

Now output the shape inference code. Output ONLY the `<response>` block:
"""
