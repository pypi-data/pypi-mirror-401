"""Persistent memory storage across sessions at global, project, and file levels"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_storage.ipynb.

# %% auto 0
__all__ = ['MEMORY_DIR', 'get_memory_path', 'convert_old_format', 'load_memories', 'save_memories', 'remember', 'recall',
           'recall_all', 'recall_history', 'forget', 'get_embedder_name', 'recall_semantic', 'clear_embeddings',
           'memory_tool', 'show_memory_tool_help']

# %% ../nbs/01_storage.ipynb 2
from .recall import cosine_similarity
from dialoghelper import add_msg
from pathlib import Path
from datetime import datetime
import json, os

MEMORY_DIR = Path.home() / '.solveit_memory'  # Global memories go here

# %% ../nbs/01_storage.ipynb 3
def get_memory_path(level: str, context: str = None, history: bool = False) -> Path:
    "Get the appropriate memory file path based on level"
    suffix = '_history.txt' if history else '_memory.txt'
    if level == 'global': path = MEMORY_DIR / f'global{suffix}'
    elif level == 'project': path = Path.cwd() / '.memory' / f'project{suffix}'
    elif level == 'file':
        if not context: raise ValueError("File-level memory requires a filename context")
        path = Path.cwd() / '.memory' / f'{context}{suffix}'
    else: raise ValueError(f"Unknown level: {level}. Use 'global', 'project', or 'file'")
    path.parent.mkdir(parents=True, exist_ok=True)
    return path


# %% ../nbs/01_storage.ipynb 4
def convert_old_format(text):
    """Convert old 'key: value' text format to new JSON structure"""
    memories = {}
    for line in text.strip().splitlines():
        if ': ' in line:
            key, value = line.split(': ', 1)
            memories[key] = {'value': value, 'embedding': None}
    return memories

def load_memories(path):
    """Load memories from file, auto-converting old format if needed"""
    if not path.exists():
        return {}
    text = path.read_text()
    if not text.strip():
        return {}
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return convert_old_format(text)

# def save_memories(path, memories):
#     """Save memories dict to JSON file"""
#     path.write_text(json.dumps(memories, indent=2))
def save_memories(path, memories):
    "Save memories dict to JSON file, keeping embeddings on one line"
    class CompactEncoder(json.JSONEncoder):
        def encode(self, o):
            if isinstance(o, dict):
                items = []
                for k, v in o.items(): items.append(f'{json.dumps(k)}: {self.encode(v)}')
                return '{\n  ' + ',\n  '.join(items) + '\n}'
            return json.dumps(o)
    path.write_text(CompactEncoder().encode(memories))

def _append_history(key, value, action, level, context=None):
    "Append an entry to the history file"
    path = get_memory_path(level, context, history=True)
    ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(path, 'a') as f: f.write(f'{ts} | {key} | {action} | {value}\n')

# %% ../nbs/01_storage.ipynb 5
def remember(
    key: str, # The memory key
    value: str, # The value to store
    level: str = 'project', # 'global', 'project', or 'file'
    context: str = None # Required for file-level (the filename)
):
    "Store a key-value pair in memory at the specified level"
    path = get_memory_path(level, context)
    memories = load_memories(path)
    memories[key] = dict(value=value, embedding=None)
    save_memories(path, memories)
    _append_history(key, value, 'remember', level, context)
    return f"Remembered ({level}): {key}"

# %% ../nbs/01_storage.ipynb 6
def recall(
    level: str = 'project', # 'global', 'project', or 'file'
    context: str = None, # Required for file-level (the filename)
    key: str = None # Optional specific key to retrieve
) -> str:
    """Read memories from the specified level"""
    path = get_memory_path(level, context)
    memories = load_memories(path)
    if not memories:
        return f"No {level} memories yet"
    if key is None:
        return '\n'.join(f"{k}: {v['value']}" for k, v in memories.items() if k != '_meta')
    if key in memories:
        return memories[key]['value']
    return None

# %% ../nbs/01_storage.ipynb 7
def recall_all(context: str = None) -> str:
    """Read memories from all levels, merged together"""
    results = []
    for level in ['global', 'project', 'file']:
        try:
            path = get_memory_path(level, context if level == 'file' else None)
            memories = load_memories(path)
            if memories:
                mem_text = '\n'.join(f"{k}: {v['value']}" for k, v in memories.items() if k != '_meta')
                results.append(f"=== {level.upper()} ===\n{mem_text}")
        except ValueError:
            pass  # Skip file level if no context provided
    return '\n'.join(results) if results else "No memories yet"

# %% ../nbs/01_storage.ipynb 8
def recall_history(
    key: str = None, # Optional specific key to filter history for
    level: str = 'project', # 'global', 'project', or 'file'
    context: str = None # Required for file-level (the filename)
) -> str:
    "Read history of changes for a key or all keys at the specified level"
    history_path = get_memory_path(level, context, history=True)
    if not history_path.exists(): return None
    lines = history_path.read_text().splitlines()
    if key is None: return '\n'.join(lines) if lines else None
    filtered = [line for line in lines if f' | {key} | ' in line]
    return '\n'.join(filtered) if filtered else None

def forget(
    key: str, # The memory key to forget
    level: str = 'project', # 'global', 'project', or 'file'
    context: str = None # Required for file-level (the filename)
):
    "Remove a key from memory at the specified level"
    path = get_memory_path(level, context)
    memories = load_memories(path)
    if key not in memories: return f"Key '{key}' not found in {level} memory"
    old_value = memories.pop(key)
    save_memories(path, memories)
    _append_history(key, old_value['value'], 'forget', level, context)
    return f"Forgot ({level}): {key}"

# %% ../nbs/01_storage.ipynb 9
def get_embedder_name(embedder):
    """Get a unique name for an embedder to track which one was used"""
    cls = type(embedder).__name__
    if hasattr(embedder, 'model_name'):
        return f"{cls}:{embedder.model_name}"
    if hasattr(embedder, 'model'):
        return f"{cls}:{getattr(embedder.model, 'model_name', 'default')}"
    return cls

def recall_semantic(
    query: str, # The search query
    level: str = 'project', # 'global', 'project', or 'file'
    context: str = None, # Required for file-level (the filename)
    top_k: int = 3, # Number of results to return
    embedder=None # An Embedder instance (if None, uses SentenceTransformerEmbedder)
) -> list[tuple[str, str, float]]:
    """Find memories semantically similar to the query"""
    if embedder is None:
        if os.environ.get('RECALL_EMBEDDER') == 'openai':
            from psg_recall.recall import OpenAIEmbedder
            embedder = OpenAIEmbedder()
        else:
            from psg_recall.recall import SentenceTransformerEmbedder
            embedder = SentenceTransformerEmbedder()
    
    path = get_memory_path(level, context)
    memories = load_memories(path)
    if not memories:
        return []
    
    embedder_name = get_embedder_name(embedder)
    
    # Check if embeddings were made with a different embedder
    stored_embedder = memories.get('_meta', {}).get('embedder')
    if stored_embedder and stored_embedder != embedder_name:
        # Clear old embeddings since they're incompatible
        print(f"Embedder changed ({stored_embedder} â†’ {embedder_name}), recomputing embeddings...")
        for data in memories.values():
            if isinstance(data, dict) and 'embedding' in data:
                data['embedding'] = None
    
    # Embed query
    query_emb = embedder.embed(query)
    
    # Compute embeddings for memories that don't have them, and save
    updated = False
    for key, data in memories.items():
        if key == '_meta':
            continue
        if data['embedding'] is None:
            data['embedding'] = embedder.embed(f"{key}: {data['value']}")
            updated = True
    
    # Store which embedder was used
    if updated or stored_embedder != embedder_name:
        memories['_meta'] = {'embedder': embedder_name}
        save_memories(path, memories)
    
    # Find most similar
    scores = []
    for key, data in memories.items():
        if key == '_meta':
            continue
        sim = cosine_similarity(query_emb, data['embedding'])
        scores.append((key, data['value'], sim))
    
    scores.sort(key=lambda x: x[2], reverse=True)
    return scores[:top_k]

# %% ../nbs/01_storage.ipynb 11
def clear_embeddings(
    level: str = 'project', # 'global', 'project', or 'file'
    context: str = None # Required for file-level (the filename)
):
    """Clear cached embeddings so they get recomputed on next semantic search"""
    path = get_memory_path(level, context)
    memories = load_memories(path)
    if not memories:
        return "No memories to clear"
    for data in memories.values():
        data['embedding'] = None
    save_memories(path, memories)
    return f"Cleared embeddings for {len(memories)} memories"

# %% ../nbs/01_storage.ipynb 12
def memory_tool(
    action: str, # 'remember', 'recall', 'recall_all', 'recall_semantic', 'recall_history', or 'forget'
    level: str = 'project', # 'global' (all projects), 'project' (current dir), or 'file' (specific file)
    key: str = None, # The memory key (required for 'remember' and 'forget')
    value: str = None, # The value to store (required for 'remember')
    context: str = None, # Filename for file-level memories (e.g. 'main.py')
    query: str = None, # Search query for 'recall_semantic'
    top_k: int = 3 # Number of results for 'recall_semantic'
) -> str:
    "Manage persistent memories across sessions."
    if action == 'remember':
        if not key or not value: return "Error: 'remember' requires both key and value"
        return remember(key, value, level, context)
    elif action == 'recall': return recall(level, context, key)
    elif action == 'recall_all': return recall_all(context)
    elif action == 'recall_history': return recall_history(key, level, context) or "No history found"
    elif action == 'recall_semantic':
        if not query: return "Error: 'recall_semantic' requires a query"
        results = recall_semantic(query, level, context, top_k)
        if not results: return "No memories found"
        return '\n'.join(f"{k}: {v} (score: {s:.3f})" for k, v, s in results)
    elif action == 'forget':
        if not key: return "Error: 'forget' requires a key"
        return forget(key, level, context)
    else: return f"Unknown action: {action}. Use 'remember', 'recall', 'recall_all', 'recall_semantic', 'recall_history', or 'forget'"

# %% ../nbs/01_storage.ipynb 21
def show_memory_tool_help():
    "Generate a note explaining how to use memory_tool"
    help_text = """## &`memory_tool` Usage

Store and retrieve persistent memories across sessions.

**Actions:**
- `memory_tool('remember', key='name', value='Alice')` - Store a memory
- `memory_tool('recall')` - Read all memories at project level
- `memory_tool('recall', key='name')` - Read a specific memory
- `memory_tool('recall_all')` - Read memories from all levels
- `memory_tool('recall_semantic', query='what tools?')` - Semantic search
- `memory_tool('recall_history')` - View all change history
- `memory_tool('recall_history', key='name')` - View history for a specific key
- `memory_tool('forget', key='name')` - Remove a memory

**Levels:**
- `'global'` - Shared across all projects
- `'project'` - Current working directory (default)
- `'file'` - Specific file (requires `context='filename.py'`)

**Examples:**
```python
memory_tool('remember', key='user_name', value='Alice')
memory_tool('remember', level='global', key='api_key', value='sk-...')
memory_tool('recall', level='project')
memory_tool('recall_semantic', query='what is the goal?', top_k=3)
memory_tool('recall_history', key='user_name')
memory_tool('forget', key='old_key')
```"""
    add_msg(content=help_text, pinned=1)
