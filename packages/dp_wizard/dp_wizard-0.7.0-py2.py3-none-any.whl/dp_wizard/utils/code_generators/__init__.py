import re
from datetime import datetime
from pathlib import Path
from typing import NamedTuple, Optional

from dp_wizard_templates.code_template import Template

from dp_wizard import __version__, opendp_version, registry_url
from dp_wizard.types import ColumnName, Product, StatisticName


class AnalysisPlanColumn(NamedTuple):
    statistic_name: StatisticName
    lower_bound: float
    upper_bound: float
    bin_count: int
    weight: int


class AnalysisPlan(NamedTuple):
    """
    >>> plan = AnalysisPlan(
    ...     product=Product.STATISTICS,
    ...     csv_path='optional.csv',
    ...     contributions=10,
    ...     contributions_entity='Family',
    ...     epsilon=2.0,
    ...     max_rows=1000,
    ...     groups={'grouping_col': ['expected', 'values']},
    ...     columns={
    ...         'data_col': [AnalysisPlanColumn('Histogram', 0, 100, 10, 1)]
    ...     })
    >>> print(plan)
    DP Statistics for `data_col` grouped by `grouping_col`
    >>> print(plan.to_stem())
    dp_statistics_for_data_col_grouped_by_grouping_col
    >>> print(plan.to_note())
    This demonstrates how to calculate ...
    Generated by DP Wizard ...
    """

    product: Product
    csv_path: Optional[str]
    contributions: int
    contributions_entity: str
    epsilon: float
    max_rows: int
    groups: dict[ColumnName, list[str | float]]
    columns: dict[ColumnName, list[AnalysisPlanColumn]]

    def __str__(self) -> str:
        def md_list(names) -> str:
            return ", ".join(f"`{name}`" for name in names)

        columns_md = md_list(self.columns.keys()) or "TBD"
        groups_md = md_list(self.groups)
        grouped_by = f" grouped by {groups_md}" if groups_md else ""
        return f"{self.product} for {columns_md}{grouped_by}"

    def get_absolute_csv_path(self) -> str:
        if self.csv_path is None:
            return ""  # pragma: no cover
        return str(Path(self.csv_path).absolute())

    def to_stem(self) -> str:
        return re.sub(r"\W+", " ", str(self)).strip().replace(" ", "_").lower()

    def to_note(self) -> str:
        now = datetime.now().strftime("%b %d, %Y at %I:%M%p")
        return f"""
This demonstrates how to calculate {self} using OpenDP (https://docs.opendp.org).
Generated by DP Wizard v{__version__} (https://github.com/opendp/dp-wizard) on {now}.
        """.strip()

    def get_groups_with_keys(self) -> dict[ColumnName, list[str | float]]:
        # When AnalysisPlan is created, we confirm that groups are selected.
        # (We preserve the list of values, even if not currently selected.)
        # This selects the subset with public keys.
        return {k: v for k, v in self.groups.items() if v}


# Public functions used to generate code snippets in the UI;
# These do not require an entire analysis plan, so they stand on their own.


def make_privacy_unit_block(
    contributions: int,
    contributions_entity: str,
):
    import opendp.prelude as dp

    def template(CONTRIBUTIONS, CONTRIBUTIONS_ENTITY):
        # Each CONTRIBUTIONS_ENTITY can contribute this many rows.
        contributions = CONTRIBUTIONS
        privacy_unit = dp.unit_of(contributions=contributions)  # noqa: F841

    return (
        Template(template)
        .fill_values(CONTRIBUTIONS=contributions)
        .fill_expressions(CONTRIBUTIONS_ENTITY=contributions_entity)
        .finish()
    )


def make_privacy_loss_block(pure: bool, epsilon: float, max_rows: int):
    """
    Comments in the *pure* privacy loss block reference synthetic data generation
    ("cuts dict"), so don't use "pure=True" for stats code!

    >>> print(
    ...     'pure DP: ',
    ...     make_privacy_loss_block(pure=True, epsilon=1, max_rows=1000)
    ... )
    pure DP: ...delta=0...
    >>> print(
    ...     'approx DP: ',
    ...     make_privacy_loss_block(pure=False, epsilon=1, max_rows=1000)
    ... )
    approx DP: ...delta=1 / max...
    """

    import opendp.prelude as dp

    if pure:

        def template(EPSILON, MAX_ROWS):
            privacy_loss = dp.loss_of(  # noqa: F841
                # EPSILON_COMMENT_BLOCK
                epsilon=EPSILON,
                # If your columns don't match your cuts dict,
                # you will also need to provide a very small "delta" value.
                # https://docs.opendp.org/en/OPENDP_V_VERSION/getting-started/tabular-data/grouping.html#Stable-Keys
                delta=0,  # or 1 / max(1e7, MAX_ROWS),
            )

    else:

        def template(EPSILON, MAX_ROWS):
            privacy_loss = dp.loss_of(  # noqa: F841
                # EPSILON_COMMENT_BLOCK
                epsilon=EPSILON,
                # There are many models of differential privacy. For flexibility,
                # we are using a model which tolerates a small probability (delta)
                # that data may be released in the clear. Delta should always be small,
                # but if the dataset is particularly large,
                # delta should be at least as small as 1/(row count).
                # https://docs.opendp.org/en/OPENDP_V_VERSION/getting-started/tabular-data/grouping.html#Stable-Keys
                delta=1 / max(1e7, MAX_ROWS),
            )

    return (
        Template(template)
        .fill_expressions(
            OPENDP_V_VERSION=f"v{opendp_version}",
        )
        .fill_values(
            EPSILON=epsilon,
            MAX_ROWS=max_rows,
        )
        .fill_comment_blocks(
            EPSILON_COMMENT_BLOCK=f"""
Your privacy budget is captured in the "epsilon" parameter.
Larger values increase the risk that personal data could be
reconstructed, so choose the smallest value that gives you
the needed accuracy. You can also compare your budget to
other projects:
{registry_url}
            """
        )
        .finish()
    )


def make_column_config_block(
    name: str,
    statistic_name: StatisticName,
    lower_bound: float,
    upper_bound: float,
    bin_count: int,
):
    from dp_wizard.utils.code_generators.analyses import get_statistic_by_name

    return get_statistic_by_name(statistic_name).make_column_config_block(
        column_name=name,
        lower_bound=lower_bound,
        upper_bound=upper_bound,
        bin_count=bin_count,
    )
