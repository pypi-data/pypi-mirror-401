#!/usr/bin/env python3
"""
Test script for the efficient model runner functionality.
"""

import sys
from pathlib import Path

import psutil

# Add the parent directory to the path so we can import the modules
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from mcli.workflow.model_service.model_service import ModelService


def test_imports():
    """Test that all required modules can be imported."""
    print("ğŸ§ª Testing imports...")

    try:

        print("âœ… requests imported")
    except ImportError as e:
        print(f"âŒ requests import failed: {e}")
        return False

    try:

        print("âœ… click imported")
    except ImportError as e:
        print(f"âŒ click import failed: {e}")
        return False

    try:

        print("âœ… psutil imported")
    except ImportError as e:
        print(f"âŒ psutil import failed: {e}")
        return False

    try:

        print("âœ… ModelService imported")
    except ImportError as e:
        print(f"âŒ ModelService import failed: {e}")
        return False

    return True


def test_system_analysis():
    """Test system analysis functionality."""
    print("\nğŸ§ª Testing system analysis...")

    try:

        # Get basic system info
        cpu_count = psutil.cpu_count()
        memory_gb = psutil.virtual_memory().total / (1024**3)

        print(f"âœ… CPU cores: {cpu_count}")
        print(f"âœ… Memory: {memory_gb:.1f} GB")

        # Test GPU detection
        try:
            import torch

            gpu_available = torch.cuda.is_available()
            print(f"âœ… GPU available: {gpu_available}")
            if gpu_available:
                gpu_name = torch.cuda.get_device_name(0)
                print(f"âœ… GPU name: {gpu_name}")
        except ImportError:
            print("âš ï¸  PyTorch not available for GPU detection")

        return True

    except Exception as e:
        print(f"âŒ System analysis failed: {e}")
        return False


def test_model_selection():
    """Test model selection logic."""
    print("\nğŸ§ª Testing model selection...")

    try:
        # Import the efficient runner
        from mcli.workflow.model_service.ollama_efficient_runner import (
            EFFICIENT_MODELS,
            get_system_info,
            recommend_model,
        )

        # Test model dictionary
        print(f"âœ… Found {len(EFFICIENT_MODELS)} efficient models:")
        for key, info in EFFICIENT_MODELS.items():
            print(f"  - {key}: {info['name']} ({info['parameters']})")

        # Test system info
        system_info = get_system_info()
        print("âœ… System info collected")

        # Test model recommendation
        recommended = recommend_model(system_info)
        print(f"âœ… Recommended model: {recommended}")

        return True

    except Exception as e:
        print(f"âŒ Model selection test failed: {e}")
        return False


def test_ollama_check():
    """Test Ollama installation check."""
    print("\nğŸ§ª Testing Ollama check...")

    try:
        from mcli.workflow.model_service.ollama_efficient_runner import check_ollama_installed

        # This will check if ollama is installed
        installed = check_ollama_installed()

        if installed:
            print("âœ… Ollama is installed")
        else:
            print("âš ï¸  Ollama not installed (this is expected if not installed)")

        return True

    except Exception as e:
        print(f"âŒ Ollama check failed: {e}")
        return False


def test_mcli_service():
    """Test MCLI model service functionality."""
    print("\nğŸ§ª Testing MCLI model service...")

    try:

        # Create service instance
        service = ModelService()
        print("âœ… ModelService created")

        # Check status
        status = service.status()
        print(f"âœ… Service status: {status['running']}")

        # Test database
        models = service.model_manager.db.get_all_models()
        print(f"âœ… Database accessible, {len(models)} models found")

        return True

    except Exception as e:
        print(f"âŒ MCLI service test failed: {e}")
        return False


def test_api_endpoints():
    """Test API endpoint definitions."""
    print("\nğŸ§ª Testing API endpoints...")

    try:

        service = ModelService()

        # Check for required endpoints
        routes = [route.path for route in service.app.routes]
        required_routes = ["/models", "/models/summary", "/models/from-url"]

        for route in required_routes:
            if route in routes:
                print(f"âœ… Route {route} found")
            else:
                print(f"âŒ Route {route} not found")
                return False

        return True

    except Exception as e:
        print(f"âŒ API endpoints test failed: {e}")
        return False


def main():
    """Run all tests."""
    print("ğŸš€ Testing Efficient Model Runner")
    print("=" * 50)

    tests = [
        ("Imports", test_imports),
        ("System Analysis", test_system_analysis),
        ("Model Selection", test_model_selection),
        ("Ollama Check", test_ollama_check),
        ("MCLI Service", test_mcli_service),
        ("API Endpoints", test_api_endpoints),
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\nğŸ“‹ Running {test_name} test...")
        if test_func():
            passed += 1
            print(f"âœ… {test_name} test passed")
        else:
            print(f"âŒ {test_name} test failed")

    print("\n" + "=" * 50)
    print(f"ğŸ“Š Test Results: {passed}/{total} tests passed")

    if passed == total:
        print("ğŸ‰ All tests passed! The efficient model runner is ready to use.")
        print("\nğŸ“ Next steps:")
        print("1. Install Ollama: https://ollama.com/download")
        print("2. Run: python ollama_efficient_runner.py")
        print("3. Follow the prompts to download and test models")
        return 0
    else:
        print("âŒ Some tests failed. Please check the errors above.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
