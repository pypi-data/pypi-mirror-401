Metadata-Version: 2.4
Name: videopython
Version: 0.10.0
Summary: Minimal video generation and processing library.
Project-URL: Homepage, https://videopython.com
Project-URL: Repository, https://github.com/bartwojtowicz/videopython/
Project-URL: Documentation, https://videopython.com
Author-email: Bartosz WÃ³jtowicz <bartoszwojtowicz@outlook.com>, Bartosz Rudnikowicz <bartoszrudnikowicz840@gmail.com>, Piotr Pukisz <piotr.pukisz@gmail.com>
License: Apache-2.0
License-File: LICENSE
Keywords: ai,editing,generation,movie,opencv,python,shorts,video,videopython
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: <3.13,>=3.10
Requires-Dist: numpy>=1.25.2
Requires-Dist: opencv-python>=4.9.0.80
Requires-Dist: pillow>=10.3.0
Requires-Dist: tqdm>=4.66.3
Provides-Extra: ai
Requires-Dist: accelerate>=0.29.2; extra == 'ai'
Requires-Dist: diffusers>=0.26.3; extra == 'ai'
Requires-Dist: easyocr>=1.7.0; extra == 'ai'
Requires-Dist: elevenlabs>=1.0.0; extra == 'ai'
Requires-Dist: google-generativeai>=0.8.0; extra == 'ai'
Requires-Dist: hf-transfer>=0.1.9; extra == 'ai'
Requires-Dist: httpx>=0.27.0; extra == 'ai'
Requires-Dist: lumaai>=1.0.0; extra == 'ai'
Requires-Dist: numba>=0.61.0; extra == 'ai'
Requires-Dist: ollama>=0.4.5; extra == 'ai'
Requires-Dist: openai-whisper>=20240930; extra == 'ai'
Requires-Dist: openai>=1.0.0; extra == 'ai'
Requires-Dist: panns-inference>=0.1.0; extra == 'ai'
Requires-Dist: runwayml>=0.10.0; extra == 'ai'
Requires-Dist: scikit-learn>=1.3.0; extra == 'ai'
Requires-Dist: scipy>=1.10.0; extra == 'ai'
Requires-Dist: torch>=2.1.0; extra == 'ai'
Requires-Dist: transformers>=4.38.1; extra == 'ai'
Requires-Dist: ultralytics>=8.0.0; extra == 'ai'
Requires-Dist: whisperx>=3.4.2; extra == 'ai'
Provides-Extra: dev
Requires-Dist: mypy>=1.8.0; extra == 'dev'
Requires-Dist: pytest-cov>=6.1.1; extra == 'dev'
Requires-Dist: pytest>=7.4.0; extra == 'dev'
Requires-Dist: ruff>=0.1.14; extra == 'dev'
Requires-Dist: types-pillow>=10.2.0.20240213; extra == 'dev'
Requires-Dist: types-tqdm>=4.66.0.20240106; extra == 'dev'
Description-Content-Type: text/markdown

# videopython

A minimal video generation and processing library designed for short-form videos, with focus on simplicity and ease of use for both humans and AI agents.

## Installation

### Install ffmpeg
```bash
# MacOS
brew install ffmpeg
# Ubuntu
sudo apt-get install ffmpeg
```

### Install library
```bash
# With AI features
uv add videopython --extra ai
# or
pip install "videopython[ai]"

# Base only (no AI dependencies)
uv add videopython
# or
pip install videopython
```

## Quick Example

```python
from videopython.base import Video, FadeTransition
from videopython.ai import TextToImage, ImageToVideo, AudioToText
from videopython.base.text import TranscriptionOverlay

# Load and transform videos using fluent API
video1 = Video.from_path("clip1.mp4").cut(0, 5).resize(1080, 1920)
video2 = Video.from_path("clip2.mp4").cut(0, 5).resize(1080, 1920)

# Combine with fade transition
video = video1.transition_to(video2, FadeTransition(effect_time_seconds=1.0))

# Generate and add AI content
def add_ai_content(video):
    # Generate an image and animate it
    image = TextToImage(backend="openai").generate_image("A sunset over mountains")
    intro = ImageToVideo().generate_video(image=image, prompt="Sunset animation")

    # Transcribe and add subtitles
    transcription = AudioToText(backend="openai").transcribe(video)
    overlay = TranscriptionOverlay()
    video = overlay.apply(video, transcription)

    return intro + video

video = add_ai_content(video)
video.save("output.mp4")
```

## Documentation

For more examples and API reference, see the [full documentation](docs/index.md).

## AI Backend Support

Cloud backends require API keys: `OPENAI_API_KEY`, `GOOGLE_API_KEY`, `ELEVENLABS_API_KEY`, `RUNWAYML_API_KEY`, `LUMAAI_API_KEY`.

| Class | local | openai | gemini | elevenlabs | luma | runway |
|-------|-------|--------|--------|------------|------|--------|
| TextToVideo | CogVideoX1.5-5B | - | - | - | Dream Machine | - |
| ImageToVideo | CogVideoX1.5-5B-I2V | - | - | - | Dream Machine | Gen-4 Turbo |
| TextToSpeech | Bark | TTS | - | Multilingual v2 | - | - |
| TextToMusic | MusicGen | - | - | - | - | - |
| TextToImage | SDXL | DALL-E 3 | - | - | - | - |
| ImageToText | BLIP | GPT-4o | Gemini | - | - | - |
| AudioToText | Whisper | Whisper API | Gemini | - | - | - |
| AudioClassifier | PANNs | - | - | - | - | - |
| LLMSummarizer | Ollama | GPT-4o | Gemini | - | - | - |
| ObjectDetector | YOLO | GPT-4o | Gemini | - | - | - |
| TextDetector | EasyOCR | GPT-4o | Gemini | - | - | - |
| FaceDetector | OpenCV | - | - | - | - | - |
| ShotTypeClassifier | - | GPT-4o | Gemini | - | - | - |
| CameraMotionDetector | OpenCV | - | - | - | - | - |
| MotionAnalyzer | OpenCV | - | - | - | - | - |

## Development

See [DEVELOPMENT.md](DEVELOPMENT.md) for setup instructions and contribution guidelines.
