# üîç PreOCR

<div align="center">

**A fast, CPU-only library that intelligently detects whether files need OCR processing**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)
[![PyPI version](https://badge.fury.io/py/preocr.svg)](https://badge.fury.io/py/preocr)

*Save time and money by skipping OCR for files that are already machine-readable*

</div>

---

## üéØ What is PreOCR?

PreOCR is a **universal document gatekeeper** that analyzes any file type and answers one simple question:

> **"Is this file already machine-readable, or do I need OCR?"**

Instead of running expensive OCR on everything, PreOCR uses intelligent analysis to determine if OCR is actually needed. Perfect for filtering documents before sending them to expensive OCR engines like MinerU, Tesseract, or cloud OCR services.

## ‚ú® Key Features

- ‚ö° **Fast**: CPU-only, typically < 1 second per file
- üéØ **Accurate**: 92-95% accuracy with hybrid pipeline
- üß† **Smart**: Adaptive pipeline - fast heuristics for clear cases, OpenCV refinement for edge cases
- üîí **Deterministic**: Same input ‚Üí same output
- üö´ **OCR-free**: Never performs OCR to detect OCR
- üìÑ **Page-level**: Analyze PDFs page-by-page (v0.2.0+)
- üè∑Ô∏è **Reason codes**: Structured codes for programmatic handling
- üé® **Layout-aware**: Detects mixed content and layout structure (v0.3.0+)
- üîÑ **Batch processing** üÜï: Process thousands of files in parallel with automatic caching, progress tracking, and resume support (v0.5.0+)

## üöÄ Quick Start

```bash
pip install preocr
```

### Single File Detection

```python
from preocr import needs_ocr

# Simple usage
result = needs_ocr("document.pdf")

if result["needs_ocr"]:
    print(f"Needs OCR: {result['reason']}")
    # Run your OCR here (e.g., MinerU)
else:
    print(f"Already readable: {result['reason']}")
```

### Batch Processing (New in v0.5.0)

Process thousands of files efficiently with parallel processing:

```python
from preocr import BatchProcessor

# Process entire directory with automatic parallelization
processor = BatchProcessor(max_workers=8)
results = processor.process_directory("documents/")

# Get comprehensive statistics
results.print_summary()

# Access results
for result in results.results:
    if result["needs_ocr"]:
        print(f"{result['file_path']} needs OCR")
```

## üìä How It Works

PreOCR uses a **hybrid adaptive pipeline**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Any File   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Heuristics     ‚îÇ ‚Üê Fast text extraction + rules
‚îÇ  (Fast Path)    ‚îÇ   (< 1 second)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Confidence ‚â•0.9?‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ       ‚îÇ
   YES     NO
   ‚îÇ       ‚îÇ
   ‚ñº       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇReturn‚îÇ ‚îÇ OpenCV Layout   ‚îÇ ‚Üê Only for edge cases
‚îÇFast! ‚îÇ ‚îÇ Analysis        ‚îÇ   (20-200ms)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ Refine Decision‚îÇ
         ‚îÇ (Better Accuracy)‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Result ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Performance:**
- **~85-90% of files**: Fast path (< 150ms) - heuristics only
- **~10-15% of files**: Refined path (150-300ms) - heuristics + OpenCV (depends on page count)
- **Overall accuracy**: 94-97% (vs 88-92% with heuristics alone)
- **Average time**: 120-180ms per file

## üì¶ Installation

### Basic Installation

```bash
pip install preocr
```

**System Requirements:**
- **libmagic**: Required for file type detection. Install system package:
  - **Linux (Debian/Ubuntu)**: `sudo apt-get install libmagic1`
  - **Linux (RHEL/CentOS)**: `sudo yum install file-devel` or `sudo dnf install file-devel`
  - **macOS**: `brew install libmagic`
  - **Windows**: Usually included with `python-magic-bin` package

### With OpenCV Refinement (Recommended)

For improved accuracy on edge cases:

```bash
pip install preocr[layout-refinement]
```

This installs `opencv-python-headless` and NumPy for layout analysis. The pipeline automatically uses OpenCV when confidence is low, even if installed separately.

## üíª Usage Examples

### Basic Detection

```python
from preocr import needs_ocr

result = needs_ocr("document.pdf")

print(f"Needs OCR: {result['needs_ocr']}")
print(f"Confidence: {result['confidence']:.2f}")
print(f"Reason: {result['reason']}")
print(f"Reason Code: {result['reason_code']}")
```

### Page-Level Analysis

```python
result = needs_ocr("mixed_document.pdf", page_level=True)

if result["reason_code"] == "PDF_MIXED":
    print(f"Mixed PDF: {result['pages_needing_ocr']} pages need OCR")
    
    for page in result["pages"]:
        if page["needs_ocr"]:
            print(f"  Page {page['page_number']}: {page['reason']}")
```

### Layout-Aware Detection

```python
result = needs_ocr("document.pdf", layout_aware=True)

if result.get("layout"):
    layout = result["layout"]
    print(f"Layout Type: {layout['layout_type']}")
    print(f"Text Coverage: {layout['text_coverage']}%")
    print(f"Image Coverage: {layout['image_coverage']}%")
    print(f"Is Mixed Content: {layout['is_mixed_content']}")
```

### Batch Processing

PreOCR provides a powerful `BatchProcessor` class for processing multiple files efficiently with parallel processing, caching, and progress tracking.

#### Basic Batch Processing

```python
from preocr import BatchProcessor

# Create processor with default settings
processor = BatchProcessor()

# Process all files in a directory
results = processor.process_directory("documents/")

# Print summary statistics
results.print_summary()

# Access individual results
for result in results.results:
    if result["needs_ocr"]:
        print(f"{result['file_path']} needs OCR: {result['reason']}")
```

#### Advanced Batch Processing

```python
from preocr import BatchProcessor

# Configure processor with options
processor = BatchProcessor(
    max_workers=8,              # Parallel workers (default: CPU count)
    use_cache=True,              # Enable caching to skip processed files
    layout_aware=True,           # Perform layout analysis for PDFs
    page_level=True,             # Enable page-level analysis
    extensions=["pdf", "png"],   # Filter by file extensions
    recursive=True,              # Scan subdirectories
    min_size=1024,               # Minimum file size (bytes)
    max_size=10*1024*1024,      # Maximum file size (bytes)
    resume_from="results.json",  # Resume from previous results
)

# Process directory with progress bar
results = processor.process_directory("documents/", progress=True)

# Get detailed statistics
stats = results.get_statistics()
print(f"Processed: {stats['processed']} files")
print(f"Needs OCR: {stats['needs_ocr']} ({stats['needs_ocr']/stats['processed']*100:.1f}%)")
print(f"Processing speed: {stats['files_per_second']:.2f} files/sec")

# Access results by type
for result in results.results:
    file_type = result.get("file_type")
    if result.get("needs_ocr"):
        # Process with OCR
        pass
    else:
        # Use existing text
        pass
```

#### Batch Processing Features

- **Parallel Processing**: Automatically uses all CPU cores for faster processing
- **Caching**: Skip already-processed files to save time on re-runs
- **Progress Tracking**: Real-time progress bar with file details (requires `tqdm`)
- **Resume Support**: Resume from previous results to continue interrupted batches
- **File Filtering**: Filter by extensions, size, and recursive scanning
- **Page-Level Analysis**: Get per-page statistics for PDFs
- **Comprehensive Statistics**: Detailed breakdown by file type, reason codes, and performance metrics

#### Simple Loop Alternative

For simple use cases, you can still use a basic loop:

```python
from pathlib import Path
from preocr import needs_ocr

files = Path("documents").glob("*.pdf")
needs_ocr_count = 0
skipped_count = 0

for file_path in files:
    result = needs_ocr(file_path)
    if result["needs_ocr"]:
        needs_ocr_count += 1
        # Process with OCR
    else:
        skipped_count += 1
        # Use existing text

print(f"OCR needed: {needs_ocr_count}, Skipped: {skipped_count}")
```

### Integration with OCR Engines

```python
from preocr import needs_ocr
# from mineru import ocr  # or your OCR engine

def process_document(file_path):
    result = needs_ocr(file_path)
    
    if result["needs_ocr"]:
        # Only run expensive OCR if needed
        ocr_result = ocr(file_path)
        return ocr_result
    else:
        # File is already machine-readable
        return {"text": extract_text(file_path), "source": "native"}
```

## üìã Supported File Types

| File Type | Detection | Accuracy |
|-----------|-----------|----------|
| **PDFs** | Digital vs Scanned | 90-95% |
| **Images** | PNG, JPG, TIFF, etc. | 100% |
| **Office Docs** | DOCX, PPTX, XLSX | 85-90% |
| **Text Files** | TXT, CSV, HTML | 99% |
| **Structured Data** | JSON, XML | 99% |
| **Unknown Binaries** | Conservative default | 50-60% |

## üéØ Reason Codes

PreOCR provides structured reason codes for programmatic handling:

### No OCR Needed
- `TEXT_FILE` - Plain text file
- `OFFICE_WITH_TEXT` - Office document with sufficient text
- `PDF_DIGITAL` - Digital PDF with extractable text
- `STRUCTURED_DATA` - JSON/XML files
- `HTML_WITH_TEXT` - HTML with sufficient content

### OCR Needed
- `IMAGE_FILE` - Image file
- `OFFICE_NO_TEXT` - Office document with insufficient text
- `PDF_SCANNED` - PDF appears to be scanned
- `PDF_MIXED` - PDF with mixed digital and scanned pages
- `HTML_MINIMAL` - HTML with minimal content
- `UNKNOWN_BINARY` - Unknown binary file type

### Page-Level Codes
- `PDF_PAGE_DIGITAL` - Individual page has extractable text
- `PDF_PAGE_SCANNED` - Individual page appears scanned

**Example:**
```python
result = needs_ocr("document.pdf")
if result["reason_code"] == "PDF_MIXED":
    # Handle mixed PDF
    process_mixed_pdf(result)
elif result["reason_code"] == "PDF_SCANNED":
    # All pages need OCR
    run_full_ocr(result)
```

## üìà Performance

### Benchmark Results

Based on comprehensive testing across various document types:

| Scenario | Time | Accuracy |
|----------|------|----------|
| **Fast Path (Heuristics Only)** | | |
| - Text files | < 5ms | ~99% |
| - Digital PDFs (1‚Äì5 pages) | 30‚Äì120ms | 95‚Äì98% |
| - Office documents | 80‚Äì200ms | 88‚Äì92% |
| - Images | 5‚Äì30ms | ~100% |
| **OpenCV Refinement (CPU, sampled pages)** | | |
| - Single-page PDF | 20‚Äì60ms | 92‚Äì96% |
| - Multi-page PDF (2‚Äì5 pages) | 40‚Äì120ms | 92‚Äì96% |
| - Large PDFs (sampled) | 80‚Äì200ms | 90‚Äì94% |
| **Overall Pipeline** | | |
| - Clear cases (~85‚Äì90%) | <150ms | ~99% |
| - Edge cases (~10‚Äì15%) | 150‚Äì300ms | 92‚Äì96% |
| - **Average** | **120‚Äì180ms** | **94‚Äì97%** |

### Performance Breakdown

**Fast Path (~85-90% of files):**
- Text extraction: 20-100ms
- Rule-based decision: < 1ms
- **Total: < 150ms** for most files

**OpenCV Refinement (~10-15% of files):**
- PDF to image conversion: 10-30ms per page
- OpenCV layout analysis: 10-40ms per page
- Decision refinement: < 1ms
- **Total: 20-200ms** (depends on page count and sampling strategy)

**Factors Affecting Performance:**
- **File size**: Larger files take longer to process
- **Page count**: More pages = longer OpenCV analysis
- **Document complexity**: Complex layouts require more processing
- **System resources**: CPU speed and available memory

### Running Benchmarks

To benchmark PreOCR on your documents:

```bash
# Install with OpenCV support
pip install preocr[layout-refinement]

# Run benchmark script
python benchmark.py /path/to/pdf/directory [max_files]
```

The benchmark script measures:
- Fast path timing (heuristics only)
- OpenCV analysis timing
- Total pipeline timing
- Performance by page count
- Statistical analysis (min, max, mean, median, P95)

## üèóÔ∏è Architecture

```
File Input
    ‚Üì
File Type Detection (MIME, extension)
    ‚Üì
Text Extraction Probe (PDF, Office, Text)
    ‚Üì
Visual/Binary Analysis (Images, entropy)
    ‚Üì
Decision Engine (Rule-based logic)
    ‚Üì
Confidence Check
    ‚îú‚îÄ High (‚â•0.9) ‚Üí Return
    ‚îî‚îÄ Low (<0.9) ‚Üí OpenCV Layout Analysis ‚Üí Refine ‚Üí Return
```

## üîß API Reference

### `needs_ocr(file_path, page_level=False, layout_aware=False)`

Main API function that determines if a file needs OCR.

**Parameters:**
- `file_path` (str or Path): Path to the file to analyze
- `page_level` (bool): If `True`, return page-level analysis for PDFs (default: `False`)
- `layout_aware` (bool): If `True`, perform explicit layout analysis for PDFs (default: `False`)

**Returns:**
Dictionary with:
- `needs_ocr` (bool): Whether OCR is needed
- `file_type` (str): File type category
- `category` (str): "structured" or "unstructured"
- `confidence` (float): Confidence score (0.0-1.0)
- `reason_code` (str): Structured reason code
- `reason` (str): Human-readable reason
- `signals` (dict): All collected signals (for debugging)
- `pages` (list, optional): Page-level results
- `layout` (dict, optional): Layout analysis results

### `BatchProcessor(max_workers=None, use_cache=True, layout_aware=False, page_level=True, extensions=None, min_size=None, max_size=None, recursive=False, resume_from=None)`

Batch processor for efficiently processing multiple files with parallel processing, caching, and progress tracking.

**Parameters:**
- `max_workers` (int, optional): Maximum number of parallel workers (default: CPU count)
- `use_cache` (bool): Enable caching to skip already-processed files (default: `True`)
- `layout_aware` (bool): Perform layout analysis for PDFs (default: `False`)
- `page_level` (bool): Perform page-level analysis for PDFs (default: `True`)
- `extensions` (list, optional): List of file extensions to process (e.g., `["pdf", "png"]`). Default: common document/image formats
- `min_size` (int, optional): Minimum file size in bytes (default: `None`)
- `max_size` (int, optional): Maximum file size in bytes (default: `None`)
- `recursive` (bool): Scan subdirectories recursively (default: `False`)
- `resume_from` (str, optional): Path to JSON file with previous results to resume from (default: `None`)

**Methods:**
- `process_directory(directory, progress=True) -> BatchResults`: Process all files in a directory

**Returns:**
`BatchResults` object with:
- `results` (list): List of result dictionaries (one per file)
- `errors` (list): List of error dictionaries for failed files
- `get_statistics() -> dict`: Get comprehensive statistics about the batch
- `print_summary()`: Print formatted summary to console

### `BatchResults`

Container for batch processing results with statistics and summary methods.

**Attributes:**
- `results` (list): List of result dictionaries
- `errors` (list): List of error dictionaries
- `total_files` (int): Total number of files found
- `processed_files` (int): Number of files successfully processed
- `skipped_files` (int): Number of files skipped (cached/resumed)

**Methods:**
- `get_statistics() -> dict`: Returns statistics including:
  - File counts (total, processed, errors, skipped)
  - OCR decisions (needs_ocr, no_ocr counts and percentages)
  - Page-level statistics (total pages, pages needing OCR)
  - Breakdown by file type and reason code
  - Performance metrics (processing time, files per second)
- `print_summary()`: Prints a formatted summary to the console

## üîß Configuration

### Logging

PreOCR uses Python's logging module for debugging and monitoring. Configure logging via environment variable:

```bash
# Set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
export PREOCR_LOG_LEVEL=INFO

# Or in Python
from preocr.logger import set_log_level
import logging
set_log_level(logging.DEBUG)
```

Default log level is `WARNING`. Set to `INFO` or `DEBUG` for more verbose output during development.

## üêõ Troubleshooting

### Common Issues

**1. File type detection fails**
- Ensure `libmagic` is installed on your system
- Linux: `sudo apt-get install libmagic1` (Debian/Ubuntu) or `sudo yum install file-devel` (RHEL/CentOS)
- macOS: `brew install libmagic`
- Windows: Usually included with `python-magic-bin` package

**2. PDF text extraction returns empty results**
- Check if PDF is password-protected
- Verify PDF is not corrupted
- Try installing both `pdfplumber` and `PyMuPDF` for better compatibility

**3. OpenCV layout analysis not working**
- Install OpenCV dependencies: `pip install preocr[layout-refinement]`
- Verify OpenCV is available: `python -c "import cv2; print(cv2.__version__)"`

**4. Low confidence scores**
- Enable layout-aware analysis: `needs_ocr(file_path, layout_aware=True)`
- Check file type is supported
- Review signals in result dictionary for debugging

**5. Performance issues**
- Most files use fast path (< 150ms)
- Large PDFs may take longer; consider page-level analysis
- Disable layout-aware analysis if speed is critical

### Getting Help

- Check existing [Issues](https://github.com/yuvaraj3855/preocr/issues)
- Enable debug logging: `export PREOCR_LOG_LEVEL=DEBUG`
- Review signals in result: `result["signals"]` for detailed analysis

## üß™ Development

```bash
# Clone repository
git clone https://github.com/yuvaraj3855/preocr.git
cd preocr

# Install in development mode
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest

# Run with coverage
pytest --cov=preocr --cov-report=html

# Run linting
ruff check preocr/
black --check preocr/

# Run type checking
mypy preocr/
```

## üìù Changelog

See [CHANGELOG.md](CHANGELOG.md) for version history.

### Recent Updates

**v0.5.0** - Batch Processing with Parallel Execution üÜï
- **BatchProcessor** class for processing thousands of files efficiently
- Parallel processing with automatic worker management
- Built-in caching to skip already-processed files
- Progress tracking with detailed statistics
- Resume support for interrupted batches
- File filtering (extensions, size, recursive scanning)
- Comprehensive statistics and reporting

**v0.3.0** - Hybrid Pipeline with OpenCV Refinement
- Adaptive pipeline: fast heuristics + OpenCV for edge cases
- Improved accuracy (92-95%)
- Layout-aware detection
- Automatic confidence-based refinement

**v0.2.0** - Page-Level Detection
- Page-by-page analysis for PDFs
- Structured reason codes
- Enhanced confidence scoring

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## üìÑ License

Apache License 2.0 - see [LICENSE](LICENSE) file for details.

## üîó Links

- **GitHub**: [https://github.com/yuvaraj3855/preocr](https://github.com/yuvaraj3855/preocr)
- **PyPI**: [https://pypi.org/project/preocr](https://pypi.org/project/preocr)
- **Issues**: [https://github.com/yuvaraj3855/preocr/issues](https://github.com/yuvaraj3855/preocr/issues)

## ‚≠ê Why PreOCR?

**Before PreOCR:**
- ‚ùå Run OCR on everything ‚Üí Expensive, slow
- ‚ùå Manual inspection ‚Üí Time-consuming
- ‚ùå No automation ‚Üí Not scalable

**With PreOCR:**
- ‚úÖ Skip OCR for 50-70% of files ‚Üí Save money
- ‚úÖ Fast decisions (< 1 second) ‚Üí Don't slow pipeline
- ‚úÖ Automated ‚Üí Scalable
- ‚úÖ 92-95% accurate ‚Üí Good enough for production

**Perfect for:**
- Document processing pipelines
- Cost optimization (skip expensive OCR)
- Batch document analysis
- Pre-filtering before OCR engines (MinerU, Tesseract, etc.)

---

<div align="center">

**Made with ‚ù§Ô∏è for efficient document processing**

[‚≠ê Star on GitHub](https://github.com/yuvaraj3855/preocr) | [üìñ Documentation](https://github.com/yuvaraj3855/preocr#readme) | [üêõ Report Issue](https://github.com/yuvaraj3855/preocr/issues)

</div>
