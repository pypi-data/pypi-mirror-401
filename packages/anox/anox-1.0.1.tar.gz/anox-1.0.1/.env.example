# AXON Environment Configuration
# Copy this file to .env and fill in your values

# API Keys for Online Models
# Uncomment and set the ones you plan to use

# Anthropic Claude (PRIMARY MODEL - Recommended)
# Get your API key from: https://console.anthropic.com/
#ANTHROPIC_API_KEY=sk-ant-...

# OpenAI (Alternative/Fallback)
#OPENAI_API_KEY=sk-...

# Google Gemini
#GOOGLE_API_KEY=...

# OpenRouter (access to multiple models)
#OPENROUTER_API_KEY=...

# Local Model Configuration
# Path to your GGUF model file for offline inference
#AXON_LOCAL_MODEL_PATH=/path/to/model.gguf

# Mobile API Configuration
# Set this to enable API key authentication for mobile endpoints
#AXON_API_KEY=your-secure-api-key-here

# Server Configuration
# Host and port for mobile API server
AXON_API_HOST=0.0.0.0
AXON_API_PORT=8000

# Ngrok Configuration
# Get your auth token from https://dashboard.ngrok.com/get-started/your-authtoken
#NGROK_AUTH_TOKEN=your-ngrok-token-here

# Model Router Configuration
# Prefer online models when available (true/false)
AXON_PREFER_ONLINE=false

# Automatically fallback to offline if online fails (true/false)
AXON_AUTO_FALLBACK=true

# Logging Configuration
AXON_LOG_LEVEL=INFO

# Error Tracking (Sentry)
# Get your DSN from https://sentry.io/
# Uncomment to enable error tracking
#SENTRY_DSN=https://your-dsn@sentry.io/project-id
#SENTRY_ENVIRONMENT=development
#SENTRY_RELEASE=axon@1.0.0

# Advanced: Custom Model Endpoints
# For self-hosted or custom OpenAI-compatible APIs
#AXON_CUSTOM_BASE_URL=https://your-custom-endpoint.com/v1
