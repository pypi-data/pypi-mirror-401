"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ (LightGBM –∏–ª–∏ XGBoost).

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/train_single.py --model lightgbm
    python scripts/train_single.py --model xgboost --run-name my_xgb_run
    python scripts/train_single.py --model lightgbm --no-submission
"""

import argparse
import logging
import sys
from pathlib import Path

import pandas as pd
import mlflow

from scripts.models.registry import create_model_from_registry, list_available_models
from scripts.training.pipeline import TrainingPipeline, setup_mlflow
from scripts.utils_validation import BaselineFeatureExtractor, TimeSeriesValidator
from scripts.modeling_config import (
    FILES,
    VALIDATION_CONFIG,
    SUBMISSION_CONFIG,
)

# === logging ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
)
logger = logging.getLogger(__name__)


def parse_args():
    """–ü–∞—Ä—Å–∏—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    available_models = list_available_models()
    models_help = "\n".join([f"  {k}: {v}" for k, v in available_models.items()])

    parser = argparse.ArgumentParser(
        description="–û–±—É—á–∞–µ—Ç –æ–¥–Ω—É –º–æ–¥–µ–ª—å (LightGBM –∏–ª–∏ XGBoost)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:
{models_help}

–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –û–±—É—á–∏—Ç—å LightGBM —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
  python scripts/train_single.py --model lightgbm

  # –û–±—É—á–∏—Ç—å XGBoost —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –∏–º–µ–Ω–µ–º run
  python scripts/train_single.py --model xgboost --run-name my_xgb_experiment

  # –û–±—É—á–∏—Ç—å –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è submission —Ñ–∞–π–ª–∞
  python scripts/train_single.py --model lightgbm --no-submission

  # –û–±—É—á–∏—Ç—å –±–µ–∑ timestamp –≤ –∏–º–µ–Ω–∏ submission —Ñ–∞–π–ª–∞
  python scripts/train_single.py --model lightgbm --no-timestamp

  # –û–±—É—á–∏—Ç—å –±–µ–∑ score –≤ –∏–º–µ–Ω–∏ submission —Ñ–∞–π–ª–∞
  python scripts/train_single.py --model lightgbm --no-score
        """,
    )

    parser.add_argument(
        "--model",
        type=str,
        choices=list(available_models.keys()),
        required=True,
        help="–¢–∏–ø –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
    )

    parser.add_argument(
        "--run-name",
        type=str,
        default=None,
        help="–ò–º—è MLflow run (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)",
    )

    parser.add_argument(
        "--model-name",
        type=str,
        default=None,
        help="–ò–º—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ)",
    )

    parser.add_argument(
        "--submission-filename",
        type=str,
        default=None,
        help="–ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è submission (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)",
    )

    parser.add_argument(
        "--no-submission",
        action="store_true",
        help="–ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å submission —Ñ–∞–π–ª",
    )

    parser.add_argument(
        "--no-timestamp",
        action="store_true",
        help="–ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å timestamp –≤ –∏–º—è submission —Ñ–∞–π–ª–∞",
    )

    parser.add_argument(
        "--no-score",
        action="store_true",
        help="–ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å score –≤ –∏–º—è submission —Ñ–∞–π–ª–∞",
    )

    parser.add_argument(
        "--skip-leak-checks",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ data leakage",
    )

    parser.add_argument(
        "--train-encoded",
        type=Path,
        default=None,
        help=f"–ü—É—Ç—å –∫ train –¥–∞–Ω–Ω—ã–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {FILES['train_encoded']})",
    )

    parser.add_argument(
        "--test-encoded",
        type=Path,
        default=None,
        help=f"–ü—É—Ç—å –∫ test –¥–∞–Ω–Ω—ã–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {FILES['test_encoded']})",
    )

    # Optional override of time splits (useful for Airflow demo / low-RAM runs)
    parser.add_argument(
        "--train-start",
        type=int,
        default=None,
        help=f"–ù–∞—á–∞–ª—å–Ω—ã–π –º–µ—Å—è—Ü train (date_block_num). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {VALIDATION_CONFIG['train_months'][0]}",
    )
    parser.add_argument(
        "--train-end",
        type=int,
        default=None,
        help=f"–ö–æ–Ω–µ—á–Ω—ã–π –º–µ—Å—è—Ü train (date_block_num). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {VALIDATION_CONFIG['train_months'][1]}",
    )
    parser.add_argument(
        "--val-start",
        type=int,
        default=None,
        help=f"–ù–∞—á–∞–ª—å–Ω—ã–π –º–µ—Å—è—Ü validation. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {VALIDATION_CONFIG['val_months'][0]}",
    )
    parser.add_argument(
        "--val-end",
        type=int,
        default=None,
        help=f"–ö–æ–Ω–µ—á–Ω—ã–π –º–µ—Å—è—Ü validation. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {VALIDATION_CONFIG['val_months'][1]}",
    )
    parser.add_argument(
        "--test-month",
        type=int,
        default=None,
        help=f"–ú–µ—Å—è—Ü test. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {VALIDATION_CONFIG['test_month']}",
    )
    parser.add_argument(
        "--production-month",
        type=int,
        default=None,
        help=f"–ú–µ—Å—è—Ü production (–¥–ª—è submission). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: {VALIDATION_CONFIG['production_month']}",
    )

    return parser.parse_args()


def main():
    args = parse_args()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    logger.info("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow...")
    setup_mlflow()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    train_path = args.train_encoded or FILES["train_encoded"]
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ train –¥–∞–Ω–Ω—ã—Ö –∏–∑ {train_path}...")

    if not train_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {train_path}")
        sys.exit(1)

    sales_encoded = pd.read_parquet(train_path)
    logger.info(
        f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sales_encoded):,} —Å—Ç—Ä–æ–∫, {len(sales_encoded.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤"
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    validation_cfg = dict(VALIDATION_CONFIG)
    if args.train_start is not None or args.train_end is not None:
        validation_cfg["train_months"] = (
            args.train_start
            if args.train_start is not None
            else validation_cfg["train_months"][0],
            args.train_end
            if args.train_end is not None
            else validation_cfg["train_months"][1],
        )
    if args.val_start is not None or args.val_end is not None:
        validation_cfg["val_months"] = (
            args.val_start
            if args.val_start is not None
            else validation_cfg["val_months"][0],
            args.val_end
            if args.val_end is not None
            else validation_cfg["val_months"][1],
        )
    if args.test_month is not None:
        validation_cfg["test_month"] = args.test_month
    if args.production_month is not None:
        validation_cfg["production_month"] = args.production_month

    validator = TimeSeriesValidator(**validation_cfg)
    feature_extractor = BaselineFeatureExtractor(features_df=sales_encoded)

    feature_list = feature_extractor.get_feature_list()
    logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: {len(feature_list)}")

    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä
    logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {args.model}")
    model = create_model_from_registry(
        model_type=args.model,
        model_name=args.model_name,
    )

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ run, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
    run_name = args.run_name
    if run_name is None:
        run_name = f"train_{model.name}"

    # –°–æ–∑–¥–∞–Ω–∏–µ pipeline
    pipeline = TrainingPipeline(
        model=model,
        validator=validator,
        feature_extractor=feature_extractor,
        mlflow_run_name=run_name,
        clip_min=SUBMISSION_CONFIG["clip_min"],
        clip_max=SUBMISSION_CONFIG["clip_max"],
    )

    # –ó–∞–ø—É—Å–∫ pipeline
    try:
        results = pipeline.run_full_pipeline(
            run_leak_checks=not args.skip_leak_checks,
            create_submission=not args.no_submission,
            submission_filename=args.submission_filename,
            include_timestamp=not args.no_timestamp,
            include_score=not args.no_score,
        )

        # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if results.get("metrics_test") is not None:
            test_rmse = results["metrics_test"]["rmse"]
            test_mae = results["metrics_test"]["mae"]
            test_r2 = results["metrics_test"]["r2"]

            print(f"\nTest RMSE: {test_rmse:.4f}")
            print(f"Test MAE:  {test_mae:.4f}")
            print(f"Test R¬≤:   {test_r2:.4f}")

        if results.get("metrics_val") is not None:
            val_rmse = results["metrics_val"]["rmse"]
            print(f"\nValidation RMSE: {val_rmse:.4f}")

        logger.info("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

        # –í—ã–≤–æ–¥ —Å—Å—ã–ª–∫–∏ –Ω–∞ MLflow
        try:
            tracking_uri = mlflow.get_tracking_uri()
            if tracking_uri and tracking_uri.startswith("http"):
                print(f"\nüìä MLflow UI: {tracking_uri}")
        except Exception:
            pass

        return 0

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ pipeline: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
