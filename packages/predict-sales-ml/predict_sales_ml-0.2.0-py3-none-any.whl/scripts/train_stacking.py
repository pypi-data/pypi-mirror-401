"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è stacking –º–æ–¥–µ–ª–∏.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/train_stacking.py
    python scripts/train_stacking.py --run-name my_stacking_run
    python scripts/train_stacking.py --meta-model Ridge --meta-alpha 0.1
    python scripts/train_stacking.py --n-folds 10 --cv-type timeseries
"""

import argparse
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd
import mlflow

from sklearn.linear_model import LinearRegression, Ridge, ElasticNet
from scripts.models.stacking_model import StackingModel
from scripts.models.registry import create_model_from_registry
from scripts.training.pipeline import TrainingPipeline, setup_mlflow
from scripts.utils_validation import BaselineFeatureExtractor, TimeSeriesValidator
from scripts.modeling_config import (
    FILES,
    VALIDATION_CONFIG,
    SUBMISSION_CONFIG,
    STACKING_CONFIG,
    LIGHTGBM_PARAMS,
    XGBOOST_PARAMS,
)

# === logging ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s",
)
logger = logging.getLogger(__name__)

# –†–µ–≥–∏—Å—Ç—Ä –º–µ—Ç–∞-–º–æ–¥–µ–ª–µ–π
META_MODEL_REGISTRY = {
    "LinearRegression": LinearRegression,
    "Ridge": Ridge,
    "ElasticNet": ElasticNet,
}


def parse_args():
    """–ü–∞—Ä—Å–∏—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
    parser = argparse.ArgumentParser(
        description="–û–±—É—á–∞–µ—Ç stacking –º–æ–¥–µ–ª—å (–∞–Ω—Å–∞–º–±–ª—å –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –û–±—É—á–∏—Ç—å stacking —Å –¥–µ—Ñ–æ–ª—Ç–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
  python scripts/train_stacking.py

  # –û–±—É—á–∏—Ç—å —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –∏–º–µ–Ω–µ–º run
  python scripts/train_stacking.py --run-name stacking_experiment_1

  # –ò–∑–º–µ–Ω–∏—Ç—å –º–µ—Ç–∞-–º–æ–¥–µ–ª—å
  python scripts/train_stacking.py --meta-model Ridge --meta-alpha 0.1

  # –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –∏ —Ç–∏–ø CV
  python scripts/train_stacking.py --n-folds 10 --cv-type timeseries

  # –î–æ–±–∞–≤–∏—Ç—å/—É–±—Ä–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
  python scripts/train_stacking.py --base-models xgboost lightgbm

  # –ë–µ–∑ OOF (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
  python scripts/train_stacking.py --no-oof

  # –ë–µ–∑ submission
  python scripts/train_stacking.py --no-submission
        """,
    )

    parser.add_argument(
        "--run-name",
        type=str,
        default=None,
        help="–ò–º—è MLflow run (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)",
    )

    parser.add_argument(
        "--model-name",
        type=str,
        default=None,
        help="–ò–º—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ)",
    )

    parser.add_argument(
        "--base-models",
        type=str,
        nargs="+",
        default=None,
        help="–°–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä: xgboost lightgbm). "
        "–ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ STACKING_CONFIG",
    )

    parser.add_argument(
        "--meta-model",
        type=str,
        choices=list(META_MODEL_REGISTRY.keys()),
        default=None,
        help="–¢–∏–ø –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ (LinearRegression, Ridge, ElasticNet)",
    )

    parser.add_argument(
        "--meta-alpha",
        type=float,
        default=None,
        help="Alpha –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è Ridge/ElasticNet –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏",
    )

    parser.add_argument(
        "--n-folds",
        type=int,
        default=None,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è OOF –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
    )

    parser.add_argument(
        "--cv-type",
        type=str,
        choices=["kfold", "timeseries"],
        default=None,
        help="–¢–∏–ø –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ (kfold –∏–ª–∏ timeseries)",
    )

    parser.add_argument(
        "--no-oof",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å out-of-fold predictions (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)",
    )

    parser.add_argument(
        "--submission-filename",
        type=str,
        default=None,
        help="–ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è submission (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)",
    )

    parser.add_argument(
        "--no-submission",
        action="store_true",
        help="–ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å submission —Ñ–∞–π–ª",
    )

    parser.add_argument(
        "--no-timestamp",
        action="store_true",
        help="–ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å timestamp –≤ –∏–º—è submission —Ñ–∞–π–ª–∞",
    )

    parser.add_argument(
        "--no-score",
        action="store_true",
        help="–ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å score –≤ –∏–º—è submission —Ñ–∞–π–ª–∞",
    )

    parser.add_argument(
        "--skip-leak-checks",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ data leakage",
    )

    parser.add_argument(
        "--train-encoded",
        type=Path,
        default=None,
        help=f"–ü—É—Ç—å –∫ train –¥–∞–Ω–Ω—ã–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {FILES['train_encoded']})",
    )

    parser.add_argument(
        "--test-encoded",
        type=Path,
        default=None,
        help=f"–ü—É—Ç—å –∫ test –¥–∞–Ω–Ω—ã–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {FILES['test_encoded']})",
    )

    return parser.parse_args()


def create_base_models(
    base_models_config: List[Dict[str, Any]],
) -> List[Any]:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

    Args:
        base_models_config: –°–ø–∏—Å–æ–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

    Returns:
        –°–ø–∏—Å–æ–∫ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
    """
    base_models = []

    for idx, model_config in enumerate(base_models_config):
        model_type = model_config["type"]
        model_name = model_config.get("name", f"{model_type}_{idx + 1}")
        model_params = model_config.get("params", {})

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä
        model = create_model_from_registry(
            model_type=model_type,
            model_name=model_name,
            custom_params=model_params,
        )

        base_models.append(model)
        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å {idx + 1}: {model_name} ({model_type})")

    return base_models


def create_stacking_model(args) -> StackingModel:
    """
    –°–æ–∑–¥–∞–µ—Ç stacking –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

    Args:
        args: –ü–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏

    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä StackingModel
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
    if args.base_models:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        base_models_config = []
        for idx, model_type in enumerate(args.base_models):
            if model_type == "xgboost":
                params = XGBOOST_PARAMS.copy()
                if idx > 0:
                    params["random_state"] = 42 + idx  # –†–∞–∑–Ω—ã–µ seeds
            elif model_type == "lightgbm":
                params = LIGHTGBM_PARAMS.copy()
                if idx > 0:
                    params["random_state"] = 42 + idx
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {model_type}")

            base_models_config.append(
                {
                    "type": model_type,
                    "name": f"{model_type}_{idx + 1}",
                    "params": params,
                }
            )
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ STACKING_CONFIG
        base_models_config = STACKING_CONFIG["base_models"]

    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
    base_models = create_base_models(base_models_config)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å
    if args.meta_model:
        meta_model_class = META_MODEL_REGISTRY[args.meta_model]
        meta_model_params = {}
        if args.meta_alpha is not None:
            meta_model_params["alpha"] = args.meta_alpha
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ STACKING_CONFIG
        meta_model_name = STACKING_CONFIG["meta_model"]["class"]
        meta_model_class = META_MODEL_REGISTRY.get(
            meta_model_name,
            LinearRegression,  # Fallback
        )
        meta_model_params = STACKING_CONFIG["meta_model"].get("params", {})

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã stacking
    use_oof = not args.no_oof if args.no_oof else STACKING_CONFIG.get("use_oof", True)
    n_folds = args.n_folds or STACKING_CONFIG.get("n_folds", 5)
    cv_type = args.cv_type or STACKING_CONFIG.get("cv_type", "kfold")
    random_state = STACKING_CONFIG.get("random_state", 42)

    # –ò–º—è –º–æ–¥–µ–ª–∏
    model_name = args.model_name or "stacking_model"

    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ stacking –º–æ–¥–µ–ª–∏:")
    logger.info(f"  –ë–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π: {len(base_models)}")
    logger.info(f"  –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å: {meta_model_class.__name__}")
    logger.info(f"  OOF: {use_oof}, –§–æ–ª–¥–æ–≤: {n_folds}, CV —Ç–∏–ø: {cv_type}")

    return StackingModel(
        base_models=base_models,
        meta_model_class=meta_model_class,
        meta_model_params=meta_model_params,
        use_oof=use_oof,
        n_folds=n_folds,
        cv_type=cv_type,
        random_state=random_state,
        name=model_name,
    )


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    args = parse_args()

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow
    logger.info("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow...")
    setup_mlflow()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    train_path = args.train_encoded or FILES["train_encoded"]
    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ train –¥–∞–Ω–Ω—ã—Ö –∏–∑ {train_path}...")

    if not train_path.exists():
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {train_path}")
        sys.exit(1)

    sales_encoded = pd.read_parquet(train_path)
    logger.info(
        f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sales_encoded):,} —Å—Ç—Ä–æ–∫, {len(sales_encoded.columns)} —Å—Ç–æ–ª–±—Ü–æ–≤"
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    validator = TimeSeriesValidator(**VALIDATION_CONFIG)
    feature_extractor = BaselineFeatureExtractor(features_df=sales_encoded)

    feature_list = feature_extractor.get_feature_list()
    logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: {len(feature_list)}")
    print(f"\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á–µ–π: {len(feature_list)}")

    # –°–æ–∑–¥–∞–Ω–∏–µ stacking –º–æ–¥–µ–ª–∏
    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ stacking –º–æ–¥–µ–ª–∏...")
    stacking_model = create_stacking_model(args)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ run, –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ
    run_name = args.run_name
    if run_name is None:
        run_name = f"stacking_{stacking_model.name}"

    # –°–æ–∑–¥–∞–Ω–∏–µ pipeline
    pipeline = TrainingPipeline(
        model=stacking_model,
        validator=validator,
        feature_extractor=feature_extractor,
        mlflow_run_name=run_name,
        clip_min=SUBMISSION_CONFIG["clip_min"],
        clip_max=SUBMISSION_CONFIG["clip_max"],
    )

    # –ó–∞–ø—É—Å–∫ pipeline
    try:
        results = pipeline.run_full_pipeline(
            run_leak_checks=not args.skip_leak_checks,
            create_submission=not args.no_submission,
            submission_filename=args.submission_filename,
            include_timestamp=not args.no_timestamp,
            include_score=not args.no_score,
        )

        # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")

        if results.get("metrics_test") is not None:
            test_rmse = results["metrics_test"]["rmse"]
            test_mae = results["metrics_test"]["mae"]
            test_r2 = results["metrics_test"]["r2"]

            print(f"\nTest RMSE: {test_rmse:.4f}")
            print(f"Test MAE:  {test_mae:.4f}")
            print(f"Test R¬≤:   {test_r2:.4f}")

        if results.get("metrics_val") is not None:
            val_rmse = results["metrics_val"]["rmse"]
            print(f"\nValidation RMSE: {val_rmse:.4f}")

        # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∫–ª–∞–¥–µ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
        if hasattr(stacking_model, "get_meta_model_coefficients"):
            coef_df = stacking_model.get_meta_model_coefficients()
            if coef_df is not None:
                print("\n" + "=" * 60)
                print("–í–∫–ª–∞–¥ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏):")
                print("=" * 60)
                print(coef_df.to_string(index=False))

        logger.info("Stacking –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

        # –í—ã–≤–æ–¥ —Å—Å—ã–ª–∫–∏ –Ω–∞ MLflow
        try:
            tracking_uri = mlflow.get_tracking_uri()
            if tracking_uri and tracking_uri.startswith("http"):
                print(f"\nüìä MLflow UI: {tracking_uri}")
        except Exception:
            pass

        return 0

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ pipeline: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    sys.exit(main())
