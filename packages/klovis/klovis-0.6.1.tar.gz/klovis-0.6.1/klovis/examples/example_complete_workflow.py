"""
Exemple complet d'un workflow Klovis de bout en bout.

Cet exemple montre comment utiliser tous les composants ensemble
pour cr√©er un pipeline complet de traitement de documents.
"""

from pathlib import Path
from klovis.pipeline import KlovisPipeline
from klovis.loaders import DirectoryLoader
from klovis.cleaning import (
    HTMLCleaner,
    TextCleaner,
    NormalizeCleaner,
    EmojiCleaner,
    CompositeCleaner,
)
from klovis.chunking import SimpleChunker, MarkdownChunker
from klovis.merger import SemanticMerger
from klovis.metadata.metadata_generator import MetadataGenerator
from klovis.transforming.markdown_transformer import MarkdownTransformer


def example_complete_workflow():
    """Exemple : Workflow complet de A √† Z."""
    print("=" * 60)
    print("üéØ Workflow Complet Klovis")
    print("=" * 60)
    
    # =====================================================================
    # √âTAPE 1: Configuration
    # =====================================================================
    data_dir = Path("data/")
    
    if not data_dir.exists():
        print(f"‚ö†Ô∏è  Le dossier {data_dir} n'existe pas.")
        print("   Cr√©ez un dossier 'data/' avec vos fichiers pour tester.")
        return
    
    # =====================================================================
    # √âTAPE 2: Chargement
    # =====================================================================
    print("\nüìÅ √âtape 1: Chargement des documents...")
    loader = DirectoryLoader(
        path=str(data_dir),
        recursive=True,
        ignore_hidden=True,
        markdownify=True,  # Convertit HTML/PDF en Markdown
    )
    documents = loader.load()
    print(f"   ‚úÖ {len(documents)} document(s) charg√©(s)")
    
    # =====================================================================
    # √âTAPE 3: Nettoyage
    # =====================================================================
    print("\nüßπ √âtape 2: Nettoyage des documents...")
    cleaner = CompositeCleaner([
        HTMLCleaner(),  # Nettoie le HTML r√©siduel
        TextCleaner(),  # Nettoie les espaces et caract√®res sp√©ciaux
        NormalizeCleaner(
            lowercase=True,  # Convertit en minuscules
            preserve_newlines=True,  # Pr√©serve les sauts de ligne
        ),
        EmojiCleaner(replace=False),  # Supprime les emojis
    ])
    cleaned_docs = cleaner.clean(documents)
    print(f"   ‚úÖ {len(cleaned_docs)} document(s) nettoy√©(s)")
    
    # =====================================================================
    # √âTAPE 4: D√©coupage (Chunking)
    # =====================================================================
    print("\n‚úÇÔ∏è  √âtape 3: D√©coupage en chunks...")
    chunker = SimpleChunker(
        chunk_size=1000,  # 1000 caract√®res par chunk
        chunk_overlap=100,  # 100 caract√®res de chevauchement
        smart_overlap=True,  # √âvite de couper au milieu d'un mot
    )
    chunks = chunker.chunk(cleaned_docs)
    print(f"   ‚úÖ {len(chunks)} chunk(s) g√©n√©r√©(s)")
    
    # =====================================================================
    # √âTAPE 5: Fusion s√©mantique (optionnel)
    # =====================================================================
    print("\nüîó √âtape 4: Fusion s√©mantique (optionnel)...")
    print("   üí° Pour utiliser SemanticMerger, vous avez besoin d'un embedder:")
    print("      embedder = YourEmbedder()")
    print("      merger = SemanticMerger(embedder=embedder, max_size=2000)")
    print("      chunks = merger.merge(chunks)")
    # D√©commentez pour utiliser:
    # embedder = YourEmbedder()
    # merger = SemanticMerger(embedder=embedder, max_size=2000)
    # chunks = merger.merge(chunks)
    
    # =====================================================================
    # √âTAPE 6: G√©n√©ration de m√©tadonn√©es
    # =====================================================================
    print("\nüìä √âtape 5: G√©n√©ration de m√©tadonn√©es...")
    metadata_gen = MetadataGenerator()
    enriched_chunks = metadata_gen.generate(chunks)
    print(f"   ‚úÖ {len(enriched_chunks)} chunk(s) enrichi(s)")
    
    # =====================================================================
    # √âTAPE 7: Transformation (optionnel)
    # =====================================================================
    print("\nüìù √âtape 6: Transformation en Markdown (optionnel)...")
    transformer = MarkdownTransformer(include_metadata=True)
    markdown_chunks = transformer.transform(enriched_chunks)
    print(f"   ‚úÖ {len(markdown_chunks)} chunk(s) transform√©(s)")
    
    # =====================================================================
    # R√âSULTAT FINAL
    # =====================================================================
    print("\n" + "=" * 60)
    print("‚úÖ Workflow termin√© avec succ√®s !")
    print("=" * 60)
    print(f"\nüìä R√©sum√©:")
    print(f"   - Documents charg√©s: {len(documents)}")
    print(f"   - Chunks g√©n√©r√©s: {len(chunks)}")
    print(f"   - Chunks enrichis: {len(enriched_chunks)}")
    print(f"   - Chunks transform√©s: {len(markdown_chunks)}")
    print()
    
    # Afficher un exemple de chunk
    if enriched_chunks:
        print("üìÑ Exemple de chunk enrichi:")
        example = enriched_chunks[0]
        print(f"   Source: {example.metadata.get('source')}")
        print(f"   Chunk ID: {example.metadata.get('chunk_id')}")
        print(f"   Longueur: {example.metadata.get('length')} caract√®res")
        print(f"   Texte (premiers 100 caract√®res):")
        print(f"   {example.text[:100]}...")
    print()


def example_workflow_with_pipeline():
    """Exemple : Workflow utilisant KlovisPipeline."""
    print("=" * 60)
    print("üöÄ Workflow avec KlovisPipeline")
    print("=" * 60)
    
    # Configuration du pipeline
    pipeline = KlovisPipeline(
        loader=DirectoryLoader(
            path="data/",
            recursive=True,
            markdownify=True,
        ),
        cleaner=CompositeCleaner([
            HTMLCleaner(),
            TextCleaner(),
            NormalizeCleaner(lowercase=True),
        ]),
        chunker=SimpleChunker(chunk_size=1000, chunk_overlap=100),
        metadata_generator=MetadataGenerator(),
        require_api_key=False,
        export_results=True,
        export_format="json",
    )
    
    # Ex√©cution (DirectoryLoader n√©cessite un appel manuel)
    documents = pipeline.loader.load()
    results = pipeline.run(documents)
    
    print(f"‚úÖ Pipeline ex√©cut√©: {len(results)} chunk(s) g√©n√©r√©(s)")
    print(f"üìÅ R√©sultats export√©s dans: outputs/")
    print()


if __name__ == "__main__":
    print("\nüéØ Exemples de Workflows Complets Klovis\n")
    
    # D√©commenter l'exemple que vous voulez tester
    # example_complete_workflow()
    # example_workflow_with_pipeline()
    
    print("üí° D√©commentez les exemples dans le code pour les tester !\n")
    print("üìù Note: Ajustez les chemins et configurations selon vos besoins.\n")

