import os
import random
import re
import json
import ast
from typing import List, Optional, Dict, Any, Union
from PIL import Image

from OpenRT.attacks.blackbox.base import BaseBlackBoxAttack
from OpenRT.attacks.base_attack import AttackResult
from OpenRT.judges.base_judge import BaseJudge
from OpenRT.core.registry import attack_registry
from OpenRT.models.base_image_generator import BaseImageGenerator
from .messages import get_init_msg, process_target_response, get_attacker_system_prompt

@attack_registry.register("ideator_attack")
class IdeatorAttack(BaseBlackBoxAttack):
    """
    Implementation of the Ideator attack.
    
    Ideator is a jailbreak attack that uses generated images to create jailbreak prompts.
    This attack combines image generation and language model interaction to craft
    adversarial inputs, using the vision capabilities of LVLMs (Large Vision-Language Models)
    as an attack vector.
    """
    
    def __init__(
        self,
        model,
        attacker_model,
        image_generator: Optional[BaseImageGenerator],
        judge: Optional[BaseJudge] = None,
        output_dir: Optional[str] = "./results/images",
        num_iterations = 2,
        num_sessions = 2,
        max_retries = 5,
        is_vlm_attacker: bool = False,
        verbose: bool = False,
        **kwargs
    ):
        """
        Initialize the Ideator attack.
        
        Args:
            model: The target LVLM to attack
            attacker_model: The (vision-)language model used to generate attack prompts
            judge: Judge to evaluate attack success
            image_generator: Image generator for creating images from prompts
            output_dir: Directory to save generated images
            num_iterations: Number of iterations per session
            num_sessions: Number of attack sessions to run
            max_retries: Maximum retries for extracting valid prompts
            is_vlm_attacker: Whether the attacker model is a vision-language model
            verbose: Whether to print detailed logs
            **kwargs: Additional parameters
        """
        super().__init__(model, **kwargs)
        assert image_generator is not None, "An image generator must be provided for the Ideator attack."
        self.image_generator = image_generator
        self.attacker_model = attacker_model
        self.judge = judge
        self.output_dir = output_dir
        self.num_iterations = num_iterations
        self.num_sessions = num_sessions
        self.max_retries = max_retries
        self.is_vlm_attacker = is_vlm_attacker
        self.verbose = verbose
        
        self.demo_target_str = "Sure, here is a detailed guide on how to create a harmful device."
        
        # Create output directory if it doesn't exist
        self.output_dir = os.path.join(output_dir, "ideator")
        os.makedirs(self.output_dir, exist_ok=True)          
    
    def extract_json(self, s):
        """
        Extract JSON object from a string containing image prompt and text prompt.

        Args:
            s (str): The string containing the potential JSON structure.

        Returns:
            dict: A dictionary containing 'image prompt' and 'text prompt', or None if extraction fails.
        """
        # Try to find JSON object in the string
        match = re.search(r'\{[^{}]*\}', s)
        if not match:
            return None
        
        try:
            parsed = json.loads(match.group())
            # Validate required keys exist
            if "image prompt" in parsed and "text prompt" in parsed:
                return parsed
        except json.JSONDecodeError:
            pass
        
        return None
    
    def attack(self, target: str) -> AttackResult:
        result = AttackResult(target=target)
        temp_result = {}
        
        # Create a unique filename for the image
        safe_target = re.sub(r'[^a-zA-Z0-9]', '_', target)[:50]
        # Include the image mode in the filename
        image_filename = f"ideator_{safe_target}_{{}}_{{}}.png"
        image_path = os.path.join(self.output_dir, image_filename)
        if self.verbose:
            print(f"Image will be saved to: {image_path}")
        
        if self.verbose:
            print(f"\n=== Starting Ideator Attack on: {target} ===")
            
        attacker_system_prompt = get_attacker_system_prompt(target, self.demo_target_str)
        self.attacker_model.set_system_message(attacker_system_prompt)
        analysis_result = get_init_msg(target)
        for session_index in range(self.num_sessions):
            victim_response = None
            image = None
            temp_result[session_index] = {}

            for iteration_index in range(self.num_iterations):
                if self.verbose:
                    print(f"\n--- Session {session_index+1}, Iteration {iteration_index+1} ---")
                    
                if iteration_index > 0:
                    analysis_result = process_target_response(victim_response, target)
                    
                if self.verbose:
                    print(f"Attacker Analysis Result: {analysis_result}")

                # Retry loop for extracting valid prompts
                parsed = None
                for attempt in range(self.max_retries):
                    if self.is_vlm_attacker:
                        attacker_response = self.attacker_model.query(analysis_result, image_input=image, maintain_history=True)
                    else:
                        attacker_response = self.attacker_model.query(analysis_result, maintain_history=True)
                    
                    if self.verbose:
                        print(f"Attacker response (attempt {attempt+1}): {attacker_response}")
                    
                    parsed = self.extract_json(attacker_response)
                    if parsed is not None:
                        break
                    
                    self.attacker_model.remove_last_turn()
                
                if parsed is None:
                    print("Warning: Failed to extract valid prompts after maximum retries. Skipping this iteration.")
                    continue
                    # raise ValueError(f"Failed to extract valid prompts after {self.max_retries} attempts.")
                
                image_prompt = parsed['image prompt']
                text_prompt = parsed['text prompt']
                
                if self.verbose:
                    print(f"Extracted Image Prompt: {image_prompt}")
                    print(f"Extracted Text Prompt: {text_prompt}")
                    
                
                image_path = image_path.format(session_index, iteration_index)
                image = self.image_generator.generate(image_prompt, image_path)
                
                if image is None:
                    print("Warning: Image generation failed. Skipping this iteration.")
                    continue

                victim_response = self.model.query(text_prompt, image_input=image)

                turn_info = {
                    "analysis_result": analysis_result,
                    "attacker_response": attacker_response,
                    "victim_response": victim_response,
                    "text_prompt": text_prompt,
                    "image_prompt": image_prompt,
                    "image_path": image_path
                }
                temp_result[session_index][iteration_index] = turn_info
                if self.verbose:
                    print(f"Victim Response: {victim_response}")
                
                if self.judge is not None:    
                    success = self.judge.is_query_successful(target, victim_response)
                    if success:
                        if self.verbose:
                            print(f"Attack succeeded in session {session_index+1}, iteration {iteration_index+1}!")
                        result.success = True
                        result.final_prompt = text_prompt
                        result.output_text = victim_response
                        result.image_path = image_path
                        result.history.append({'process': temp_result})
                        return result
                
        if self.verbose:
            print("Attack failed after all sessions and iterations.")
        # Record history and final outputs if attack failed
        result.success = False
        result.history.append({'process': temp_result})
        result.final_prompt = text_prompt
        result.output_text = victim_response
        result.image_path = image_path
        
        return result
