from OpenRT.attacks.base_attack import BaseAttack, AttackResult
from OpenRT.core.registry import attack_registry
from .coa_modules import SeedChainGenerator, AttackChainExecutor, AttackChainUpdater, SemanticScorer, ChainStep
from typing import Dict, Any
from OpenRT.judges.base_judge import BaseJudge
from dataclasses import dataclass, field

@dataclass
class CoAResult(AttackResult):
    chain_rounds: list = field(default_factory=list)
    semantic_progression: list = field(default_factory=list)
    walk_decisions: list = field(default_factory=list)
    final_round: int = 0

@attack_registry.register("coa_attack")
class CoAAttack(BaseAttack):
    def __init__(self, model: Any, attack_model: Any, judge: BaseJudge, max_rounds: int = 5, max_iterations: int = 20, **kwargs):
        super().__init__(model, **kwargs)
        self.attack_model = attack_model
        self.judge = judge
        self.max_rounds = max_rounds
        self.max_iterations = max_iterations

        # Initialize CoA components
        self.chain_generator = SeedChainGenerator(attack_model)
        self.executor = AttackChainExecutor(model, judge)
        self.semantic_scorer = SemanticScorer()
        self.updater = AttackChainUpdater(self.semantic_scorer)

        print(f"Initialized CoAAttack with {max_rounds} max rounds")

    def attack(self, target: str) -> CoAResult:
        result = CoAResult(target=target)

        # Generate initial seed chains
        seed_chains = self.chain_generator.generate_seed_chains(target, self.max_rounds)
        if not seed_chains:
            print("No valid chains generated, using fallback")
            return self._fallback_attack(target)

        # Select best chain (use first for simplicity)
        selected_chain = seed_chains[0]
        current_round = 1
        previous_step = None

        print(f"Starting CoA with {len(selected_chain)} rounds")

        for iteration in range(self.max_iterations):
            print(f"\n--- Iteration {iteration + 1} (Round {current_round}) ---")

            if current_round > self.max_rounds:
                print("Max rounds reached")
                break

            # Get current prompt from chain
            current_prompt = selected_chain[current_round - 1]

            # Execute the step
            response, judge_score = self.executor.execute_step(current_prompt, target)

            # Create chain step
            current_step = ChainStep(
                prompt=current_prompt,
                response=response,
                semantic_score=0.0,
                judge_score=judge_score
            )

            print(f"  Prompt: {current_prompt[:100]}...")
            print(f"  Response: {response[:100]}...")
            print(f"  Judge Score: {judge_score}/5")

            # Check for immediate success
            if self.judge.is_successful(judge_score):
                print(f"  > CoA SUCCESSFUL - returning immediately (Round {current_round})")
                result.success = True
                result.final_prompt = current_prompt
                result.output_text = response
                result.final_round = current_round
                result.chain_rounds.append(current_round)
                result.semantic_progression.append(current_step.semantic_score)
                return result

            # Decide next walk
            walk_decision = self.updater.decide_walk(current_step, previous_step, target)

            print(f"  Walk Decision: {walk_decision}")
            print(f"  Semantic Score: {current_step.semantic_score:.3f}")

            # Update chain based on walk decision
            if walk_decision == "next_walk":
                # Progress to next round
                current_round += 1
                selected_chain[current_round - 2] = current_prompt  # Store successful prompt
            elif walk_decision == "back_walk":
                # Go back to previous round
                current_round = max(1, current_round - 1)
            elif walk_decision == "regen_walk":
                # Stay in current round with alternative prompt
                alternative_prompt = self.updater.generate_alternative_prompt(current_prompt, walk_decision, current_round)
                selected_chain[current_round - 1] = alternative_prompt

            # Record progression
            result.chain_rounds.append(current_round)
            result.semantic_progression.append(current_step.semantic_score)
            result.walk_decisions.append(walk_decision)

            previous_step = current_step

        # If we reach here, attack failed
        result.success = False
        result.final_round = current_round
        print(f"  > CoA FAILED after {iteration + 1} iterations")

        return result

    def _fallback_attack(self, target: str) -> CoAResult:
        """Simple fallback attack if CoA fails"""
        result = CoAResult(target=target)

        # Direct single prompt attempt
        response, judge_score = self.executor.execute_step(target, target)

        result.success = self.judge.is_successful(judge_score)
        result.final_prompt = target
        result.output_text = response
        result.final_round = 1
        result.chain_rounds.append(1)

        print(f"Fallback attack: {'Success' if result.success else 'Failed'}")
        return result