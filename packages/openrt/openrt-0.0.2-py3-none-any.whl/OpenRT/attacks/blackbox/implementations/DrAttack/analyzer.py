"""
Automated prompt analysis using helper model for DrAttack.

This class provides methods to analyze and parse prompts automatically
with helper model models, facilitating downstream processing and semantic understanding.
"""

import ast
import json
from .parser import PromptSemanticParser
from .library import templates

class PromptAnalyzer():
    def __init__(self, helper_model):
        self.helper_model = helper_model
        self.templates = templates
        self.data = {}
    
    def process_harmless(self, prompt, prompt_substituable_phrases, generate_mode):

        template = self.templates[generate_mode]
        
        substitutable_parts = "'" + "', '".join(prompt_substituable_phrases) + "'"

        input_prompt = template.replace("{user request}", prompt)
        input_prompt = input_prompt.replace("{substitutable parts}", substitutable_parts)
        trial = 0
        valid = False
        while trial <= 10 and not valid:
            try:    
                response = self.helper_model.query(input_prompt)
                word_mapping = ast.literal_eval(response)
                valid = True
            except Exception as e:
                trial += 1

        self.data[prompt][generate_mode] = word_mapping

    def process_opposite(self, prompt, prompt_substituable_phrases, generate_mode):
        
        template = self.templates[generate_mode]

        self.data[prompt][generate_mode] = {}

        for sub_word in prompt_substituable_phrases:

            input_prompt = template + sub_word
            response = self.helper_model.query(input_prompt)
            self.data[prompt][generate_mode][sub_word] = response.split(", ")

    def process_synonym(self, prompt, prompt_substituable_phrases, generate_mode):
        
        template = self.templates[generate_mode]

        self.data[prompt][generate_mode] = {}

        for sub_word in prompt_substituable_phrases:

            input_prompt = template + sub_word
            response = self.helper_model.query(input_prompt)
            self.data[prompt][generate_mode][sub_word] = response.split(", ")

    def process_decomposition(self, prompt, generate_mode, max_trial=5):
        
        template = self.templates[generate_mode]
        
        trial = 0
        get_response = False
        parsing_tree_dictonary = {}
        while not get_response and trial <= max_trial:

            input_prompt = template + '\"' + prompt + '\"'
            response = self.helper_model.query(input_prompt)
            seg = response.replace("'", "")
            trial += 1
            try:
                parsing_tree_dictonary = json.loads(seg)
                get_response = True
            except:
                get_response = False

        self.data[prompt] = {
            'parsing_tree_dictionary': parsing_tree_dictonary,
            'prompt': prompt
        }


    def automate(self, prompt, generate_mode="joint"):
        
        if generate_mode == "harmless":

            self.process_harmless(prompt, self.data[prompt]["substitutable"], generate_mode)

        elif generate_mode == "opposite":

            self.process_opposite(prompt, self.data[prompt]["substitutable"], generate_mode)

        elif generate_mode == "synonym":

            self.process_synonym(prompt, self.data[prompt]["substitutable"], generate_mode)

        elif generate_mode == "decomposition":

            self.process_decomposition(prompt, generate_mode)

        elif generate_mode == "joint":

            self.process_decomposition(prompt, "decomposition")

            parser = PromptSemanticParser(self.data[prompt]["parsing_tree_dictionary"])
            parser.process_parsing_tree()

            self.data[prompt]["substitutable"] = parser.words_substitution
            self.data[prompt]["words"] = parser.words
            self.data[prompt]["words_level"] = parser.words_level
            self.data[prompt]["words_type"] = parser.words_type

            self.process_synonym(prompt, self.data[prompt]["substitutable"], "synonym")
            self.process_opposite(prompt, self.data[prompt]["substitutable"], "opposite")

            self.process_harmless(prompt, self.data[prompt]["substitutable"], "harmless")

        else:
            raise ValueError(f"Generate mode '{generate_mode}' not implemented!")
        
        return self.data