import copy
import datetime
import json
import math
from collections.abc import Iterable
from decimal import Decimal
from enum import Enum, IntEnum
from typing import Any, Optional, TypedDict, Union
from urllib.parse import parse_qsl, urlencode, urlsplit, urlunsplit

import pandas as pd
import pytz
from pydantic import BaseModel, Field, constr, model_validator, root_validator, validator

from mainsequence.logconf import logger

from .base import (
    TDAG_ENDPOINT,
    BaseObjectOrm,
    BasePydanticModel,
    HtmlSaveException,
)
from .models_tdag import DataNodeUpdate
from .utils import DATE_FORMAT, DoesNotExist, make_request
from .utils import MARKETS_CONSTANTS as CONSTANTS

CRYPTO_EXCHANGE_CODE = [
    "abts",
    "acxi",
    "alcn",
    "bbit",
    "bbox",
    "bbsp",
    "bcex",
    "bequ",
    "bfly",
    "bfnx",
    "bfrx",
    "bgon",
    "binc",
    "bitc",
    "bitz",
    "bjex",
    "bl3p",
    "blc2",
    "blcr",
    "bnbd",
    "bnce",
    "bndx",
    "bnf8",
    "bnus",
    "bopt",
    "bpnd",
    "bt38",
    "btba",
    "btbu",
    "btby",
    "btca",
    "btcb",
    "btcc",
    "bthb",
    "btma",
    "btmx",
    "btrk",
    "btrx",
    "btsh",
    "btso",
    "bull",
    "bxth",
    "bybt",
    "cbse",
    "ccck",
    "ccex",
    "cexi",
    "cflr",
    "cflx",
    "cnex",
    "cngg",
    "cnhd",
    "cnmt",
    "cone",
    "crco",
    "crfl",
    "crtw",
    "crv2",
    "cucy",
    "curv",
    "delt",
    "drbt",
    "dydx",
    "eris",
    "ethx",
    "etrx",
    "exxa",
    "ftxu",
    "ftxx",
    "gacn",
    "gate",
    "gmni",
    "hbdm",
    "hitb",
    "huob",
    "inch",
    "indr",
    "itbi",
    "kcon",
    "korb",
    "krkn",
    "lclb",
    "lgom",
    "lmax",
    "merc",
    "mexc",
    "mtgx",
    "ngcs",
    "nova",
    "nvdx",
    "okcn",
    "okex",
    "oslx",
    "pksp",
    "polo",
    "qsp2",
    "qsp3",
    "quon",
    "sghd",
    "stmp",
    "sush",
]

COMPOSITE_TO_ISO = {
    "AR": "XBUE",
    "AU": "XASX",
    "BZ": "BVMF",
    "CN": "XTSE",
    "CB": "XBOG",
    "CH": "XSHG",
    "CI": "XSGO",
    "CP": "XPRA",
    "DC": "XCSE",
    "FH": "XHEL",
    "FP": "XPAR",
    "GA": "ASEX",
    "GR": "XFRA",
    "HK": "XHKG",
    "IE": "XDUB",
    "IM": "XMIL",
    "IN": "XBOM",
    "IT": "XTAE",
    "JP": "XTKS",
    "KS": "XKRX",
    "KZ": "AIXK",
    "LN": "XLON",
    "MM": "XMEX",
    "MK": "XKLS",
    "NA": "XAMS",
    "PL": "XLIS",
    "PM": "XPHS",
    "PW": "XWAR",
    "RO": "XBSE",
    "SA": "XSAU",
    "SM": "XMAD",
    "SS": "XSTO",
    "SW": "XSWX",
    "TH": "XBKK",
    "TI": "XIST",
    "TT": "XTAI",
    "US": "XNYS",
    "AT": "XWBO",
    "BB": "XBRU",
}


def validator_for_string(value):
    if isinstance(value, str):
        # Parse the string to a datetime object
        try:
            return datetime.datetime.strptime(value, "%Y-%m-%dT%H:%M:%SZ")
        except ValueError as err:
            raise ValueError(
                f"Invalid datetime format: {value!r}. Expected format is 'YYYY-MM-DDTHH:MM:SSZ'."
            ) from err


def get_model_class(model_class: str):
    """
    Reverse look from model class by name
    """
    MODEL_CLASS_MAP = {
        "Asset": Asset,
        "AssetCurrencyPair": AssetCurrencyPair,
        "AssetFutureUSDM": AssetFutureUSDM,
        "PortfolioIndexAsset": PortfolioIndexAsset,
        "Calendar": Calendar,
        "ExecutionVenue": ExecutionVenue,
        "PortfolioGroup": PortfolioGroup,
    }
    return MODEL_CLASS_MAP[model_class]


def create_from_serializer_with_class(asset_list: list[dict]):
    new_list = []
    for a in asset_list:
        AssetClass = get_model_class(a["AssetClass"])
        a.pop("AssetClass")
        new_list.append(AssetClass(**a))
    return new_list


def resolve_asset(asset_dict: dict):
    asset = create_from_serializer_with_class([asset_dict])[0]
    return asset


class Calendar(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    name: str
    calendar_dates: dict | None = None

    def __str__(self):
        return self.name

    def __repr__(self) -> str:
        return self.name


class Organization(BaseModel):
    id: int
    uid: str
    name: str
    url: str | None  # URL can be None


class Group(BaseModel):
    id: int
    name: str
    permissions: list[Any]  # Adjust the type for permissions as needed


class User(BaseObjectOrm, BasePydanticModel):

    first_name: str
    last_name: str
    is_active: bool
    date_joined: datetime.datetime
    role: str
    username: str
    email: str
    last_login: datetime.datetime
    api_request_limit: int
    mfa_enabled: bool
    organization: Organization
    plan: Any | None  # Use a specific model if plan details are available
    groups: list[Group]
    user_permissions: list[Any]  # Adjust as necessary for permission structure
    phone_number: str | None = None

    @classmethod
    def get_object_url(cls):
        # TODO should be also orm/api
        url = f"{cls.ROOT_URL.replace('orm/api', 'user/api')}/{cls.END_POINTS[cls.class_name()]}"
        return url

    @classmethod
    def get_authenticated_user_details(cls):
        url = f"{cls.get_object_url()}/get_user_details/"
        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="GET",
            url=url,
        )
        if r.status_code not in [200, 201]:
            raise Exception(f" {r.text()}")

        return cls(**r.json())


class AssetSnapshot(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    asset: Union["AssetMixin", int]

    # Validity window
    effective_from: datetime.datetime = Field(
        description="Date at which this snapshot became effective"
    )
    effective_to: datetime.datetime | None = Field(
        None, description="Date at which this snapshot was superseded (null if current)"
    )

    # Mutable fields
    name: constr(max_length=255) = Field(
        ..., description="Security name as recorded in the FIGI database"
    )
    ticker: constr(max_length=50) | None = Field(
        None, description="FIGI ticker field (often shorter symbol used by OpenFIGI)"
    )
    exchange_code: constr(max_length=50) | None = Field(
        None, description="Exchange/market MIC code (e.g. XNYS, XNAS) or composite code"
    )
    asset_ticker_group_id: constr(max_length=12) | None = Field(
        None, description="Highest aggregation level for share class grouping"
    )
    venue_specific_properties: dict[str, Any] | None = Field(
        None, description="Exchange-specific metadata"
    )


def _set_query_param_on_url(url: str, key: str, value) -> str:
    """
    Add or replace a query parameter in a URL without disturbing others (e.g., offset/page).
    Works with absolute or relative URLs.
    """
    parts = urlsplit(url)
    q = dict(parse_qsl(parts.query, keep_blank_values=True))
    q[key] = str(value)
    new_query = urlencode(q, doseq=True)
    return urlunsplit((parts.scheme, parts.netloc, parts.path, new_query, parts.fragment))


class AssetPricingDetail(BasePydanticModel):
    instrument_dump: dict
    pricing_details_date: datetime.datetime


class AssetMixin(BaseObjectOrm, BasePydanticModel):
    id: int | None = None

    # Immutable identifiers
    unique_identifier: constr(max_length=255)
    figi: constr(max_length=12) | None = Field(
        None,
        description="FIGI identifier (unique to a specific instrument on a particular market/exchange)",
    )
    composite: constr(max_length=12) | None = Field(
        None,
        description="Composite FIGI identifier (aggregates multiple local listings within one market)",
    )
    share_class: constr(max_length=12) | None = Field(
        None,
        description="Share class designation (e.g. 'Common', 'Class A', 'Preferred') as per FIGI",
    )

    isin: constr(max_length=12) | None = Field(
        None, description="International Securities Identification Number"
    )

    security_type: constr(max_length=50) | None = Field(
        None, description="Instrument type (e.g. 'CS' for common stock, 'PS' for preferred)"
    )
    security_type_2: constr(max_length=50) | None = Field(
        None, description="OpenFIGI Security Type 2"
    )
    security_market_sector: constr(max_length=50) | None = Field(
        None,
        description="High-level sector classification (e.g. 'Equity', 'Corporate Bond') as per FIGI",
    )

    is_tradable:bool = Field(
        default=True, description="Flag indicating if this asset is tradable "
    )
    is_custom_by_organization: bool = Field(
        default=False,
        description="Flag indicating if this asset was custom-created by the organization",
    )

    # Snapshot relationship
    current_snapshot: AssetSnapshot | None = Field(
        None, description="Latest active snapshot (effective_to is null)"
    )
    current_pricing_detail: AssetPricingDetail | None = Field(
        None, description="details for instrument pricing"
    )

    def __repr__(self) -> str:
        return f"{self.class_name()}: {self.unique_identifier}"

    @model_validator(mode="after")
    def _inject_main_sequence_asset_id(self) -> "AssetMixin":
        """
        After model construction, if instrument_pricing_detail is present,
        ensure it contains {'main_sequence_asset_id': self.id}.
        """
        ipd = self.current_pricing_detail
        if ipd is not None:
            # Be tolerant: coerce to a dict if necessary.
            try:
                ipd.instrument_dump["instrument"]["main_sequence_asset_id"] = self.id
            except Exception as e:
                self.clear_asset_pricing_details()
                raise e
            self.current_pricing_detail = ipd
        return self

    @property
    def ticker(self):
        return self.current_snapshot.ticker

    @property
    def name(self):
        return self.current_snapshot.name

    @property
    def exchange_code(self):
        return self.current_snapshot.exchange_code

    @property
    def asset_ticker_group_id(self):
        return self.current_snapshot.asset_ticker_group_id

    @classmethod
    def _translate_query_params(cls, query_params: dict[str, Any]):
        translation_map = {
            "ticker": "current_snapshot__ticker",
            "name": "current_snapshot__name",
            "exchange_code": "current_snapshot__exchange_code",
            "asset_ticker_group_id": "current_snapshot__asset_ticker_group_id",
        }

        translated_params = {}
        for key, value in query_params.items():
            # django search uses '__' for nested objects
            full_query = key.split("__")
            asset_query = full_query[0]

            if asset_query in translation_map:
                # Reconstruct the key using the translated base and the original suffix
                translated_base = translation_map[asset_query]
                # Join the translated base with the rest of the query parts
                new_key_parts = [translated_base] + full_query[1:]
                new_key = "__".join(new_key_parts)
                translated_params[new_key] = value
            else:
                # If no translation is needed, use the original key
                translated_params[key] = value

        return translated_params

    @classmethod
    def query(cls, timeout=None, per_page: int = None, **kwargs):
        """
        POST-based filtering for large requests that don't fit in the URL.

        - per_page: desired number of items per page (client-side).


        Follows DRF pagination and accumulates ALL pages. Returns raw dict items.
        """
        base_url = cls.get_object_url()  # e.g. "https://api.example.com/assets"
        body = cls._parse_parameters_filter(kwargs)  # same filters as GET
        accumulated = []

        # Start at the collection action
        next_url = f"{base_url}/query/"

        # Choose which page-size param(s) to set
        # If not specified, we try the common ones in order.
        page_size_params = ["limit", "page_size"]

        only_fields = "fields" in body  # your existing flag

        while next_url:
            # Inject per_page into the URL (NOT the JSON body), preserving offset/page/cursor.
            if per_page:
                for pname in page_size_params:
                    if pname:  # skip None if passed
                        next_url = _set_query_param_on_url(next_url, pname, per_page)

            r = make_request(
                s=cls.build_session(),
                loaders=cls.LOADERS,
                r_type="POST",
                url=next_url,
                payload={"json": body},  # filters stay in body
                time_out=timeout,
            )

            if r.status_code != 200:
                if r.status_code == 401:
                    raise Exception("Unauthorized. Please add credentials to environment.")
                elif r.status_code == 500:
                    raise Exception("Server Error.")
                elif r.status_code == 404:
                    raise DoesNotExist("Not Found.")
                elif r.status_code == 405:
                    raise Exception("Method Not Allowed. Ensure the 'query' endpoint accepts POST.")
                else:
                    raise Exception(f"{r.status_code} - {r.text}")

            data = r.json()
            next_url = data.get("next")  # DRF-provided next URL (may be relative or absolute)

            # Collect results
            for item in data.get("results", []):
                if only_fields:
                    accumulated.append(item)
                else:
                    item["orm_class"] = cls.__name__
                    try:

                        accumulated.append(
                            cls(**item) if issubclass(cls, BasePydanticModel) else item
                        )
                    except Exception as e:
                        print(item)
                        print(cls)
                        print(cls(**item))
                        import traceback

                        traceback.print_exc()
                        raise e

        return accumulated

    @classmethod
    def filter(cls, *args, **kwargs):
        """
        Overrides the default filter to remap 'ticker' and 'name' lookup keys
        to the corresponding fields on the related current_snapshot.
        """
        transformed_kwargs = cls._translate_query_params(kwargs)
        return super().filter(*args, **transformed_kwargs)

    @classmethod
    def get(cls, *args, **kwargs):
        """
        Overrides the default get to remap lookup keys
        to the corresponding fields on the related current_snapshot.
        """
        transformed_kwargs = cls._translate_query_params(kwargs)
        return super().get(*args, **transformed_kwargs)

    @property
    def ms_instrument(self):
        if hasattr(self, "_ms_instrument"):
            return self._ms_instrument
        self.set_ms_instrument()
        return self._ms_instrument
    def set_ms_instrument(self):
        """
        Delicate function that mixes functionality it only works with pricing details from
        Main Sequence
        Returns
        -------

        """
        import mainsequence.instruments as msi
        if self.current_pricing_detail:
            if hasattr(self.current_pricing_detail, "instrument_dump"):
                self._ms_instrument=msi.Instrument.rebuild(self.current_pricing_detail.instrument_dump)
                return None
        raise Exception("Instrument does not have Main Sequence Current Pricing Details")


    def get_calendar(self):
        if self.current_snapshot.exchange_code in COMPOSITE_TO_ISO.keys():
            return Calendar(name=COMPOSITE_TO_ISO[self.current_snapshot.exchange_code])
        elif self.security_type == CONSTANTS.FIGI_SECURITY_TYPE_CRYPTO:
            return Calendar(name="24/7")
        elif self.security_type_2 == CONSTANTS.FIGI_SECURITY_TYPE_2_CRYPTO:
            return Calendar(name="24/7")
        elif self.security_type_2 == CONSTANTS.FIGI_SECURITY_TYPE_2_PERPETUAL:
            return Calendar(name="24/7")
        else:
            return Calendar(name="XNYS")

    def pretty_print(self) -> None:
        """
        Print all asset properties in a neat, aligned table.
        """
        # Gather (field_name, value) pairs
        rows = []
        for field_name in self.__fields__:
            value = getattr(self, field_name)
            rows.append((field_name, value))

        # Compute column widths
        max_name_len = max(len(name) for name, _ in rows)
        max_val_len = max(len(str(val)) for _, val in rows)

        # Header
        header = f"{'Property':<{max_name_len}} | {'Value':<{max_val_len}}"
        separator = "-" * len(header)
        print(header)
        print(separator)

        # Rows
        for name, val in rows:
            print(f"{name:<{max_name_len}} | {val}")

    @classmethod
    def register_asset_from_figi(cls, figi: str, timeout=None):
        base_url = cls.get_object_url() + "/register_asset_from_figi/"
        payload = {"json": {"figi": figi}}
        s = cls.build_session()

        r = make_request(
            s=s, loaders=cls.LOADERS, r_type="POST", url=base_url, payload=payload, time_out=timeout
        )

        if r.status_code not in [200, 201]:
            raise Exception(r.text)

        return cls(**r.json())

    @classmethod
    def filter_with_asset_class(
        cls, timeout=None, include_relationship_details_depth=None, *args, **kwargs
    ):
        """
        Filters assets and returns instances with their correct asset class,
        """

        from .models_helpers import create_from_serializer_with_class

        base_url = cls.get_object_url()
        # Convert `kwargs` to query parameters
        # kwargs["include_relationship_details_depth"]=include_details
        transformed_kwargs = cls._translate_query_params(kwargs)
        params = cls._parse_parameters_filter(parameters=transformed_kwargs)

        # We'll call the custom action endpoint
        url = f"{base_url}/list_with_asset_class/"
        all_results = []

        # Build a single requests session
        s = cls.build_session()

        while url:
            # Make the request to the current page URL
            request_kwargs = {"params": params} if params else {}
            r = make_request(
                s=s,
                loaders=cls.LOADERS,
                r_type="GET",
                url=url,
                payload=request_kwargs,
                time_out=timeout,
            )

            if r.status_code != 200:
                raise Exception(f"Error getting assets (status code: {r.status_code})")

            data = r.json()

            # Check if it's a DRF paginated response by looking for "results"
            if isinstance(data, dict) and "results" in data:
                # Paginated response
                results = data["results"]
                next_url = data["next"]
            else:
                # Either not paginated or no "results" key
                # It's possible your endpoint returns a plain list or other structure
                # Adjust accordingly if needed
                results = data
                next_url = None

            # Accumulate the results
            all_results.extend(results)

            # Prepare for the next loop iteration
            url = next_url
            # After the first request, DRF's `next` link is a full URL that already includes
            # appropriate query params, so we set `params=None` to avoid conflicts.
            params = None

        # Convert the accumulated raw data into asset instances with correct classes
        return create_from_serializer_with_class(all_results)

    def clear_asset_pricing_details(self, timeout=None):
        base_url = self.get_object_url()  # e.g., https://api.example.com/assets
        url = f"{base_url}/{self.id}/clear-asset-pricing-details/"
        r = make_request(
            s=self.build_session(),
            loaders=self.LOADERS,
            r_type="PATCH",
            url=url,
            time_out=timeout,
        )

        if r.status_code not in (200, 201):
            raise Exception(r.text)

    def add_instrument_pricing_details_from_ms_instrument(
        self, instrument, pricing_details_date: datetime.datetime, timeout=None
    ):

        data = instrument.serialize_for_backend()
        data = json.loads(data)
        data["instrument"]["main_sequence_asset_id"] = self.id
        data["pricing_details_date"] = pricing_details_date.timestamp()

        return self.add_instrument_pricing_details(instrument_pricing_details=data, timeout=timeout)

    def add_instrument_pricing_details(
        self,
        instrument_pricing_details: dict[str, Any],
        timeout: float | None = None,
    ) -> dict[str, Any]:
        """
        POST /assets/{self.id}/set-asset-pricing-detail/

        Sends the pricing details as a RAW JSON object (no wrapper keys).
        The backend action treats the entire body as the pricing dump and
        associates it to (asset, organization_owner).

        Args:
            instrument_pricing_details: JSON object to store.
            timeout: optional request timeout (seconds).

        Returns:
            The server's JSON response (dict).
        """
        if not getattr(self, "id", None):
            raise ValueError("This object has no 'id'; cannot POST to detail action.")
        if not isinstance(instrument_pricing_details, dict):
            raise ValueError("instrument_pricing_details must be a JSON object (dict).")

        base_url = self.get_object_url()  # e.g., https://api.example.com/assets
        url = f"{base_url}/{self.id}/set-asset-pricing-detail/"

        r = make_request(
            s=self.build_session(),
            loaders=self.LOADERS,
            r_type="POST",
            url=url,
            payload={
                "json": instrument_pricing_details
            },  # raw body (no 'dump', no 'organization_id')
            time_out=timeout,
        )

        if r.status_code not in (200, 201):
            if r.status_code == 401:
                raise Exception("Unauthorized. Please add credentials to environment.")
            elif r.status_code == 404:
                raise DoesNotExist("Asset not found.")
            elif r.status_code == 405:
                raise Exception("Method Not Allowed. Ensure the custom action is enabled.")
            elif r.status_code == 413:
                raise Exception("Payload Too Large. Consider compressing or splitting.")
            elif r.status_code >= 500:
                raise Exception("Server Error.")
            else:
                raise Exception(f"{r.status_code} - {r.text}")

        data = r.json()

        data.get("instrument_pricing_detail")
        when = data["pricing_details_date"]
        self.current_pricing_detail = AssetPricingDetail(
            instrument_dump=data["instrument_dump"],
            pricing_details_date=datetime.datetime.utcfromtimestamp(when).replace(tzinfo=pytz.utc),
        )


class AssetCategory(BaseObjectOrm, BasePydanticModel):
    id: int
    unique_identifier: str
    display_name: str
    assets: list[Union[int, "Asset"]]
    description: str | None = None

    def __repr__(self):
        return f"{self.display_name} source: {self.source}, {len(self.assets)} assets"

    def get_assets(self):
        if not self.assets:
            raise ValueError(f"No assets in Asset Category {self.display_name}")
        return Asset.filter(id__in=self.assets)

    def update_assets(self, asset_ids: list[int]):
        self.remove_assets(self.assets)
        self.append_assets(asset_ids)

    def append_assets(
        self, asset_ids: list[int] | None = None, assets: AssetMixin | None = None
    ) -> "AssetCategory":
        """
        Append the given asset IDs to this category.
        Expects a payload: {"assets": [<asset_id1>, <asset_id2>, ...]}
        """
        assert asset_ids is not None or assets is not None, "asset_ids or assets must be provided"

        url = f"{self.get_object_url()}/{self.id}/append-assets/"
        if assets is not None:
            asset_ids = [a.id for a in assets]
        payload = {"assets": asset_ids}
        r = make_request(
            s=self.build_session(),
            loaders=self.LOADERS,
            r_type="POST",
            url=url,
            payload={"json": payload},
        )
        if r.status_code not in [200, 201]:
            raise Exception(f"Error appending assets: {r.text()}")
        # Return a new instance of AssetCategory built from the response JSON.
        cat = AssetCategory(**r.json())
        self.assets = cat.assets

    def remove_assets(self, asset_ids: list[int]) -> "AssetCategory":
        """
        Remove the given asset IDs from this category.
        Expects a payload: {"assets": [<asset_id1>, <asset_id2>, ...]}
        """
        url = f"{self.get_object_url()}/{self.id}/remove-assets/"
        payload = {"assets": asset_ids}
        r = make_request(
            s=self.build_session(),
            loaders=self.LOADERS,
            r_type="POST",
            url=url,
            payload={"json": payload},
        )
        if r.status_code not in [200, 201]:
            raise Exception(f"Error removing assets: {r.text()}")
        # Return a new instance of AssetCategory built from the response JSON.
        return AssetCategory(**r.json())

    @classmethod
    def get_or_create(cls, *args, **kwargs):
        url = f"{cls.get_object_url()}/get-or-create/"
        payload = {"json": kwargs}
        r = make_request(
            s=cls.build_session(), loaders=cls.LOADERS, r_type="POST", url=url, payload=payload
        )
        if r.status_code not in [200, 201]:
            raise Exception(f"Error appending creating: {r.text}")
        # Return a new instance of AssetCategory built from the response JSON.
        return AssetCategory(**r.json())


class TranslationError(RuntimeError):
    """Raised when no translation rule (or more than one) matches an asset."""


class AssetFilter(BaseModel):
    security_type: str | None = None
    security_market_sector: str | None = None

    def filter_triggered(self, asset: "Asset") -> bool:
        if self.security_type and asset.security_type != self.security_type:
            return False
        if (
            self.security_market_sector
            and asset.security_market_sector != self.security_market_sector
        ):
            return False
        return True


class AssetTranslationRule(BaseModel):
    asset_filter: AssetFilter
    markets_time_serie_unique_identifier: str
    target_exchange_code: str | None = None

    def is_asset_in_rule(self, asset: "Asset") -> bool:
        return self.asset_filter.filter_triggered(asset)


class AssetTranslationTable(BaseObjectOrm, BasePydanticModel):
    """
    Mirrors the Django model 'AssetTranslationTableModel' in the backend.
    """

    id: int = None
    unique_identifier: str
    rules: list[AssetTranslationRule] = Field(default_factory=list)

    @classmethod
    def get_or_create(
        cls,
        translation_table_identifier,
        rules,
    ):
        translation_table = cls.get_or_none(unique_identifier=translation_table_identifier)
        rules_serialized = [r.model_dump() for r in rules]

        if translation_table is None:
            translation_table = AssetTranslationTable.create(
                unique_identifier=translation_table_identifier,
                rules=rules_serialized,
            )
        else:
            translation_table.add_rules(rules)

    def evaluate_asset(self, asset):
        for rule in self.rules:
            if rule.is_asset_in_rule(asset):
                return {
                    "markets_time_serie_unique_identifier": rule.markets_time_serie_unique_identifier,
                    "exchange_code": rule.target_exchange_code,
                }

        raise TranslationError(f"No rules for asset {asset} found")

    def add_rules(self, rules: list[AssetTranslationRule], open_for_everyone=False) -> None:
        """
        Add each rule to the translation table by calling the backend's 'add_rule' endpoint.
        Prevents local duplication. If the server also rejects a duplicate,
        it returns an error which we silently ignore.
        """
        base_url = self.get_object_url()
        for new_rule in rules:
            # 1) Check for local duplicates
            if any(
                r.asset_filter == new_rule.asset_filter
                and r.markets_time_serie_unique_identifier
                == new_rule.markets_time_serie_unique_identifier
                and r.target_exchange_code == new_rule.target_exchange_code
                for r in self.rules
            ):
                # Already in local table, skip adding
                logger.debug(f"Rule {new_rule} already present - skipping")
                continue

            # 2) Post to backend's "add_rule"
            url = f"{base_url}/{self.id}/add_rule/"
            payload = new_rule.model_dump()
            if open_for_everyone:
                payload["open_for_everyone"] = True
                payload["asset_filter"]["open_for_everyone"] = True

            r = make_request(
                s=self.build_session(),
                loaders=self.LOADERS,
                r_type="POST",
                url=url,
                payload={"json": payload},
            )

            if r.status_code == 201:
                # Successfully created on server. Append locally
                self.rules.append(new_rule)
            elif r.status_code not in (200, 201):
                raise Exception(f"Error adding rule: {r.text}")

    def remove_rules(self, rules: list[AssetTranslationRule]) -> None:
        """
        Remove each rule from the translation table by calling the backend's 'remove_rule' endpoint.
        Once successfully removed on the server, remove it from the local list `self.rules`.
        If a rule is not found on the server, we skip silently.
        """
        base_url = self.get_object_url()
        for rule_to_remove in rules:
            # 1) Check if we even have it locally
            matching_local = [
                r
                for r in self.rules
                if r.asset_filter == rule_to_remove.asset_filter
                and r.markets_time_serie_unique_identifier
                == rule_to_remove.markets_time_serie_unique_identifier
                and r.target_exchange_code == rule_to_remove.target_exchange_code
            ]
            if not matching_local:
                # Not in local rules, skip
                continue

            # 2) Post to backend's "remove_rule"
            url = f"{base_url}/{self.id}/remove_rule/"
            payload = rule_to_remove.model_dump()
            r = make_request(
                s=self.build_session(),
                loaders=self.LOADERS,
                r_type="POST",
                url=url,
                payload={"json": payload},
            )

            if r.status_code == 200:
                # Successfully removed from server => remove from local
                for matched in matching_local:
                    self.rules.remove(matched)
            elif r.status_code not in (200, 204):
                raise Exception(f"Error removing rule: {r.text()}")


class Asset(AssetMixin, BaseObjectOrm):

    def get_spot_reference_asset_unique_identifier(self):
        return self.unique_identifier

    @classmethod
    def create_or_update_index_asset_from_portfolios(
        cls, reference_portfolio: int, timeout=None
    ) -> "PortfolioIndexAsset":
        url = f"{cls.get_object_url()}/create_or_update_index_asset_from_portfolios/"
        payload = {
            "json": dict(
                reference_portfolio=reference_portfolio,
            )
        }
        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=url,
            payload=payload,
            time_out=timeout,
        )
        if r.status_code not in [200, 201]:
            raise Exception(f"{r.text}")

        return PortfolioIndexAsset(**r.json())

    @classmethod
    def get_or_register_from_isin(
        cls,
        isin: str,
        exchange_code: str,
        timeout=None,
    ) -> "Asset":

        base_url = cls.get_object_url() + "/get_or_register_from_isin/"
        payload = {"json": {"isin": isin, "exchange_code": exchange_code}}
        s = cls.build_session()

        r = make_request(
            s=s, loaders=cls.LOADERS, r_type="POST", url=base_url, payload=payload, time_out=timeout
        )
        if r.status_code not in (200, 201):
            raise Exception(f"Error registering asset: {r.text}")
        return cls(**r.json())

    @classmethod
    def get_or_register_custom_asset(
        cls,
        timeout=None,
        **kwargs,
    ):
        base_url = cls.get_object_url() + "/get_or_register_custom_asset/"
        payload = {"json": kwargs}
        s = cls.build_session()

        r = make_request(
            s=s, loaders=cls.LOADERS, r_type="POST", url=base_url, payload=payload, time_out=timeout
        )
        if r.status_code not in (200, 201):
            raise Exception(f"Error registering asset: {r.text}")
        return cls(**r.json())

    @classmethod
    def batch_get_or_register_custom_assets(
        cls, assets_data: list[dict], timeout=None
    ) -> list["Asset"]:
        """
        Calls the batch endpoint to get or register multiple custom assets.

        Args:
            assets_data: A list of dictionaries, where each dictionary
                         represents the data for one asset.
            timeout: Optional request timeout in seconds.

        Returns:
            A list of Asset objects.
        """
        base_url = cls.get_object_url() + "/batch_get_or_register_custom_assets/"
        payload = {"json": assets_data}
        s = cls.build_session()

        r = make_request(
            s=s, loaders=cls.LOADERS, r_type="POST", url=base_url, payload=payload, time_out=timeout
        )

        if r.status_code != 200:
            raise Exception(f"Error in batch asset registration: {r.text}")

        return [cls(**data) for data in r.json()]


class PortfolioIndexAsset(Asset):
    reference_portfolio: Union["Portfolio", int]

    @property
    def reference_portfolio_details_url(self):
        return f"{TDAG_ENDPOINT}/dashboards/portfolio-detail/?target_portfolio_id={self.reference_portfolios.id}"


class AssetCurrencyPair(AssetMixin, BasePydanticModel):
    base_asset: AssetMixin | int
    quote_asset: AssetMixin | int

    def get_spot_reference_asset_unique_identifier(self):
        return self.base_asset.unique_identifier

    def get_ms_share_class(self):
        return self.base_asset.get_ms_share_class()


class FutureUSDMMixin(AssetMixin, BasePydanticModel):
    maturity_code: str = Field(..., max_length=50)
    last_trade_time: datetime.datetime | None = None
    currency_pair: AssetCurrencyPair

    def get_spot_reference_asset_unique_identifier(self):

        base_asset_symbol = self.currency_pair.base_asset.unique_identifier
        if self.execution_venue_symbol == CONSTANTS.BINANCE_FUTURES_EV_SYMBOL:
            # replace() will do nothing if “1000SHIB” isn’t present
            return base_asset_symbol.replace("1000SHIB", "SHIB")
        return base_asset_symbol


class AssetFutureUSDM(FutureUSDMMixin, BaseObjectOrm):
    pass


class AccountPortfolioScheduledRebalance(BaseObjectOrm, BasePydanticModel):
    id: int
    target_account_portfolio: dict | None = None
    scheduled_time: str = None
    received_in_execution_engine: bool = False
    executed: bool = False
    execution_start: str | None = None
    execution_end: datetime.datetime | None = None
    execution_message: str | None = None


class AccountExecutionConfiguration(BasePydanticModel):
    related_account: int  # Assuming related_account is represented by its ID
    rebalance_tolerance_percent: float = Field(0.02, ge=0)
    minimum_notional_for_a_rebalance: float = Field(15.00, ge=0)
    max_latency_in_cdc_seconds: float = Field(60.00, ge=0)
    force_market_order_on_execution_remaining_balances: bool = Field(False)
    orders_execution_configuration: dict[str, Any]
    cooldown_configuration: dict[str, Any]


class AccountPortfolioPosition(BasePydanticModel):
    id: int | None
    parent_positions: int | None
    target_asset: int
    weight_notional_exposure: float | None = 0.0
    constant_notional_exposure: float | None = 0.0
    single_asset_quantity: float | None = 0.0


class AccountPortfolioHistoricalPositions(BaseObjectOrm, BasePydanticModel):
    id: int | None
    positions_date: datetime.datetime
    comments: str | None
    positions: list[AccountPortfolioPosition]


class AccountPortfolio(BaseObjectOrm, BasePydanticModel):
    id: int
    related_account: int | None
    latest_positions: AccountPortfolioHistoricalPositions | None = None
    model_portfolio_name: str | None = None
    model_portfolio_description: str | None = None

    @property
    def unique_identifier(self):
        return self.related_account_id


class AccountMixin(BasePydanticModel):
    id: int | None = None
    uuid: str
    execution_venue: Union["ExecutionVenue", int]
    account_is_active: bool
    account_name: str | None = None
    is_paper: bool
    account_target_portfolio: AccountPortfolio | None = (
        None  # can be none on creation without holdings
    )
    latest_holdings: Union["AccountLatestHoldings", None] = None

    def build_rebalance(
        self,
        latest_holdings: "AccountHistoricalHoldings",
        tolerance: float,
        change_cash_asset_to_currency_asset: Asset | None = None,
    ):
        nav = self.get_nav()
        nav, _ = nav["nav"], nav["nav_date"]
        related_expected_asset_exposure_df = latest_holdings.related_expected_asset_exposure_df
        # extract Target Rebalance

        # extract expected holdings
        try:
            implicit_holdings_df = (
                related_expected_asset_exposure_df.groupby("aid")
                .aggregate({"holding": "sum", "price": "last", "expected_holding_in_fund": "sum"})
                .rename(columns={"expected_holding_in_fund": "expected_holding"})
            )
        except Exception as e:
            raise e
        implicit_holdings_df["difference"] = (
            implicit_holdings_df["expected_holding"] - implicit_holdings_df["holding"]
        )
        implicit_holdings_df["relative_w"] = (
            implicit_holdings_df["difference"] * implicit_holdings_df["price"]
        ) / nav
        implicit_holdings_df["tolerance_flag"] = implicit_holdings_df["relative_w"].apply(
            lambda x: 1 if x >= tolerance else 0
        )
        implicit_holdings_df["difference"] = (
            implicit_holdings_df["difference"] * implicit_holdings_df["tolerance_flag"]
        )
        implicit_holdings_df["expected_holding"] = (
            implicit_holdings_df["holding"] + implicit_holdings_df["difference"]
        )

        implicit_holdings = (
            implicit_holdings_df[["expected_holding", "price"]]
            .rename(columns={"expected_holding": "holding"})
            .T.to_dict()
        )

        implicit_holdings_df["reference_notional"] = (
            implicit_holdings_df["price"] * implicit_holdings_df["difference"]
        )
        rebalance = (
            implicit_holdings_df[["difference", "reference_notional", "price"]]
            .rename(columns={"difference": "quantity", "price": "reference_price"})
            .T.to_dict()
        )

        all_assets = implicit_holdings.keys()
        new_rebalance, new_implicit_holdings = {}, {}
        # build_asset_switch
        asset_switch_map = Asset.switch_cash_in_asset_list(
            asset_id_list=[c for c in all_assets if c != change_cash_asset_to_currency_asset.id],
            target_currency_asset_id=int(change_cash_asset_to_currency_asset.id),
        )
        asset_switch_map[str(change_cash_asset_to_currency_asset.id)] = (
            change_cash_asset_to_currency_asset.serialized_config
        )

        for a_id in all_assets:
            try:
                new_a = Asset(**asset_switch_map[str(a_id)])
            except Exception as e:
                raise e
            if rebalance[a_id]["quantity"] != 0.0:
                new_rebalance[new_a.id] = {"rebalance": rebalance[a_id], "asset": new_a}
            try:
                new_implicit_holdings[new_a.id] = implicit_holdings[a_id]
            except Exception as e:
                raise e
        not_rebalanced_by_tolerance = implicit_holdings_df[implicit_holdings_df["difference"] != 0]
        not_rebalanced_by_tolerance = not_rebalanced_by_tolerance[
            not_rebalanced_by_tolerance["tolerance_flag"] == 0
        ]["relative_w"]
        not_rebalanced_by_tolerance = {"tolerance": not_rebalanced_by_tolerance.to_dict()}
        return new_rebalance, new_implicit_holdings, not_rebalanced_by_tolerance

    def get_latest_holdings(self):
        base_url = self.get_object_url()
        url = f"{base_url}/{self.id}/latest_holdings/"
        r = make_request(s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url)
        if r.status_code != 200:
            raise Exception("Error Syncing funds in account")
        return AccountHistoricalHoldings(**r.json())

    def get_missing_assets_in_exposure(self, asset_list_ids, timeout=None) -> list[Asset]:
        base_url = self.get_object_url()
        url = f"{base_url}/{self.id}/get_missing_assets_in_exposure/"
        payload = {
            "json": {
                "asset_list_ids": asset_list_ids,
            }
        }

        r = make_request(
            s=self.build_session(),
            payload=payload,
            loaders=self.LOADERS,
            r_type="GET",
            url=url,
            time_out=timeout,
        )
        if r.status_code != 200:
            raise Exception(r.text)

        asset_list = []
        for a in r.json():
            asset_list.append(resolve_asset(a))

        return asset_list


class RebalanceTargetPosition(BasePydanticModel):
    target_portfolio_id: int
    weight_notional_exposure: float


class Account(AccountMixin, BaseObjectOrm, BasePydanticModel):

    @classmethod
    def get_or_create(
        cls,
        create_without_holdings=False,
        timeout=None,
        **kwargs,
    ):
        base_url = cls.get_object_url()
        url = f"{base_url}/get-or-create/"
        kwargs["create_without_holdings"] = create_without_holdings
        payload = {"json": kwargs}

        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=url,
            payload=payload,
            time_out=timeout,
        )
        if r.status_code not in [200, 201]:
            raise Exception(f"Error geting or creating account {r.text}")
        return cls(**r.json())

    def set_account_target_portfolio_from_asset_holdings(self, timeout=None):
        base_url = self.get_object_url()
        url = f"{base_url}/{self.id}/set_account_target_portfolio_from_asset_holdings/"
        r = make_request(
            s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url, time_out=timeout
        )
        if r.status_code != 200:
            raise Exception(
                f"Error set_account_target_portfolio_from_asset_holdings in account {r.text}"
            )

    def snapshot_account(self, timeout=None):

        base_url = self.get_object_url()
        url = f"{base_url}/{self.id}/snapshot_account/"
        r = make_request(
            s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url, time_out=timeout
        )
        if r.status_code != 200:
            raise Exception(f"Error Getting NAV in account {r.text}")

    def get_tracking_error_details(self, timeout=None):

        base_url = self.get_object_url()
        url = f"{base_url}/{self.id}/get_tracking_error_details/"
        r = make_request(
            s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url, time_out=timeout
        )
        if r.status_code != 200:
            raise Exception(f"Error Getting NAV in account {r.text}")
        result = r.json()
        return result["fund_summary"], result["account_tracking_error"]

    def rebalance(
        self,
        target_positions: list[RebalanceTargetPosition],
        scheduled_time: datetime.datetime | None = None,
        timeout=None,
    ) -> AccountPortfolioScheduledRebalance:

        parsed_target_positions = {}
        for target_position in target_positions:
            if target_position.target_portfolio_id in parsed_target_positions:
                raise ValueError(
                    f"Duplicate target portfolio id: {target_position.target_portfolio_id} not allowed"
                )

            parsed_target_positions[target_position.target_portfolio_id] = {
                "weight_notional_exposure": target_position.weight_notional_exposure,
            }

        return AccountPortfolioScheduledRebalance.create(
            timeout=timeout,
            target_positions=parsed_target_positions,
            target_account_portfolio=self.id,
            scheduled_time=scheduled_time,
        )

    def get_historical_holdings(
        self,
        start_date: datetime.datetime | None = None,
        end_date: datetime.datetime | None = None,
        timeout=None,
    ) -> pd.DataFrame:
        """
        Retrieves historical holdings data for the account over a specified date range.

        Args:
            start_date_timestamp (datetime, optional): The start datetime (UTC) for filtering holdings.
            end_date_timestamp (datetime, optional): The end datetime (UTC) for filtering holdings.
            timeout (int, optional): Optional timeout parameter for the query (currently unused).

        Returns:
            pd.DataFrame: A DataFrame indexed by a multi-index of `time_index` (UTC datetime) and `asset_id` (int),
            containing the following columns:

            - **missing_price (bool)**: Indicates whether the price for the asset was missing on that date.
            - **price (float)**: The recorded price of the asset at the time of the holding.
            - **quantity (float)**: The quantity of the asset held at that time.

            If no holdings are found within the specified range, an empty DataFrame is returned.

        Example Output:
                                                        missing_price  price   quantity
        time_index                     asset_id
        2025-06-23 17:59:57+00:00      62376               False        1.0   1000000.0
        2025-05-30 09:43:19+00:00      62376               False        1.0   1000000.0
        2025-05-30 09:43:26+00:00      62376               False        1.0   1000000.0
        """

        filter_search = dict(related_account__id=self.id)
        if start_date is not None:
            if isinstance(start_date, datetime.datetime):
                if start_date.tzinfo is None:
                    start_date_timestamp = start_date.replace(tzinfo=pytz.utc)
                filter_search["holdings_date__gte"] = start_date_timestamp.isoformat()

        if end_date is not None:
            if isinstance(end_date, datetime.datetime):
                if end_date.tzinfo is None:
                    end_date = end_date.replace(tzinfo=pytz.utc)
            filter_search["holdings_date__lte"] = end_date.isoformat()

        holdings = AccountHistoricalHoldings.filter(**filter_search)
        if len(holdings) == 0:
            return pd.DataFrame()
        positions_df = []
        for holding in holdings:
            holding_date = holding.holdings_date
            for position in holding.holdings:
                pos = position.model_dump()
                pos.pop("orm_class", None)
                pos.pop("parents_holdings", None)
                pos.pop("id", None)
                pos.pop("extra_details", None)
                pos["time_index"] = holding_date

                positions_df.append(pos)

        positions_df = (
            pd.DataFrame(positions_df)
            .rename(columns={"asset": "asset_id"})
            .set_index(["time_index", "asset_id"])
        )
        return positions_df


class AccountPositionDetail(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    asset: Asset | int = None
    missing_price: bool = False
    price: float
    quantity: float
    parents_holdings: int | None = None
    extra_details: dict | None = None

    @validator("price")
    def price_must_be_finite(cls, v: float) -> float:
        if isinstance(v, float) and (math.isnan(v) or math.isinf(v)):
            raise ValueError("price must be a finite number (not NaN/Infinity)")
        return v

class AccountHistoricalHoldingsMixin:
    id: int | None = Field(None, primary_key=True)
    holdings_date: datetime.datetime
    comments: str | None = Field(None, max_length=150)
    nav: float | None = None

    is_trade_snapshot: bool = Field(default=False)
    target_trade_time: datetime.datetime | None = None
    related_expected_asset_exposure_df: list[dict[str, Any]] | None = None

    holdings: list[AccountPositionDetail]

    def get_nav(self):
        base_url = self.get_object_url()
        url = f"{base_url}/{self.id}/get_nav/"
        r = make_request(s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url)
        if r.status_code != 200:
            raise Exception(f"Error Getting NAV in account {r.text}")
        return r.json()


class AccountLatestHoldings(AccountHistoricalHoldingsMixin, BaseObjectOrm, BasePydanticModel):
    """
    Same as Account HistoricalHoldings but Does not include related account

    """

    ...


class AccountHistoricalHoldings(AccountHistoricalHoldingsMixin, BaseObjectOrm, BasePydanticModel):

    related_account: Union[int, "Account"]

    @classmethod
    def filter(
            cls,
            *,
            # related_account__id: ["in", "exact"]
            related_account__id: int | None = None,
            related_account__id__in: Iterable[int] | None = None,

            # target_trade_time: ["in", "exact", "gte", "lte"]
            target_trade_time: datetime.datetime | str | None = None,
            target_trade_time__in: Iterable[datetime.datetime | str] | None = None,
            target_trade_time__gte: datetime.datetime | str | None = None,
            target_trade_time__lte: datetime.datetime | str | None = None,

            # is_trade_snapshot: ["exact"]
            is_trade_snapshot: bool | None = None,

            # holdings_date: ["gte", "lte", "exact"]
            holdings_date: datetime.datetime | str | None = None,
            holdings_date__gte: datetime.datetime | str | None = None,
            holdings_date__lte: datetime.datetime | str | None = None,

            **kwargs: Any,
    ):
        def to_iso(v: Any) -> str:
            if isinstance(v, (datetime.datetime, datetime.date)):
                return v.isoformat()
            return str(v)

        def to_csv(values: Iterable[Any], *, iso: bool = False) -> str:
            if iso:
                return ",".join(to_iso(x) for x in values)
            return ",".join(str(x) for x in values)

        params: dict[str, Any] = {}

        if related_account__id is not None:
            params["related_account__id"] = related_account__id
        if related_account__id__in is not None:
            params["related_account__id__in"] = to_csv(related_account__id__in)

        if target_trade_time is not None:
            params["target_trade_time"] = to_iso(target_trade_time)
        if target_trade_time__in is not None:
            params["target_trade_time__in"] = to_csv(target_trade_time__in, iso=True)
        if target_trade_time__gte is not None:
            params["target_trade_time__gte"] = to_iso(target_trade_time__gte)
        if target_trade_time__lte is not None:
            params["target_trade_time__lte"] = to_iso(target_trade_time__lte)

        if is_trade_snapshot is not None:
            params["is_trade_snapshot"] = str(is_trade_snapshot).lower()  # "true"/"false"

        if holdings_date is not None:
            params["holdings_date"] = to_iso(holdings_date)
        if holdings_date__gte is not None:
            params["holdings_date__gte"] = to_iso(holdings_date__gte)
        if holdings_date__lte is not None:
            params["holdings_date__lte"] = to_iso(holdings_date__lte)

        return super().filter(**params, **kwargs)

    @classmethod
    def destroy_holdings_before_date(
        cls, target_date: datetime.datetime, keep_trade_snapshots: bool
    ):
        base_url = cls.get_object_url()
        payload = {
            "json": {
                "target_date": target_date.strftime(DATE_FORMAT),
                "keep_trade_snapshots": keep_trade_snapshots,
            }
        }

        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=f"{base_url}/destroy_holdings_before_date/",
            payload=payload,
        )
        if r.status_code != 204:
            raise Exception(r.text)

    @classmethod
    def create_with_holdings(
        cls,
        position_list: list[AccountPositionDetail],
        holdings_date: int,
        related_account: int,
        extra_details: dict = None,
        timeout=None,
    ):

        base_url = cls.get_object_url()
        payload = {
            "json": {
                "position_list": [
                    {
                        k: v
                        for k, v in p.model_dump().items()
                        if k not in ["orm_class", "id", "parents_holdings"]
                    }
                    for p in position_list
                ],
                "holdings_date": holdings_date,
                "related_account": related_account,
            }
        }

        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=f"{base_url}/create_with_holdings/",
            payload=payload,
            time_out=timeout,
        )
        if r.status_code != 201:
            raise Exception(r.text)
        return cls(**r.json())


class AccountRiskFactors(BaseObjectOrm, BasePydanticModel):
    related_holdings: int | AccountHistoricalHoldings
    account_balance: float


class FundingFeeTransaction(BaseObjectOrm):
    pass


class AccountPortfolioHistoricalWeights(BaseObjectOrm):
    pass


class WeightPosition(BaseObjectOrm, BasePydanticModel):
    # id: Optional[int] = None
    # parent_weights: int
    asset: AssetMixin | int
    weight_notional_exposure: float

    @property
    def asset_id(self):
        return self.asset if isinstance(self.asset, int) else self.asset.id

    @root_validator(pre=True)
    def resolve_assets(cls, values):
        # Check if 'asset' is a dict and determine its type
        if isinstance(values.get("asset"), dict):
            asset = values.get("asset")
            asset = resolve_asset(asset_dict=asset)
            values["asset"] = asset

        return values


class ExecutionVenue(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    symbol: str
    name: str

    @property
    def unique_identifier(self):
        return f"{self.symbol}"


class TradeSide(IntEnum):
    SELL = -1
    BUY = 1


class Trade(BaseObjectOrm, BasePydanticModel):
    id: int | None = None

    # Use a default_factory to set the default trade_time to now (with UTC timezone)
    trade_time: datetime.datetime
    trade_side: TradeSide
    asset: AssetMixin | int | None
    quantity: float
    price: float
    commission: float | None
    commission_asset: AssetMixin | int | None

    related_fund: Union["VirtualFund", int] | None
    related_account: Account | int | None
    related_order: Union["Order", int] | None

    settlement_cost: float | None
    settlement_asset: AssetMixin | int | None

    comments: str | None
    venue_specific_properties: dict | None

    @classmethod
    def create_or_update(cls, trade_kwargs, timeout=None) -> None:
        url = f"{cls.get_object_url()}/create_or_update/"
        data = cls.serialize_for_json(trade_kwargs)
        payload = {"json": data}
        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=url,
            payload=payload,
            time_out=timeout,
        )
        if r.status_code !=200:
            raise Exception(f" {r.text()}")
        return cls(**r.json())


class OrdersExecutionConfiguration(BaseModel):
    broker_class: str
    broker_configuration: dict


class PortfolioTags(BasePydanticModel):
    id: int | None = None
    name: str
    color: str





class PortfolioAbout(TypedDict):
    description: str
    signal_name: str
    signal_description: str
    rebalance_strategy_name: str



class Portfolio(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    data_node_update: Optional["DataNodeUpdate"]
    signal_data_node_update: Optional["DataNodeUpdate"]
    backtest_table_price_column_name: str | None = Field(None, max_length=20)
    tags: list["PortfolioTags"] | None = None
    calendar: Optional["Calendar"]
    index_asset: PortfolioIndexAsset
    builds_from_target_weights: bool =True
    builds_from_target_positions:bool=False

    def pretty_print(self) -> str:
        def format_field(name, value):
            if isinstance(value, list):
                val = ", ".join(str(v) for v in value)
            elif hasattr(value, "__str__"):
                val = str(value)
            else:
                val = repr(value)
            return f"{name:35}: {val}"

        fields = self.__fields__
        lines = [format_field(name, getattr(self, name, None)) for name in fields]
        return "\n".join(lines)

    @classmethod
    def create_from_time_series(
        cls,
        portfolio_name: str,
        data_node_update_id: int,
        signal_data_node_update_id: int,
        calendar_name: str,
        target_portfolio_about: PortfolioAbout,
        backtest_table_price_column_name: str,
        tags: list | None = None,
        timeout=None,
    ) -> "Portfolio":
        url = f"{cls.get_object_url()}/create_from_time_series/"
        # Build the payload with the required arguments.
        payload_data = {
            "portfolio_name": portfolio_name,
            "data_node_update_id": data_node_update_id,
            "signal_data_node_update_id": signal_data_node_update_id,
            # Using the same ID for local_signal_time_serie_id as specified.
            "calendar_name": calendar_name,
            "target_portfolio_about": target_portfolio_about,
            "backtest_table_price_column_name": backtest_table_price_column_name,
            "tags": tags,
        }

        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=url,
            payload={"json": payload_data},
            time_out=timeout,
        )
        if r.status_code not in [201]:
            raise Exception(f" {r.text}")
        response = r.json()

        return cls(**response["portfolio"]), PortfolioIndexAsset(
            **response["portfolio_index_asset"]
        )

    @property
    def portfolio_name(self) -> str:
        return self.index_asset.current_snapshot.name

    @property
    def portfolio_ticker(self) -> str:
        return self.index_asset.current_snapshot.ticker

    def add_venue(self, venue_id) -> None:
        url = f"{self.get_object_url()}/{self.id}/add_venue/"
        payload = {"json": {"venue_id": venue_id}}
        r = make_request(
            s=self.build_session(), loaders=self.LOADERS, r_type="PATCH", url=url, payload=payload
        )
        if r.status_code != 200:
            raise RuntimeError(f"PATCH {url} failed: {r.status_code} {r.text}")




    def get_latest_weights(self, timeout=None) -> dict[str, float]:
        url = f"{self.get_object_url()}/{self.id}/get_latest_weights/"
        r = make_request(
            s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url, time_out=timeout
        )
        if r.status_code  !=200:
            raise Exception(f" {r.text}")
        results = r.json()
        return results["weights"], datetime.datetime.utcfromtimestamp(
            results["weights_date"]
        ).replace(tzinfo=pytz.utc)



class PortfolioGroup(BaseObjectOrm, BasePydanticModel):
    id: int
    unique_identifier: str
    display_name: str
    source: str
    portfolios: list[Union[int, "Portfolio"]]
    description: str | None = None

    def __repr__(self):
        return f"{self.display_name} ({self.unique_identifier}), {len(self.portfolios)} portfolios"

    @classmethod
    def get_or_create(
        cls,
        unique_identifier: str,
        display_name: str,
        portfolio_ids: list[int],
        source: str | None = None,
        description: str | None = None,
        timeout=None,
    ):
        url = f"{cls.get_object_url()}/get_or_create/"
        payload = {
            "json": {
                "display_name": display_name,
                "source": source,
                "unique_identifier": unique_identifier,
                "portfolios": portfolio_ids,
                "description": description,
            }
        }
        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=url,
            payload=payload,
            time_out=timeout,
        )
        if r.status_code not in [201, 200]:
            raise Exception(f" {r.text}")
        return cls(**r.json())

    def append_portfolios(self, portfolio_ids: list[int]) -> "PortfolioGroup":
        """
        Appends portfolios to the group by calling the custom API action.

        Args:
            portfolio_ids: A list of portfolio primary keys to add to the group.

        Returns:
            The updated PortfolioGroup instance.
        """
        if not self.id:
            raise ValueError("Cannot append portfolios to an unsaved PortfolioGroup.")

        url = f"{self.get_object_url()}/{self.id}/append-portfolios/"
        payload = {"portfolios": portfolio_ids}

        r = make_request(
            s=self.build_session(),
            loaders=self.LOADERS,
            r_type="POST",
            url=url,
            payload={"json": payload},
        )

        if r.status_code != 200:
            raise Exception(f"Error appending portfolios: {r.text}")

        # Update the current instance in-place with the response from the server
        updated_data = r.json()
        for key, value in updated_data.items():
            setattr(self, key, value)

        return self

    def remove_portfolios(self, portfolio_ids: list[int]) -> "PortfolioGroup":
        """
        Removes portfolios from the group by calling the custom API action.

        Args:
            portfolio_ids: A list of portfolio primary keys to remove from the group.

        Returns:
            The updated PortfolioGroup instance.
        """
        if not self.id:
            raise ValueError("Cannot remove portfolios from an unsaved PortfolioGroup.")

        url = f"{self.get_object_url()}/{self.id}/remove-portfolios/"
        payload = {"portfolios": portfolio_ids}

        r = make_request(
            s=self.build_session(),
            loaders=self.LOADERS,
            r_type="POST",
            url=url,
            payload={"json": payload},
        )

        if r.status_code != 200:
            raise Exception(f"Error removing portfolios: {r.text}")

        # Update the current instance in-place with the response from the server
        updated_data = r.json()
        for key, value in updated_data.items():
            setattr(self, key, value)

        return self


class VirtualFundPositionDetail(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    asset: Asset | AssetFutureUSDM | int
    price: float
    quantity: float
    parents_holdings: Union[int, "VirtualFundHistoricalHoldings"]

    @property
    def asset_id(self):
        return self.asset if isinstance(self.asset, int) else self.asset.id

    @root_validator(pre=True)
    def resolve_assets(cls, values):
        # Check if 'asset' is a dict and determine its type
        if isinstance(values.get("asset"), dict):
            asset = values.get("asset")
            asset = resolve_asset(asset_dict=asset)
            values["asset"] = asset

        return values


class VirtualFundHistoricalHoldings(BaseObjectOrm, BasePydanticModel):
    related_fund: Union["VirtualFund", int]  # assuming VirtualFund is another Pydantic model
    target_trade_time: datetime.datetime | None = None
    target_weights: dict | None = Field(default=None)
    is_trade_snapshot: bool = Field(default=False)
    fund_account_target_exposure: float = Field(default=0)
    fund_account_units_exposure: float | None = Field(default=None)
    holdings: list[VirtualFundPositionDetail]


class ExecutionQuantity(BaseModel):
    asset: Asset | AssetFutureUSDM | int
    quantity: float
    reference_price: None | float

    def __repr__(self):
        return f"{self.__class__.__name__}(asset={self.asset}, quantity={self.quantity})"

    @root_validator(pre=True)
    def resolve_assets(cls, values):
        # Check if 'asset' is a dict and determine its type
        if isinstance(values.get("asset"), dict):
            asset = values.get("asset")
            asset = resolve_asset(asset_dict=asset)
            values["asset"] = asset

        return values


class TargetRebalance(BaseModel):
    # target_execution_positions: ExecutionPositions
    execution_target: list[ExecutionQuantity]

    @property
    def rebalance_asset_map(self):
        return {e.asset.id: e.asset for e in self.execution_target}

class InstrumentsConfiguration(BaseObjectOrm,BasePydanticModel):
    discount_curves_storage_node:int | None
    reference_rates_fixings_storage_node:int | None

class VirtualFund(BaseObjectOrm, BasePydanticModel):
    id: float | None = None
    target_portfolio: Union[int, "Portfolio"]
    target_account: AccountMixin
    notional_exposure_in_account: float
    latest_holdings: "VirtualFundHistoricalHoldings" = None
    latest_rebalance: datetime.datetime | None = None
    fund_nav: float = Field(default=0)
    fund_nav_date: datetime.datetime | None = None
    requires_nav_adjustment: bool = Field(default=False)
    target_portfolio_weight_in_account: float | None = None
    last_trade_time: datetime.datetime | None = None

    # def sanitize_target_weights_for_execution_venue(self,target_weights:dict):
    #     """
    #     This functions switches assets from main net to test net to guarante consistency in the recording
    #     of trades and orders
    #     Args:
    #         target_weights:{asset_id:WeightExecutionPosition}
    #
    #     Returns:
    #
    #     """
    #     if self.target_account.execution_venue.symbol == CONSTANTS.BINANCE_TESTNET_FUTURES_EV_SYMBOL:
    #         target_ev=CONSTANTS.BINANCE_TESTNET_FUTURES_EV_SYMBOL
    #         new_target_weights={}
    #         for _, position in target_weights.items():
    #             AssetClass = position.asset.__class__
    #             asset,_ = AssetClass.filter(symbol=position.asset.unique_symbol, execution_venue__symbol=target_ev,
    #                                     asset_type=position.asset.asset_type,
    #                                     )
    #             asset = asset[0]
    #             new_position = copy.deepcopy(position)
    #             new_position.asset=asset
    #             new_target_weights[asset.id] = new_position
    #             # todo create in DB an execution position
    #     else:
    #         new_target_weights = target_weights
    #
    #     return new_target_weights

    # def build_rebalance_from_target_weights(
    #         self,
    #         target_execution_postitions: ExecutionPositions,
    #         positions_prices: dict(),
    #         absolute_rebalance_weight_limit=.02
    # ) -> TargetRebalance:
    #     actual_positions = {}
    #     target_weights = {p.asset_id: p for p in target_execution_postitions.positions}
    #     #substitute target weights in case of testnets
    #     target_weights = self.sanitize_target_weights_for_execution_venue(target_weights)
    #
    #     positions_to_rebalance = []
    #     if self.latest_holdings is not None:
    #         actual_positions = {p.asset_id : p for p in self.latest_holdings.holdings}
    #
    #         # positions to unwind first
    #         positions_to_unwind=[]
    #         for position in self.latest_holdings.holdings:
    #             if position.quantity == 0.0:
    #                 continue
    #             if position.asset_id not in target_weights.keys():
    #                 positions_to_unwind.append(
    #                     ExecutionQuantity(
    #                         asset=position.asset,
    #                         reference_price=None,
    #                         quantity=-position.quantity
    #                     )
    #                 )
    #
    #         positions_to_rebalance.extend(positions_to_unwind)
    #
    #     for target_position in target_execution_postitions.positions:
    #         price = positions_prices[target_position.asset_id]
    #
    #         current_weight, current_position = 0, 0
    #         if target_position.asset_id in actual_positions.keys():
    #             current_weight = actual_positions[target_position.asset_id].quantity * price / self.notional_exposure_in_account
    #             current_position = actual_positions[target_position.asset_id].quantity
    #         target_weight = target_position.weight_notional_exposure
    #         if abs(target_weight - current_weight) <= absolute_rebalance_weight_limit:
    #             continue
    #         target_quantity = self.notional_exposure_in_account * target_position.weight_notional_exposure / price
    #         rebalance_quantity = target_quantity - current_position
    #         positions_to_rebalance.append(ExecutionQuantity(asset=target_position.asset,
    #                                                         quantity=rebalance_quantity,
    #                                                         reference_price=price
    #                                                         ))
    #
    #     target_rebalance = TargetRebalance(target_execution_positions=target_execution_postitions,
    #                                        execution_target=positions_to_rebalance
    #                                        )
    #     return target_rebalance

    @validator("last_trade_time", pre=True, always=True)
    def parse_last_trade_time(cls, value):
        value = validator_for_string(value)
        return value

    @validator("fund_nav_date", pre=True, always=True)
    def parse_fund_nav_date(cls, value):
        value = validator_for_string(value)
        return value

    @validator("latest_rebalance", pre=True, always=True)
    def parse_latest_rebalance(cls, value):
        value = validator_for_string(value)
        return value

    def get_account(self):
        a, r = Account.get(id=self.target_account)
        return a

    def get_latest_trade_snapshot_holdings(self):
        url = f"{self.get_object_url()}/{int(self.id)}/get_latest_trade_snapshot_holdings/"
        r = make_request(s=self.build_session(), loaders=self.LOADERS, r_type="GET", url=url)

        if r.status_code != 200:
            raise HtmlSaveException(r.text)
        if len(r.json()) == 0:
            return None
        return VirtualFundHistoricalHoldings(**r.json())


class OrderStatus(str, Enum):
    LIVE = "live"
    FILLED = "filled"
    PARTIALLY_FILLED = "partially_filled"
    CANCELED = "canceled"
    NOT_PLACED = "not_placed"


class OrderTimeInForce(str, Enum):
    GOOD_TILL_CANCELED = "gtc"


class OrderSide(IntEnum):
    SELL = -1
    BUY = 1


class OrderType(str, Enum):
    MARKET = "market"
    LIMIT = "limit"
    NOT_PLACED = "not_placed"


class Order(BaseObjectOrm, BasePydanticModel):
    id: int | None = Field(None, primary_key=True)
    order_remote_id: str
    client_order_id: str
    order_type: OrderType
    order_time: datetime.datetime
    expires_time: datetime.datetime | None = None
    order_side: OrderSide  # Use int for choices (-1: SELL, 1: BUY)
    quantity: float
    status: OrderStatus = OrderStatus.NOT_PLACED
    filled_quantity: float | None = 0.0
    filled_price: float | None = None
    order_manager: Union[int, "OrderManager"] = None  # Assuming foreign key ID is used
    asset: int  # Assuming foreign key ID is used
    related_fund: int | None = None  # Assuming foreign key ID is used
    related_account: int  # Assuming foreign key ID is used
    time_in_force: str
    comments: str | None = None

    class Config:
        use_enum_values = True  # This allows using enum values directly

    @classmethod
    def create_or_update(cls, order_time_stamp: float, *args, **kwargs):
        """

        Args:
            order_time: timestamp
            *args:
            **kwargs:

        Returns:

        """
        url = f"{cls.get_object_url()}/create_or_update/"
        kwargs["order_time"] = order_time_stamp
        payload = {"json": kwargs}

        r = make_request(
            s=cls.build_session(), loaders=cls.LOADERS, r_type="POST", url=url, payload=payload
        )

        if r.status_code not in [200, 201]:
            raise r.text
        return cls(**r.json())


class MarketOrder(Order):
    pass


class LimitOrder(Order):
    limit_price: float


class OrderManagerTargetQuantity(BaseModel):
    asset: int | Asset
    quantity: Decimal


class OrderManager(BaseObjectOrm, BasePydanticModel):
    id: int | None = None
    target_time: datetime.datetime
    target_rebalance: list[OrderManagerTargetQuantity]
    order_received_time: datetime.datetime | None = None
    execution_end: datetime.datetime | None = None
    related_account: Account | int  # Representing the ForeignKey field with the related account ID

    @staticmethod
    def serialize_for_json(kwargs):
        new_data = {}
        for key, value in kwargs.items():
            new_value = copy.deepcopy(value)
            if isinstance(value, datetime.datetime):
                new_value = str(value)
            elif key == "target_rebalance":
                new_value = [json.loads(c.model_dump_json()) for c in value]
            new_data[key] = new_value
        return new_data

    @classmethod
    def destroy_before_date(cls, target_date: datetime.datetime):
        base_url = cls.get_object_url()
        payload = {
            "json": {
                "target_date": target_date.strftime(DATE_FORMAT),
            },
        }

        r = make_request(
            s=cls.build_session(),
            loaders=cls.LOADERS,
            r_type="POST",
            url=f"{base_url}/destroy_before_date/",
            payload=payload,
        )

        if r.status_code != 204:
            raise Exception(r.text)


# ------------------------------
# ALPACA
# ------------------------------


class AlpacaAccountRiskFactors(AccountRiskFactors):
    total_initial_margin: float
    total_maintenance_margin: float
    last_equity: float
    buying_power: float
    cash: float
    last_maintenance_margin: float
    long_market_value: float
    non_marginable_buying_power: float
    options_buying_power: float
    portfolio_value: float
    regt_buying_power: float
    sma: float


class AlpacaAccount(
    AccountMixin,
):
    api_key: str
    secret_key: str

    account_number: str
    id_hex: str
    account_blocked: bool
    multiplier: float
    options_approved_level: int
    options_trading_level: int
    pattern_day_trader: bool
    trade_suspended_by_user: bool
    trading_blocked: bool
    transfers_blocked: bool
    shorting_enabled: bool


# ------------------------------
# BINANCE
# ------------------------------


class BinanceFuturesAccountRiskFactors(AccountRiskFactors):
    total_initial_margin: float
    total_maintenance_margin: float
    total_margin_balance: float
    total_unrealized_profit: float
    total_cross_wallet_balance: float
    total_cross_unrealized_pnl: float
    available_balance: float
    max_withdraw_amount: float


class BaseFuturesAccount(Account):
    api_key: str
    secret_key: str

    multi_assets_margin: bool = False
    fee_burn: bool = False
    can_deposit: bool = False
    can_withdraw: bool = False


