# loreley.config

Centralised configuration for the Loreley application, backed by `pydantic-settings` and environment variables.

## Settings

- **`Settings`**: `BaseSettings` subclass that loads core application configuration.
  - **Environment**: `app_name`, `environment`, `log_level`, `logs_base_dir`. `log_level` controls the global Loguru log level used across long-running processes (including the scheduler, workers, and their CLI wrappers); `logs_base_dir` (via `LOGS_BASE_DIR`) optionally overrides the base directory where long-running process logs are written, defaulting to a `logs/` directory under the current working directory. See the scripts documentation under `docs/script` for concrete examples.
  - **OpenAI-compatible API**: `OPENAI_API_KEY`, `OPENAI_BASE_URL`, `OPENAI_API_SPEC` configure the API key, base URL, and API surface for all OpenAI-compatible LLM and embedding calls, used by `loreley.core.map_elites.code_embedding.CodeEmbedder` and `loreley.core.worker.commit_summary.CommitSummarizer`. When unset, `OPENAI_API_KEY`/`OPENAI_BASE_URL` fall back to the OpenAI Python client's own environment variable defaults. `OPENAI_API_SPEC` accepts:
    - `"responses"` (default): use the unified `responses` API (`client.responses.create`) for text generation.
    - `"chat_completions"`: use the classic Chat Completions API (`client.chat.completions.create`) while preserving the same high-level behaviour.
  - **Database**: either a raw `DATABASE_URL` or individual `DB_*` fields (scheme, host, port, username, password, database name, pool options, echo flag).
  - **Metrics**: `metrics_retention_days` controls how long metrics are retained.
  - **Task queue**: `TASKS_REDIS_URL`, `TASKS_REDIS_HOST`, `TASKS_REDIS_PORT`, `TASKS_REDIS_DB`, `TASKS_REDIS_PASSWORD`, `TASKS_REDIS_NAMESPACE`, `TASKS_QUEUE_NAME`, `TASKS_WORKER_MAX_RETRIES`, `TASKS_WORKER_TIME_LIMIT_SECONDS`, and `WORKER_EXPERIMENT_ID` configure the Dramatiq Redis broker connection details, logical namespace, queue routing, retry policy, and actor time limits used by `loreley.tasks.broker` and `loreley.tasks.workers`. `TASKS_QUEUE_NAME` is treated as a **queue prefix**; Loreley derives a per-experiment queue as `"{TASKS_QUEUE_NAME}.{experiment_id.hex}"` and workers attach to a single experiment via `WORKER_EXPERIMENT_ID`. When `TASKS_REDIS_URL` is set and includes credentials, only a sanitised `scheme://host:port/db` form is logged, never the raw URL or password. `TASKS_WORKER_TIME_LIMIT_SECONDS` is interpreted in seconds and converted to Dramatiq's millisecond `time_limit`: values `<= 0` disable the time limit (no hard cap on actor runtime), while positive values enforce a per-job wall-clock limit.
  - **Scheduler**: `SCHEDULER_REPO_ROOT`, `SCHEDULER_POLL_INTERVAL_SECONDS`, `SCHEDULER_MAX_UNFINISHED_JOBS`, `SCHEDULER_MAX_TOTAL_JOBS`, `SCHEDULER_SCHEDULE_BATCH_SIZE`, `SCHEDULER_DISPATCH_BATCH_SIZE`, and `SCHEDULER_INGEST_BATCH_SIZE` drive `loreley.scheduler.main`. The scheduler also enforces **single-scheduler-per-experiment** using a Postgres advisory lock at startup. Before entering the main loop, the scheduler requires **startup approval** for the experiment root commit: it prints the observed eligible repo-state file count (and filter knobs) and asks a y/n question. In non-interactive environments, set `SCHEDULER_STARTUP_APPROVE=true` or pass `--yes` to proceed; otherwise the scheduler refuses to start (fail fast).
  - **Worker repository**: `WORKER_REPO_REMOTE_URL`, `WORKER_REPO_BRANCH`, `WORKER_REPO_WORKTREE`, `WORKER_REPO_WORKTREE_RANDOMIZE`, `WORKER_REPO_WORKTREE_RANDOM_SUFFIX_LEN`, `WORKER_REPO_GIT_BIN`, `WORKER_REPO_FETCH_DEPTH`, `WORKER_REPO_CLEAN_EXCLUDES`, `WORKER_REPO_JOB_BRANCH_PREFIX`, `WORKER_REPO_ENABLE_LFS`, and `WORKER_REPO_JOB_BRANCH_TTL_HOURS` configure the worker repository base clone (upstream remote and branch, local base path, optional randomised suffix for isolated base clones, git binary, shallow clone depth, clean exclusions, job branch naming, optional Git LFS support, and remote job branch retention). The worker creates isolated per-job git worktrees under `<WORKER_REPO_WORKTREE>-worktrees/` so concurrent jobs do not share a mutable working directory, used by `loreley.core.worker.repository.WorkerRepository`.
  - **Worker planning**: `WORKER_PLANNING_*` options configuring how the external Codex CLI planner is invoked (binary path, optional profile, maximum attempts, timeout, extra environment variables, an optional JSON schema override, the Codex schema mode, and the validation mode), used by `loreley.core.worker.planning.PlanningAgent`. You can override the entire backend via `WORKER_PLANNING_BACKEND` (dotted `module:attr`), and `WORKER_PLANNING_CODEX_SCHEMA_MODE` selects `"auto"` / `"native"` / `"prompt"` / `"none"` when the Codex backend is used. `WORKER_PLANNING_VALIDATION_MODE` controls how strictly the worker enforces the planner's JSON output:
    - `"strict"`: require the backend to produce JSON that matches the planning schema; both Codex (in native schema mode) and the local Pydantic models validate the payload, and failures cause retries and eventually a hard error.
    - `"lenient"` (default): still provide the JSON schema to the backend when applicable, but treat JSON decoding / schema validation failures as non-fatal. The worker first tries to parse the response using the planning schema; if that fails, it synthesises a minimal `PlanningPlan` from the free-form output while preserving as much structure as possible for downstream consumers.
    - `"none"`: disable JSON-based validation entirely. The planner may respond in arbitrary free-form text; the worker skips JSON parsing and always builds a minimal `PlanningPlan` directly from the raw output and job context.
  - **Worker coding**: `WORKER_CODING_*` options configuring how the external Codex-based coding agent is invoked (binary path, optional profile, maximum attempts, timeout, extra environment variables, an optional JSON schema override, the Codex schema mode, and the validation mode), used by `loreley.core.worker.coding.CodingAgent`. You can override the backend via `WORKER_CODING_BACKEND` (dotted `module:attr`), and `WORKER_CODING_CODEX_SCHEMA_MODE` selects `"auto"` / `"native"` / `"prompt"` / `"none"` when the Codex backend is used. `WORKER_CODING_VALIDATION_MODE` follows the same `"strict"` / `"lenient"` / `"none"` semantics as the planning agent, but applied to the coding agent's structured execution report.
  - **Cursor backend**: `WORKER_CURSOR_MODEL` selects the model passed to the Cursor Agent CLI (default `"gpt-5.2-high"`), used by `loreley.core.worker.agent.backends.cursor_backend_from_settings()` when wiring Cursor as a backend for planning or coding.
  `WORKER_CURSOR_FORCE` (default `true`) appends `--force` so the Cursor agent allows commands unless explicitly denied; set it to `false` to omit the flag.
  - **Worker evaluator**: `WORKER_EVALUATOR_PLUGIN`, `WORKER_EVALUATOR_PYTHON_PATHS`, `WORKER_EVALUATOR_TIMEOUT_SECONDS`, and `WORKER_EVALUATOR_MAX_METRICS` configure the evaluation plugin entry point, additional Python paths, subprocess timeout, and the maximum number of metrics to keep, used by `loreley.core.worker.evaluator.Evaluator`.
  - **Worker evolution commits**: `WORKER_EVOLUTION_COMMIT_MODEL`, `WORKER_EVOLUTION_COMMIT_TEMPERATURE`, `WORKER_EVOLUTION_COMMIT_MAX_OUTPUT_TOKENS`, `WORKER_EVOLUTION_COMMIT_MAX_RETRIES`, `WORKER_EVOLUTION_COMMIT_RETRY_BACKOFF_SECONDS`, `WORKER_EVOLUTION_COMMIT_AUTHOR`, `WORKER_EVOLUTION_COMMIT_EMAIL`, and `WORKER_EVOLUTION_COMMIT_SUBJECT_MAX_CHARS` configure how the evolution worker generates and records commit subjects (LLM model, sampling behaviour, retry policy, and subject length) and which author identity is used when creating commits, used by `loreley.core.worker.commit_summary.CommitSummarizer` and `loreley.core.worker.repository.WorkerRepository`.
  - **Worker evolution global goal**: `WORKER_EVOLUTION_GLOBAL_GOAL` provides a single, plain‑language evolution objective that is shared across all jobs. When a job row does not provide a per‑job `goal`, this value is used as the **Global objective** in both the planning and coding prompts so that the worker consistently optimises towards a user‑defined high‑level target.
  - **Map-Elites preprocessing**: `MAPELITES_PREPROCESS_*` options controlling which repository code files are considered for feature extraction (limits on file size, allowed extensions/filenames, excluded path globs, whitespace handling, and comment stripping), used by `loreley.core.map_elites.preprocess.CodePreprocessor` and the repo-state embedding file enumerator.
  - **Map-Elites chunking**: `MAPELITES_CHUNK_*` options controlling how preprocessed files are split into chunks (target and minimum lines per chunk, overlap, maximum chunks per file, and boundary keywords used by the chunker), used by `loreley.core.map_elites.chunk.CodeChunker`.
  - **Map-Elites code embedding**: `MAPELITES_CODE_EMBEDDING_*` options configuring the embedding model, output dimensions (`MAPELITES_CODE_EMBEDDING_DIMENSIONS`, set by the scheduler and persisted per experiment), batch size, per-commit chunk budget, retry count, and exponential backoff for embedding requests, used by `loreley.core.map_elites.code_embedding.CodeEmbedder`.
  - **Map-Elites dimensionality reduction**: `MAPELITES_DIMENSION_REDUCTION_*` options controlling how commit embeddings are normalised, the target feature dimensions, minimum sample count for fitting PCA, rolling history size, and refit cadence, used by `loreley.core.map_elites.dimension_reduction.DimensionReducer`. In repo-state mode, the input embedding is the repo-state code vector.
  - **Map-Elites feature normalization and archive**: `MAPELITES_FEATURE_TRUNCATION_K` sets the symmetric clip radius applied to PCA outputs before they are linearly mapped into `[0, 1]^d`; `MAPELITES_FEATURE_NORMALIZATION_WARMUP_SAMPLES` controls the minimum history required before fitting/using PCA (never below `MAPELITES_DIMENSION_REDUCTION_MIN_FIT_SAMPLES`); and `MAPELITES_FEATURE_CLIP` toggles defensive clipping. `MAPELITES_ARCHIVE_*` options continue to configure grid resolution and learning parameters for the underlying MAP-Elites archive, used by `loreley.core.map_elites.map_elites.MapElitesManager`.
  - **Map-Elites fitness and sampling**: `MAPELITES_FITNESS_*` and `MAPELITES_SAMPLER_*` options that configure which metric to optimise, how to treat fitness direction/floor, and how new jobs are drawn from the archive (inspiration count, neighbour radius, fallback sampling, default priority), used by `loreley.core.map_elites.map_elites.MapElitesManager` and `loreley.core.map_elites.sampler.MapElitesSampler`. `MAPELITES_SEED_POPULATION_SIZE` sets the initial seed population size for new islands.
  - **Map-Elites embedding cache**: `MAPELITES_FILE_EMBEDDING_CACHE_BACKEND` selects the file-level embedding cache backend (`"db"` (default) or `"memory"`). For incremental-only repo-state ingestion, the scheduler requires the `"db"` backend so repo-state aggregates can be persisted and incrementally derived.
  - **Map-Elites experiment root commit**: `MAPELITES_EXPERIMENT_ROOT_COMMIT` pins the logical root for a given experiment and is required by the scheduler for repo-state bootstrap and incremental-only ingestion. The scheduler resolves the value to a canonical full hash and persists it in the experiment snapshot. At experiment creation time, Loreley also pins repository-root ignore rules used by repo-state embeddings (derived from the root commit and stored in the experiment snapshot as `mapelites_repo_state_ignore_text` / `mapelites_repo_state_ignore_sha256`), removing dynamic-ignore edge cases during runtime ingestion.
- **`database_dsn`**: computed property that returns a SQLAlchemy-compatible DSN, preferring `DATABASE_URL` when set and otherwise building one from the individual DB fields (with credentials URL-encoded).
- **`export_safe()`**: helper that returns a dict of non-sensitive configuration values suitable for logging.

## Access helpers

- **`get_settings()`**: cached factory that instantiates `Settings`, logs a concise summary of the environment and DB host using `rich`/`loguru`, and returns a singleton instance for reuse across the loreley.
