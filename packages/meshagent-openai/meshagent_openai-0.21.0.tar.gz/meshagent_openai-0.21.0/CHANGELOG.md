## [0.21.0]
- Breaking: the Image model no longer exposes manifest/template metadata in image listings.
- Add token-backed environment variables in service specs so Python clients can inject participant tokens instead of static values.
- Add `on_demand` and `writable_root_fs` flags on container specs to control per-request services and filesystem mutability.
- Breaking: the agent schedule annotation key is corrected to `meshagent.agent.schedule`; update any existing annotations using the old spelling.
- Add a Shell agent type and a shell command annotation for service metadata.

## [0.20.6]
- Stability

## [0.20.5]
- Stability

## [0.20.4]
- Stability

## [0.20.3]
- Stability

## [0.20.2]
- Stability

## [0.20.1]
- Stability

## [0.20.0]
- Breaking: mailbox create/update requests must now include a `public` flag (SDK defaults to `False` when omitted in method calls)
- Mailbox response models include a `public` field
- Breaking: service specs now require either `external` or `container` to be set
- External service specs allow omitting the base URL
- Service template variables include optional `annotations` metadata
- CLI mailbox commands support `--public` and include the `public` value in listings
- Mailbot whitelist parsing accepts comma-separated values
- Fixed JSON schema generation for database delete/search tools

## [0.19.5]
- Stability

## [0.19.4]
- Stability

## [0.19.3]
- Stability

## [0.19.2]
- Add boolean data type support plus `nullable`/`metadata` on schema types and generated JSON Schema.
- BREAKING: OpenAI proxy client creation now takes an optional `http_client` (request logging is configured via a separate logging client helper).
- Shell tool now reuses a long-lived container with a writable root filesystem, runs commands via `bash -lc`, and defaults to the `python:3.13` image.
- Add `log_llm_requests` support to enable OpenAI request/response logging.

## [0.19.1]
- Add optional metadata to agent chat contexts and propagate it through message-stream LLM delegation, including recording thread participant lists
- Add an option for the mailbot CLI to delegate LLM interactions to a remote participant instead of using the local LLM adapter

## [0.19.0]
- Add a reusable transcript logger/transcriber agent that writes conversation segments to transcript documents from live conversation events or user-turn completion
- Add optional voicebot transcription via a provided transcript path, wrapping the voice agent to persist user/assistant speech to a transcript document
- Refactor meeting transcription to use the shared transcript logger with per-participant sessions and improved session lifecycle cleanup
- Breaking change: starting a new email thread no longer accepts attachments; attachments are now handled by a dedicated “new thread with attachments” tool that downloads files from room storage before sending
- Simplify CLI agent room-rules loading and ensure worker message toolkits include inherited toolkits

## [0.18.2]
- Stability

## [0.18.1]
- Updated OpenAI Python SDK dependency to `openai~=2.14.0` (from `~2.6.0`).
- Breaking: OpenAI Responses adapter no longer sends tool definitions with requests, disabling tool/function calling via the Responses API.
- CLI deploy commands now report “Deployed service” on successful deploys.
- Shell toolkit/tool builders now pass the configured shell image via the `image` field.

## [0.18.0]
- Added local TCP port-forwarding helper that bridges to the remote tunnel WebSocket
- Added a CLI `port forward` command to expose container ports locally
- Added `writable_root_fs` support when running containers
- Added `host_port` support for service port specs
- Added `ApiScope.tunnels` support in participant tokens (including `agent_default(tunnels=...)`)
- Added container-based Playwright “computer use” and enabled computer-use toolkits for chatbot/worker/mailbot flows
- Removed `scrapybara` from the computers package dependencies
- OpenAI proxy client can now optionally log requests/responses with redacted authorization headers

## [0.17.1]
- Prevented worker toolkit lifecycle collisions when running alongside other toolkits by isolating the worker’s remote toolkit handling.
- Improved the error message when attempting to start a single-room agent more than once.

## [0.17.0]
- Added scheduled tasks support to the Python accounts client (create/update/list/delete scheduled tasks) with typed models
- Added mailbox CRUD helpers to the Python accounts client and improved error handling with typed HTTP exceptions (404/403/409/400/5xx)
- Added `RequiredTable` requirement type plus helper to create required tables, indexes, and optimize them automatically
- Added database namespace support for database toolkit operations (inspect/search/insert/update/delete in a namespace)
- Enhanced worker and mail agents (per-message tool selection, optional remote toolkit exposure for queue task submission, reply-all/cc support)
- Updated Python dependency: `supabase-auth` from `~2.12.3` to `~2.22.3`

## [0.16.0]
- Add optional `namespace` support across database client operations (list/inspect/create/drop/index/etc.) to target namespaced tables
- Update dependencies `livekit-api` to `~1.1` (from `>=1.0`) and `livekit-agents`/`livekit-plugins-openai`/`livekit-plugins-silero`/`livekit-plugins-turn-detector` to `~1.3` (from `~1.2`)

## [0.15.0]
- Added new UI schema widgets for `tabs`/`tab` (including initial tab selection and active background styling) plus a `visible` boolean widget property for conditional rendering.
- Updated Python LiveKit integration dependencies to include `livekit==1.0.20`.

## [0.14.0]
- Breaking change: toolkit extension hooks were simplified to a synchronous `get_toolkit_builders()` API and tool selection now uses per-toolkit configuration objects (not just tool names)
- `LLMTaskRunner` now supports per-client and per-room rules, plus dynamically injected required toolkits at call time
- `TaskRunner.ask` now supports optional binary attachments; `LLMTaskRunner` can unpack tar attachments and pass images/files into the LLM conversation context
- `AgentsClient.ask` now returns `TextResponse` when the agent responds with plain text (instead of always treating answers as JSON)
- Added a CLI `task-runner` command to run/join LLM task runners with configurable rules, schemas, toolkits, and optional remote LLM delegation

## [0.13.0]
- Added `initial_json` and explicit schema support when opening MeshDocuments, enabling schema-first document initialization
- Added binary attachment support when invoking agent tools so tool calls can include raw payload data
- Breaking change: toolkit construction is now async and receives the active room client, enabling toolkits that introspect room state during build
- Added database schema inspection and JSON Schema mappings for data types to support tool input validation and generation
- Introduced database toolkits (list/inspect/search/insert/update/delete) and integrated optional per-table enablement into the chatbot/mailbot/helpers CLI flows

## [0.12.0]
- Reduce worker-queue logging verbosity to avoid logging full message payloads

## [0.11.0]
- Stability

## [0.10.1]
- Stability

## [0.10.0]
- Stability

## [0.9.3]
- Stability

## [0.9.2]
- Stability

## [0.9.1]
- Stability

## [0.9.0]
- Stability

## [0.8.4]
- Stability

## [0.8.3]
- Stability

## [0.8.2]
- Stability

## [0.8.1]
- Stability

## [0.8.0]
- Stability

## [0.7.2]
- Stability

## [0.7.1]
- Stability
