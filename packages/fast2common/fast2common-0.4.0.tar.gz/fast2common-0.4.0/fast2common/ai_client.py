#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI å®¢æˆ·ç«¯ - è´Ÿè´£ä¸æ™ºè°± AutoGLM-Phone API äº¤äº’
"""

import os
import base64
from pathlib import Path
from typing import Dict, Optional

try:
    from zhipuai import ZhipuAI
except ImportError:
    # Only show warning when actually needed, not on module import
    # The warning will be shown when AIClient is initialized with enable_analysis=True
    ZhipuAI = None

# å°è¯•å¯¼å…¥é…ç½®åŠ è½½å™¨
get_config = None
try:
    from core.config.simple_loader import get_config
except ImportError:
    try:
        import sys
        from pathlib import Path
        sys.path.insert(0, str(Path(__file__).parent.parent / "auto-test"))
        from core.config.simple_loader import get_config
    except ImportError:
        pass


class AIClient:
    """æ™ºè°± AutoGLM-Phone AI å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: str = None, enable_analysis: bool = False, model: str = None):
        """
        åˆå§‹åŒ– AI å®¢æˆ·ç«¯
        
        Args:
            api_key: æ™ºè°± API Keyã€‚å¦‚æœä¸ä¼ ï¼Œå°†å°è¯•ä» ZHIPU_API_KEY ç¯å¢ƒå˜é‡è·å–
            enable_analysis: æ˜¯å¦å¯ç”¨AIåˆ†æ
            model: æ¨¡å‹åç§°ï¼ˆå¦‚ "glm-4-flash", "autoglm-phone"ï¼‰ï¼Œé»˜è®¤ "glm-4.6v"
        """
        self.api_key = api_key or os.getenv("ZHIPU_API_KEY")
        self.enable_analysis = enable_analysis
        self.client = None
        self.model = model or "glm-4.6v"
        
        if enable_analysis:
            if not self.api_key:
                raise ValueError(
                    "è¯·è®¾ç½® ZHIPU_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_key å‚æ•°\n"
                    "è·å– API Key: https://open.bigmodel.cn/"
                )
            
            if ZhipuAI is None:
                # Show warning only when actually trying to use AI
                print("âš ï¸  æœªå®‰è£… zhipuaiï¼Œè¯·è¿è¡Œ: pip install zhipuai")
                raise ImportError("è¯·å…ˆå®‰è£… zhipuai: pip install zhipuai")
            
            self.client = ZhipuAI(api_key=self.api_key)
            print(f"âœ… AI å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.model})")
        else:
            print(f"âœ… AI å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆï¼ˆAIåˆ†æå·²å…³é—­ï¼‰")
    
    def _encode_image(self, image_path: Path, max_size: int = 1024) -> str:
        """
        å‹ç¼©å¹¶ç¼–ç å›¾ç‰‡ä¸º base64
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            max_size: æœ€å¤§è¾¹é•¿ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤1024
            
        Returns:
            base64 ç¼–ç å­—ç¬¦ä¸²
        """
        try:
            from PIL import Image
            import io
            
            # æ‰“å¼€å›¾ç‰‡
            img = Image.open(image_path) 
            # ä¿å­˜ä¸º JPEG æ ¼å¼ï¼ˆè´¨é‡85ï¼Œå¹³è¡¡è´¨é‡å’Œå¤§å°ï¼‰
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=85, optimize=True)
            
            # ç¼–ç ä¸º base64
            image_bytes = buffer.getvalue()
            original_kb = Path(image_path).stat().st_size / 1024
            compressed_kb = len(image_bytes) / 1024
            print(f"  ğŸ“¦ æ–‡ä»¶å¤§å°: {original_kb:.1f}KB â†’ {compressed_kb:.1f}KB ({compressed_kb/original_kb*100:.1f}%)")
            
            return base64.b64encode(image_bytes).decode('utf-8')
            
        except ImportError:
            # å¦‚æœæ²¡æœ‰ Pillowï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•
            print("  âš ï¸  æœªå®‰è£… Pillowï¼Œè·³è¿‡å‹ç¼©ï¼ˆå®‰è£…: pip install Pillowï¼‰")
            with open(image_path, "rb") as f:
                return base64.b64encode(f.read()).decode('utf-8')
        except Exception as e:
            # å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶
            print(f"  âš ï¸  å›¾ç‰‡å‹ç¼©å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶")
            with open(image_path, "rb") as f:
                return base64.b64encode(f.read()).decode('utf-8')
    
    def analyze_screen(self, screenshot_path: Path, task: str = None, response_format: str = None) -> Dict:
        """
        ä½¿ç”¨æ™ºè°± AutoGLM-Phone åˆ†æå±å¹•
        
        Args:
            screenshot_path: æˆªå›¾è·¯å¾„
            task: åˆ†æä»»åŠ¡ï¼Œå¦‚æœä¸ºNoneåˆ™è¿›è¡Œé€šç”¨åˆ†æ
            response_format: å“åº”æ ¼å¼ï¼Œå¯é€‰ "json_object" æˆ– Noneï¼ˆé»˜è®¤æ–‡æœ¬ï¼‰
            
        Returns:
            åˆ†æç»“æœ
        """
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIåˆ†æ
        if not self.enable_analysis:
            return {
                'success': False,
                'error': 'AIåˆ†æåŠŸèƒ½å·²å…³é—­',
                'screenshot': str(screenshot_path)
            }
        
        if not self.client:
            return {
                'success': False,
                'error': 'AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–',
                'screenshot': str(screenshot_path)
            }
        
        try:
            # ç¼–ç å›¾ç‰‡
            image_base64 = self._encode_image(screenshot_path)
            
            # é»˜è®¤ä»»åŠ¡ï¼šåˆ†æç•Œé¢å…ƒç´ 
            if task is None:
                task = (
                    "è¯·åˆ†æè¿™ä¸ªæ‰‹æœºåº”ç”¨ç•Œé¢ï¼Œåˆ—å‡ºæ‰€æœ‰å¯è§çš„UIå…ƒç´ ï¼Œ"
                    "åŒ…æ‹¬æŒ‰é’®ã€æ–‡æœ¬ã€è¾“å…¥æ¡†ç­‰ï¼Œå¹¶è¯´æ˜å®ƒä»¬çš„åŠŸèƒ½ã€‚"
                )
            
            # è°ƒç”¨æ™ºè°± AI APIï¼ˆæ”¯æŒ glm-4.6v å’Œ autoglm-phone æ¨¡å‹ï¼‰
            # glm-4.6v ä½¿ç”¨ data URI æ ¼å¼ä¼ é€’å›¾ç‰‡ï¼Œautoglm-phone ç›´æ¥ä¼ base64å­—ç¬¦ä¸²
            image_url = image_base64
            if self.model == "glm-4.6v":
                # glm-4.6v éœ€è¦ data URI æ ¼å¼
                image_url = f"data:image/png;base64,{image_base64}"
            
            api_params = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": image_url
                                }
                            },
                            {
                                "type": "text",
                                "text": task
                            }
                        ]
                    }
                ],
            }
            
            # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®ä¸åŒçš„å‚æ•°
            if self.model == "glm-4.6v":
                # glm-4.6v æ¨¡å‹å‚æ•°ï¼ˆå‚è€ƒ screenshot_feature_analyzer.py çš„æˆåŠŸå®ç°ï¼‰
                api_params["temperature"] = 0.2  # æ›´ä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´å’Œè¯¦ç»†çš„ç»“æœ
                api_params["max_tokens"] = 4096   # å¢åŠ æœ€å¤§tokenæ•°ä»¥å…è®¸æ›´è¯¦ç»†çš„è¾“å‡º
                # glm-4.6v ä¸éœ€è¦ stop å‚æ•°
            else:
                # autoglm-phone ç­‰å…¶ä»–æ¨¡å‹çš„å‚æ•°
                api_params["stop"] = ["[finish]"]  # autoglm-phone çš„ç»ˆæ­¢æ ‡è®°
                api_params["temperature"] = 0.3    # é™ä½éšæœºæ€§ï¼Œé¿å…å‘æ•£
                api_params["max_tokens"] = 2048    # æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼Œé˜²æ­¢æ— é™ç”Ÿæˆ
                # æ³¨æ„ï¼šæ™ºè°±APIä¸æ”¯æŒ repetition_penaltyï¼Œé  stop+temperature æ§åˆ¶
            
            # glm-4.6v å’Œ autoglm-phone æ¨¡å‹éƒ½æ”¯æŒ response_format å‚æ•°
            if response_format == "json_object":
                api_params["response_format"] = {"type": "json_object"}
                print(f"  ğŸ“„ ä½¿ç”¨JSONæ ¼å¼ï¼ˆæ¨¡å‹: {self.model}ï¼‰")
            
            # æ·»åŠ é€Ÿç‡é™åˆ¶é‡è¯•é€»è¾‘
            max_retries = 3
            retry_delay = 10  # ç§’
            
            for attempt in range(max_retries):
                try:
                    response = self.client.chat.completions.create(**api_params)
                    break  # æˆåŠŸåˆ™è·³å‡ºå¾ªç¯
                    
                except Exception as e:
                    error_str = str(e)
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯ï¼ˆ429ï¼‰
                    if "429" in error_str or "1305" in error_str or "è¯·æ±‚è¿‡å¤š" in error_str:
                        if attempt < max_retries - 1:
                            wait_time = retry_delay * (attempt + 1)  # é€’å¢ç­‰å¾…æ—¶é—´
                            print(f"  âš ï¸  APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•ï¼ˆ{attempt + 1}/{max_retries}ï¼‰...")
                            import time
                            time.sleep(wait_time)
                        else:
                            print(f"  âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä»ç„¶å¤±è´¥")
                            raise
                    else:
                        # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
                        raise
            
            # æå–åˆ†æç»“æœ
            analysis = response.choices[0].message.content
            
            return {
                'success': True,
                'analysis': analysis,
                'model': self.model,
                'screenshot': str(screenshot_path)
            }
            
        except Exception as e:
            import traceback
            error_detail = str(e) if str(e) else type(e).__name__
            print(f"âŒ AIåˆ†æå¤±è´¥: {error_detail}")
            print(f"ğŸ” é”™è¯¯è¯¦æƒ…:")
            traceback.print_exc()
            
            return {
                'success': False,
                'error': error_detail,
                'error_type': type(e).__name__,
                'error_traceback': traceback.format_exc(),
                'screenshot': str(screenshot_path)
            }
