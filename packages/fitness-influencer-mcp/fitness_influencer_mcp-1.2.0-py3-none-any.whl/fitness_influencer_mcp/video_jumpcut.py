#!/usr/bin/env python3
"""
video_jumpcut.py - Automatic Jump Cut Video Editor

WHAT: Removes silence from videos using FFmpeg silence detection
WHY: Save hours of manual editing time (10-15 min video ‚Üí 8 min typical)
INPUT: Video file (MP4/MOV/AVI), silence threshold (default -40dB)
OUTPUT: Edited video with jump cuts applied, processing stats
COST: FREE (uses FFmpeg + MoviePy)
TIME: ~2-5 minutes for 10-minute video

QUICK USAGE:
  python video_jumpcut.py --input raw_video.mp4 --output edited.mp4

CAPABILITIES:
  - Silence detection and removal (configurable threshold)
  - Automatic jump cuts (maintains natural flow)
  - Branded intro/outro insertion (optional)
  - Thumbnail generation from best frame
  - Processing stats (cuts made, time saved, file size)

DEPENDENCIES: ffmpeg, moviepy, pillow
API_KEYS: None required

---
Original Features:
- Silence detection and removal
- Automatic jump cuts
- Branded intro/outro insertion
- Thumbnail generation
- Multiple format export

Usage:
    python video_jumpcut.py --input raw_video.mp4
    python video_jumpcut.py --input raw_video.mp4 --silence-thresh -35 --output edited.mp4
"""

import argparse
import sys
import os
import subprocess
import json
from pathlib import Path

try:
    from moviepy.editor import (
        VideoFileClip, concatenate_videoclips, TextClip,
        CompositeVideoClip, ImageClip
    )
    from moviepy.video.fx import resize
except ImportError:
    print("ERROR: moviepy not installed")
    print("Install with: pip install moviepy")
    sys.exit(1)


class VideoJumpCutter:
    """
    Automatically removes silence from videos using FFmpeg silence detection.
    """

    def __init__(self, silence_thresh=-40, min_silence_dur=0.3, min_clip_dur=0.5):
        """
        Initialize jump cutter.

        Args:
            silence_thresh: Silence threshold in dB (default: -40dB)
            min_silence_dur: Minimum silence duration to detect (seconds)
            min_clip_dur: Minimum clip duration to keep (seconds)
        """
        self.silence_thresh = silence_thresh
        self.min_silence_dur = min_silence_dur
        self.min_clip_dur = min_clip_dur

    def detect_silence(self, video_path):
        """
        Detect silent segments in video using FFmpeg.

        Args:
            video_path: Path to input video

        Returns:
            List of tuples (start_time, end_time) for silent segments
        """
        print(f"\\n‚Üí Detecting silence (threshold: {self.silence_thresh}dB)...")

        # FFmpeg command to detect silence
        cmd = [
            'ffmpeg',
            '-i', video_path,
            '-af', f'silencedetect=n={self.silence_thresh}dB:d={self.min_silence_dur}',
            '-f', 'null',
            '-'
        ]

        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=False
            )

            # Parse silence detection output
            silence_start = []
            silence_end = []

            for line in result.stderr.split('\\n'):
                if 'silence_start' in line:
                    time = float(line.split('silence_start: ')[1].split()[0])
                    silence_start.append(time)
                elif 'silence_end' in line:
                    time = float(line.split('silence_end: ')[1].split('|')[0].strip())
                    silence_end.append(time)

            # Pair up start/end times
            silent_segments = list(zip(silence_start, silence_end))

            print(f"  ‚úì Detected {len(silent_segments)} silent segments")
            return silent_segments

        except Exception as e:
            print(f"  ‚ö†Ô∏è  Warning: Silence detection failed: {e}")
            print(f"  Continuing without jump cuts...")
            return []

    def generate_keep_segments(self, video_duration, silent_segments):
        """
        Generate list of segments to keep (non-silent parts).

        Args:
            video_duration: Total video duration in seconds
            silent_segments: List of (start, end) tuples for silent parts

        Returns:
            List of (start, end) tuples for segments to keep
        """
        if not silent_segments:
            return [(0, video_duration)]

        keep_segments = []
        current_time = 0

        for silence_start, silence_end in silent_segments:
            # Add the segment before this silence
            if silence_start - current_time > self.min_clip_dur:
                keep_segments.append((current_time, silence_start))

            current_time = silence_end

        # Add final segment after last silence
        if video_duration - current_time > self.min_clip_dur:
            keep_segments.append((current_time, video_duration))

        print(f"  ‚úì Generated {len(keep_segments)} keep segments")
        return keep_segments

    def apply_jump_cuts(self, video_path, output_path, silent_segments=None):
        """
        Apply jump cuts to remove silence.

        Args:
            video_path: Input video file
            output_path: Output video file
            silent_segments: Optional pre-detected silent segments

        Returns:
            Path to edited video
        """
        print(f"\\n{'='*70}")
        print(f"VIDEO JUMP CUT EDITOR")
        print(f"{'='*70}")
        print(f"Input:  {video_path}")
        print(f"Output: {output_path}")

        # Load video
        print(f"\\n‚Üí Loading video...")
        video = VideoFileClip(video_path)
        original_duration = video.duration
        print(f"  ‚úì Loaded: {original_duration:.2f} seconds")

        # Detect silence if not provided
        if silent_segments is None:
            silent_segments = self.detect_silence(video_path)

        # Generate keep segments
        keep_segments = self.generate_keep_segments(original_duration, silent_segments)

        if not keep_segments:
            print(f"\\n‚ö†Ô∏è  No valid segments found, copying original...")
            video.write_videofile(output_path, codec='libx264', audio_codec='aac')
            video.close()
            return output_path

        # Extract and concatenate clips
        print(f"\\n‚Üí Extracting clips and applying jump cuts...")
        clips = []

        for i, (start, end) in enumerate(keep_segments):
            try:
                clip = video.subclip(start, end)
                clips.append(clip)
                print(f"  Clip {i+1}/{len(keep_segments)}: {start:.2f}s - {end:.2f}s ({end-start:.2f}s)")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Warning: Could not extract clip {i+1}: {e}")

        if not clips:
            print(f"\\n‚úó Error: No clips could be extracted")
            video.close()
            return None

        # Concatenate all clips
        print(f"\\n‚Üí Concatenating {len(clips)} clips...")
        final_video = concatenate_videoclips(clips, method="compose")
        final_duration = final_video.duration

        # Calculate statistics
        time_removed = original_duration - final_duration
        reduction_pct = (time_removed / original_duration) * 100
        num_cuts = len(clips) - 1

        print(f"\\nüìä EDITING STATISTICS")
        print(f"{'-'*70}")
        print(f"  Original duration:  {original_duration:.2f}s ({original_duration/60:.2f} min)")
        print(f"  Final duration:     {final_duration:.2f}s ({final_duration/60:.2f} min)")
        print(f"  Time removed:       {time_removed:.2f}s ({time_removed/60:.2f} min)")
        print(f"  Reduction:          {reduction_pct:.1f}%")
        print(f"  Jump cuts applied:  {num_cuts}")

        # Write output
        print(f"\\n‚Üí Rendering final video...")
        final_video.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            fps=video.fps,
            preset='medium',
            threads=4
        )

        # Cleanup
        final_video.close()
        video.close()

        print(f"\\n‚úÖ SUCCESS!")
        print(f"  Edited video saved: {output_path}")
        print(f"{'='*70}\\n")

        return output_path

    def add_intro_outro(self, video_path, output_path, intro_path=None, outro_path=None):
        """
        Add branded intro and outro to video.

        Args:
            video_path: Input video file
            output_path: Output video file
            intro_path: Path to intro video (optional)
            outro_path: Path to outro video (optional)

        Returns:
            Path to final video
        """
        print(f"\\n‚Üí Adding intro/outro...")

        clips = []

        # Add intro
        if intro_path and os.path.exists(intro_path):
            intro = VideoFileClip(intro_path)
            clips.append(intro)
            print(f"  ‚úì Added intro ({intro.duration:.1f}s)")

        # Add main video
        main_video = VideoFileClip(video_path)
        clips.append(main_video)

        # Add outro
        if outro_path and os.path.exists(outro_path):
            outro = VideoFileClip(outro_path)
            clips.append(outro)
            print(f"  ‚úì Added outro ({outro.duration:.1f}s)")

        if len(clips) == 1:
            # No intro/outro, just copy
            print(f"  ‚ÑπÔ∏è  No intro/outro specified, using original video")
            main_video.write_videofile(output_path, codec='libx264', audio_codec='aac')
            main_video.close()
        else:
            # Concatenate with intro/outro
            final = concatenate_videoclips(clips, method="compose")
            final.write_videofile(output_path, codec='libx264', audio_codec='aac')

            # Cleanup
            for clip in clips:
                clip.close()

        print(f"  ‚úì Final video with intro/outro saved")
        return output_path

    def generate_thumbnail(self, video_path, output_path, time_position=0.5):
        """
        Generate thumbnail from video frame.

        Args:
            video_path: Input video file
            output_path: Output thumbnail image
            time_position: Position in video (0-1) to capture frame

        Returns:
            Path to thumbnail
        """
        print(f"\\n‚Üí Generating thumbnail...")

        video = VideoFileClip(video_path)
        frame_time = video.duration * time_position

        # Get frame at specified time
        frame = video.get_frame(frame_time)

        # Save as image
        from PIL import Image
        img = Image.fromarray(frame)

        # Resize to standard YouTube thumbnail size
        img = img.resize((1280, 720), Image.Resampling.LANCZOS)
        img.save(output_path, quality=95)

        video.close()

        print(f"  ‚úì Thumbnail saved: {output_path}")
        return output_path


def main():
    """CLI for video jump cut editor."""
    parser = argparse.ArgumentParser(
        description='Automatic Jump Cut Video Editor - Remove silence and add branding'
    )
    parser.add_argument('--input', required=True, help='Input video file')
    parser.add_argument('--output', help='Output video file (default: input_edited.mp4)')
    parser.add_argument('--silence-thresh', type=float, default=-40, help='Silence threshold in dB (default: -40)')
    parser.add_argument('--min-silence', type=float, default=0.3, help='Minimum silence duration in seconds')
    parser.add_argument('--min-clip', type=float, default=0.5, help='Minimum clip duration in seconds')
    parser.add_argument('--intro', help='Path to intro video')
    parser.add_argument('--outro', help='Path to outro video')
    parser.add_argument('--thumbnail', action='store_true', help='Generate thumbnail')
    parser.add_argument('--thumbnail-pos', type=float, default=0.3, help='Thumbnail position (0-1)')
    parser.add_argument('--no-cuts', action='store_true', help='Skip jump cuts, only add intro/outro')

    args = parser.parse_args()

    # Validate input file
    if not os.path.exists(args.input):
        print(f"‚úó Error: Input file not found: {args.input}")
        return 1

    # Set output path
    if not args.output:
        input_path = Path(args.input)
        args.output = str(input_path.parent / f"{input_path.stem}_edited{input_path.suffix}")

    # Create editor
    editor = VideoJumpCutter(
        silence_thresh=args.silence_thresh,
        min_silence_dur=args.min_silence,
        min_clip_dur=args.min_clip
    )

    try:
        # Apply jump cuts (unless skipped)
        if args.no_cuts:
            print(f"\\n‚ÑπÔ∏è  Skipping jump cuts (--no-cuts specified)")
            temp_output = args.input
        else:
            # Create temporary output for jump cuts
            temp_output = str(Path(args.output).parent / f"temp_{Path(args.output).name}")
            result = editor.apply_jump_cuts(args.input, temp_output)

            if not result:
                print(f"\\n‚úó Jump cut processing failed")
                return 1

        # Add intro/outro if specified
        if args.intro or args.outro:
            editor.add_intro_outro(temp_output, args.output, args.intro, args.outro)

            # Remove temp file if different from input
            if temp_output != args.input and os.path.exists(temp_output):
                os.remove(temp_output)
        else:
            # Rename temp to final output
            if temp_output != args.output:
                os.rename(temp_output, args.output)

        # Generate thumbnail if requested
        if args.thumbnail:
            thumb_path = str(Path(args.output).parent / f"{Path(args.output).stem}_thumbnail.jpg")
            editor.generate_thumbnail(args.output, thumb_path, args.thumbnail_pos)

        print(f"\\nüé¨ Video editing complete!")
        print(f"   Output: {args.output}")

        return 0

    except Exception as e:
        print(f"\\n‚úó Error during video processing: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())