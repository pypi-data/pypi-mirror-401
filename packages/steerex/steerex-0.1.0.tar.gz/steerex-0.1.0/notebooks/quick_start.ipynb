{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "309a01ab-058a-4a2c-b4d7-e853b8e69d88",
            "metadata": {},
            "source": [
                "# Quick Start: English to Spanish Steering Vector\n",
                "\n",
                "This notebook demonstrates how to use the `steering-vectors` library to optimize a steering vector that causes a language model to generate Spanish text instead of English.\n",
                "\n",
                "This is a direct adaptation of the original `llm-steering-opt/quickstart.ipynb` using the new modular API."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d7f09296-8cdc-4a23-bc8c-10da8a29fdbf",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "id": "a49a1764-9a8c-40d1-9d4b-6e95807f7a29",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
                "import torch\n",
                "from dotenv import load_dotenv\n",
                "import os\n",
                "\n",
                "# Import from the new steering-vectors library\n",
                "from steering_vectors import (\n",
                "    SteeringOptimizer,\n",
                "    VectorSteering,\n",
                "    ClampSteering,\n",
                "    HuggingFaceBackend,\n",
                "    TrainingDatapoint,\n",
                "    OptimizationConfig,\n",
                ")\n",
                "\n",
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "id": "8ac09c4a-433d-48d3-ab83-22f1117d5eb8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "91cf221dded64173ba8812c8ccbdaf14",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "hf_token = os.getenv(\"HF_TOKEN\")\n",
                "\n",
                "model_name = \"google/gemma-2-2b\"\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
                "model = AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.bfloat16, token=hf_token)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "id": "7377d62c-014a-4844-82ca-0641c807696c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cuda\n"
                    ]
                }
            ],
            "source": [
                "# Move to GPU if available\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "model = model.to(device)\n",
                "print(f\"Using device: {device}\")\n",
                "backend = HuggingFaceBackend(model, tokenizer, device)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6a67c6b4-8b12-4022-b7ef-0eefeb847dc4",
            "metadata": {},
            "source": [
                "## Task Definition: English to Spanish Switching\n",
                "\n",
                "We'll optimize a steering vector that causes the model to generate Spanish instead of English, given an English prompt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "id": "12733ccb-37e0-4f99-8cb3-5a08f17e8e2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Our training prompt - a recipe introduction\n",
                "prompt = \"\"\"Some of my fondest childhood memories are from my summer vacations back when I was little. Every now and then, after a long day of playing outside, I would come back home to be greeted with the delicious smell of my grandma's hazelnut cake wafting out of the kitchen. In this recipe, I'll teach you how to make that very cake, and create your own summer memories.\n",
                "\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "id": "d0ebac18-77f8-4307-8dcd-a272f928eeea",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unsteered completion:\n",
                        "<h2>Ingredients</h2>\n",
                        "\n",
                        "* 1 cup of butter\n",
                        "* 1 cup\n"
                    ]
                }
            ],
            "source": [
                "# Generate an unsteered completion to see what the model normally produces\n",
                "generated = backend.generate(\n",
                "    prompt,\n",
                "    max_new_tokens=15,\n",
                "    do_sample=False\n",
                ")\n",
                "print(\"Unsteered completion:\")\n",
                "print(generated_str.replace(prompt, \"\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "id": "af025225-ba0c-4e0a-9321-40ce4d6d6160",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define our completions: suppress English, promote Spanish\n",
                "en_completion = \"\"\"<h2>Ingredients</h2>\n",
                "\n",
                "* 1 cup of all-purpose flour\"\"\"\n",
                "\n",
                "es_completion = \"\"\"<h2>Ingredientes</h2>\n",
                "\n",
                "* 1 taza de harina común\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1b007485-31ef-4603-a105-601d011a0a90",
            "metadata": {},
            "source": [
                "## Optimizing the Steering Vector\n",
                "\n",
                "Now we use the `steering-vectors` library's API:\n",
                "1. Create a `HuggingFaceBackend` to handle model operations\n",
                "2. Create a `VectorSteering` mode for additive steering\n",
                "3. Configure with `OptimizationConfig`\n",
                "4. Run optimization with `SteeringOptimizer`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "id": "5ae5c2d2-2610-4aec-837a-8cd596259205",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create our training datapoint\n",
                "datapoint = TrainingDatapoint(\n",
                "    prompt=prompt,\n",
                "    src_completions=[en_completion],  # Suppress English\n",
                "    dst_completions=[es_completion],  # Promote Spanish\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "id": "e65babff-c7df-49c9-8915-116e85735c85",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set up the components\n",
                "backend = HuggingFaceBackend(model, tokenizer)\n",
                "steering = VectorSteering()\n",
                "\n",
                "# Configure optimization (matching original: lr=0.1, max_iters=20)\n",
                "config = OptimizationConfig(\n",
                "    lr=0.1,\n",
                "    max_iters=20,\n",
                ")\n",
                "\n",
                "# Create optimizer\n",
                "optimizer = SteeringOptimizer(backend, steering, config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "id": "run-optimization",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimization complete!\n",
                        "  Iterations: 20\n",
                        "  Final loss: 4.0312\n",
                        "  Vector norm: 46.75\n"
                    ]
                }
            ],
            "source": [
                "# Run optimization at layer 10\n",
                "layer = 10\n",
                "result = optimizer.optimize([datapoint], layer=layer)\n",
                "\n",
                "print(f\"Optimization complete!\")\n",
                "print(f\"  Iterations: {result.iterations}\")\n",
                "print(f\"  Final loss: {result.final_loss:.4f}\")\n",
                "print(f\"  Vector norm: {steering.get_vector().norm().item():.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "58e2c8f0-b232-47c0-93dd-21e1ed574ab1",
            "metadata": {},
            "source": [
                "## Testing the Steering Vector\n",
                "\n",
                "Let's see if our optimized vector causes the model to generate Spanish!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "id": "aaf39b6e-1f93-4d78-afe9-4c539bf2ebd3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Steered completion:\n",
                        "Some of my fondest childhood memories are from my summer vacations back when I was little. Every now and then, after a long day of playing outside, I would come back home to be greeted with the delicious smell of my grandma's hazelnut cake wafting out of the kitchen. In this recipe, I'll teach you how to make that very cake, and create your own summer memories.\n",
                        "\n",
                        "<h2>Ingredientes</h2>\n",
                        "\n",
                        "* 1 taza de harina común\n",
                        "* 1 taza de azúcar\n",
                        "* 1 taza de leche\n",
                        "* 1 cucharadita\n"
                    ]
                }
            ],
            "source": [
                "# Create the steering hook\n",
                "hook = steering.create_hook()\n",
                "\n",
                "# Generate with steering\n",
                "steered_str = backend.generate_with_steering(\n",
                "    prompt,\n",
                "    steering_mode=steering,\n",
                "    layers=layer,\n",
                "    max_new_tokens=30,\n",
                "    do_sample=False\n",
                ")\n",
                "\n",
                "print(\"Steered completion:\")\n",
                "print(steered_str)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "03c02aad-696c-4074-9a7b-2b8455931854",
            "metadata": {},
            "source": [
                "### Generalization Test\n",
                "\n",
                "Does the vector generalize to other prompts?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "id": "7b444dac-4284-427a-acc7-298f18540cc9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Unsteered generation ---\n",
                        "My favorite programming language is Python. I love the simplicity of the language and the fact that it is easy to learn. I also love the fact that it is a general-purpose language,\n",
                        "\n",
                        "--- Steered generation ---\n",
                        "My favorite programming lenguaje es el C, pero me gustaría aprender el C++ y el Java.\n",
                        "\n",
                        "I like the C, pero me gustaría aprender el C++ y el Java.\n",
                        "\n",
                        "I\n"
                    ]
                }
            ],
            "source": [
                "test_prompt = \"My favorite programming\"\n",
                "max_new_tokens = 35\n",
                "\n",
                "print(\"--- Unsteered generation ---\")\n",
                "unsteered_text = backend.generate(\n",
                "    test_prompt,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=False\n",
                ")\n",
                "print(unsteered_text)\n",
                "print()\n",
                "\n",
                "print(\"--- Steered generation ---\")\n",
                "steered_text = backend.generate_with_steering(\n",
                "    test_prompt,\n",
                "    steering_mode=steering,\n",
                "    layers=layer,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=False\n",
                ")\n",
                "print(steered_text)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "reverse-steering",
            "metadata": {},
            "source": [
                "### Reverse Steering\n",
                "\n",
                "If we negate the vector, we can switch from Spanish to English!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "id": "379dc665-8d59-43a3-9eca-9304af940ffd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Unsteered generation (Spanish prompt) ---\n",
                        "Unos de mis lenguajes de programación favoritos incluyen Python, Java, C++, C#, y JavaScript.\n",
                        "\n",
                        "Python es un lenguaje de programación muy popular que se utiliza para crear aplicaciones web, juegos,\n",
                        "\n",
                        "--- Reverse-steered generation (should switch to English) ---\n",
                        "Unos de mis lenguajes de programación favoritos incluyen Python, C#, and C++.\n",
                        "\n",
                        "I’ve been using Python for a long time, and I’ve been using C# for a long\n"
                    ]
                }
            ],
            "source": [
                "spanish_prompt = \"Unos de mis lenguajes de programación favoritos incluyen\"\n",
                "max_new_tokens = 30\n",
                "\n",
                "print(\"--- Unsteered generation (Spanish prompt) ---\")\n",
                "spanish_unsteered = backend.generate(spanish_prompt, max_new_tokens=max_new_tokens, do_sample=False)\n",
                "print(spanish_unsteered)\n",
                "print()\n",
                "\n",
                "print(\"--- Reverse-steered generation (should switch to English) ---\")\n",
                "\n",
                "# Use strength=-1 to negate the vector\n",
                "reverse_steered = backend.generate_with_steering(\n",
                "    spanish_prompt,\n",
                "    steering_mode=steering,\n",
                "    layers=layer,\n",
                "    strength=-1.0,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=False\n",
                ")\n",
                "print(reverse_steered)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "id": "2142a9a4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Unsteered generation ---\n",
                        "\"How dare you cheat on me with him!\" Jim roared.\n",
                        "\n",
                        "\"I'm sorry, Jim. I didn't mean to. I just wanted to be with him.\"\n",
                        "\n",
                        "\"You're a\n",
                        "\n",
                        "--- Steered generation (steering caused incoherent text)---\n",
                        "\"How dare you cheat on me with him!\" Jim roared.\n",
                        "\n",
                        "\"No, no, no, no, no, no, no, no, no, no, no, no, no, no,\n"
                    ]
                }
            ],
            "source": [
                "test_prompt_2 = '\"How dare you cheat on me with him!\" Jim roared.'\n",
                "\n",
                "print(\"--- Unsteered generation ---\")\n",
                "generated = backend.generate(\n",
                "    test_prompt_2,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=False\n",
                ")\n",
                "print(generated)\n",
                "print()\n",
                "\n",
                "print(\"--- Steered generation (steering caused incoherent text)---\")\n",
                "generated = backend.generate_with_steering(\n",
                "    test_prompt_2,\n",
                "    steering_mode=steering,\n",
                "    layers=layer,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=False\n",
                ")\n",
                "\n",
                "print(generated)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "norm-constrained",
            "metadata": {},
            "source": [
                "## Norm-Constrained Steering\n",
                "\n",
                "We can limit the vector's norm to prevent overly strong steering effects."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "id": "24f65cd0-3093-4041-9c7d-f9ba918b0ed2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Norm-constrained optimization:\n",
                        "  Final loss: 7.0625\n",
                        "  Vector norm: 20.00\n"
                    ]
                }
            ],
            "source": [
                "# Create a new steering mode and optimizer with norm constraint\n",
                "steering_constrained = VectorSteering()\n",
                "config_constrained = OptimizationConfig(\n",
                "    lr=0.1,\n",
                "    max_iters=20,\n",
                "    max_norm=20.0,  # Limit vector norm to 20\n",
                ")\n",
                "\n",
                "optimizer_constrained = SteeringOptimizer(backend, steering_constrained, config_constrained)\n",
                "result_constrained = optimizer_constrained.optimize([datapoint], layer=layer)\n",
                "\n",
                "print(f\"Norm-constrained optimization:\")\n",
                "print(f\"  Final loss: {result_constrained.final_loss:.4f}\")\n",
                "print(f\"  Vector norm: {steering_constrained.get_vector().norm().item():.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "id": "test-constrained",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Steered with norm-constrained vector ---\n",
                        "My favorite programming languages are:\n",
                        "\n",
                        "* <strong>Python</strong>: es un lenguaje de programación de alto nivel, orientado a objetos, multiplataforma, libre y de código\n"
                    ]
                }
            ],
            "source": [
                "# Test the norm-constrained vector\n",
                "test_prompt = \"My favorite programming languages are\"\n",
                "hook_constrained = steering_constrained.create_hook()\n",
                "\n",
                "print(\"--- Steered with norm-constrained vector ---\")\n",
                "\n",
                "generated = backend.generate(\n",
                "    test_prompt,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    hooks=[(layer, hook_constrained)],\n",
                "    do_sample=False,\n",
                ")\n",
                "\n",
                "print(generated)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "id": "eb70eab6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Unsteered generation ---\n",
                        "\"How dare you cheat on me with him!\" Jim roared.\n",
                        "\n",
                        "\"I'm sorry, Jim. I didn't mean to. I just wanted to be with him.\"\n",
                        "\n",
                        "\"You're a\n",
                        "\n",
                        "--- Steered generation (still doesn't work) ---\n",
                        "\"How dare you cheat on me with him!\" Jim roared.\n",
                        "\n",
                        "\"Jim, I'm sorry, I didn't mean to, I just...\"\n",
                        "\n",
                        "\"You just what? You just cheated on me\n"
                    ]
                }
            ],
            "source": [
                "test_prompt_2 = '\"How dare you cheat on me with him!\" Jim roared.'\n",
                "\n",
                "print(\"--- Unsteered generation ---\")\n",
                "generated = backend.generate(\n",
                "    test_prompt_2,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=False\n",
                ")\n",
                "print(generated)\n",
                "print()\n",
                "\n",
                "print(\"--- Steered generation (still doesn't work) ---\")\n",
                "generated = backend.generate(\n",
                "    test_prompt_2,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    hooks=[(layer, hook_constrained)],\n",
                "    do_sample=False,\n",
                ")\n",
                "\n",
                "print(generated)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "80c6cb34",
            "metadata": {},
            "source": [
                "## Clamp Steering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "id": "63cdcdbf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimization complete!\n",
                        "  Iterations: 20\n",
                        "  Final loss: 1.8398\n",
                        "  Vector norm: 32.25\n"
                    ]
                }
            ],
            "source": [
                "clamp_steering = ClampSteering()\n",
                "\n",
                "clamp_optimizer = SteeringOptimizer(backend, clamp_steering, config)\n",
                "\n",
                "clamped_result = clamp_optimizer.optimize([datapoint], layer=layer)\n",
                "\n",
                "print(f\"Optimization complete!\")\n",
                "print(f\"  Iterations: {clamped_result.iterations}\")\n",
                "print(f\"  Final loss: {clamped_result.final_loss:.4f}\")\n",
                "print(f\"  Vector norm: {clamp_steering.get_vector().norm().item():.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "id": "3ce5a8ea",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Steered generation ---\n",
                        "My favorite programming languages are:\n",
                        "\n",
                        "* <em>Java</em> - Java tiene una buena comunidad de desarrolladores, tiene buenas herramientas como Eclipse, etc. Es uno de los mejores\n",
                        "\n",
                        "--- Steered generation ---\n",
                        "\"How dare you cheat on me with him!\" Jim roared.\n",
                        "\n",
                        "\"Qué, tú crees que voy a quedar aquí... Me voy!\"\n",
                        "\n",
                        "\"Tú le metiste en esto, tú tenías que cuidarlo\n"
                    ]
                }
            ],
            "source": [
                "print(\"--- Steered generation ---\")\n",
                "\n",
                "generated = backend.generate_with_steering(\n",
                "    test_prompt,\n",
                "    steering_mode=clamp_steering,\n",
                "    layers=layer,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=True,\n",
                ")\n",
                "\n",
                "print(generated)\n",
                "print()\n",
                "\n",
                "print(\"--- Steered generation ---\")\n",
                "generated = backend.generate_with_steering(\n",
                "    test_prompt_2,\n",
                "    steering_mode=clamp_steering,\n",
                "    layers=layer,\n",
                "    max_new_tokens=max_new_tokens,\n",
                "    do_sample=True, # with do_sample=False steering didn't work\n",
                ")\n",
                "\n",
                "print(generated)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
