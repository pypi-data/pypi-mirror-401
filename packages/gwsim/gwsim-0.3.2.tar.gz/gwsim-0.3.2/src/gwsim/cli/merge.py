# ruff: noqa PLC0415

"""CLI to merge the frame files generated by gwsim simulations."""

from __future__ import annotations

from pathlib import Path
from typing import Annotated

import typer


def merge_command(  # pylint: disable=too-many-locals,too-many-branches,too-many-statements
    file_names: Annotated[list[Path], typer.Argument(..., help="List of frame files to merge")],
    channel: Annotated[str, typer.Option("--channel", help="Channel name to merge")] = "STRAIN",
    output: Annotated[str, typer.Option("--output", help="Output merged frame file name")] = "merged.gwf",
    output_channel: (
        Annotated[str, typer.Option("--output-channel", help="Channel name for the output file")] | None
    ) = None,
    metadata: Annotated[list[str], typer.Option("--metadata", help="Metadata file to use for merging")] | None = None,
    author: Annotated[str, typer.Option("--author", help="Author of the merged file")] | None = None,
    email: Annotated[str, typer.Option("--email", help="Email of the author")] | None = None,
    force: Annotated[bool, typer.Option("--force", help="Bypass the requirements of providing metadata files")] = False,
):
    """Merge multiple frame files into a single file.

    Args:
        file_names (list[str]): List of frame files to merge.
        channel (str): Channel name to merge.
        output (str): Output merged frame file name.
        output_channel (str | None): Channel name for the output file. If None, use
        metadata (list[str] | None): List of metadata files corresponding to the frame files.
        author (str | None): Author of the merged file.
        email (str | None): Email of the author.
        force (bool): If True, bypass the requirement of providing metadata files.

    Raises:
        ValueError: If metadata files are not provided and force is False.
    """
    import datetime
    import getpass
    from typing import cast

    import yaml
    from gwpy.timeseries import TimeSeries

    from gwsim.cli.utils.hash import compute_file_hash
    from gwsim.utils.log import get_dependency_versions

    if file_names is None:
        file_names = []
    if not isinstance(metadata, list) and not force:
        raise ValueError("Metadata files must be provided unless --force is used.")

    if isinstance(metadata, list) and not force:
        typer.echo("Validating files...")

        if len(file_names) != len(metadata or []):
            raise ValueError("The number of metadata files must match the number of frame files.")

        # Validate the files against the metadata
        for i, file_name in enumerate(file_names):
            metadata_file = Path(metadata[i])

            # Find the corresponding metadata entry for the file_name
            with metadata_file.open("r", encoding="utf-8") as f:
                file_metadata = yaml.safe_load(f)

            file_hashes: dict = file_metadata.get("file_hashes", {})
            expected_hash = file_hashes.get(file_name.name)

            if expected_hash is None:
                raise ValueError(f"No hash found in metadata for file {file_name.name}")

            actual_hash = compute_file_hash(file_name)

            if actual_hash != expected_hash:
                raise ValueError(
                    f"Hash mismatch for file {file_name.name}: expected {expected_hash}, got {actual_hash}"
                )

    # Placeholder for actual merging logic
    typer.echo(f"Merging files: {file_names}")

    # Read the first file
    frame_data = cast(TimeSeries, TimeSeries.read(file_names[0], channel))

    # Get the start time, duration and sampling frequency
    start_time = frame_data.epoch
    duration = frame_data.duration
    sampling_frequency = frame_data.sample_rate

    for i in range(1, len(file_names)):
        next_frame_data = cast(TimeSeries, TimeSeries.read(file_names[i], channel))

        if next_frame_data.epoch != start_time:
            raise ValueError(f"Start time mismatch: {next_frame_data.epoch} != {start_time}")
        if next_frame_data.duration != duration:
            raise ValueError(f"Duration mismatch: {next_frame_data.duration} != {duration}")
        if next_frame_data.sample_rate != sampling_frequency:
            raise ValueError(f"Sampling frequency mismatch: {next_frame_data.sample_rate} != {sampling_frequency}")

        frame_data = frame_data.inject(next_frame_data)

    # Write the merged data to a new file
    # Atomic write to avoid partial writes
    # The write function is suffix sensitive, so we prepend a .tmp to the original suffix
    temp_output = Path(output).with_suffix(".tmp" + Path(output).suffix)
    if output_channel is not None:
        frame_data.channel = output_channel
    frame_data.write(temp_output)
    temp_output.rename(output)

    if metadata:
        # If metadata is provided, create a new metadata file for the merged file

        typer.echo("Creating merged metadata file...")

        merged_metadata = {"type": "merged", "source_files": {}}

        for i, file_name in enumerate(file_names):
            metadata_file = Path(metadata[i])

            with metadata_file.open("r", encoding="utf-8") as f:
                file_metadata = yaml.safe_load(f)

            merged_metadata["source_files"][file_name] = file_metadata

        if author is None:
            author = getpass.getuser()

        timestamp = datetime.datetime.now(datetime.timezone.utc)

        merged_metadata["output_files"] = [output]
        merged_metadata["file_hashes"] = {output: compute_file_hash(output)}
        merged_metadata["author"] = author
        merged_metadata["email"] = email
        merged_metadata["timestamp"] = timestamp.isoformat()
        merged_metadata["versions"] = get_dependency_versions()

        # Atomic write of metadata file
        merged_metadata_file = Path(output).with_suffix(".metadata.yaml")
        temp_metadata_file = merged_metadata_file.with_suffix(".tmp")
        with temp_metadata_file.open("w", encoding="utf-8") as f:
            yaml.safe_dump(merged_metadata, f)
        temp_metadata_file.rename(merged_metadata_file)

        typer.echo(f"Merged metadata file created at {merged_metadata_file}")

    else:
        typer.echo("No metadata provided for the source files.")
        typer.echo("No metadata file will be created for the merged file.")
