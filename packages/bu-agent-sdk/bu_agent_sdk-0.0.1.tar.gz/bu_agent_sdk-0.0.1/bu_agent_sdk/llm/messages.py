"""
This implementation is based on the OpenAI types, while removing all the parts that are not needed for Browser Use.
"""

# region - Content parts
from typing import Literal, Union

from pydantic import BaseModel


def _truncate(text: str, max_length: int = 50) -> str:
	"""Truncate text to max_length characters, adding ellipsis if truncated."""
	if len(text) <= max_length:
		return text
	return text[: max_length - 3] + '...'


def _format_image_url(url: str, max_length: int = 50) -> str:
	"""Format image URL for display, truncating if necessary."""
	if url.startswith('data:'):
		# Base64 image
		media_type = url.split(';')[0].split(':')[1] if ';' in url else 'image'
		return f'<base64 {media_type}>'
	else:
		# Regular URL
		return _truncate(url, max_length)


class ContentPartTextParam(BaseModel):
	text: str
	type: Literal['text'] = 'text'

	def __str__(self) -> str:
		return f'Text: {_truncate(self.text)}'

	def __repr__(self) -> str:
		return f'ContentPartTextParam(text={_truncate(self.text)})'


class ContentPartRefusalParam(BaseModel):
	refusal: str
	type: Literal['refusal'] = 'refusal'

	def __str__(self) -> str:
		return f'Refusal: {_truncate(self.refusal)}'

	def __repr__(self) -> str:
		return f'ContentPartRefusalParam(refusal={_truncate(repr(self.refusal), 50)})'


class ContentPartThinkingParam(BaseModel):
	"""Thinking content block for extended thinking / reasoning models.

	Used by:
	- Anthropic Claude models with extended thinking enabled
	- Can be included in AssistantMessage content for conversation history
	"""

	thinking: str
	"""The thinking/reasoning content."""

	signature: str | None = None
	"""Anthropic signature for the thinking block (required when sending back)."""

	type: Literal['thinking'] = 'thinking'

	def __str__(self) -> str:
		return f'Thinking: {_truncate(self.thinking)}'

	def __repr__(self) -> str:
		return f'ContentPartThinkingParam(thinking={_truncate(repr(self.thinking), 50)})'


class ContentPartRedactedThinkingParam(BaseModel):
	"""Redacted thinking content block.

	Used when thinking content has been redacted by the model (Anthropic).
	Must be preserved in conversation history.
	"""

	data: str
	"""The encrypted/redacted thinking data."""

	type: Literal['redacted_thinking'] = 'redacted_thinking'

	def __str__(self) -> str:
		return f'RedactedThinking: <{len(self.data)} bytes>'

	def __repr__(self) -> str:
		return f'ContentPartRedactedThinkingParam(data=<{len(self.data)} bytes>)'


SupportedImageMediaType = Literal['image/jpeg', 'image/png', 'image/gif', 'image/webp']
SupportedDocumentMediaType = Literal['application/pdf']


class DocumentSource(BaseModel):
	"""Source for a document attachment (base64 encoded)."""

	data: str
	"""Base64 encoded document data."""
	media_type: SupportedDocumentMediaType = 'application/pdf'
	"""MIME type of the document."""

	def __str__(self) -> str:
		return f'Document[{self.media_type}]: <base64 {len(self.data)} chars>'

	def __repr__(self) -> str:
		return f'DocumentSource(media_type={repr(self.media_type)}, data=<{len(self.data)} chars>)'


class ContentPartDocumentParam(BaseModel):
	"""Document content block for PDFs."""

	source: DocumentSource
	"""The document source (base64 encoded)."""
	type: Literal['document'] = 'document'

	def __str__(self) -> str:
		return str(self.source)

	def __repr__(self) -> str:
		return f'ContentPartDocumentParam(source={repr(self.source)})'


class ImageURL(BaseModel):
	url: str
	"""Either a URL of the image or the base64 encoded image data."""
	detail: Literal['auto', 'low', 'high'] = 'auto'
	"""Specifies the detail level of the image.

    Learn more in the
    [Vision guide](https://platform.openai.com/docs/guides/vision#low-or-high-fidelity-image-understanding).
    """
	# needed for Anthropic
	media_type: SupportedImageMediaType = 'image/png'

	def __str__(self) -> str:
		url_display = _format_image_url(self.url)
		return f'ðŸ–¼ï¸  Image[{self.media_type}, detail={self.detail}]: {url_display}'

	def __repr__(self) -> str:
		url_repr = _format_image_url(self.url, 30)
		return f'ImageURL(url={repr(url_repr)}, detail={repr(self.detail)}, media_type={repr(self.media_type)})'


class ContentPartImageParam(BaseModel):
	image_url: ImageURL
	type: Literal['image_url'] = 'image_url'

	def __str__(self) -> str:
		return str(self.image_url)

	def __repr__(self) -> str:
		return f'ContentPartImageParam(image_url={repr(self.image_url)})'


class Function(BaseModel):
	arguments: str
	"""
    The arguments to call the function with, as generated by the model in JSON
    format. Note that the model does not always generate valid JSON, and may
    hallucinate parameters not defined by your function schema. Validate the
    arguments in your code before calling your function.
    """
	name: str
	"""The name of the function to call."""

	def __str__(self) -> str:
		args_preview = _truncate(self.arguments, 80)
		return f'{self.name}({args_preview})'

	def __repr__(self) -> str:
		args_repr = _truncate(repr(self.arguments), 50)
		return f'Function(name={repr(self.name)}, arguments={args_repr})'


class ToolCall(BaseModel):
	id: str
	"""The ID of the tool call."""
	function: Function
	"""The function that the model called."""
	type: Literal['function'] = 'function'
	"""The type of the tool. Currently, only `function` is supported."""
	thought_signature: bytes | None = None
	"""Google Gemini thought signature for this function call.

	Required by Gemini to maintain conversation coherence when sending
	function calls back in the history. Other providers ignore this field.
	"""

	def __str__(self) -> str:
		return f'ToolCall[{self.id}]: {self.function}'

	def __repr__(self) -> str:
		return f'ToolCall(id={repr(self.id)}, function={repr(self.function)})'


# endregion


# region - Message types
class _MessageBase(BaseModel):
	"""Base class for all message types"""

	role: Literal['user', 'system', 'assistant', 'tool', 'developer']

	cache: bool = False
	"""Whether to cache this message. This is only applicable when using Anthropic models.
	"""


class UserMessage(_MessageBase):
	role: Literal['user'] = 'user'
	"""The role of the messages author, in this case `user`."""

	content: str | list[ContentPartTextParam | ContentPartImageParam | ContentPartDocumentParam]
	"""The contents of the user message."""

	name: str | None = None
	"""An optional name for the participant.

    Provides the model information to differentiate between participants of the same
    role.
    """

	@property
	def text(self) -> str:
		"""
		Automatically parse the text inside content, whether it's a string or a list of content parts.
		"""
		if isinstance(self.content, str):
			return self.content
		elif isinstance(self.content, list):
			return '\n'.join([part.text for part in self.content if part.type == 'text'])
		else:
			return ''

	def __str__(self) -> str:
		return f'UserMessage(content={self.text})'

	def __repr__(self) -> str:
		return f'UserMessage(content={repr(self.text)})'


class SystemMessage(_MessageBase):
	role: Literal['system'] = 'system'
	"""The role of the messages author, in this case `system`."""

	content: str | list[ContentPartTextParam]
	"""The contents of the system message."""

	name: str | None = None

	@property
	def text(self) -> str:
		"""
		Automatically parse the text inside content, whether it's a string or a list of content parts.
		"""
		if isinstance(self.content, str):
			return self.content
		elif isinstance(self.content, list):
			return '\n'.join([part.text for part in self.content if part.type == 'text'])
		else:
			return ''

	def __str__(self) -> str:
		return f'SystemMessage(content={self.text})'

	def __repr__(self) -> str:
		return f'SystemMessage(content={repr(self.text)})'


class AssistantMessage(_MessageBase):
	role: Literal['assistant'] = 'assistant'
	"""The role of the messages author, in this case `assistant`."""

	content: (
		str
		| list[ContentPartTextParam | ContentPartRefusalParam | ContentPartThinkingParam | ContentPartRedactedThinkingParam]
		| None
	)
	"""The contents of the assistant message.

	Can include:
	- Text content
	- Refusal content
	- Thinking content (for extended thinking models)
	- Redacted thinking content (must be preserved in history)
	"""

	name: str | None = None

	refusal: str | None = None
	"""The refusal message by the assistant."""

	tool_calls: list[ToolCall] | None = None
	"""The tool calls generated by the model, such as function calls."""

	@property
	def text(self) -> str:
		"""
		Automatically parse the text inside content, whether it's a string or a list of content parts.
		"""
		if isinstance(self.content, str):
			return self.content
		elif isinstance(self.content, list):
			text = ''
			for part in self.content:
				if part.type == 'text':
					text += part.text
				elif part.type == 'refusal':
					text += f'[Refusal] {part.refusal}'
				# Thinking parts are not included in text output
			return text
		else:
			return ''

	@property
	def thinking(self) -> str | None:
		"""Extract thinking content from the message, if any."""
		if isinstance(self.content, list):
			thinking_parts = []
			for part in self.content:
				if part.type == 'thinking':
					thinking_parts.append(part.thinking)
			return '\n'.join(thinking_parts) if thinking_parts else None
		return None

	def __str__(self) -> str:
		return f'AssistantMessage(content={self.text})'

	def __repr__(self) -> str:
		return f'AssistantMessage(content={repr(self.text)})'


class ToolMessage(_MessageBase):
	"""Message containing tool execution result.

	This is used to send tool results back to the model after it has made a tool call.
	- OpenAI: Serialized as a separate message with role='tool'
	- Anthropic: Serialized as ToolResultBlockParam in user message content
	- Google: Serialized as FunctionResponse in Part
	"""

	role: Literal['tool'] = 'tool'
	"""The role of the message, in this case `tool`."""

	tool_call_id: str
	"""The ID of the tool call this message is responding to.

	Must match the `id` field of the corresponding ToolCall from the assistant message.
	"""

	tool_name: str
	"""The name of the tool that was called.

	Required for Anthropic and Google serialization.
	"""

	content: str | list[ContentPartTextParam | ContentPartImageParam]
	"""The result of the tool execution.

	Can include text and images (e.g., screenshots from browser tools).
	"""

	is_error: bool = False
	"""Whether the tool execution resulted in an error.

	If True, content should contain the error message.
	Anthropic and Google support this natively.
	"""

	ephemeral: bool = False
	"""Whether this message should be destroyed after the LLM processes it.

	Ephemeral messages are shown to the LLM once, then their content is saved
	to disk and replaced with a short placeholder. Use for large outputs like
	screenshots or DOM state that would explode context if kept.
	"""

	destroyed: bool = False
	"""Whether this message's content has been destroyed to save context.

	When True, serializers will use a placeholder instead of the actual content.
	The original content remains intact in the message for debugging/logging.
	"""

	@property
	def text(self) -> str:
		"""Extract text content from the message."""
		if isinstance(self.content, str):
			return self.content
		elif isinstance(self.content, list):
			return '\n'.join([part.text for part in self.content if part.type == 'text'])
		else:
			return ''

	def __str__(self) -> str:
		error_prefix = '[ERROR] ' if self.is_error else ''
		return f'ToolMessage(tool={self.tool_name}, content={error_prefix}{_truncate(self.text)})'

	def __repr__(self) -> str:
		return f'ToolMessage(tool_call_id={repr(self.tool_call_id)}, tool_name={repr(self.tool_name)}, is_error={self.is_error})'


class DeveloperMessage(_MessageBase):
	"""Developer-provided instructions for reasoning models.

	With OpenAI o1 models and newer, `developer` messages replace the previous `system` messages.
	For other providers, this will be converted to a system message.
	"""

	role: Literal['developer'] = 'developer'
	"""The role of the message, in this case `developer`."""

	content: str | list[ContentPartTextParam]
	"""The contents of the developer message."""

	name: str | None = None
	"""An optional name for the participant."""

	@property
	def text(self) -> str:
		"""Extract text content from the message."""
		if isinstance(self.content, str):
			return self.content
		elif isinstance(self.content, list):
			return '\n'.join([part.text for part in self.content if part.type == 'text'])
		else:
			return ''

	def __str__(self) -> str:
		return f'DeveloperMessage(content={_truncate(self.text)})'

	def __repr__(self) -> str:
		return f'DeveloperMessage(content={repr(_truncate(self.text, 50))})'


BaseMessage = Union[UserMessage, SystemMessage, AssistantMessage, ToolMessage, DeveloperMessage]

# endregion
