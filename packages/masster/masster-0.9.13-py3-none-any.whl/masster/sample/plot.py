"""
_plots.py

This module provides visualization functions for mass spectrometry data analysis.
It contains plotting utilities for extracted ion chromatograms (EICs), 2D data maps,
feature visualizations, and interactive dashboards using modern visualization libraries.

Key Features:
- **Extracted Ion Chromatograms (EICs)**: Interactive chromatographic plotting with feature annotations.
- **2D Data Visualization**: Mass spectrometry data visualization with datashader for large datasets.
- **Feature Plotting**: Visualize detected features with retention time and m/z information.
- **Interactive Dashboards**: Create interactive panels for data exploration and analysis.
- **Multi-Sample Plotting**: Comparative visualizations across multiple samples.
- **Export Capabilities**: Save plots in various formats (HTML, PNG, SVG).

Dependencies:
- `holoviews`: For high-level data visualization and interactive plots.
- `datashader`: For rendering large datasets efficiently.
- `panel`: For creating interactive web applications and dashboards.
- `bokeh`: For low-level plotting control and customization.
- `polars` and `pandas`: For data manipulation and processing.
- `numpy`: For numerical computations.

Functions:
- `plot_chrom()`: Generate chromatograms with feature overlays.
- `plot_2d()`: Create 2D mass spectrometry data visualizations.
- `plot_features()`: Visualize detected features in retention time vs m/z space.
- Various utility functions for plot styling and configuration.

Supported Plot Types:
- Chromatograms
- Total Ion Chromatograms (TIC)
- Base Peak Chromatograms (BPC)
- 2D intensity maps (RT vs m/z)
- Feature scatter plots
- Interactive dashboards

See Also:
- `parameters._plot_parameters`: For plot-specific parameter configuration.
- `single.py`: For applying plotting methods to ddafile objects.
- `study.py`: For study-level visualization functions.

"""

import os
import warnings

import numpy as np
import pandas as pd
import polars as pl

# Lazy imports for heavy visualization libraries
# These are imported on-demand inside plotting functions
_bokeh_imported = False
_holoviews_imported = False
_datashader_imported = False
_panel_imported = False
_cmap_imported = False

# Caches for lazy-loaded modules
_bokeh_models = None
_cmap_colormap = None
_datashader = None
_holoviews = None
_holoviews_dim = None
_holoviews_datashader_ops = None
_holoviews_process_cmap = None
_panel_module = None


def _import_plotting_libs():
    """Lazy import visualization libraries on first use."""
    global \
        _bokeh_imported, \
        _holoviews_imported, \
        _datashader_imported, \
        _panel_imported, \
        _cmap_imported
    global \
        _bokeh_models, \
        _cmap_colormap, \
        _datashader, \
        _holoviews, \
        _holoviews_dim, \
        _holoviews_datashader_ops
    global _holoviews_process_cmap, _panel_module

    if _bokeh_imported and _holoviews_imported and _datashader_imported:
        return

    if not _bokeh_imported:
        from bokeh.models import HoverTool

        _bokeh_models = HoverTool
        _bokeh_imported = True

    if not _cmap_imported:
        from cmap import Colormap

        _cmap_colormap = Colormap
        _cmap_imported = True

    if not _datashader_imported:
        import datashader as ds

        _datashader = ds
        _datashader_imported = True

    if not _holoviews_imported:
        import holoviews as hv
        from holoviews import dim
        import holoviews.operation.datashader as hd
        from holoviews.plotting.util import process_cmap

        _holoviews = hv
        _holoviews_dim = dim
        _holoviews_datashader_ops = hd
        _holoviews_process_cmap = process_cmap
        _holoviews_imported = True

    if not _panel_imported:
        import panel

        _panel_module = panel
        _panel_imported = True


def HoverTool(*args, **kwargs):
    """Lazy-loaded HoverTool from bokeh."""
    _import_plotting_libs()
    return _bokeh_models(*args, **kwargs)


def Colormap(*args, **kwargs):
    """Lazy-loaded Colormap from cmap."""
    _import_plotting_libs()
    return _cmap_colormap(*args, **kwargs)


# Expose lazy-loaded modules as module-level attributes
class _LazyModuleProxy:
    """Proxy to lazy-load modules on attribute access."""

    def __init__(self, name):
        self.name = name

    def __getattr__(self, item):
        _import_plotting_libs()
        if self.name == "ds":
            return getattr(_datashader, item)
        if self.name == "hv":
            return getattr(_holoviews, item)
        if self.name == "dim":
            return _holoviews_dim
        if self.name == "hd":
            return getattr(_holoviews_datashader_ops, item)
        if self.name == "panel":
            return getattr(_panel_module, item)
        raise AttributeError(f"Cannot lazy-load {self.name}.{item}")


ds = _LazyModuleProxy("ds")
hv = _LazyModuleProxy("hv")
dim = _LazyModuleProxy("dim")
hd = _LazyModuleProxy("hd")
panel = _LazyModuleProxy("panel")
process_cmap = None  # Will be set in _import_plotting_libs


def _get_process_cmap():
    """Get the process_cmap function after lazy import."""
    _import_plotting_libs()
    return _holoviews_process_cmap


def _process_cmap(cmap, fallback="viridis", logger=None):
    """
    Process colormap using the cmap package, similar to study's implementation.

    Parameters:
        cmap: Colormap specification (string name, cmap.Colormap object, or None)
        fallback: Fallback colormap name if cmap processing fails
        logger: Logger for warnings (optional)

    Returns:
        list: List of hex color strings for the colormap
    """
    _import_plotting_libs()

    # Handle None case
    if cmap is None:
        cmap = "viridis"
    elif cmap == "grey":
        cmap = "greys"

    # If cmap package is not available, fall back to process_cmap
    if _cmap_colormap is None:
        if logger:
            logger.warning("cmap package not available, using holoviews process_cmap")
        return _get_process_cmap()(cmap, provider="bokeh")

    try:
        # Handle colormap using cmap.Colormap
        if isinstance(cmap, str):
            colormap = _cmap_colormap(cmap)
            # Generate 256 colors and convert to hex
            import matplotlib.colors as mcolors

            colors = colormap(np.linspace(0, 1, 256))
            palette = [mcolors.rgb2hex(color) for color in colors]
        else:
            colormap = cmap
            # Try to use to_bokeh() method first
            try:
                palette = colormap.to_bokeh()
                # Ensure we got a color palette, not another mapper
                if not isinstance(palette, (list, tuple)):
                    # Fall back to generating colors manually
                    import matplotlib.colors as mcolors

                    colors = colormap(np.linspace(0, 1, 256))
                    palette = [mcolors.rgb2hex(color) for color in colors]
            except AttributeError:
                # Fall back to generating colors manually
                import matplotlib.colors as mcolors

                colors = colormap(np.linspace(0, 1, 256))
                palette = [mcolors.rgb2hex(color) for color in colors]

        return palette

    except (AttributeError, ValueError, TypeError) as e:
        # Fallback to process_cmap if cmap interpretation fails
        if logger:
            logger.warning(
                f"Could not interpret colormap '{cmap}': {e}, falling back to {fallback}",
            )
        return process_cmap(fallback, provider="bokeh")


def _is_notebook_environment():
    """
    Detect if code is running in a notebook environment (Jupyter, JupyterLab, or Marimo).

    Returns:
        bool: True if running in a notebook, False otherwise
    """
    try:
        # Check for Jupyter/JupyterLab
        from IPython import get_ipython

        ipython = get_ipython()
        if ipython is not None:
            # Check if we're in a notebook context
            shell = ipython.__class__.__name__
            if shell in ["ZMQInteractiveShell", "Shell"]:  # Jupyter notebook/lab
                return True

        # Check for Marimo - multiple ways to detect it
        import sys

        # Check if marimo is in modules
        if "marimo" in sys.modules:
            return True

        # Check for marimo in the call stack or environment
        import inspect

        frame = inspect.currentframe()
        try:
            while frame:
                if frame.f_globals.get("__name__", "").startswith("marimo"):
                    return True
                frame = frame.f_back
        finally:
            del frame

    except Exception:
        pass

    return False


def _is_vscode_notebook():
    """
    Detect if code is running in a VS Code notebook.

    Returns:
        bool: True if running in VS Code notebook, False otherwise
    """
    try:
        from IPython import get_ipython

        ipython = get_ipython()
        if ipython is not None:
            # Check for VS Code specific environment variables or attributes
            import os

            # VS Code sets these environment variables
            if "VSCODE_PID" in os.environ or "VSCODE_IPC_HOOK" in os.environ:
                return True

            # Check IPython configuration for VS Code indicators
            if hasattr(ipython, "config"):
                config_str = str(ipython.config)
                if "vscode" in config_str.lower():
                    return True

            # Check for VS Code kernel in the kernel name
            try:
                try:
                    import ipykernel
                except ImportError:
                    # ipykernel not available, skip this check
                    pass
                else:
                    if hasattr(ipykernel, "kernelapp"):
                        kernel_app = ipykernel.kernelapp.IPKernelApp.instance()
                        if kernel_app and hasattr(kernel_app, "connection_file"):
                            connection_file = str(kernel_app.connection_file)
                            if "vscode" in connection_file.lower():
                                return True
            except Exception:
                pass

    except Exception:
        pass

    return False


def _display_plot(plot_object, layout=None):
    """
    Display a plot object in the appropriate way based on the environment.

    Args:
        plot_object: The plot object to display (holoviews overlay, etc.)
        layout: Optional panel layout object

    Returns:
        The plot object for inline display in notebooks, None for browser display
    """
    if _is_notebook_environment():
        # In notebook environments, return the plot object for inline display
        # For Jupyter notebooks, holoviews/panel objects display automatically when returned
        if layout is not None:
            # Return the layout object which will display inline in notebooks
            return layout
        # Return the plot object directly for holoviews automatic display
        return plot_object
    # Display in browser (original behavior)
    if layout is not None:
        layout.show()
    else:
        # Create a simple layout for browser display
        simple_layout = panel.Column(plot_object)
        simple_layout.show()
    return None


def _export_with_webdriver_manager(plot_obj, filename, format_type, logger=None):
    """
    Export plot to PNG or SVG using webdriver-manager for automatic driver management.

    Parameters:
        plot_obj: Bokeh plot object or holoviews object to export
        filename: Output filename
        format_type: Either "png" or "svg"
        logger: Logger for error reporting (optional)

    Returns:
        bool: True if export successful, False otherwise
    """
    try:
        # Convert holoviews to bokeh if needed
        if hasattr(plot_obj, "opts"):  # Likely a holoviews object
            import holoviews as hv

            bokeh_plot = hv.render(plot_obj)
        else:
            bokeh_plot = plot_obj

        # Try webdriver-manager export first
        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.options import Options
            from selenium.webdriver.chrome.service import Service
            from webdriver_manager.chrome import ChromeDriverManager

            # Set up Chrome options for headless operation
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")

            # Use webdriver-manager to automatically get the correct ChromeDriver
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)

            # Export with managed webdriver
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=UserWarning)
                # Filter out bokeh.io.export warnings specifically
                warnings.filterwarnings("ignore", module="bokeh.io.export")

                if format_type == "png":
                    from bokeh.io import export_png

                    export_png(bokeh_plot, filename=filename, webdriver=driver)
                elif format_type == "svg":
                    from bokeh.io import export_svg

                    export_svg(bokeh_plot, filename=filename, webdriver=driver)
                else:
                    raise ValueError(f"Unsupported format: {format_type}")

            driver.quit()
            return True

        except ImportError:
            if logger:
                logger.debug(
                    f"webdriver-manager not available, using default {format_type.upper()} export",
                )
            # Fall back to default export
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", category=UserWarning)
                # Filter out bokeh.io.export warnings specifically
                warnings.filterwarnings("ignore", module="bokeh.io.export")

                if format_type == "png":
                    from bokeh.io import export_png

                    export_png(bokeh_plot, filename=filename)
                elif format_type == "svg":
                    from bokeh.io import export_svg

                    export_svg(bokeh_plot, filename=filename)
            return True

        except Exception as e:
            if logger:
                logger.debug(
                    f"{format_type.upper()} export with webdriver-manager failed: {e}, using default {format_type.upper()} export",
                )
            try:
                # Final fallback to default export
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore", category=UserWarning)
                    # Filter out bokeh.io.export warnings specifically
                    warnings.filterwarnings("ignore", module="bokeh.io.export")

                    if format_type == "png":
                        from bokeh.io import export_png

                        export_png(bokeh_plot, filename=filename)
                    elif format_type == "svg":
                        from bokeh.io import export_svg

                        export_svg(bokeh_plot, filename=filename)
                return True
            except Exception as e2:
                if logger:
                    logger.error(f"{format_type.upper()} export failed: {e2}")
                return False

    except Exception as e:
        if logger:
            logger.error(f"Export preparation failed: {e}")
        return False


def _handle_sample_plot_output(self, plot_obj, filename=None, plot_type="bokeh"):
    """
    Helper function to handle consistent save/display behavior for sample plots.

    Parameters:
        plot_obj: The plot object (bokeh figure, holoviews layout, or panel object)
        filename: Optional filename to save the plot
        plot_type: Type of plot object ("bokeh", "panel", "holoviews")
    """
    if filename is not None:
        # Convert relative paths to absolute paths using sample folder as base
        import os

        if hasattr(self, "folder") and self.folder and not os.path.isabs(filename):
            filename = os.path.join(self.folder, filename)

        # Convert to absolute path for logging
        abs_filename = os.path.abspath(filename)

        if filename.endswith(".html"):
            if plot_type == "panel":
                plot_obj.save(filename, embed=True)
            elif plot_type == "holoviews":
                import panel

                panel.panel(plot_obj).save(filename, embed=True)
            elif plot_type == "bokeh":
                from bokeh.io import save
                from bokeh.plotting import output_file

                output_file(filename)
                save(plot_obj)
            self.logger.success(f"Plot saved to: {abs_filename}")
        elif filename.endswith(".png"):
            success = _export_with_webdriver_manager(
                plot_obj,
                filename,
                "png",
                self.logger,
            )
            if success:
                self.logger.success(f"Plot saved to: {abs_filename}")
            else:
                # Fall back to HTML if PNG export fails completely
                html_filename = filename.replace(".png", ".html")
                abs_html_filename = os.path.abspath(html_filename)
                if plot_type == "panel":
                    plot_obj.save(html_filename, embed=True)
                elif plot_type == "holoviews":
                    import panel

                    panel.panel(plot_obj).save(html_filename, embed=True)
                elif plot_type == "bokeh":
                    from bokeh.io import save
                    from bokeh.plotting import output_file

                    output_file(html_filename)
                    save(plot_obj)
                self.logger.warning(
                    f"PNG export not available, saved as HTML instead: {abs_html_filename}",
                )
        elif filename.endswith(".svg"):
            success = _export_with_webdriver_manager(
                plot_obj,
                filename,
                "svg",
                self.logger,
            )
            if success:
                self.logger.success(f"Plot saved to: {abs_filename}")
            else:
                # Fall back to HTML if SVG export fails completely
                html_filename = filename.replace(".svg", ".html")
                abs_html_filename = os.path.abspath(html_filename)
                if plot_type == "panel":
                    plot_obj.save(html_filename, embed=True)
                elif plot_type == "holoviews":
                    import panel

                    panel.panel(plot_obj).save(html_filename, embed=True)
                elif plot_type == "bokeh":
                    from bokeh.io import save
                    from bokeh.plotting import output_file

                    output_file(html_filename)
                    save(plot_obj)
                self.logger.warning(
                    f"SVG export not available, saved as HTML instead: {abs_html_filename}",
                )
        elif filename.endswith(".pdf"):
            # Try to save as PDF, fall back to HTML if not available
            try:
                if plot_type == "bokeh":
                    from bokeh.io.export import export_pdf

                    export_pdf(plot_obj, filename=filename)
                elif plot_type in ["panel", "holoviews"]:
                    import holoviews as hv

                    hv.save(plot_obj, filename, fmt="pdf")
                self.logger.success(f"Plot saved to: {abs_filename}")
            except ImportError:
                # Fall back to HTML if PDF export not available
                html_filename = filename.replace(".pdf", ".html")
                abs_html_filename = os.path.abspath(html_filename)
                if plot_type == "panel":
                    plot_obj.save(html_filename, embed=True)
                elif plot_type == "holoviews":
                    import panel

                    panel.panel(plot_obj).save(html_filename, embed=True)
                elif plot_type == "bokeh":
                    from bokeh.io import save
                    from bokeh.plotting import output_file

                    output_file(html_filename)
                    save(plot_obj)
                self.logger.warning(
                    f"PDF export not available, saved as HTML instead: {abs_html_filename}",
                )
        else:
            # Default to HTML for unknown extensions
            if plot_type == "panel":
                plot_obj.save(filename, embed=True)
            elif plot_type == "holoviews":
                import panel

                panel.panel(plot_obj).save(filename, embed=True)
            elif plot_type == "bokeh":
                from bokeh.io import save
                from bokeh.plotting import output_file

                output_file(filename)
                save(plot_obj)
            self.logger.success(f"Plot saved to: {abs_filename}")
    # Show in notebook when no filename provided
    else:
        if _is_notebook_environment():
            return plot_obj

        if plot_type == "panel":
            plot_obj.show()
        elif plot_type == "holoviews":
            import panel

            panel.panel(plot_obj).show()
        elif plot_type == "bokeh":
            from bokeh.plotting import show

            show(plot_obj)
        return None


def plot_chrom(
    self,
    feature_id=None,
    filename=None,
    rt_tol=10,
    rt_tol_factor_plot=1,
    mz_tol=0.0005,
    mz_tol_factor_plot=1,
    link_x=False,
):
    """
    Plot chromatograms for one or more features using MS1 data and feature metadata.

    This function filters MS1 data based on retention time (rt) and mass-to-charge ratio (mz) windows
    derived from feature information in `features_df`. It then generates interactive chromatogram plots using
    HoloViews, with feature retention time windows annotated. Plots can be displayed interactively or
    saved to a file.

    Parameters:
        feature_id (int or list of int, optional):
            Feature identifier(s) for chromatogram generation. If None, chromatograms for all features in `features_df` are plotted.
        filename (str, optional):
            Output file path. If ending with `.html`, saves as interactive HTML; otherwise, saves as PNG.
            If not provided, displays the plot interactively.
        rt_tol (float, default=10):
            Retention time tolerance (in seconds) added to feature boundaries for MS1 data filtering.
        rt_tol_factor_plot (float, default=1):
            Retention time tolerance factor.
        mz_tol (float, default=0.0005):
            m/z tolerance added to feature boundaries for MS1 data filtering.
        mz_tol_factor_plot (float, default=1):
            m/z time tolerance factor.
        link_x (bool, default=True):
            If True, links the x-axes (retention time) across all chromatogram subplots.

    Returns:
        None

    Notes:
        - Uses `features_df` for feature metadata and `ms1_df` (Polars DataFrame) for MS1 data.
        - Aggregates MS1 intensities by retention time.
        - Utilizes HoloViews for visualization and Panel for layout/display.
    """
    # Ensure bokeh backend is loaded for holoviews plotting
    if "bokeh" not in hv.Store.loaded_backends():
        hv.extension("bokeh")

    # plots the chromatogram for a given feature id
    # If rt or mz are not provided, they are extracted from features_df using the supplied feature id (feature_id)

    feature_ids = feature_id
    # if feature_ids is None, plot all features
    if feature_ids is None:
        feats = self.features_df.clone()
    else:
        if isinstance(feature_ids, int):
            feature_ids = [feature_ids]
        # select only the features with feature_id in feature_ids
        feats = self.features_df.filter(pl.col("feature_id").is_in(feature_ids)).clone()

    # make sure feature_id is a list of integers

    chrom_plots = []
    feature_ids = feats["feature_id"].to_list()
    mz_tol_plot = mz_tol * mz_tol_factor_plot
    rt_tol_plot = rt_tol * rt_tol_factor_plot
    # iterate over the list of feature_id
    for feature_id in feature_ids:
        # Retrieve the feature info
        feature_row = feats.filter(pl.col("feature_id") == feature_id)
        # rt = feature_row["rt"].values[0]
        rt_start = feature_row["rt_start"].to_list()[0]
        rt_end = feature_row["rt_end"].to_list()[0]
        mz = feature_row["mz"].to_list()[0]
        mz_start = feature_row["mz_start"].to_list()[0]
        mz_end = feature_row["mz_end"].to_list()[0]

        # filter self.ms1_df with rt_start, rt_end, mz_start, mz_end
        chrom_df = self.ms1_df.filter(
            pl.col("rt") >= rt_start - rt_tol_plot,
            pl.col("rt") <= rt_end + rt_tol_plot,
        )
        chrom_df = chrom_df.filter(
            pl.col("mz") >= mz_start - mz_tol_plot,
            pl.col("mz") <= mz_end + mz_tol_plot,
        )

        if chrom_df.is_empty():
            print("No MS1 data found in the specified window.")
            continue

        # convert to pandas DataFrame
        chrom_df = chrom_df.to_pandas()
        # aggregate all points with the same rt using the sum of inty
        chrom_df = chrom_df.groupby("rt").agg({"inty": "sum"}).reset_index()
        yname = f"inty_{feature_id}"
        chrom_df.rename(columns={"inty": yname}, inplace=True)

        # Plot the chromatogram using bokeh and ensure axes are independent by setting axiswise=True
        chrom = hv.Curve(chrom_df, kdims=["rt"], vdims=[yname]).opts(
            title=f"Chromatogram for feature {feature_id}, mz = {mz:.4f}",
            xlabel="Retention time (s)",
            ylabel="Intensity",
            width=1000,
            tools=["hover"],
            height=250,
            axiswise=True,
            color="black",
        )

        # Add vertical lines at the start and end of the retention time
        chrom = chrom * hv.VLine(rt_start).opts(
            color="blue",
            line_width=1,
            line_dash="dashed",
            axiswise=True,
        )
        chrom = chrom * hv.VLine(rt_end).opts(
            color="blue",
            line_width=1,
            line_dash="dashed",
            axiswise=True,
        )

        # Append the subplot without linking axes
        chrom_plots.append(chrom)

    if not chrom_plots:
        self.logger.warning(
            "No chromatograms to plot (no MS1 data in requested windows).",
        )
        return None
    if link_x:
        # Create a layout with shared x-axis for all chromatogram plots
        layout = hv.Layout(chrom_plots).opts(shared_axes=True)
    else:
        layout = hv.Layout(chrom_plots).opts(shared_axes=False)

    layout = layout.cols(1)
    layout_obj = panel.panel(layout)

    # Use consistent save/display behavior
    if filename is not None:
        self._handle_sample_plot_output(layout_obj, filename, "panel")
        return None
    return _display_plot(layout, layout_obj)


def _create_raster_plot(
    sample,
    mz_range=None,
    rt_range=None,
    raster_cmap="greys",
    raster_log=True,
    raster_min=1,
    raster_dynamic=True,
    raster_threshold=0.8,
    raster_max_px=8,
    width=750,
    height=600,
    filename=None,
):
    """Create the raster plot layer from MS1 data."""
    # Process colormap using the cmap package with proper error handling
    raster_cmap_processed = _process_cmap(
        raster_cmap if raster_cmap is not None else "greys",
        fallback="greys",
        logger=sample.logger,
    )

    # get columns rt, mz, inty from sample.ms1_df, It's polars DataFrame
    spectradf = sample.ms1_df.to_pandas()

    # remove any inty<raster_min
    spectradf = spectradf[spectradf["inty"] >= raster_min]
    # keep only rt, mz, and inty
    spectradf = spectradf[["rt", "mz", "inty"]]
    if mz_range is not None:
        spectradf = spectradf[
            (spectradf["mz"] >= mz_range[0]) & (spectradf["mz"] <= mz_range[1])
        ]
    if rt_range is not None:
        spectradf = spectradf[
            (spectradf["rt"] >= rt_range[0]) & (spectradf["rt"] <= rt_range[1])
        ]

    maxrt = spectradf["rt"].max()
    minrt = spectradf["rt"].min()
    maxmz = spectradf["mz"].max()
    minmz = spectradf["mz"].min()

    def new_bounds_hook(plot, elem):
        x_range = plot.state.x_range
        y_range = plot.state.y_range
        x_range.bounds = minrt, maxrt
        y_range.bounds = minmz, maxmz

    # Add log-transformed intensity for coloring if raster_log is True
    if raster_log:
        spectradf = spectradf.with_columns(pl.col("inty").log().alias("inty_log"))
        color_column = "inty_log"
    else:
        color_column = "inty"

    points = hv.Points(
        spectradf,
        kdims=["rt", "mz"],
        vdims=["inty", color_column] if raster_log else ["inty"],
        label="MS1 survey scans",
    ).opts(
        fontsize={"title": 16, "labels": 14, "xticks": 6, "yticks": 12},
        color=_holoviews_dim(color_column),
        colorbar=True,
        cmap="Magma",
        tools=["hover"],
    )

    if filename is not None:
        dyn = False
        if not filename.endswith(".html"):
            raster_dynamic = False

    dyn = raster_dynamic
    raster = hd.rasterize(
        points,
        aggregator=ds.max("inty"),
        interpolation="bilinear",
        dynamic=dyn,
    ).opts(
        active_tools=["box_zoom"],
        cmap=raster_cmap_processed,
        tools=["hover"],
        hooks=[new_bounds_hook],
        width=width,
        height=height,
        cnorm="log" if raster_log else "linear",
        xlabel="Retention time (s)",
        ylabel="m/z",
        colorbar=True,
        colorbar_position="right",
        axiswise=True,
    )
    raster = hd.dynspread(
        raster,
        threshold=raster_threshold,
        how="add",
        shape="square",
        max_px=raster_max_px,
    )

    return raster


def _load_and_merge_oracle_data(
    sample,
    oracle_folder,
    link_by_feature_id,
    min_id_level,
    max_id_level,
    min_ms_level,
):
    """Load oracle data and merge with features."""
    if sample.features_df is None:
        sample.logger.error("Cannot plot 2D oracle: features_df is not available")
        return None

    feats = sample.features_df.clone()
    sample.logger.debug(f"Features data shape: {len(feats)} rows")

    # Convert to pandas for oracle operations that require pandas functionality
    if hasattr(feats, "to_pandas"):
        feats = feats.to_pandas()

    # check if annotationfile is not None
    if oracle_folder is None:
        sample.logger.info("No oracle folder provided, plotting features only")
        return None

    # try to read the annotationfile as a csv file and add it to feats
    oracle_file_path = os.path.join(oracle_folder, "diag", "summary_by_feature.csv")
    sample.logger.debug(f"Loading oracle data from: {oracle_file_path}")
    try:
        oracle_data = pd.read_csv(oracle_file_path)
        sample.logger.info(
            f"Oracle data loaded successfully with {len(oracle_data)} rows",
        )
    except Exception as e:
        sample.logger.error(f"Could not read {oracle_file_path}: {e}")
        return None

    if link_by_feature_id:
        cols_to_keep = [
            "title",
            "scan_idx",
            "mslevel",
            "hits",
            "id_level",
            "id_label",
            "id_ion",
            "id_class",
            "id_evidence",
            "score",
            "score2",
        ]
        oracle_data = oracle_data[cols_to_keep]

        # extract feature_id from title. It begins with "uid:XYZ,"
        sample.logger.debug(
            "Extracting feature UIDs from oracle titles using pattern 'uid:(\\d+)'",
        )
        oracle_data["feature_id"] = oracle_data["title"].str.extract(r"uid:(\d+)")
        oracle_data["feature_id"] = oracle_data["feature_id"].astype(int)

        # sort by id_level, remove duplicate feature_id, keep the first one
        sample.logger.debug("Sorting by ID level and removing duplicates")
        oracle_data = oracle_data.sort_values(by=["id_level"], ascending=False)
        oracle_data = oracle_data.drop_duplicates(subset=["feature_id"], keep="first")
        sample.logger.debug(
            f"After deduplication: {len(oracle_data)} unique oracle annotations",
        )
    else:
        cols_to_keep = [
            "precursor",
            "rt",
            "title",
            "scan_idx",
            "mslevel",
            "hits",
            "id_level",
            "id_label",
            "id_ion",
            "id_class",
            "id_evidence",
            "score",
            "score2",
        ]
        oracle_data = oracle_data[cols_to_keep]
        oracle_data["feature_id"] = None

        # iterate over the rows and find the feature_id in feats by looking at the closest rt and mz
        for i, row in oracle_data.iterrows():
            candidates = feats[
                (abs(feats["rt"] - row["rt"]) < 1)
                & (abs(feats["mz"] - row["precursor"]) < 0.005)
            ].copy()
            if len(candidates) > 0:
                # sort by delta rt
                candidates["delta_rt"] = abs(candidates["rt"] - row["rt"])
                candidates = candidates.sort_values(by=["delta_rt"])
                oracle_data.at[i, "feature_id"] = candidates["feature_id"].values[0]
        # remove precursor and rt columns
        oracle_data = oracle_data.drop(columns=["precursor", "rt"])

    # Merge features with oracle data
    sample.logger.debug(f"Merging {len(feats)} features with oracle data")
    feats = feats.merge(oracle_data, how="left", on="feature_id")
    sample.logger.debug(f"After merge: {len(feats)} total features")

    # filter feats by id_level
    initial_count = len(feats)
    if min_id_level is not None:
        feats = feats[(feats["id_level"] >= min_id_level)]
        sample.logger.debug(
            f"After min_id_level filter ({min_id_level}): {len(feats)} features",
        )
    if max_id_level is not None:
        feats = feats[(feats["id_level"] <= max_id_level)]
        sample.logger.debug(
            f"After max_id_level filter ({max_id_level}): {len(feats)} features",
        )
    if min_ms_level is not None:
        feats = feats[(feats["mslevel"] >= min_ms_level)]
        sample.logger.debug(
            f"After min_ms_level filter ({min_ms_level}): {len(feats)} features",
        )

    sample.logger.info(
        f"Feature filtering complete: {initial_count} -> {len(feats)} features remaining",
    )
    return feats


def _setup_color_mapping(sample, feats, colorby, cmap, legend_groups=None):
    """Set up categorical color mapping for features."""
    import matplotlib.colors as mcolors

    feats["color"] = "black"  # Default fallback color
    cvalues = None
    color_column = "color"  # Default to fixed color
    colors: list[str] = []

    # Determine which column to use for categorical coloring
    if colorby in ["class", "hg", "id_class", "id_hg"]:
        categorical_column = "id_class"
        # replace nans with 'mix'
        feats[categorical_column] = feats[categorical_column].fillna("mix")
    elif colorby in ["ion", "id_ion"]:
        categorical_column = "id_ion"
        feats[categorical_column] = feats[categorical_column].fillna("mix")
    elif colorby in ["evidence", "id_evidence"]:
        categorical_column = "id_evidence"
        feats[categorical_column] = feats[categorical_column].fillna("mix")
    elif colorby in ["level", "id_level"]:
        categorical_column = "id_level"
        feats[categorical_column] = feats[categorical_column].fillna("mix")
    else:
        categorical_column = None

    if categorical_column is not None:
        # Use provided legend_groups or derive from data
        if legend_groups is not None:
            # Use all specified groups to ensure consistent legend/coloring
            cvalues = legend_groups[:]  # Copy the list
            # Ensure 'mix' is always present as the last group if not already included
            if "mix" not in cvalues:
                cvalues.append("mix")
            sample.logger.info(f"Using provided legend_groups for legend: {cvalues}")

            # Check which provided groups actually have data
            present_groups = feats[categorical_column].unique()
            missing_groups = [grp for grp in cvalues if grp not in present_groups]
            if missing_groups:
                sample.logger.warning(
                    f"Provided legend_groups not found in data: {missing_groups}",
                )
            sample.logger.info(f"Groups present in data: {sorted(present_groups)}")

            # Assign any points not in legend_groups to 'mix'
            feats.loc[
                ~feats[categorical_column].isin(cvalues[:-1]),
                categorical_column,
            ] = "mix"
        else:
            # Original behavior: use only groups present in data
            cvalues = feats[categorical_column].unique()
            # sort alphabetically
            cvalues = sorted(cvalues)
            # flip the strings left to right
            fcvalues = [cvalues[i][::-1] for i in range(len(cvalues))]
            # sort in alphabetical order the flipped strings and return the index
            idx = np.argsort(fcvalues)
            # apply to cvalues
            cvalues = [cvalues[i] for i in idx]
            sample.logger.info(f"Using groups derived from data: {cvalues}")

        color_column = categorical_column  # Use categorical coloring

    # Process colormap for categorical data
    if cvalues is not None:
        num_colors = len(cvalues)

        # Use colormap for categorical data - use _process_cmap for proper handling
        try:
            colormap = Colormap(cmap)
            colors = []
            for i in range(num_colors):
                # Generate evenly spaced colors across the colormap
                t = i / (num_colors - 1) if num_colors > 1 else 0.5
                color = colormap(t)
                # Convert to hex - handle different color formats
                if hasattr(color, "__len__") and len(color) >= 3:
                    # It's an array-like color (RGB or RGBA)
                    colors.append(mcolors.to_hex(color[:3]))
                else:
                    # It's a single value, convert to RGB
                    colors.append(mcolors.to_hex([color, color, color]))
        except (AttributeError, ValueError, TypeError):
            # Fallback to using _process_cmap if direct Colormap fails
            cmap_palette = _process_cmap(cmap, fallback="viridis", logger=sample.logger)
            # Sample colors from the palette
            colors = []
            for i in range(num_colors):
                idx = (
                    int(i * (len(cmap_palette) - 1) / (num_colors - 1))
                    if num_colors > 1
                    else len(cmap_palette) // 2
                )
                colors.append(cmap_palette[idx])

        # Create a mapping from class name to color to ensure consistent color assignment
        # Each class gets the same color based on its position in the cvalues list
        class_to_color = {class_name: colors[i] for i, class_name in enumerate(cvalues)}

        # assign color to each row based on colorby category
        feats["color"] = "black"
        for class_name, color in class_to_color.items():
            if colorby in ["class", "hg", "id_class", "id_hg"]:
                feats.loc[feats["id_class"] == class_name, "color"] = color
            elif colorby in ["ion", "id_ion"]:
                feats.loc[feats["id_ion"] == class_name, "color"] = color
            elif colorby in ["id_evidence", "ms2_evidence"]:
                feats.loc[feats["id_evidence"] == class_name, "color"] = color

    return cvalues, color_column, colors


def _create_feature_overlay(
    sample,
    raster,
    feats,
    cvalues,
    color_column,
    colors,
    markersize,
    title,
    legend,
):
    """Create feature overlay with identified and unidentified features."""
    # replace NaN with 0 in id_level
    feats["id_level"] = feats["id_level"].fillna(0)

    # Create unified visualization with all features in single layer
    # This avoids the multiple layer legend conflicts that cause dark colors and shared toggling
    sample.logger.debug(
        "Creating unified feature visualization with categorical coloring",
    )

    # Prepare categorical coloring for identified features only (id_level >= 1)
    identified_feats = (
        feats[feats["id_level"] >= 1].copy()
        if len(feats[feats["id_level"] >= 1]) > 0
        else pd.DataFrame()
    )
    unidentified_feats = (
        feats[feats["id_level"] < 1].copy()
        if len(feats[feats["id_level"] < 1]) > 0
        else pd.DataFrame()
    )

    overlay = raster

    # Single layer for identified features with categorical coloring
    if len(identified_feats) > 0 and cvalues is not None:
        # Create proper confidence-based marker styling
        identified_feats["marker_style"] = identified_feats["id_level"].apply(
            lambda x: "circle" if x >= 2 else "circle_cross",
        )
        identified_feats["fill_alpha"] = identified_feats["id_level"].apply(
            lambda x: 1.0
            if x >= 2
            else 0.3,  # Full opacity for high conf, transparent for medium
        )

        oracle_hover_identified = HoverTool(
            tooltips=[
                ("rt", "@rt"),
                ("m/z", "@mz{0.0000}"),
                ("feature_id", "@feature_id"),
                ("id_level", "@id_level"),
                ("id_class", "@id_class"),
                ("id_label", "@id_label"),
                ("id_ion", "@id_ion"),
                ("id_evidence", "@id_evidence"),
                ("score", "@score"),
                ("score2", "@score2"),
            ],
        )

        # Create completely separate overlay elements for each category
        overlays_to_combine = [raster]  # Start with raster base

        for i, category in enumerate(cvalues):
            category_data = identified_feats[
                identified_feats[color_column] == category
            ].copy()
            if len(category_data) > 0:
                # Create a completely separate Points element for this category
                category_points = hv.Points(
                    category_data,
                    kdims=["rt", "mz"],
                    vdims=[
                        "inty",
                        "feature_id",
                        "id_level",
                        "id_class",
                        "id_label",
                        "id_ion",
                        "id_evidence",
                        "score",
                        "score2",
                        "fill_alpha",
                    ],
                    label=str(category),  # This becomes the legend label
                ).options(
                    color=colors[i],  # Use pre-computed hex color for this category
                    marker="circle",
                    size=markersize,
                    alpha="fill_alpha",
                    tools=[oracle_hover_identified],
                    show_legend=True,
                    muted_alpha=0.0,
                )
                overlays_to_combine.append(category_points)
            else:
                # Create empty Points element for categories with no data to ensure they appear in legend
                empty_data = pd.DataFrame(
                    columns=[
                        "rt",
                        "mz",
                        "inty",
                        "feature_id",
                        "id_level",
                        "id_class",
                        "id_label",
                        "id_ion",
                        "id_evidence",
                        "score",
                        "score2",
                        "fill_alpha",
                    ],
                )
                category_points = hv.Points(
                    empty_data,
                    kdims=["rt", "mz"],
                    vdims=[
                        "inty",
                        "feature_id",
                        "id_level",
                        "id_class",
                        "id_label",
                        "id_ion",
                        "id_evidence",
                        "score",
                        "score2",
                        "fill_alpha",
                    ],
                    label=str(category),  # This becomes the legend label
                ).options(
                    color=colors[i],  # Use pre-computed hex color for this category
                    marker="circle",
                    size=markersize,
                    alpha=1.0,
                    tools=[oracle_hover_identified],
                    show_legend=True,
                    muted_alpha=0.0,
                )
                overlays_to_combine.append(category_points)

        # Combine all overlays
        overlay = overlays_to_combine[0]  # Start with raster
        for layer in overlays_to_combine[1:]:
            overlay = overlay * layer

    else:
        # No categorical data - just set overlay to raster
        overlay = raster

    # Separate layer for unidentified features (always black crosses)
    if len(unidentified_feats) > 0:
        oracle_hover_no_id = HoverTool(
            tooltips=[
                ("rt", "@rt"),
                ("m/z", "@mz{0.0000}"),
                ("feature_id", "@feature_id"),
                ("id_level", "@id_level"),
            ],
        )

        feature_points_no_id = hv.Points(
            unidentified_feats,
            kdims=["rt", "mz"],
            vdims=["inty", "feature_id", "id_level"],
        ).options(
            color="black",
            marker="x",
            size=markersize,
            alpha=1.0,
            tools=[oracle_hover_no_id],
            show_legend=False,
        )

        overlay = overlay * feature_points_no_id

    if title is not None:
        sample.logger.debug(f"Setting plot title: {title}")
        overlay = overlay.opts(title=title)

    # Configure legend if requested and categorical coloring is available
    if legend is not None and cvalues is not None and len(cvalues) > 1:
        sample.logger.debug(
            f"Configuring integrated legend at '{legend}' position with {len(cvalues)} categories: {cvalues}",
        )

        # Map legend position parameter to HoloViews legend position
        legend_position_map = {
            "top_right": "top_right",
            "top_left": "top_left",
            "bottom_right": "bottom_right",
            "bottom_left": "bottom_left",
            "right": "right",
            "left": "left",
            "top": "top",
            "bottom": "bottom",
        }

        hv_legend_pos = legend_position_map.get(legend, "bottom_right")

        # Apply legend configuration to the overlay
        overlay = overlay.opts(
            legend_position=hv_legend_pos,
            legend_opts={"title": "", "padding": 2, "spacing": 2},
        )

        sample.logger.debug(f"Applied integrated legend at position '{hv_legend_pos}'")
    elif legend is None:
        # Explicitly hide legend when legend=None
        overlay = overlay.opts(show_legend=False)
        sample.logger.debug("Legend hidden (legend=None)")

    return overlay


def _handle_output(sample, overlay, filename):
    """Handle plot export or display."""
    if filename is not None:
        # if filename includes .html, save the layout to an HTML file
        if filename.endswith(".html"):
            # For HoloViews overlay, we need to convert to Panel for saving
            panel.Column(overlay).save(filename, embed=True)
        elif filename.endswith(".svg"):
            success = _export_with_webdriver_manager(
                overlay,
                filename,
                "svg",
                sample.logger,
            )
            if success:
                sample.logger.success(f"SVG exported: {os.path.abspath(filename)}")
            else:
                sample.logger.warning(f"SVG export failed: {os.path.abspath(filename)}")
        elif filename.endswith(".png"):
            success = _export_with_webdriver_manager(
                overlay,
                filename,
                "png",
                sample.logger,
            )
            if success:
                sample.logger.success(f"PNG exported: {os.path.abspath(filename)}")
            else:
                sample.logger.warning(f"PNG export failed: {os.path.abspath(filename)}")
        else:
            # Default to PNG for any other format
            png_filename = (
                filename + ".png"
                if not filename.endswith((".png", ".svg", ".html"))
                else filename
            )
            success = _export_with_webdriver_manager(
                overlay,
                png_filename,
                "png",
                sample.logger,
            )
            if success:
                sample.logger.success(f"PNG exported: {os.path.abspath(png_filename)}")
            else:
                sample.logger.warning(
                    f"PNG export failed: {os.path.abspath(png_filename)}",
                )
    else:
        # Create a Panel layout for consistent alignment with plot_2d()
        layout = panel.Column(overlay)
        # In notebook environments, explicitly display and return the layout
        if _is_notebook_environment():
            from IPython.display import clear_output, display

            # Clear previous output to ensure fresh display
            clear_output(wait=True)
            display(layout)
            return layout
        # Return the Panel layout (consistent with plot_2d behavior)
        return layout


def plot_2d(
    self,
    filename=None,
    show_features=True,
    show_only_features_with_ms2=False,
    show_only_features_with_id=False,
    show_isotopes=False,
    show_ms2=False,
    show_in_browser=False,
    title=None,
    raster_cmap="iridescent",
    marker_cmap="plasma_r",
    marker="circle",
    markersize=5,
    size="static",
    raster_log=True,
    raster_min=1,
    raster_dynamic=True,
    raster_max_px=8,
    raster_threshold=0.8,
    height=600,
    width=750,
    mz_range=None,
    rt_range=None,
    legend=None,
    colorby=None,
    tooltip="id",
):
    """Plot a two-dimensional visualization of MS1 survey scan data with optional overlays.

    Creates an interactive 2D plot (m/z vs. retention time) from MS1 data with optional
    overlays of detected features, isotopes, and MS2 scans. Uses HoloViews with dynamic
    rasterization for efficient rendering of large datasets.

    Args:
        filename (str | None): Path to save the plot. If ends with ".html", saves as
            interactive HTML; otherwise saves as PNG. If None, displays interactively.
        show_features (bool): Whether to overlay detected features. Defaults to True.
        show_only_features_with_ms2 (bool): If True, display only features with MS2
            spectra. Defaults to False.
        show_only_features_with_id (bool): If True, display only identified features
            (non-null id_top_name). Only applies when colorby="id". Defaults to False.
        show_isotopes (bool): Whether to overlay isotope annotations. Defaults to False.
        show_ms2 (bool): Whether to overlay MS2 scan locations. Defaults to False.
        show_in_browser (bool): Whether to open plot in web browser. Defaults to False.
        title (str | None): Plot title. If None, uses default title.
        raster_cmap (str): Colormap for MS1 background raster. Options include
            "iridescent" (default), "viridis", "plasma", "fire", "blues", etc.
        marker_cmap (str): Colormap for continuous feature coloring when colorby is
            numeric. Options include "plasma_r" (default), "viridis", "inferno", etc.
        marker (str): Marker type for features and MS2 points. Options include "circle"
            (default), "square", "triangle", "diamond", etc.
        markersize (int): Base marker size. Defaults to 5.
        size (str): Marker sizing behavior. Options:

            - "static": Fixed screen-based size (default)
            - "dynamic": Coordinate-based size that scales with zoom
            - "slider": Interactive slider for dynamic size adjustment

        raster_log (bool): Use logarithmic (True) or linear (False) intensity scaling
            for MS1 raster. Defaults to True.
        raster_min (float): Minimum intensity threshold for MS1 raster data. Points
            below this value are filtered. Defaults to 1.
        raster_dynamic (bool): Use dynamic rasterization for MS1 background. Defaults
            to True.
        raster_max_px (int): Maximum pixel size for dynamic rasterization (dynspread).
            Defaults to 8.
        raster_threshold (float): Threshold for dynspread process (0.0-1.0). Higher
            values create smoother rasters. Defaults to 0.8.
        height (int): Plot height in pixels. Defaults to 600.
        width (int): Plot width in pixels. Defaults to 750.
        mz_range (tuple[float, float] | None): m/z range to plot (min_mz, max_mz).
            If None, uses full data range.
        rt_range (tuple[float, float] | None): Retention time range to plot in seconds
            (min_rt, max_rt). If None, uses full data range.
        legend (str | None): Legend position for categorical coloring. Options include
            "top_right", "bottom_left", "top_left", "bottom_right". Only applies when
            colorby contains categorical data.
        colorby (str | None): Feature property for coloring. If None, uses green for
            features with MS2 and red for features without MS2. If specified, colors
            features by the property value (categorical or numeric).
        tooltip (str): Tooltip content mode. Options:

            - "id": Show identification info (default)
            - "uid": Show feature UID
            - "chrom": Show chromatographic info
            - "full": Show all available info

    Returns:
        None: Displays plot or saves to file.

    Example:
        ::

            from masster import Sample

            # Basic 2D plot with features
            s = Sample(file="data.mzML")
            s.find_features()
            s.plot_2d()

            # Show only identified features with MS2
            s.identify(lib="mmc")
            s.plot_2d(
                show_only_features_with_id=True,
                show_only_features_with_ms2=True
            )

            # Save as interactive HTML with isotopes and MS2
            s.plot_2d(
                filename="ms1_map.html",
                show_isotopes=True,
                show_ms2=True
            )

            # Zoom to specific region
            s.plot_2d(
                mz_range=(200, 400),
                rt_range=(300, 600)
            )

            # Color features by intensity with custom colormap
            s.plot_2d(
                colorby="inty_max",
                marker_cmap="viridis"
            )

    Note:
        **Prerequisites:**

        Requires file_obj to be loaded (file must be opened) and ms1_df to be populated.
        Call find_features() before plotting to overlay features.

        **Performance:**

        Uses dynamic rasterization to efficiently render large MS1 datasets. For very
        large files (>1M MS1 points), consider filtering by mz_range or rt_range to
        improve rendering speed.

        **Intensity Filtering:**

        MS1 points with intensity < raster_min are filtered out before plotting to
        reduce noise and improve visualization quality.

        **Feature Coloring:**

        Default coloring (colorby=None) uses green for features with MS2 and red for
        features without MS2. Custom coloring can be applied via colorby parameter
        using any column from features_df.

        **Interactive Features:**

        HTML output supports pan, zoom, hover tooltips, and legend interactions.
        PNG output is static but suitable for publications.

        **Visualization Stack:**

        Built using HoloViews with Bokeh backend, Panel for layout, and Datashader
        for dynamic rasterization.

    See Also:
        - :meth:`find_features`: Detect features before plotting
        - :meth:`find_ms2`: Link MS2 spectra to features
        - :meth:`identify`: Identify features for annotation
    """

    if self.ms1_df is None:
        self.logger.error("No MS1 data available.")
        return None

    # Initialize bokeh extension for inline display in notebooks
    # Only initialize if not already done to avoid affecting marimo/scripts
    try:
        # Check if we're in a notebook environment
        from IPython import get_ipython

        ipython = get_ipython()
        if ipython is not None and "IPKernelApp" in ipython.config:
            # We're in a Jupyter notebook - ensure bokeh extension is loaded
            if "bokeh" not in hv.Store.loaded_backends():
                hv.extension("bokeh")
            # Initialize panel for inline rendering
            # Use vscode comms for VS Code notebooks to ensure proper widget updates
            # Use default comms for regular Jupyter notebooks
            comms_mode = "vscode" if _is_vscode_notebook() else "default"
            panel.extension(comms=comms_mode, inline=True)
    except (ImportError, AttributeError):
        # Not in IPython/Jupyter environment, skip initialization
        pass

    # Process colormap using the cmap package
    cmap_palette = _process_cmap(raster_cmap, fallback="iridescent", logger=self.logger)

    # get columns rt, mz, inty from self.ms1_df, It's polars DataFrame
    spectradf = self.ms1_df.select(["rt", "mz", "inty"])
    # remove any inty<raster_min
    spectradf = spectradf.filter(pl.col("inty") >= raster_min)
    # keep only rt, mz, and inty
    spectradf = spectradf.select(["rt", "mz", "inty"])
    if mz_range is not None:
        spectradf = spectradf.filter(
            (pl.col("mz") >= mz_range[0]) & (pl.col("mz") <= mz_range[1]),
        )
    if rt_range is not None:
        spectradf = spectradf.filter(
            (pl.col("rt") >= rt_range[0]) & (pl.col("rt") <= rt_range[1]),
        )
    maxrt = spectradf["rt"].max()
    minrt = spectradf["rt"].min()
    maxmz = spectradf["mz"].max()
    minmz = spectradf["mz"].min()

    def new_bounds_hook(plot, elem):
        x_range = plot.state.x_range
        y_range = plot.state.y_range
        x_range.bounds = minrt, maxrt
        y_range.bounds = minmz, maxmz

    # Add log-transformed intensity for coloring if raster_log is True
    if raster_log:
        spectradf = spectradf.with_columns(pl.col("inty").log().alias("inty_log"))
        color_column = "inty_log"
    else:
        color_column = "inty"

    points = hv.Points(
        spectradf,
        kdims=["rt", "mz"],
        vdims=["inty", color_column] if raster_log else ["inty"],
        label="MS1 survey scans",
    ).opts(
        fontsize={"title": 16, "labels": 14, "xticks": 6, "yticks": 12},
        color=_holoviews_dim(color_column),
        colorbar=True,
        cmap="Magma",
        tools=["hover"],
    )

    # Configure marker and size behavior based on size parameter
    use_dynamic_sizing = size.lower() in ["dyn", "dynamic"]
    use_slider_sizing = size.lower() == "slider"

    def dynamic_sizing_hook(plot, element):
        """Hook to convert size-based markers to radius-based for dynamic behavior"""
        try:
            if (
                use_dynamic_sizing
                and hasattr(plot, "state")
                and hasattr(plot.state, "renderers")
            ):
                from bokeh.models import Circle

                for renderer in plot.state.renderers:
                    if hasattr(renderer, "glyph"):
                        glyph = renderer.glyph
                        # Check if it's a circle/scatter glyph that we can convert
                        if hasattr(glyph, "size") and marker_type == "circle":
                            # Create a new Circle glyph with radius instead of size
                            new_glyph = Circle(
                                x=glyph.x,
                                y=glyph.y,
                                radius=base_radius,
                                fill_color=glyph.fill_color,
                                line_color=glyph.line_color,
                                fill_alpha=glyph.fill_alpha,
                                line_alpha=glyph.line_alpha,
                            )
                            renderer.glyph = new_glyph
        except Exception:
            # Silently fail and use regular sizing if hook doesn't work
            pass

    if use_dynamic_sizing:
        # Dynamic sizing: use coordinate-based sizing that scales with zoom
        marker_type = "circle"
        # Calculate radius based on data range for coordinate-based sizing
        rtrange = maxrt - minrt
        mzrange = maxmz - minmz
        # Use a fraction of the smaller dimension for radius
        base_radius = min(rtrange, mzrange) * 0.0005 * markersize
        size_1 = markersize  # Use regular size initially, hook will convert to radius
        size_2 = markersize
        hooks = [dynamic_sizing_hook]
    elif use_slider_sizing:
        # Slider sizing: create an interactive slider for marker size
        marker_type = marker  # Use the original marker parameter
        size_1 = markersize  # Use markersize initially, will be updated by slider
        size_2 = markersize
        base_radius = None  # Not used in slider mode
        hooks = []
    else:
        # Static sizing: use pixel-based sizing that stays fixed
        marker_type = marker  # Use the original marker parameter
        size_1 = markersize
        size_2 = markersize
        base_radius = None  # Not used in static mode
        hooks = []

    color_1 = "forestgreen"
    color_2 = "darkorange"

    if filename is not None:
        dyn = False
        if not filename.endswith(".html"):
            if use_dynamic_sizing:
                # For exported files, use smaller coordinate-based size
                size_1 = 2
                size_2 = 2
            else:
                size_1 = 2
                size_2 = 2
            color_1 = "forestgreen"
            color_2 = "darkorange"
            raster_dynamic = False

    # For slider functionality, disable raster dynamic to avoid DynamicMap nesting
    if use_slider_sizing:
        raster_dynamic = False

    dyn = raster_dynamic
    raster = hd.rasterize(
        points,
        aggregator=ds.max("inty"),
        interpolation="bilinear",
        dynamic=dyn,  # alpha=10,                min_alpha=0,
    ).opts(
        active_tools=["box_zoom"],
        cmap=cmap_palette,
        tools=["hover"],
        hooks=[new_bounds_hook],
        width=width,
        height=height,
        cnorm="log" if raster_log else "linear",
        xlabel="Retention time (s)",
        ylabel="m/z",
        colorbar=True,
        colorbar_position="right",
        axiswise=True,
    )

    raster = hd.dynspread(
        raster,
        threshold=raster_threshold,
        how="add",
        shape="square",
        max_px=raster_max_px,
    )
    feature_points_1 = None
    feature_points_2 = None
    feature_points_3 = None
    feature_points_4 = None
    feature_points_iso = None
    colorby_id_mode = False

    # Initialize colorby-related variables before they're used
    use_continuous_coloring = False
    use_categorical_coloring = False
    handled_colorby = False
    continuous_cmap = None
    continuous_min = None
    continuous_max = None
    feature_colors: dict[int, str] = {}
    categorical_groups = []

    # Plot features as red dots if features is True
    if self.features_df is not None and show_features:
        feats = self.features_df.clone()
        # Convert to pandas for operations that require pandas functionality
        if hasattr(feats, "to_pandas"):
            feats = feats.to_pandas()
        # if ms2_scans is not null, keep only the first element of the list
        feats["ms2_scans"] = feats["ms2_scans"].apply(
            lambda x: x[0] if isinstance(x, list) else x,
        )
        if mz_range is not None:
            feats = feats[(feats["mz"] >= mz_range[0]) & (feats["mz"] <= mz_range[1])]
        if rt_range is not None:
            feats = feats[(feats["rt"] >= rt_range[0]) & (feats["rt"] <= rt_range[1])]
        # keep only iso==0, i.e. the main
        feats = feats[feats["iso"] == 0]

        # Apply show_only_features_with_id filter if requested
        if show_only_features_with_id:
            if "id_top_name" in feats.columns:
                id_mask = feats["id_top_name"].notna() & (
                    feats["id_top_name"].astype(str).str.strip() != ""
                )
                feats = feats[id_mask]
            else:
                self.logger.warning(
                    "show_only_features_with_id=True requested but 'id_top_name' column is missing",
                )

        # Replace None/NaN values with empty strings for cleaner tooltips
        # This prevents "???" from appearing in tooltips
        for col in feats.columns:
            if col in feats.select_dtypes(include=["object", "string"]).columns:
                feats[col] = feats[col].fillna("")

        tooltip_mode = str(tooltip).lower() if tooltip is not None else "id"
        if tooltip_mode not in {"chrom", "id", "full"}:
            tooltip_mode = "id"

        id_columns = [
            col
            for col in feats.columns
            if isinstance(col, str) and col.startswith("id_")
        ]

        def build_feature_tooltips(
            *,
            include_iso=True,
            include_iso_of=False,
            include_colorby=None,
        ):
            base_tooltips = [
                ("rt", "@rt"),
                ("m/z", "@mz{0.0000}"),
                ("feature_id", "@feature_id"),
                ("inty", "@inty"),
            ]

            if tooltip_mode == "id":
                base_tooltips.extend((col, f"@{col}") for col in id_columns)
                return base_tooltips

            if tooltip_mode == "full":
                # Show both chromatogram and ID information
                if include_iso:
                    base_tooltips.append(("iso", "@iso"))
                if include_iso_of:
                    base_tooltips.append(("iso_of", "@iso_of"))
                base_tooltips.append(("adduct", "@adduct"))
                base_tooltips.append(("chrom_coherence", "@chrom_coherence"))
                base_tooltips.append(
                    ("chrom_prominence_scaled", "@chrom_prominence_scaled"),
                )
                base_tooltips.extend((col, f"@{col}") for col in id_columns)
                if include_colorby:
                    base_tooltips.append((include_colorby, f"@{include_colorby}"))
                return base_tooltips

            # tooltip_mode == "chrom"
            if include_iso:
                base_tooltips.append(("iso", "@iso"))
            if include_iso_of:
                base_tooltips.append(("iso_of", "@iso_of"))
            base_tooltips.append(("adduct", "@adduct"))
            base_tooltips.append(("chrom_coherence", "@chrom_coherence"))
            base_tooltips.append(
                ("chrom_prominence_scaled", "@chrom_prominence_scaled"),
            )

            if include_colorby and tooltip_mode != "id":
                base_tooltips.append((include_colorby, f"@{include_colorby}"))

            return base_tooltips

        handled_colorby = False

        if colorby == "id":
            if "id_top_name" not in feats.columns:
                self.logger.warning(
                    "colorby='id' requested but 'id_top_name' column is missing; using default colors",
                )
            else:
                handled_colorby = True
                colorby_id_mode = True
                id_values = feats["id_top_name"]
                annotated_mask = id_values.notna() & (
                    id_values.astype(str).str.strip() != ""
                )

                annotated_features = feats[annotated_mask].copy()
                unannotated_features = feats[~annotated_mask].copy()

                feature_hover_annotated = HoverTool(
                    tooltips=build_feature_tooltips(),
                )
                feature_hover_unannotated = HoverTool(
                    tooltips=build_feature_tooltips(),
                )

                # Select only plottable columns for vdims (exclude complex objects like Chromatogram)
                base_vdims = [
                    "feature_id",
                    "inty",
                    "iso",
                    "adduct",
                    "chrom_coherence",
                    "chrom_prominence_scaled",
                ]
                # Add id_* columns if they exist
                id_vdims = [
                    col
                    for col in feats.columns
                    if isinstance(col, str) and col.startswith("id_")
                ]
                all_vdims = base_vdims + id_vdims

                if len(annotated_features) > 0:
                    vdims_annotated = [
                        col for col in all_vdims if col in annotated_features.columns
                    ]
                    feature_points_1 = hv.Points(
                        annotated_features,
                        kdims=["rt", "mz"],
                        vdims=vdims_annotated,
                        label="Annotated features",
                    ).options(
                        color="#2e7d32",
                        marker=marker_type,
                        size=size_1,
                        tools=[feature_hover_annotated],
                        hooks=hooks,
                        show_legend=True,
                        muted_alpha=0.0,
                    )

                if len(unannotated_features) > 0:
                    vdims_unannotated = [
                        col for col in all_vdims if col in unannotated_features.columns
                    ]
                    feature_points_2 = hv.Points(
                        unannotated_features,
                        kdims=["rt", "mz"],
                        vdims=vdims_unannotated,
                        label="Unannotated features",
                    ).options(
                        color="#9e9e9e",
                        marker=marker_type,
                        size=size_2,
                        tools=[feature_hover_unannotated],
                        hooks=hooks,
                        show_legend=True,
                        muted_alpha=0.0,
                    )

        # Check if colorby column exists
        if (
            (not handled_colorby)
            and colorby is not None
            and colorby not in feats.columns
        ):
            self.logger.warning(
                f"colorby='{colorby}' not found in features_df columns. "
                f"Using default coloring. Available columns: {', '.join(feats.columns)}",
            )

        if (not handled_colorby) and colorby is not None and colorby in feats.columns:
            # Check if colorby data is categorical (string-like) or continuous (numeric)
            colorby_values = feats[colorby].dropna()
            is_categorical = feats[colorby].dtype in [
                "object",
                "string",
                "category",
            ] or (len(colorby_values) > 0 and isinstance(colorby_values.iloc[0], str))
            is_numeric = feats[colorby].dtype in [
                "int64",
                "float64",
                "int32",
                "float32",
            ] or (
                len(colorby_values) > 0
                and isinstance(
                    colorby_values.iloc[0],
                    (int, float, np.integer, np.floating),
                )
            )

            if is_categorical:
                use_categorical_coloring = True
                # Get unique categories, sorted
                categorical_groups = sorted(feats[colorby].dropna().unique())

                # Set up colors for categorical data using matplotlib colormap
                from matplotlib.colors import to_hex

                try:
                    from matplotlib.cm import get_cmap

                    colormap_func = get_cmap(
                        marker_cmap
                        if marker_cmap not in ["iridescent", "iridescent_r"]
                        else "tab20",
                    )
                    feature_colors = {}
                    for i, group in enumerate(categorical_groups):
                        if len(categorical_groups) <= 20:
                            # Use qualitative colors for small number of categories
                            color_val = colormap_func(
                                i / max(1, len(categorical_groups) - 1),
                            )
                        else:
                            # Use continuous colormap for many categories
                            color_val = colormap_func(
                                i / max(1, len(categorical_groups) - 1),
                            )
                        feature_colors[group] = to_hex(color_val)
                except Exception as e:
                    self.logger.warning(
                        f"Could not set up categorical coloring: {e}, using default colors",
                    )
                    use_categorical_coloring = False

            elif is_numeric:
                # Set up continuous coloring for numeric data
                use_continuous_coloring = True
                handled_colorby = True

                # Use marker_cmap for continuous feature coloring
                continuous_cmap = marker_cmap

                # Calculate min/max for color normalization (use log scale for intensity)
                continuous_min = colorby_values.min()
                continuous_max = colorby_values.max()

                # Use log scale for intensity-like columns
                if colorby in ["inty", "chrom_area", "chrom_height_scaled"]:
                    # Filter out zeros and negative values for log scale
                    positive_values = colorby_values[colorby_values > 0]
                    if len(positive_values) > 0:
                        continuous_min = np.log10(positive_values.min())
                        continuous_max = np.log10(positive_values.max())
                        # Add log-transformed column for coloring
                        feats[f"{colorby}_log"] = feats[colorby].apply(
                            lambda x: np.log10(x) if x > 0 else continuous_min,
                        )
                        colorby_for_plotting = f"{colorby}_log"
                    else:
                        colorby_for_plotting = colorby
                else:
                    colorby_for_plotting = colorby

        if use_categorical_coloring and colorby is not None:
            # Create separate feature points for each category
            for i, group in enumerate(categorical_groups):
                group_features = feats[feats[colorby] == group]
                if len(group_features) == 0:
                    continue

                # Split by MS2 status
                group_with_ms2 = group_features[group_features["ms2_scans"].notnull()]
                group_without_ms2 = group_features[group_features["ms2_scans"].isnull()]

                group_color = feature_colors.get(group, color_1)

                # Build vdims including id_* columns
                base_vdims_cat = [
                    "feature_id",
                    "inty",
                    "iso",
                    "adduct",
                    "chrom_coherence",
                    "chrom_prominence_scaled",
                    colorby,
                ]
                vdims_with_ms2_cat = base_vdims_cat + ["ms2_scans"] + id_columns
                vdims_without_ms2_cat = base_vdims_cat + id_columns

                if len(group_with_ms2) > 0:
                    feature_hover = HoverTool(
                        tooltips=build_feature_tooltips(include_colorby=colorby),
                    )
                    # Filter vdims to only include columns that exist
                    vdims_available = [
                        col
                        for col in vdims_with_ms2_cat
                        if col in group_with_ms2.columns
                    ]
                    group_points_ms2 = hv.Points(
                        group_with_ms2,
                        kdims=["rt", "mz"],
                        vdims=vdims_available,
                        label=f"{group} (MS2)",
                    ).options(
                        color=group_color,
                        marker=marker_type,
                        size=size_1,
                        tools=[feature_hover],
                        hooks=hooks,
                        muted_alpha=0.0,
                    )
                    if feature_points_1 is None:
                        feature_points_1 = group_points_ms2
                    else:
                        feature_points_1 = feature_points_1 * group_points_ms2

                if len(group_without_ms2) > 0:
                    feature_hover = HoverTool(
                        tooltips=build_feature_tooltips(include_colorby=colorby),
                    )
                    # Filter vdims to only include columns that exist
                    vdims_available = [
                        col
                        for col in vdims_without_ms2_cat
                        if col in group_without_ms2.columns
                    ]
                    group_points_no_ms2 = hv.Points(
                        group_without_ms2,
                        kdims=["rt", "mz"],
                        vdims=vdims_available,
                        label=f"{group} (no MS2)",
                    ).options(
                        color=group_color,
                        marker=marker_type,
                        size=size_2,
                        tools=[feature_hover],
                        hooks=hooks,
                        muted_alpha=0.0,
                    )
                    if feature_points_2 is None:
                        feature_points_2 = group_points_no_ms2
                    else:
                        feature_points_2 = feature_points_2 * group_points_no_ms2

        # Handle continuous/numeric coloring
        if use_continuous_coloring and colorby is not None:
            # Build vdims including the colorby column and id_* columns
            base_vdims_cont = [
                "feature_id",
                "inty",
                "iso",
                "adduct",
                "chrom_coherence",
                "chrom_prominence_scaled",
                colorby,
            ]
            if colorby_for_plotting != colorby:
                base_vdims_cont.append(colorby_for_plotting)

            vdims_with_ms2_cont = base_vdims_cont + ["ms2_scans"] + id_columns
            vdims_without_ms2_cont = base_vdims_cont + id_columns

            # Split features by MS2 status
            features_with_ms2 = feats[feats["ms2_scans"].notnull()]
            features_without_ms2 = feats[feats["ms2_scans"].isnull()]

            if len(features_with_ms2) > 0:
                feature_hover_cont_ms2 = HoverTool(
                    tooltips=build_feature_tooltips(include_colorby=colorby),
                )
                vdims_available = [
                    col
                    for col in vdims_with_ms2_cont
                    if col in features_with_ms2.columns
                ]
                feature_points_1 = hv.Points(
                    features_with_ms2,
                    kdims=["rt", "mz"],
                    vdims=vdims_available,
                    label="Features with MS2",
                ).options(
                    color=colorby_for_plotting,
                    cmap=continuous_cmap,
                    colorbar=True,
                    clim=(continuous_min, continuous_max),
                    marker=marker_type,
                    size=size_1,
                    tools=[feature_hover_cont_ms2],
                    hooks=hooks,
                    colorbar_opts={"title": colorby},
                    muted_alpha=0.0,
                )

            if len(features_without_ms2) > 0:
                feature_hover_cont_no_ms2 = HoverTool(
                    tooltips=build_feature_tooltips(include_colorby=colorby),
                )
                vdims_available = [
                    col
                    for col in vdims_without_ms2_cont
                    if col in features_without_ms2.columns
                ]
                feature_points_2 = hv.Points(
                    features_without_ms2,
                    kdims=["rt", "mz"],
                    vdims=vdims_available,
                    label="Features without MS2",
                ).options(
                    color=colorby_for_plotting,
                    cmap=continuous_cmap,
                    colorbar=True,
                    clim=(continuous_min, continuous_max),
                    marker=marker_type,
                    size=size_2,
                    tools=[feature_hover_cont_no_ms2],
                    hooks=hooks,
                    colorbar_opts={"title": colorby},
                    muted_alpha=0.0,
                )

        # Only use default coloring if no special colorby mode was handled
        if (
            not handled_colorby
            and not use_categorical_coloring
            and not use_continuous_coloring
        ):
            # Use original green/red coloring scheme for MS2 presence
            # Build base vdims list and add id_* columns if they exist
            base_vdims = [
                "feature_id",
                "inty",
                "iso",
                "adduct",
                "chrom_coherence",
                "chrom_prominence_scaled",
            ]
            # Add id_* columns to vdims
            vdims_with_ms2 = base_vdims + ["ms2_scans"] + id_columns
            vdims_without_ms2 = base_vdims + id_columns

            # find features with ms2_scans not None  and iso==0
            features_df = feats[feats["ms2_scans"].notnull()]
            # Create feature points with proper sizing method
            feature_hover_1 = HoverTool(
                tooltips=build_feature_tooltips(),
            )
            if len(features_df) > 0:
                # Filter vdims to only include columns that exist in features_df
                vdims_available = [
                    col for col in vdims_with_ms2 if col in features_df.columns
                ]
                feature_points_1 = hv.Points(
                    features_df,
                    kdims=["rt", "mz"],
                    vdims=vdims_available,
                    label="Features with MS2",
                ).options(
                    color=color_1,
                    marker=marker_type,
                    size=size_1,
                    tools=[feature_hover_1],
                    hooks=hooks,
                    muted_alpha=0.0,
                )

            # find features without MS2 data
            features_df = feats[feats["ms2_scans"].isnull()]
            feature_hover_2 = HoverTool(
                tooltips=build_feature_tooltips(),
            )
            if len(features_df) > 0:
                # Filter vdims to only include columns that exist in features_df
                vdims_available = [
                    col for col in vdims_without_ms2 if col in features_df.columns
                ]
                feature_points_2 = hv.Points(
                    features_df,
                    kdims=["rt", "mz"],
                    vdims=vdims_available,
                    label="Features without MS2",
                ).options(
                    color="red",
                    marker=marker_type,
                    size=size_2,
                    tools=[feature_hover_2],
                    hooks=hooks,
                    muted_alpha=0.0,
                )

        if show_isotopes:
            # Use proper Polars filter syntax to avoid boolean indexing issues
            features_df = self.features_df.filter(pl.col("iso") > 0)
            # Convert to pandas for plotting compatibility
            if hasattr(features_df, "to_pandas"):
                features_df = features_df.to_pandas()
            feature_hover_iso = HoverTool(
                tooltips=build_feature_tooltips(include_iso_of=True),
            )
            # Build vdims including id_* columns
            base_vdims_iso = [
                "feature_id",
                "inty",
                "iso",
                "iso_of",
                "adduct",
                "chrom_coherence",
                "chrom_prominence_scaled",
            ]
            vdims_iso = base_vdims_iso + id_columns
            # Filter vdims to only include columns that exist
            vdims_available = [col for col in vdims_iso if col in features_df.columns]

            feature_points_iso = hv.Points(
                features_df,
                kdims=["rt", "mz"],
                vdims=vdims_available,
                label="Isotopes",
            ).options(
                color="violet",
                marker=marker_type,
                size=size_1,
                tools=[feature_hover_iso],
                hooks=hooks,
                muted_alpha=0.0,
            )
    if show_ms2:
        # find all self.scans_df with mslevel 2 that are not linked to a feature
        ms2_orphan = self.scans_df.filter(pl.col("ms_level") == 2).filter(
            pl.col("feature_id") < 0,
        )

        if len(ms2_orphan) > 0:
            # pandalize
            ms2 = ms2_orphan.to_pandas()
            ms2_hover_3 = HoverTool(
                tooltips=[
                    ("rt", "@rt"),
                    ("prec_mz", "@prec_mz{0.0000}"),
                    ("index", "@index"),
                    ("inty_tot", "@inty_tot"),
                    ("bl", "@bl"),
                ],
            )
            feature_points_3 = hv.Points(
                ms2,
                kdims=["rt", "prec_mz"],
                vdims=["index", "inty_tot", "bl"],
                label="Orphan MS2 scans",
            ).options(
                color=color_2,
                marker="x",
                size=size_2,
                tools=[ms2_hover_3],
                muted_alpha=0.0,
            )

        ms2_linked = self.scans_df.filter(pl.col("ms_level") == 2).filter(
            pl.col("feature_id") >= 0,
        )
        if len(ms2_linked) > 0:
            # pandalize
            ms2 = ms2_linked.to_pandas()
            ms2_hover_4 = HoverTool(
                tooltips=[
                    ("rt", "@rt"),
                    ("prec_mz", "@prec_mz{0.0000}"),
                    ("index", "@index"),
                    ("inty_tot", "@inty_tot"),
                    ("bl", "@bl"),
                ],
            )
            feature_points_4 = hv.Points(
                ms2,
                kdims=["rt", "prec_mz"],
                vdims=["index", "inty_tot", "bl"],
                label="Linked MS2 scans",
            ).options(
                color=color_1,
                marker="x",
                size=size_2,
                tools=[ms2_hover_4],
                muted_alpha=0.0,
            )

    overlay = raster

    if feature_points_4 is not None:
        overlay = overlay * feature_points_4
    if feature_points_3 is not None:
        overlay = overlay * feature_points_3

    # In colorby='id' mode, draw unannotated (grey) first, then annotated (green) on top
    if colorby_id_mode:
        # Draw grey points first (bottom layer)
        if feature_points_2 is not None:
            overlay = overlay * feature_points_2
        # Draw green points last (top layer)
        if feature_points_1 is not None:
            overlay = overlay * feature_points_1
    else:
        # Default order: green (with MS2) first, then red (without MS2)
        if feature_points_1 is not None:
            overlay = overlay * feature_points_1
        # In non-id mode, only show features without MS2 if show_only_features_with_ms2 is False
        if not show_only_features_with_ms2 and feature_points_2 is not None:
            overlay = overlay * feature_points_2

    if feature_points_iso is not None:
        overlay = overlay * feature_points_iso

    # Enable merge_tools=False for continuous coloring to show both colorbars
    # Actually, just hide the raster colorbar when continuous coloring is used
    if use_continuous_coloring:
        # Re-apply raster options to hide its colorbar
        raster = raster.opts(colorbar=False)

    if title is not None:
        overlay = overlay.opts(title=title)

    # Define hook to set legend click policy to "hide" instead of "mute"
    def legend_hide_hook(plot, element):
        """Set legend click_policy to 'hide' so items disappear completely when toggled"""
        if hasattr(plot, "state") and hasattr(plot.state, "legend"):
            for legend in plot.state.legend:
                legend.click_policy = "hide"

    # Handle legend positioning for categorical coloring or colorby='id' mode
    if legend is not None and (
        colorby_id_mode or (use_categorical_coloring and len(categorical_groups) > 1)
    ):
        # Map legend position parameter to HoloViews legend position
        legend_position_map = {
            "top_right": "top_right",
            "top_left": "top_left",
            "bottom_right": "bottom_right",
            "bottom_left": "bottom_left",
            "right": "right",
            "left": "left",
            "top": "top",
            "bottom": "bottom",
        }

        hv_legend_pos = legend_position_map.get(legend, "bottom_right")

        # Apply legend configuration to the overlay with hide hook
        overlay = overlay.opts(
            legend_position=hv_legend_pos,
            legend_opts={"title": "", "padding": 2, "spacing": 2},
            hooks=[legend_hide_hook],
        )
    elif legend is None and (colorby_id_mode or use_categorical_coloring):
        # Explicitly hide legend when legend=None but categorical coloring or id mode is used
        overlay = overlay.opts(show_legend=False)

    # Handle slider functionality
    if use_slider_sizing:
        # For slider functionality, we need to work with the feature points directly
        # and not nest DynamicMaps. We'll create the slider using param and panel.
        import panel as on
        import param

        class MarkerSizeController(param.Parameterized):
            size_slider = param.Number(default=markersize, bounds=(1, 20), step=0.5)

        # Create a function that generates just the feature overlays with different sizes
        def create_feature_overlay(size_val):
            feature_overlay = None

            if feature_points_4 is not None:
                updated_points_4 = feature_points_4.opts(size=size_val)
                feature_overlay = (
                    updated_points_4
                    if feature_overlay is None
                    else feature_overlay * updated_points_4
                )
            if feature_points_3 is not None:
                updated_points_3 = feature_points_3.opts(size=size_val)
                feature_overlay = (
                    updated_points_3
                    if feature_overlay is None
                    else feature_overlay * updated_points_3
                )

            # In colorby='id' mode, draw unannotated (grey) first, then annotated (green) on top
            if colorby_id_mode:
                # Draw grey points first (bottom layer)
                if feature_points_2 is not None:
                    updated_points_2 = feature_points_2.opts(size=size_val)
                    feature_overlay = (
                        updated_points_2
                        if feature_overlay is None
                        else feature_overlay * updated_points_2
                    )
                # Draw green points last (top layer)
                if feature_points_1 is not None:
                    updated_points_1 = feature_points_1.opts(size=size_val)
                    feature_overlay = (
                        updated_points_1
                        if feature_overlay is None
                        else feature_overlay * updated_points_1
                    )
            else:
                # Default order: green (with MS2) first, then red (without MS2)
                if feature_points_1 is not None:
                    updated_points_1 = feature_points_1.opts(size=size_val)
                    feature_overlay = (
                        updated_points_1
                        if feature_overlay is None
                        else feature_overlay * updated_points_1
                    )
                # In non-id mode, only show features without MS2 if show_only_features_with_ms2 is False
                if not show_only_features_with_ms2 and feature_points_2 is not None:
                    updated_points_2 = feature_points_2.opts(size=size_val)
                    feature_overlay = (
                        updated_points_2
                        if feature_overlay is None
                        else feature_overlay * updated_points_2
                    )

            if feature_points_iso is not None:
                updated_points_iso = feature_points_iso.opts(size=size_val)
                feature_overlay = (
                    updated_points_iso
                    if feature_overlay is None
                    else feature_overlay * updated_points_iso
                )

            # Combine with the static raster background
            if feature_overlay is not None:
                combined_overlay = raster * feature_overlay
            else:
                combined_overlay = raster

            if title is not None:
                combined_overlay = combined_overlay.opts(title=title)

            return combined_overlay

        # Create a horizontal control widget on top of the plot
        # Create the slider widget with explicit visibility
        size_slider = on.widgets.FloatSlider(
            name="Marker Size",
            start=1.0,
            end=20.0,
            step=0.5,
            value=markersize,
            width=300,
            height=40,
            margin=(5, 5),
            show_value=True,
        )

        # Create the slider widget row with clear styling
        slider_widget = on.Row(
            on.pane.HTML(
                "<b>Marker Size Control:</b>",
                width=150,
                height=40,
                margin=(5, 10),
            ),
            size_slider,
            height=60,
            margin=10,
        )

        # Create slider widget
        size_slider = on.widgets.FloatSlider(
            name="Marker Size",
            start=1.0,
            end=20.0,
            step=0.5,
            value=markersize,
            width=300,
            height=40,
            margin=(5, 5),
            show_value=True,
        )

        slider_widget = on.Row(
            on.pane.HTML("<b>Marker Size:</b>", width=100, height=40, margin=(5, 10)),
            size_slider,
            height=60,
            margin=10,
        )

        # Simple reactive plot - slider mode doesn't use dynamic rasterization
        @on.depends(size_slider.param.value)
        def reactive_plot(size_val):
            overlay = create_feature_overlay(float(size_val))
            # Apply static rasterization for slider mode
            if raster_dynamic:
                return hd.rasterize(
                    overlay,
                    aggregator=ds.count(),
                    width=raster_max_px,
                    height=raster_max_px,
                    dynamic=False,  # Static raster for slider mode
                ).opts(
                    cnorm="eq_hist",
                    tools=["hover"],
                    width=width,
                    height=height,
                )
            return overlay

        # Create layout
        layout = on.Column(slider_widget, reactive_plot, sizing_mode="stretch_width")

        # Handle filename saving for slider mode
        if filename is not None:
            if filename.endswith(".html"):
                layout.save(filename, embed=True)
            else:
                # For slider plots, save the current state
                hv.save(create_feature_overlay(markersize), filename, fmt="png")
        else:
            # Use show() for display in notebook
            layout.show()
    else:
        # Create a panel layout without slider
        layout = panel.Column(overlay)

    # Handle display logic based on show_in_browser and raster_dynamic
    if filename is not None:
        # Use consistent save/display behavior
        self._handle_sample_plot_output(layout, filename, "panel")
    # Show in browser if both show_in_browser and raster_dynamic are True
    elif show_in_browser and raster_dynamic:
        layout.show()
    else:
        # Return to notebook for inline display
        return layout


def plot_2d_oracle(
    self,
    oracle_folder=None,
    link_by_feature_id=True,
    min_id_level=1,
    max_id_level=4,
    min_ms_level=2,
    colorby="hg",
    legend_groups=None,
    markersize=5,
    cmap="Turbo",
    raster_cmap="grey",
    raster_log=True,
    raster_min=1,
    raster_dynamic=True,
    raster_max_px=8,
    raster_threshold=0.8,
    mz_range=None,
    rt_range=None,
    width=750,
    height=600,
    filename=None,
    title=None,
    legend="bottom_right",
):
    """
    Plot a 2D visualization combining MS1 raster data and oracle-annotated features.

    Creates an interactive plot overlaying MS1 survey scan data with feature annotations
    from oracle files. Features are colored categorically based on identification class,
    ion type, or evidence level.

    Parameters:
        oracle_folder (str, optional): Path to oracle folder containing
            "diag/summary_by_feature.csv". Required for oracle annotations.
        link_by_feature_id (bool): Whether to link features by UID (True) or by m/z/RT proximity.
        min_id_level (int): Minimum identification confidence level to include.
        max_id_level (int): Maximum identification confidence level to include.
        min_ms_level (int): Minimum MS level for features to include.
        colorby (str): Feature coloring scheme - "id_class", "id_ion", "id_evidence", etc.
        legend_groups (list, optional): List of groups to include in legend and coloring scheme.
            If provided, legend will show exactly these groups. 'mix' is automatically added
            as the last group to contain points not matching other groups. Works for all
            categorical coloring types (id_class, id_ion, id_evidence, etc.).
            If None (default), all groups present in the data will be shown without filtering.
            All specified classes will appear in the legend even if no features are present.
        markersize (int): Size of feature markers.
        cmap (str): Colormap name for categorical coloring.
        raster_cmap (str): Colormap for MS1 raster background.
        raster_log (bool): Use logarithmic scaling for raster intensity (True) or linear scaling (False).
        raster_min (float): Minimum intensity threshold for raster data filtering.
        raster_dynamic (bool): Enable dynamic rasterization.
        raster_threshold (float): Dynamic raster spread threshold.
        raster_max_px (int): Maximum pixel size for rasterization.
        mz_range (tuple, optional): m/z range filter (min, max).
        rt_range (tuple, optional): Retention time range filter (min, max).
        width/height (int): Plot dimensions in pixels.
        filename (str, optional): Export filename (.html/.svg/.png). If None, displays inline.
        title (str, optional): Plot title.
        legend (str, optional): Legend position ("top_right", "bottom_left", etc.) or None.

    Returns:
        HoloViews layout for display (if filename is None), otherwise None.
    """

    self.logger.info(f"Starting plot_2d_oracle with oracle_folder: {oracle_folder}")
    self.logger.debug(
        f"Parameters - link_by_feature_id: {link_by_feature_id}, min_id_level: {min_id_level}, max_id_level: {max_id_level}",
    )
    self.logger.debug(
        f"Plot parameters - colorby: {colorby}, markersize: {markersize}, filename: {filename}",
    )

    # Early validation
    if self.features_df is None:
        self.logger.error("Cannot plot 2D oracle: features_df is not available")
        return None

    if oracle_folder is None:
        self.logger.info("No oracle folder provided, plotting features only")
        return None

    # Create raster plot layer
    raster = _create_raster_plot(
        self,
        mz_range=mz_range,
        rt_range=rt_range,
        raster_cmap=raster_cmap,
        raster_log=raster_log,
        raster_min=raster_min,
        raster_dynamic=raster_dynamic,
        raster_threshold=raster_threshold,
        raster_max_px=raster_max_px,
        width=width,
        height=height,
        filename=filename,
    )

    # Load and process oracle data
    feats = _load_and_merge_oracle_data(
        self,
        oracle_folder=oracle_folder,
        link_by_feature_id=link_by_feature_id,
        min_id_level=min_id_level,
        max_id_level=max_id_level,
        min_ms_level=min_ms_level,
    )

    if feats is None:
        return None

    # Set up color scheme and categorical mapping
    cvalues, color_column, colors = _setup_color_mapping(
        self,
        feats,
        colorby,
        cmap,
        legend_groups,
    )

    # Create feature overlay with all visualization elements
    overlay = _create_feature_overlay(
        self,
        raster=raster,
        feats=feats,
        cvalues=cvalues,
        color_column=color_column,
        colors=colors,
        markersize=markersize,
        title=title,
        legend=legend,
    )

    # Handle output: export or display
    return _handle_output(self, overlay, filename)


def plot_ms2_eic(
    self,
    feature_id=None,
    rt_tol=5,
    mz_tol=0.05,
    link_x=True,
    n=20,
    deisotope=True,
    centroid=True,
    use_cache=True,
    filename=None,
    **kwargs,
):
    """Plot Extracted Ion Chromatograms (EIC) for precursor and fragment ions.

    Creates EIC plots for the precursor and top n MS2 fragment ions of a feature.
    Each fragment gets its own subplot showing intensity vs retention time, useful
    for assessing fragmentation pattern consistency across the chromatographic peak.

    Args:
        feature_id (int | None): Feature identifier to plot. Required.
        rt_tol (float): Retention time tolerance in seconds to extend beyond
            feature boundaries. Defaults to 5.
        mz_tol (float): m/z tolerance in Da for matching peaks. Defaults to 0.05.
        link_x (bool): Link x-axis zoom across plots. Defaults to True.
        n (int): Number of top intensity fragments to display. Defaults to 20.
        deisotope (bool): Remove isotope peaks when use_cache=False. Defaults
            to True.
        centroid (bool): Centroid spectrum when use_cache=False. Defaults to
            True.
        use_cache (bool): Use cached spectrum from feature (ms2_specs[0]) if
            True, otherwise retrieve fresh spectrum with specified parameters.
            Defaults to True.
        filename (str | None): Path to save plot. Supports .html and .png.
            None displays interactively. Defaults to None.
        **kwargs: Additional parameters passed to get_spectrum() when
            use_cache=False. Includes:

            max_peaks (int | None): Maximum peaks to keep. None keeps all.
            precursor_trim (int): m/z window to remove precursor. Negative
                disables. Defaults to -10.
            dia_stats (bool): Collect DIA statistics (q1_ratio, eic_corr).
                Defaults to False.
            feature (int | None): Feature ID for DIA statistics.
            label (str | None): Custom spectrum label.
            centroid_algo (str | None): Centroiding algorithm ('lmp', 'cwt',
                'gaussian'). None uses sample default.
            clean (bool): Remove peaks below baseline noise. Adds "t[CL]" to
                history. Defaults to False.

    Returns:
        holoviews.core.overlay.Overlay | panel.layout.Column | None: Interactive
            plot object (notebook) or panel layout, None if saved to file or
            if feature has no MS2 data.

    Example:
        Basic EIC plot::

            >>> sample.plot_ms2_eic(feature_id=1186)

        Use fresh spectrum with custom parameters::

            >>> sample.plot_ms2_eic(
            ...     feature_id=1186,
            ...     use_cache=False,
            ...     deisotope=True,
            ...     clean=True,
            ...     dia_stats=True
            ... )

        Wider RT window with more fragments::

            >>> sample.plot_ms2_eic(
            ...     feature_id=1186,
            ...     rt_tol=10,
            ...     n=50
            ... )

        Save to file::

            >>> sample.plot_ms2_eic(
            ...     feature_id=1186,
            ...     filename="fragment_eic.html"
            ... )

    Note:
        - Cached spectrum (use_cache=True) uses stored ms2_specs[0] with
          original processing parameters from find_ms2()
        - Fresh retrieval (use_cache=False) applies current deisotope, centroid,
          and all **kwargs parameters
        - Precursor EIC extracted from MS1 scans (always centroid, no deisotope)
        - Fragment EICs extracted from MS2 scans across entire RT window
        - Useful for detecting co-elution, in-source fragmentation, or contaminants

    See Also:
        get_spectrum: Retrieve and process individual spectra.
        plot_ms2_q1: Plot Q1 vs product ion heatmap.
        find_ms2: Link MS2 spectra to features.
    """

    if feature_id is None:
        print("Please provide a feature id.")
        return None
    # check if feature_id is in features_df
    if feature_id not in self.features_df["feature_id"].to_list():
        print("Feature id not found in features_df.")

    feature = self.features_df.filter(self.features_df["feature_id"] == feature_id)

    # Determine which scan to use
    ms2_scans = feature["ms2_scans"][0]
    if ms2_scans is None or len(ms2_scans) == 0:
        print("No MS2 data found for this feature.")
        return None

    # Get the spectrum - either from cache or fresh retrieval
    if use_cache:
        # Use stored spectrum
        ms2_specs = feature["ms2_specs"][0]
        if ms2_specs is None or len(ms2_specs) == 0:
            print("No cached MS2 data found for this feature.")
            return None
        reference_spec = ms2_specs[0]
    else:
        # Retrieve fresh spectrum with user-specified parameters
        scan_id = ms2_scans[0]
        reference_spec = self.get_spectrum(
            scan_id,
            centroid=centroid,
            deisotope=deisotope,
            **kwargs,
        )
        if reference_spec is None or len(reference_spec.mz) == 0:
            print("Failed to retrieve spectrum.")
            return None

    # get the mz of the top n fragments
    ms2_specs_df = reference_spec.pandalize()
    ms2_specs_df = ms2_specs_df.sort_values(by="inty", ascending=False)
    ms2_specs_df = ms2_specs_df.head(n)
    top_mzs = ms2_specs_df["mz"].values.tolist()

    # find rt_start and rt_end of the feature_id
    rt_start = feature["rt_start"][0] - rt_tol
    rt_end = feature["rt_end"][0] + rt_tol
    # get the cycle at rt_start and the cycle at rt_end from the closest scan with ms_level == 1
    scans = self.scans_df.filter(pl.col("ms_level") == 1)
    scans = scans.filter(pl.col("rt") > rt_start)
    scans = scans.filter(pl.col("rt") < rt_end)
    rts = scans["rt"].to_list()
    if len(scans) == 0:
        print(f"No scans found between {rt_start} and {rt_end}.")
        return None
    scan_ids = scans["scan_id"].to_list()
    eic_prec = self._spec_to_mat(
        scan_ids,
        mz_ref=feature["mz"].to_list(),
        mz_tol=mz_tol,
        deisotope=False,
        centroid=True,
    )
    # convert eic_prec from matrix to list
    eic_prec = eic_prec[0].tolist()

    # get all unique cycles from scans
    cycles = scans["cycle"].unique()
    scan_ids = []
    # iterate over all cycles and get the scan_id of scan with ms_level == 2 and closest precursor_mz to spec.precursor_mz
    for cycle in cycles:
        scans = self.scans_df.filter(pl.col("cycle") == cycle)
        scans = scans.filter(pl.col("ms_level") == 2)
        scans = scans.filter(pl.col("prec_mz") > feature["mz"][0] - 5)
        scans = scans.filter(pl.col("prec_mz") < feature["mz"][0] + 5)
        if len(scans) == 0:
            print(
                f"No scans found for cycle {cycle} and mz {feature['mz'][0]}. Increase mz_tol tolerance.",
            )
            return None
        # get the scan with the closest precursor_mz to feature['mz']
        scan = scans[(scans["prec_mz"] - feature["mz"][0]).abs().arg_sort()[:1]]
        scan_ids.append(scan["scan_id"][0])
    eic_prod = self._spec_to_mat(
        scan_ids,
        mz_ref=top_mzs,
        mz_tol=mz_tol,
        deisotope=deisotope,
        centroid=centroid,
        **kwargs,
    )

    prec_name = f"prec {feature['mz'][0]:.3f}"
    eic_df = pd.DataFrame({"rt": rts, prec_name: eic_prec})
    # add scan_id to eic_df for the tooltips
    eic_df["scan_id"] = scan_ids

    frag_names = [prec_name]
    for i, mz in enumerate(top_mzs):
        # add column to eic_df
        name = f"frag {mz:.3f}"
        frag_names.append(name)
        eic_df[name] = eic_prod[i]

    # create a plot for all columns in eic_df
    eic_plots: list[hv.Curve] = []
    for name in frag_names:
        eic = hv.Curve(eic_df, kdims=["rt"], vdims=[name, "scan_id"]).opts(
            title=name,
            xlabel="RT (s)",
            ylabel=f"Inty_f{len(eic_plots)}",
            width=250,
            height=200,
            axiswise=True,
            color="black",
            tools=[HoverTool(tooltips=[("rt", "@rt"), ("scan_id", "@scan_id")])],
        )
        eic_plots.append(eic)

    # add as

    layout = hv.Layout(eic_plots).cols(4)
    if link_x:
        layout = layout.opts(shared_axes=True)

    if filename is not None:
        if filename.endswith(".html"):
            panel.panel(layout).save(filename, embed=True)
        else:
            hv.save(layout, filename, fmt="png")
    else:
        # Check if we're in a notebook environment and display appropriately
        layout_obj = panel.panel(layout)
        return _display_plot(layout, layout_obj)


def plot_ms2_cycle(
    self,
    cycle=None,
    filename=None,
    title=None,
    cmap=None,
    raster_dynamic=True,
    raster_max_px=8,
    raster_threshold=0.8,
    centroid=True,
    deisotope=True,
):
    if self.file_obj is None:
        print("Please load a mzML file first.")
        return None

    if cycle is None:
        print("Please provide a cycle number.")
        return None

    if cycle not in self.scans_df["cycle"].unique():
        print("Cycle number not found in scans_df.")
        return None

    # Process colormap using the cmap package
    cmap_palette = _process_cmap(cmap, fallback="iridescent_r", logger=self.logger)

    # find all scans in cycle
    scans = self.scans_df.filter(pl.col("cycle") == cycle)
    scans = scans.filter(pl.col("ms_level") == 2)

    ms2data = []
    # iterate through all rows
    for scan in scans.iter_rows(named=True):
        scan_id = scan["scan_id"]
        # get spectrum
        spec = self.get_spectrum(
            scan_id,
            precursor_trim=None,
            centroid=centroid,
            deisotope=deisotope,
        )
        if spec.mz.size == 0:
            continue
        d = {
            "prec_mz": [scan["prec_mz"]] * spec.mz.size,
            "mz": spec.mz,
            "inty": spec.inty,
        }
        ms2data.append(d)

    # convert to pandas DataFrame
    spectradf = pd.DataFrame(ms2data)

    # remove any inty<1
    spectradf = spectradf[spectradf["inty"] >= 1]
    # keep only rt, mz, and inty
    spectradf = spectradf[["prec_mz", "mz", "inty"]]
    maxrt = spectradf["prec_mz"].max()
    minrt = spectradf["prec_mz"].min()
    maxmz = spectradf["mz"].max()
    minmz = spectradf["mz"].min()

    def new_bounds_hook(plot, elem):  # elem required by hook interface
        x_range = plot.state.x_range
        y_range = plot.state.y_range
        x_range.bounds = minrt, maxrt
        y_range.bounds = minmz, maxmz

    # Add log-transformed intensity for coloring if raster_log is True
    if raster_log:
        spectradf = spectradf.with_columns(pl.col("inty").log().alias("inty_log"))
        color_column = "inty_log"
    else:
        color_column = "inty"

    points = hv.Points(
        spectradf,
        kdims=["prec_mz", "mz"],
        vdims=["inty", color_column] if raster_log else ["inty"],
        label="MS1 survey scans",
    ).opts(
        fontsize={"title": 16, "labels": 14, "xticks": 6, "yticks": 12},
        color=_holoviews_dim(color_column),
        colorbar=True,
        cmap="Magma",
        tools=["hover"],
    )

    raster = hd.rasterize(
        points,
        aggregator=ds.max("inty"),
        interpolation="bilinear",
        dynamic=raster_dynamic,  # alpha=10,                min_alpha=0,
    ).opts(
        active_tools=["box_zoom"],
        cmap=cmap_palette,
        tools=["hover"],
        hooks=[new_bounds_hook],
        width=1000,
        height=1000,
        cnorm="log",
        xlabel="Q1 m/z",
        ylabel="m/z",
        colorbar=True,
        colorbar_position="right",
        axiswise=True,
    )

    overlay = hd.dynspread(
        raster,
        threshold=raster_threshold,
        how="add",
        shape="square",
        max_px=raster_max_px,
    )

    if title is not None:
        overlay = overlay.opts(title=title)

    # Create a panel layout
    layout = panel.Column(overlay)

    if filename is not None:
        # if filename includes .html, save the panel layout to an HTML file
        if filename.endswith(".html"):
            layout.save(filename, embed=True)
        else:
            # save the panel layout as a png
            hv.save(overlay, filename, fmt="png")
    else:
        # Check if we're in a notebook environment and display appropriately
        return _display_plot(overlay, layout)


def plot_ms2_q1(
    self,
    feature_id=None,
    q1_width=10.0,
    mz_tol=0.01,
    link_x=True,
    n=20,
    deisotope=True,
    centroid=True,
    use_cache=True,
    filename=None,
    **kwargs,
):
    """Plot Q1 vs product ion heatmap for a feature's MS2 spectra.

    Creates a 2D heatmap showing precursor m/z (Q1) on x-axis and fragment m/z
    on y-axis, with intensity as color. Useful for visualizing DIA/SWATH data
    fragmentation patterns across the isolation window.

    Args:
        feature_id (int | None): Feature identifier to plot. Required.
        q1_width (float): Number of scans before/after feature scan to include
            in Q1 dimension. Defaults to 10.0.
        mz_tol (float): m/z tolerance in Da for matching fragment peaks across
            scans. Defaults to 0.01.
        link_x (bool): Link x-axis zoom across plots. Defaults to True.
        n (int): Number of top intensity fragments to display. Defaults to 20.
        deisotope (bool): Remove isotope peaks when use_cache=False. Defaults
            to True.
        centroid (bool): Centroid spectrum when use_cache=False. Defaults to
            True.
        use_cache (bool): Use cached spectrum from feature (ms2_specs[0]) if
            True, otherwise retrieve fresh spectrum with specified parameters.
            Defaults to True.
        filename (str | None): Path to save plot. Supports .html and .png.
            None displays interactively. Defaults to None.
        **kwargs: Additional parameters passed to get_spectrum() when
            use_cache=False. Includes:

            max_peaks (int | None): Maximum peaks to keep. None keeps all.
            precursor_trim (int): m/z window to remove precursor. Negative
                disables. Defaults to -10.
            dia_stats (bool): Collect DIA statistics. Defaults to False.
            feature (int | None): Feature ID for DIA statistics.
            label (str | None): Custom spectrum label.
            centroid_algo (str | None): Centroiding algorithm ('lmp', 'cwt',
                'gaussian'). None uses sample default.
            clean (bool): Remove peaks below baseline noise. Adds "t[CL]" to
                history. Defaults to False.

    Returns:
        holoviews.core.overlay.Overlay | panel.layout.Column | None: Interactive
            plot object (notebook) or panel layout, None if saved to file or
            if feature has no MS2 data.

    Example:
        Basic Q1 plot::

            >>> sample.plot_ms2_q1(feature_id=1186)

        Use fresh spectrum with custom parameters::

            >>> sample.plot_ms2_q1(
            ...     feature_id=1186,
            ...     use_cache=False,
            ...     deisotope=True,
            ...     clean=True,
            ...     max_peaks=500
            ... )

        Wider Q1 window with more fragments::

            >>> sample.plot_ms2_q1(
            ...     feature_id=1186,
            ...     q1_width=20.0,
            ...     n=50
            ... )

        Save to file::

            >>> sample.plot_ms2_q1(
            ...     feature_id=1186,
            ...     filename="q1_heatmap.html"
            ... )

    Note:
        - Cached spectrum (use_cache=True) uses stored ms2_specs[0] with
          original processing parameters from find_ms2()
        - Fresh retrieval (use_cache=False) applies current deisotope, centroid,
          and all **kwargs parameters
        - Q1 dimension spans scan_id  q1_width around feature's cycle
        - Only top n most intense fragments displayed to reduce clutter
        - Interactive plot supports zoom, pan, hover for intensity values

    See Also:
        get_spectrum: Retrieve and process individual spectra.
        plot_ms2_eic: Plot MS2 fragment EICs.
        find_ms2: Link MS2 spectra to features.
    """

    if feature_id is None:
        print("Please provide a feature id.")
        return None
    # check if feature_id is in features_df
    if feature_id not in self.features_df["feature_id"].to_list():
        print("Feature id not found in features_df.")

    feature = self.features_df.filter(self.features_df["feature_id"] == feature_id)

    # Determine which scan to use
    ms2_scans = feature["ms2_scans"][0]
    if ms2_scans is None or len(ms2_scans) == 0:
        print("No MS2 data found for this feature.")
        return None

    # Get the spectrum - either from cache or fresh retrieval
    if use_cache:
        # Use stored spectrum
        ms2_specs = feature["ms2_specs"][0]
        if ms2_specs is None or len(ms2_specs) == 0:
            print("No cached MS2 data found for this feature.")
            return None
        reference_spec = ms2_specs[0]
    else:
        # Retrieve fresh spectrum with user-specified parameters
        scan_id = ms2_scans[0]
        reference_spec = self.get_spectrum(
            scan_id,
            centroid=centroid,
            deisotope=deisotope,
            **kwargs,
        )
        if reference_spec is None or len(reference_spec.mz) == 0:
            print("Failed to retrieve spectrum.")
            return None

    # get the mz of the top n fragments
    ms2_specs_df = reference_spec.pandalize()
    ms2_specs_df = ms2_specs_df.sort_values(by="inty", ascending=False)
    ms2_specs_df = ms2_specs_df.head(n)
    top_mzs = ms2_specs_df["mz"].values.tolist()

    # cycles is the cycle of the feature plus/minus q1_width
    feature_scan = self.select_closest_scan(feature["rt"][0])
    cycle = feature_scan["cycle"][0]
    scans = self.scans_df.filter(pl.col("cycle") == cycle)
    scans = scans.filter(pl.col("ms_level") == 2)
    # find the scan in cycle whose 'prec_mz' is the closest to the feature['mz']
    scan_id = scans[(scans["prec_mz"] - feature["mz"][0]).abs().arg_sort()[:1]][
        "scan_id"
    ][0]
    # get q1_width scans before and after the scan_id
    scans = self.scans_df.filter(pl.col("scan_id") >= scan_id - q1_width)
    scans = scans.filter(pl.col("scan_id") <= scan_id + q1_width)
    scan_ids = scans["scan_id"].to_list()
    q1s = scans["prec_mz"].to_list()

    q1_prod = self._spec_to_mat(
        scan_ids=scan_ids,
        mz_ref=top_mzs,
        mz_tol=mz_tol,
        deisotope=deisotope,
        centroid=centroid,
        **kwargs,
    )
    q1_df = pd.DataFrame({"q1": q1s})

    frag_names = []
    for i, mz in enumerate(top_mzs):
        # add column to q1_df
        name = f"frag {mz:.3f}"
        # if q1_ratio exists, add it to the name
        if "q1_ratio" in ms2_specs_df.columns:
            q1_ratio = ms2_specs_df["q1_ratio"].values[i]
            name += f" q1r: {q1_ratio:.2f}"
        frag_names.append(name)
        q1_df[name] = q1_prod[i]
    # add scan_id to q1_df for the tooltips
    q1_df["scan_id"] = scan_ids

    # create a plot for all columns in eic_df
    eic_plots: list[hv.Curve] = []
    for name in frag_names:
        eic = hv.Curve(q1_df, kdims=["q1"], vdims=[name, "scan_id"]).opts(
            title=name,
            xlabel="Q1 (m/z)",
            ylabel=f"Inty_f{len(eic_plots)}",
            width=250,
            height=200,
            axiswise=True,
            color="black",
            tools=[HoverTool(tooltips=[("Q1", "@q1"), ("scan_id", "@scan_id")])],
        )
        eic_plots.append(eic)

    # add as

    layout = hv.Layout(eic_plots).cols(4)
    if link_x:
        layout = layout.opts(shared_axes=True)

    if filename is not None:
        if filename.endswith(".html"):
            panel.panel(layout).save(filename, embed=True)
        else:
            hv.save(layout, filename, fmt="png")
    else:
        # Check if we're in a notebook environment and display appropriately
        layout_obj = panel.panel(layout)
        return _display_plot(layout, layout_obj)


def plot_dda_stats(
    self,
    filename=None,
):
    """
    Generates scatter plots for DDA statistics.
    This method retrieves statistical data using the `get_dda_stats` method, filters relevant
    columns, and preprocesses the data by replacing any values below 0 with None. It then creates
    a scatter plot for each metric specified in the `cols_to_plot` list. Each scatter plot uses "cycle"
    as the x-axis, and the corresponding metric as the y-axis. In addition, common hover tooltips are
    configured to display auxiliary data including "index", "cycle", "rt", and all other metric values.
    If the `filename` parameter is provided:
        - If it ends with ".html", the layout is saved as an interactive HTML file using Panel.
        - Otherwise, the layout is saved as a PNG image using HoloViews.
    If no filename is provided, the interactive panel is displayed.
    Parameters:
        filename (str, optional): The path and filename where the plot should be saved. If the filename
            ends with ".html", the plot is saved as an HTML file; otherwise, it is saved as a PNG image.
            If not provided, the plot is displayed interactively.
    Notes:
        - The method requires the holoviews, panel, and bokeh libraries for visualization.
        - The data is expected to include the columns 'index', 'cycle', 'rt', and the metrics listed in
            `cols_to_plot`.
    """
    # Initialize holoviews extension
    # Ensure bokeh backend is loaded for holoviews plotting
    if "bokeh" not in hv.Store.loaded_backends():
        hv.extension("bokeh")

    stats = self.get_dda_stats()
    cols_to_plot = [
        "inty_tot",
        "bl",
        "ms2_n",
        "time_cycle",
        "time_ms1_to_ms1",
        "time_ms1_to_ms2",
        "time_ms2_to_ms2",
        "time_ms2_to_ms1",
    ]
    # skip cols that are not in stats
    cols_to_plot = [col for col in cols_to_plot if col in stats.columns]
    stats = stats[["scan_id", "cycle", "rt", *cols_to_plot]]
    # set any value < 0 to None
    # Replace negative values with nulls in a polars-friendly way
    numeric_types = {
        pl.Float32,
        pl.Float64,
        pl.Int8,
        pl.Int16,
        pl.Int32,
        pl.Int64,
        pl.UInt8,
        pl.UInt16,
        pl.UInt32,
        pl.UInt64,
    }
    exprs = []
    for col_name, dtype in stats.schema.items():
        if dtype in numeric_types:
            exprs.append(
                pl.when(pl.col(col_name) < 0)
                .then(None)
                .otherwise(pl.col(col_name))
                .alias(col_name),
            )
        else:
            exprs.append(pl.col(col_name))
    stats = stats.select(exprs)

    # Convert to pandas for holoviews compatibility
    stats = stats.to_pandas()

    # Create a Scatter for each column in cols_to_plot stacked vertically, with hover enabled
    scatter_plots = []
    # Define common hover tooltips for all plots including all cols_to_plot
    common_tooltips = [
        ("scan_id", "@scan_id"),
        ("cycle", "@cycle"),
        ("rt", "@rt"),
    ] + [(c, f"@{c}") for c in cols_to_plot]
    for col in cols_to_plot:
        hover = HoverTool(tooltips=common_tooltips)
        scatter = hv.Scatter(
            stats,
            kdims="cycle",
            vdims=[col, "scan_id", "rt"] + [c for c in cols_to_plot if c != col],
        ).opts(
            title=col,
            xlabel="Cycle",
            ylabel=col,
            height=250,
            width=800,
            tools=[hover],
            size=3,
        )
        scatter_plots.append(scatter)

    layout = hv.Layout(scatter_plots).cols(1)
    if filename is not None:
        if filename.endswith(".html"):
            panel.panel(layout).save(filename, embed=True)
        else:
            hv.save(layout, filename, fmt="png")
    else:
        # Check if we're in a notebook environment and display appropriately
        layout_obj = panel.panel(layout)
        return _display_plot(layout, layout_obj)


def plot_features_stats(
    self,
    filename=None,
):
    """
    Generates vertically stacked density plots for selected feature metrics.
    The distributions are created separately for features with and without MS2 data.
    Metrics include mz, rt, log10(inty), chrom_coherence, chrom_prominence, and chrom_prominence_scaled.
    The plots help to visualize the distribution differences between features that are linked to MS2 spectra and those that are not.

    Parameters:
        filename (str, optional): The output filename. If the filename ends with ".html",
                                    the plot is saved as an interactive HTML file; otherwise,
                                    if provided, the plot is saved as a PNG image. If not provided,
                                    the interactive plot is displayed.

    Returns:
        None
    """
    # Initialize holoviews extension
    # Ensure bokeh backend is loaded for holoviews plotting
    if "bokeh" not in hv.Store.loaded_backends():
        hv.extension("bokeh")

    # Work on a copy of features_df
    feats = self.features_df.clone()
    # Convert to pandas for operations that require pandas functionality
    if hasattr(feats, "to_pandas"):
        feats = feats.to_pandas()

    # Apply log10 transformation to intensity (handling non-positive values)
    feats["inty"] = np.where(feats["inty"] <= 0, np.nan, np.log10(feats["inty"]))

    # Apply log10 transformation to quality (handling non-positive values)
    feats["quality"] = np.where(
        feats["quality"] <= 0,
        np.nan,
        np.log10(feats["quality"]),
    )

    # Separate features based on presence of MS2 data
    feats_with_MS2 = feats[feats["ms2_scans"].notnull()]
    feats_without_MS2 = feats[feats["ms2_scans"].isnull()]

    # Define the specific metrics to plot
    cols_to_plot = [
        "mz",
        "rt",
        "inty",  # Already log10 transformed above
        "rt_delta",
        "quality",  # Already log10 transformed above
        "chrom_coherence",
        "chrom_prominence",
        "chrom_prominence_scaled",
        "chrom_height_scaled",
    ]

    # Ensure an index column is available for plotting
    feats["index"] = feats.index

    density_plots = []
    # Create overlaid distribution plots for each metric
    for col in cols_to_plot:
        # Extract non-null values from both groups
        data_with = feats_with_MS2[col].dropna().values
        data_without = feats_without_MS2[col].dropna().values

        # Create distribution elements - Green for WITH MS2, Red for WITHOUT MS2
        dist_with = hv.Distribution(data_with, label="With MS2").opts(
            fill_color="green",
            fill_alpha=0.1,
            line_color="green",
            line_width=3,
            line_alpha=1.0,
            muted_alpha=0.0,
        )
        dist_without = hv.Distribution(data_without, label="Without MS2").opts(
            fill_color="red",
            fill_alpha=0.1,
            line_color="red",
            line_width=3,
            line_alpha=1.0,
            muted_alpha=0.0,
        )

        # Overlay the distributions with a legend and hover tool enabled
        title = col
        xlabel = col
        if col == "inty":
            title = "log10(inty)"
            xlabel = "log10(inty)"
        elif col == "quality":
            title = "log10(quality)"
            xlabel = "log10(quality)"

        overlay = (dist_with * dist_without).opts(
            title=title,
            xlabel=xlabel,
            show_legend=True,
            tools=["hover"],
            legend_position="right",
            legend_offset=(10, 0),
            width=800,
            height=250,
        )
        density_plots.append(overlay)

    # Arrange the plots in a vertical layout (1 column)
    layout = hv.Layout(density_plots).cols(1).opts(shared_axes=False)

    # Use consistent save/display behavior
    if filename is not None:
        self._handle_sample_plot_output(layout, filename, "holoviews")
    else:
        # Return the layout directly for notebook display, wrapped in panel for alignment
        return panel.Column(layout, align="start")


def plot_comparison(
    self,
    reference=None,
    mz_tol=0.005,
    rt_tol=10,
    filename=None,
):
    """
    Compare features between this sample and a reference sample.

    Creates overlaid density distribution plots showing features specific to this sample,
    common features between both samples, and features specific to the reference sample.
    Similar to plot_features_stats, but with three categories for comparison.

    Parameters:
        reference (Sample): Reference sample to compare against. Required.
        mz_tol (float): m/z tolerance for matching features (default: 0.005 Da)
        rt_tol (float): Retention time tolerance for matching features (default: 10 seconds)
        filename (str, optional): Output filename. If ends with ".html", saves as interactive HTML;
                                 otherwise saves as PNG. If None, displays interactively.

    Returns:
        None or layout object for notebook display
    """
    # Initialize holoviews extension
    # Ensure bokeh backend is loaded for holoviews plotting
    if "bokeh" not in hv.Store.loaded_backends():
        hv.extension("bokeh")

    if reference is None:
        self.logger.error("Reference sample is required for comparison")
        return None

    if self.features_df is None or len(self.features_df) == 0:
        self.logger.error("No features found in current sample")
        return None

    if reference.features_df is None or len(reference.features_df) == 0:
        self.logger.error("No features found in reference sample")
        return None

    # Work on copies
    feats_self = self.features_df.clone()
    feats_ref = reference.features_df.clone()

    # Convert to pandas for easier manipulation
    if hasattr(feats_self, "to_pandas"):
        feats_self = feats_self.to_pandas()
    if hasattr(feats_ref, "to_pandas"):
        feats_ref = feats_ref.to_pandas()

    self.logger.info(
        f"Comparing {len(feats_self)} features from sample vs {len(feats_ref)} features from reference",
    )

    # Find common and unique features
    # Mark each feature in self as "unique_self", "common", or neither
    feats_self["comparison_status"] = "unique_self"
    feats_ref["comparison_status"] = "unique_ref"

    # For each feature in self, check if it matches any in reference
    common_self_indices = []
    common_ref_indices = []

    for idx_self, row_self in feats_self.iterrows():
        mz_self = row_self["mz"]
        rt_self = row_self["rt"]

        # Find matching features in reference
        matches = feats_ref[
            (abs(feats_ref["mz"] - mz_self) <= mz_tol)
            & (abs(feats_ref["rt"] - rt_self) <= rt_tol)
        ]

        if len(matches) > 0:
            common_self_indices.append(idx_self)
            common_ref_indices.extend(matches.index.tolist())

    # Mark common features
    feats_self.loc[common_self_indices, "comparison_status"] = "common"
    feats_ref.loc[common_ref_indices, "comparison_status"] = "common"

    # Get feature counts
    unique_self = feats_self[feats_self["comparison_status"] == "unique_self"]
    common = feats_self[feats_self["comparison_status"] == "common"]
    unique_ref = feats_ref[feats_ref["comparison_status"] == "unique_ref"]

    self.logger.debug(
        f"Found {len(unique_self)} unique to sample, {len(common)} common, {len(unique_ref)} unique to reference",
    )

    # Apply log10 transformation to intensity
    feats_self["inty"] = np.where(
        feats_self["inty"] <= 0,
        np.nan,
        np.log10(feats_self["inty"]),
    )
    feats_ref["inty"] = np.where(
        feats_ref["inty"] <= 0,
        np.nan,
        np.log10(feats_ref["inty"]),
    )

    # Apply log10 transformation to quality
    feats_self["quality"] = np.where(
        feats_self["quality"] <= 0,
        np.nan,
        np.log10(feats_self["quality"]),
    )
    feats_ref["quality"] = np.where(
        feats_ref["quality"] <= 0,
        np.nan,
        np.log10(feats_ref["quality"]),
    )

    # Separate features by comparison status
    unique_self = feats_self[feats_self["comparison_status"] == "unique_self"]
    common_self = feats_self[feats_self["comparison_status"] == "common"]
    unique_ref = feats_ref[feats_ref["comparison_status"] == "unique_ref"]

    # Define metrics to plot
    cols_to_plot = [
        "mz",
        "rt",
        "inty",  # Already log10 transformed
        "rt_delta",
        "quality",  # Already log10 transformed
        "chrom_coherence",
        "chrom_prominence",
        "chrom_prominence_scaled",
        "chrom_height_scaled",
    ]

    density_plots = []

    # Create overlaid distribution plots for each metric
    for col in cols_to_plot:
        # Extract non-null values from each group
        data_unique_self = (
            unique_self[col].dropna().values if len(unique_self) > 0 else np.array([])
        )
        data_common = (
            common_self[col].dropna().values if len(common_self) > 0 else np.array([])
        )
        data_unique_ref = (
            unique_ref[col].dropna().values if len(unique_ref) > 0 else np.array([])
        )

        # Create distribution elements with different colors
        # Blue for unique to self
        # Green for common
        # Red for unique to reference
        overlays = []

        if len(data_unique_self) > 0:
            dist_unique_self = hv.Distribution(
                data_unique_self,
                label=f"Unique to sample (n={len(data_unique_self)})",
            ).opts(
                fill_color="blue",
                fill_alpha=0.1,
                line_color="blue",
                line_width=2,
                line_alpha=1.0,
                muted_alpha=0.0,
            )
            overlays.append(dist_unique_self)

        if len(data_common) > 0:
            dist_common = hv.Distribution(
                data_common,
                label=f"Common (n={len(data_common)})",
            ).opts(
                fill_color="green",
                fill_alpha=0.1,
                line_color="green",
                line_width=2,
                line_alpha=1.0,
                muted_alpha=0.0,
            )
            overlays.append(dist_common)

        if len(data_unique_ref) > 0:
            dist_unique_ref = hv.Distribution(
                data_unique_ref,
                label=f"Unique to reference (n={len(data_unique_ref)})",
            ).opts(
                fill_color="red",
                fill_alpha=0.1,
                line_color="red",
                line_width=2,
                line_alpha=1.0,
                muted_alpha=0.0,
            )
            overlays.append(dist_unique_ref)

        # Build title and xlabel
        title = col
        xlabel = col
        if col == "inty":
            title = "log10(inty)"
            xlabel = "log10(inty)"
        elif col == "quality":
            title = "log10(quality)"
            xlabel = "log10(quality)"

        # Overlay all distributions
        if overlays:
            overlay = overlays[0]
            for dist in overlays[1:]:
                overlay = overlay * dist

            overlay = overlay.opts(
                title=title,
                xlabel=xlabel,
                show_legend=True,
                tools=["hover"],
                legend_position="right",
                legend_offset=(10, 0),
                width=800,
                height=250,
            )
            density_plots.append(overlay)

    # Arrange plots in a vertical layout (1 column)
    layout = hv.Layout(density_plots).cols(1).opts(shared_axes=False)

    # Use consistent save/display behavior
    if filename is not None:
        self._handle_sample_plot_output(layout, filename, "holoviews")
    else:
        # Return the layout directly for notebook display, wrapped in panel for alignment
        return panel.Column(layout, align="start")


def plot_tic(
    self,
    title=None,
    filename=None,
):
    """
    Plot Total Ion Chromatogram (TIC) by summing MS1 peak intensities at each retention time.

    Uses `self.ms1_df` (Polars DataFrame) and aggregates intensities by `rt` (sum).
    Creates a `Chromatogram` object and uses its `plot()` method to display the result.
    """
    if self.ms1_df is None:
        self.logger.error("No MS1 data available.")
        return

    # Import helper locally to avoid circular imports
    from masster.study.helpers import get_tic

    # Delegate TIC computation to study helper which handles ms1_df and scans_df fallbacks
    try:
        chrom = get_tic(self, label=title)
    except Exception as e:
        self.logger.exception("Failed to compute TIC via helper: %s", e)
        return

    # Create bokeh figure from chromatogram
    from bokeh.models import ColumnDataSource, HoverTool
    import bokeh.plotting as bp

    p = bp.figure(
        title=title or self.label,
        width=1000,
        height=250,
    )
    p.xaxis.axis_label = f"rt ({chrom.rt_unit})"
    p.yaxis.axis_label = "inty"

    # Sort by rt
    sorted_indices = np.argsort(chrom.rt)
    rt_sorted = chrom.rt[sorted_indices]
    inty_sorted = chrom.inty[sorted_indices]

    source = ColumnDataSource(data={"rt": rt_sorted, "inty": inty_sorted})
    line = p.line("rt", "inty", source=source)

    # Add hover tool
    hover = HoverTool(
        tooltips=[
            ("rt", "@rt"),
            ("inty", "@inty"),
        ],
        renderers=[line],
    )
    p.add_tools(hover)

    if filename is not None:
        # Use the standard plot output handler
        _handle_sample_plot_output(self, p, filename=filename, plot_type="bokeh")
        return

    # No filename: display interactively
    bp.show(p)
    return


def plot_bpc(
    self,
    title=None,
    filename=None,
    rt_unit="s",
):
    """
    Plot Base Peak Chromatogram (BPC) using MS1 data.

    Aggregates MS1 points by retention time and selects the maximum intensity (base peak)
    at each time point. Uses `self.ms1_df` (Polars DataFrame) as the source of MS1 peaks.

    Parameters:
        title (str, optional): Plot title.
        filename (str, optional): If provided and ends with `.html` saves an interactive html,
            otherwise saves a png. If None, returns a displayable object for notebooks.
        rt_unit (str, optional): Unit label for the x-axis, default 's' (seconds).

    Returns:
        None or notebook display object (via _display_plot)
    """
    if self.ms1_df is None:
        self.logger.error("No MS1 data available.")
        return

    # Import helper locally to avoid circular imports
    from masster.study.helpers import get_bpc

    # Delegate BPC computation to study helper
    try:
        chrom = get_bpc(self, rt_unit=rt_unit, label=title)
    except Exception as e:
        self.logger.exception("Failed to compute BPC via helper: %s", e)
        return

    # Create bokeh figure from chromatogram
    from bokeh.models import ColumnDataSource, HoverTool
    import bokeh.plotting as bp

    p = bp.figure(
        title=title or self.label,
        width=1000,
        height=250,
    )
    p.xaxis.axis_label = f"rt ({chrom.rt_unit})"
    p.yaxis.axis_label = "inty"

    # Sort by rt
    sorted_indices = np.argsort(chrom.rt)
    rt_sorted = chrom.rt[sorted_indices]
    inty_sorted = chrom.inty[sorted_indices]

    source = ColumnDataSource(data={"rt": rt_sorted, "inty": inty_sorted})
    line = p.line("rt", "inty", source=source)

    # Add hover tool
    hover = HoverTool(
        tooltips=[
            ("rt", "@rt"),
            ("inty", "@inty"),
        ],
        renderers=[line],
    )
    p.add_tools(hover)

    if filename is not None:
        # Use the standard plot output handler
        _handle_sample_plot_output(self, p, filename=filename, plot_type="bokeh")
        return

    # No filename: display interactively
    bp.show(p)
    return


def plot_ms2(
    self,
    feature_id=None,
    width=800,
    height=200,
    normalize=False,
    logy=False,
    show_title=True,
    use_cache=False,
    centroid=True,
    centroid_algo=None,
    deisotope=True,
    max_peaks=None,
    precursor_trim=5,
    dia_stats=False,
    label=None,
    clean=False,
):
    """
    Plot MS2 spectra for selected features in a stacked form.

    Parameters:
        feature_id: Feature selection using same format as features_select():
            - None: all features with MS2 spectra
            - int: single feature ID
            - list: list of feature IDs
            - tuple: range of feature IDs (min, max)
            - DataFrame: with feature_id column
        width: Plot width in pixels (default: 800)
        height: Height per spectrum in pixels (default: 200)
        normalize: Normalize each spectrum to 100% (default: False)
        logy: Use log10 scale for y-axis (default: False)
        show_title: Show title with feature information (default: True)
        use_cache: Use cached MS2 spectra from features_df (default: False).
            If True, retrieves spectra from ms2_specs column (as in get_ms2_stats).
            If False, calls get_spectrum() with specified parameters.
        centroid: Centroid the spectrum (default: True). Only used if use_cache=False.
        centroid_algo: Centroiding algorithm ('lmp', 'cwt', 'gaussian', None) (default: None).
            Only used if use_cache=False.
        deisotope: Remove isotope peaks (default: True). Only used if use_cache=False.
        max_peaks: Maximum peaks to keep (default: None). Only used if use_cache=False.
        precursor_trim: m/z window to remove precursor from MS2 (default: 5).
            Only used if use_cache=False.
        dia_stats: Collect DIA/ztscan statistics (default: False). Only used if use_cache=False.
        label: Custom label for spectrum (default: None). Only used if use_cache=False.
        clean: Remove peaks below noise threshold (default: False). Only used if use_cache=False.

    Returns:
        holoviews Layout object with stacked spectra

    Examples:
        Plot with cached spectra::

            >>> sample.plot_ms2(feature_id=42, use_cache=True)

        Plot with custom spectrum processing::

            >>> sample.plot_ms2(
            ...     feature_id=[10, 20, 30],
            ...     use_cache=False,
            ...     deisotope=False,
            ...     clean=True,
            ...     max_peaks=50
            ... )

        Plot all features with DIA statistics::

            >>> sample.plot_ms2(dia_stats=True, normalize=True)
    """
    from bokeh.models import HoverTool
    import holoviews as hv
    import pandas as pd

    # Get feature IDs using the helper method
    feature_ids = self._get_feature_ids(features=feature_id, verbose=False)

    if not feature_ids:
        self.logger.warning("No features selected.")
        return None

    # Filter features_df for selected IDs with non-null ms2_specs
    if self.features_df is None:
        self.logger.warning("No features_df found.")
        return None

    feats = self.features_df.filter(
        pl.col("feature_id").is_in(feature_ids) & pl.col("ms2_specs").is_not_null(),
    )

    if feats.is_empty():
        self.logger.warning("No features with MS2 spectra found.")
        return None

    self.logger.debug(f"Found {len(feats)} features with MS2 spectra to plot.")

    # Convert to list of dicts using Polars to preserve Spectrum objects
    feats_list = feats.to_dicts()
    self.logger.debug(f"Processing {len(feats_list)} features...")

    plots = []
    for idx, row in enumerate(feats_list):
        feature_id_val = row["feature_id"]
        feature_id_val = row.get("feature_id", feature_id_val)
        mz = row["mz"]
        rt = row["rt"]

        self.logger.debug(
            f"Processing feature {idx + 1}/{len(feats_list)}: ID={feature_id_val}",
        )

        # Get MS2 spectrum based on use_cache setting
        if use_cache:
            # Use cached spectrum from ms2_specs column (as in get_ms2_stats)
            ms2_specs = row["ms2_specs"]
            if ms2_specs is None or (
                isinstance(ms2_specs, list) and len(ms2_specs) == 0
            ):
                self.logger.warning(
                    f"Feature {feature_id_val} has null or empty ms2_specs, skipping.",
                )
                continue

            # Use first spectrum if multiple are available
            spectrum = ms2_specs[0] if isinstance(ms2_specs, list) else ms2_specs
        else:
            # Get fresh spectrum using get_spectrum with specified parameters
            ms2_scans = row.get("ms2_scans")
            if ms2_scans is None or (
                isinstance(ms2_scans, list) and len(ms2_scans) == 0
            ):
                self.logger.warning(
                    f"Feature {feature_id_val} has no ms2_scans, skipping.",
                )
                continue

            # Take first scan
            scan_id = ms2_scans[0] if isinstance(ms2_scans, list) else ms2_scans

            # Call get_spectrum with user-specified parameters
            spectrum = self.get_spectrum(
                scan_id=scan_id,
                centroid=centroid,
                centroid_algo=centroid_algo,
                deisotope=deisotope,
                max_peaks=max_peaks,
                precursor_trim=precursor_trim,
                dia_stats=dia_stats,
                feature_id=feature_id_val if dia_stats else None,
                label=label,
                clean=clean,
            )

            if spectrum is None:
                self.logger.warning(
                    f"Feature {feature_id_val} get_spectrum returned None, skipping.",
                )
                continue

        # Get energy from spectrum
        energy = getattr(spectrum, "energy", "N/A")

        # Build title
        title = f"MS2 spectrum for m/z {mz:.4f}, rt {rt:.2f}, e {energy}, id {feature_id_val}"

        # Extract m/z and intensity
        if not (hasattr(spectrum, "mz") and hasattr(spectrum, "inty")):
            self.logger.warning(
                f"Feature {feature_id_val} spectrum missing mz or inty attributes, skipping.",
            )
            continue

        spec_mz = np.array(spectrum.mz)
        spec_inty = np.array(spectrum.inty)

        if len(spec_mz) == 0:
            self.logger.info(f"Feature {feature_id_val} has empty spectrum, skipping.")
            continue

        self.logger.debug(
            f"Feature {feature_id_val}: spectrum has {len(spec_mz)} peaks",
        )

        # Normalize if requested
        if normalize and spec_inty.max() > 0:
            spec_inty = (spec_inty / spec_inty.max()) * 100

        # Apply log10 if requested
        if logy:
            # Add small epsilon to avoid log(0)
            spec_inty = np.log10(spec_inty + 1)

        # Create DataFrame for proper hover tooltips with all available data
        n_peaks = len(spec_mz)
        spec_data = {
            "mz": spec_mz,
            "intensity": spec_inty,
            "nl": mz - spec_mz,  # Neutral loss
        }

        # Add optional attributes if they exist in the spectrum
        if (
            hasattr(spectrum, "top")
            and spectrum.top is not None
            and len(spectrum.top) == n_peaks
        ):
            spec_data["top"] = np.array(spectrum.top)

        if (
            hasattr(spectrum, "prominence")
            and spectrum.prominence is not None
            and len(spectrum.prominence) == n_peaks
        ):
            spec_data["prominence"] = np.array(spectrum.prominence)

        if (
            hasattr(spectrum, "monoiso")
            and spectrum.monoiso is not None
            and len(spectrum.monoiso) == n_peaks
        ):
            spec_data["monoiso"] = np.array(spectrum.monoiso)

        # Note: spectrum.clean is a method, not an attribute, so check if it's callable
        if (
            hasattr(spectrum, "clean_flag")
            and spectrum.clean_flag is not None
            and len(spectrum.clean_flag) == n_peaks
        ):
            spec_data["clean"] = np.array(spectrum.clean_flag)

        if (
            hasattr(spectrum, "eic_corr")
            and spectrum.eic_corr is not None
            and not callable(spectrum.eic_corr)
            and len(spectrum.eic_corr) == n_peaks
        ):
            spec_data["eic_corr"] = np.array(spectrum.eic_corr)

        if (
            hasattr(spectrum, "q1_ratio")
            and spectrum.q1_ratio is not None
            and not callable(spectrum.q1_ratio)
            and len(spectrum.q1_ratio) == n_peaks
        ):
            spec_data["q1_ratio"] = np.array(spectrum.q1_ratio)

        spec_data_df = pd.DataFrame(spec_data)

        # Build tooltip list dynamically based on available columns
        tooltips = [
            ("m/z", "@mz{0.0000}"),
            ("Neutral Loss", "@nl{0.0000}"),
            ("Intensity", "@intensity{0.0f}"),
        ]

        if "top" in spec_data_df.columns:
            tooltips.append(("Rank", "@top"))
        if "prominence" in spec_data_df.columns:
            tooltips.append(("Prominence", "@prominence{0.0f}"))
        if "eic_corr" in spec_data_df.columns:
            tooltips.append(("EIC Corr", "@eic_corr{0.000}"))
        if "q1_ratio" in spec_data_df.columns:
            tooltips.append(("Q1 Ratio", "@q1_ratio{0.000}"))

        # Create stem plot with thin vertical lines
        plot_opts = {
            "width": width,
            "height": height,
            "color": "steelblue",
            "line_width": 1,
            "xlabel": "m/z",
            "ylabel": "Intensity (%)"
            if normalize
            else ("log10(Intensity)" if logy else "Intensity"),
            "title": title if show_title else "",
            "show_grid": True,
            "toolbar": "above",
            "default_tools": ["pan", "wheel_zoom", "box_zoom", "reset"],
            "tools": [HoverTool(tooltips=tooltips)],
        }

        # Only add ylim if normalizing
        if normalize:
            plot_opts["ylim"] = (0, 105)

        # Determine which columns to use for visualization
        vdims = ["intensity", "nl"]
        if "top" in spec_data_df.columns:
            vdims.append("top")
        if "prominence" in spec_data_df.columns:
            vdims.append("prominence")
        if "monoiso" in spec_data_df.columns:
            vdims.append("monoiso")
        if "clean" in spec_data_df.columns:
            vdims.append("clean")
        if "eic_corr" in spec_data_df.columns:
            vdims.append("eic_corr")
        if "q1_ratio" in spec_data_df.columns:
            vdims.append("q1_ratio")

        # Create thin vertical lines (stems) with hover tooltips
        stems = hv.Spikes(spec_data_df, kdims=["mz"], vdims=vdims).opts(
            **plot_opts,
        )

        # Create scatter points at the top of each stem (no hover)
        scatter_opts = {
            "width": width,
            "height": height,
            "size": 5,
            "color": "steelblue",
            "marker": "o",
            "line_width": 0,
            "fill_alpha": 1.0,
            "tools": [],  # No tools for scatter points
        }
        if normalize:
            scatter_opts["ylim"] = (0, 105)

        points = hv.Scatter(spec_data_df, kdims=["mz"], vdims=vdims).opts(
            **scatter_opts,
        )

        # Combine stems and points
        combined = stems * points

        self.logger.debug(f"Created plot for feature {feature_id_val}")
        plots.append(combined)

    if not plots:
        self.logger.warning("No spectra could be plotted.")
        return None

    self.logger.debug(f"Created {len(plots)} spectrum plots.")

    # Stack plots vertically
    if len(plots) == 1:
        return plots[0]
    layout = plots[0]
    for plot in plots[1:]:
        layout = layout + plot
    layout = layout.cols(1)
    # Unlink y-axis if not normalizing
    if not normalize:
        layout = layout.opts(shared_axes=False)
    return layout
